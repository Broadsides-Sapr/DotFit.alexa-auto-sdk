{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview of the Alexa Auto SDK The Alexa Auto SDK contains essential client-side software required to integrate Alexa into the automobile. The Auto SDK provides libraries that connect to Alexa and expose interfaces for your vehicle software to implement the platform-specific behavior for audio input, media streaming, calling through a connected phone, turn-by-turn navigation, controlling vehicle features such as heaters and lights, and more. You can use the included sample application to learn about the Auto SDK interfaces and to test interactions before integration. The contents of this repository are distributed under several different license agreements. Please refer to the LICENSE file for the license terms applicable to the materials that you are using. Table of Contents Auto SDK Architecture Getting Started Auto SDK Integration Security Best Practices See Also Auto SDK Architecture The Auto SDK is modular, with a system of components that provide the runtime implementation of the Auto SDK. Each module exposes interfaces to handle specific functionality such as audio input and output, authorization, media streaming, navigation and controlling vehicle features. Most of the modules are included in the Auto SDK. Modules not downloadable with the Auto SDK from GitHub are available as extensions, which you can obtain with help from your Amazon Solutions Architect (SA) or Partner Manager. See here for more information on Auto SDK modules and extensions. Getting Started Prerequisites Complete the following steps before you get started with the Auto SDK: Register for an Amazon Developer Account and create an Alexa device and security profile to use the Auto SDK. Make sure that you meet the requirements for building the Auto SDK and understand the dependencies, as described in the SDK builder README . Build Auto SDK Follow these steps to get started with the Auto SDK: Clone the alexa-auto-sdk repository into your project. If you want to use the optional Auto SDK modules, download the modules from the locations listed below. AmazonLite Wake Word extension Alexa Communications extension Local Voice Control extension Device Client Metrics (DCM) extension Voice Chrome for Android extension The version of the optional extension archive must match the version of the Auto SDK that you are using. For example, if you are using Auto SDK 3.0 and want to install the Local Voice Control extension, you must download version 3.0 of the Local Voice Control extension archive. Note: The Alexa Presentation Language (APL) module is provided publicly, but requires additional packages to be downloaded to successfully build. Build the Auto SDK as described in the builder README . The following section provides the details of integrating with Android and Linux based platforms: Auto SDK Integration Integrating Auto SDK in Android-based platforms The Alexa Auto Client Service (AACS) simplifies the process of integrating the Auto SDK in Android-based devices. AACS is an Alexa Auto SDK feature packaged in a stand alone Android application package (APK) or in an Android archive library (AAR). After you install, configure, and initialize AACS, it communicates with the applications, providing an interface between the applications and various Alexa functions, such as navigation and car control. You can also include AACS as an Android archive (AAR) in the application if you do not want to run AACS as a separate app. Learn more >> Integrating Auto SDK in Linux-based platforms The Alexa Auto Service Bridge (AASB) simplifies the process of integrating the Auto SDK in Linux-based devices. AASB framework provides a Message Broker API that transmits JSON messages between the OEM application and the Auto SDK. This API can be used publish and subscribe to AASB messages to implement the platform-specific functionality of the Auto SDK integration. Learn more >> Security Best Practices All Alexa products are required to follow the Security Best Practices for Alexa . When building an Alexa experience using the Auto SDK, additionally adhere to the following security principles: Protect configuration files for the Auto SDK Engine from tampering and inspection. Protect configuration parameters, such as those found in Auto SDK Engine configuration files, from tampering and inspection, including but not limited to the following: SQLite database files, Unix Domain Sockets, wake word models, and metrics sink files. Protect components used for the Local Voice Control (LVC) extension, including associated LVC language model packages (Linux) and APKs (Android), from tampering and inspection, including but not limited to the following: Unix Domain Sockets, model directories, skill and service executables, prompts and assets JSON files, and all files configuring these components. Your C++ implementation of Auto SDK interfaces must not retain locks, crash, hang, or throw exceptions. Use exploit mitigation flags and memory randomization techniques when you compile your source code to prevent vulnerabilities from exploiting buffer overflows and memory corruptions. See Also The following documents or websites provide more information about the Auto SDK. In-vehicle Alexa experience design guidelines include principles, voice, visual, user interface (UI) patterns, and multimodal best practices. Change Log provides a summary of feature enhancements, updates, and resolved and known issues. AASB message definition provides the reference documentation for AASB messages. You can find AASB message definition for each module here. by navigating to \"Modules\" tab and select a module on the left menu. For example, you can find AASB message definition for Address Book module here. AACS Sample App and C++ Sample App READMEs provide information about the sample apps. This helps you test interactions before integration. Migration Guide describes how to migrate from one Auto SDK version to another.","title":"Home"},{"location":"#overview-of-the-alexa-auto-sdk","text":"The Alexa Auto SDK contains essential client-side software required to integrate Alexa into the automobile. The Auto SDK provides libraries that connect to Alexa and expose interfaces for your vehicle software to implement the platform-specific behavior for audio input, media streaming, calling through a connected phone, turn-by-turn navigation, controlling vehicle features such as heaters and lights, and more. You can use the included sample application to learn about the Auto SDK interfaces and to test interactions before integration. The contents of this repository are distributed under several different license agreements. Please refer to the LICENSE file for the license terms applicable to the materials that you are using.","title":"Overview of the Alexa Auto SDK"},{"location":"#table-of-contents","text":"Auto SDK Architecture Getting Started Auto SDK Integration Security Best Practices See Also","title":"Table of Contents"},{"location":"#auto-sdk-architecture","text":"The Auto SDK is modular, with a system of components that provide the runtime implementation of the Auto SDK. Each module exposes interfaces to handle specific functionality such as audio input and output, authorization, media streaming, navigation and controlling vehicle features. Most of the modules are included in the Auto SDK. Modules not downloadable with the Auto SDK from GitHub are available as extensions, which you can obtain with help from your Amazon Solutions Architect (SA) or Partner Manager. See here for more information on Auto SDK modules and extensions.","title":"Auto SDK Architecture"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#prerequisites","text":"Complete the following steps before you get started with the Auto SDK: Register for an Amazon Developer Account and create an Alexa device and security profile to use the Auto SDK. Make sure that you meet the requirements for building the Auto SDK and understand the dependencies, as described in the SDK builder README .","title":"Prerequisites"},{"location":"#build-auto-sdk","text":"Follow these steps to get started with the Auto SDK: Clone the alexa-auto-sdk repository into your project. If you want to use the optional Auto SDK modules, download the modules from the locations listed below. AmazonLite Wake Word extension Alexa Communications extension Local Voice Control extension Device Client Metrics (DCM) extension Voice Chrome for Android extension The version of the optional extension archive must match the version of the Auto SDK that you are using. For example, if you are using Auto SDK 3.0 and want to install the Local Voice Control extension, you must download version 3.0 of the Local Voice Control extension archive. Note: The Alexa Presentation Language (APL) module is provided publicly, but requires additional packages to be downloaded to successfully build. Build the Auto SDK as described in the builder README . The following section provides the details of integrating with Android and Linux based platforms:","title":"Build Auto SDK"},{"location":"#auto-sdk-integration","text":"","title":"Auto SDK Integration"},{"location":"#integrating-auto-sdk-in-android-based-platforms","text":"The Alexa Auto Client Service (AACS) simplifies the process of integrating the Auto SDK in Android-based devices. AACS is an Alexa Auto SDK feature packaged in a stand alone Android application package (APK) or in an Android archive library (AAR). After you install, configure, and initialize AACS, it communicates with the applications, providing an interface between the applications and various Alexa functions, such as navigation and car control. You can also include AACS as an Android archive (AAR) in the application if you do not want to run AACS as a separate app. Learn more >>","title":"Integrating Auto SDK in Android-based platforms"},{"location":"#integrating-auto-sdk-in-linux-based-platforms","text":"The Alexa Auto Service Bridge (AASB) simplifies the process of integrating the Auto SDK in Linux-based devices. AASB framework provides a Message Broker API that transmits JSON messages between the OEM application and the Auto SDK. This API can be used publish and subscribe to AASB messages to implement the platform-specific functionality of the Auto SDK integration. Learn more >>","title":"Integrating Auto SDK in Linux-based platforms"},{"location":"#security-best-practices","text":"All Alexa products are required to follow the Security Best Practices for Alexa . When building an Alexa experience using the Auto SDK, additionally adhere to the following security principles: Protect configuration files for the Auto SDK Engine from tampering and inspection. Protect configuration parameters, such as those found in Auto SDK Engine configuration files, from tampering and inspection, including but not limited to the following: SQLite database files, Unix Domain Sockets, wake word models, and metrics sink files. Protect components used for the Local Voice Control (LVC) extension, including associated LVC language model packages (Linux) and APKs (Android), from tampering and inspection, including but not limited to the following: Unix Domain Sockets, model directories, skill and service executables, prompts and assets JSON files, and all files configuring these components. Your C++ implementation of Auto SDK interfaces must not retain locks, crash, hang, or throw exceptions. Use exploit mitigation flags and memory randomization techniques when you compile your source code to prevent vulnerabilities from exploiting buffer overflows and memory corruptions.","title":"Security Best Practices"},{"location":"#see-also","text":"The following documents or websites provide more information about the Auto SDK. In-vehicle Alexa experience design guidelines include principles, voice, visual, user interface (UI) patterns, and multimodal best practices. Change Log provides a summary of feature enhancements, updates, and resolved and known issues. AASB message definition provides the reference documentation for AASB messages. You can find AASB message definition for each module here. by navigating to \"Modules\" tab and select a module on the left menu. For example, you can find AASB message definition for Address Book module here. AACS Sample App and C++ Sample App READMEs provide information about the sample apps. This helps you test interactions before integration. Migration Guide describes how to migrate from one Auto SDK version to another.","title":"See Also"},{"location":"BUILDING/","text":"Build Alexa Auto SDK Supported platforms and architectures Auto SDK can be built for the following supported target platforms and hardware architectures: Android 5.1 Lollipop API Level 22 or higher. ARM 64-bit x86 64-bit QNX 7.0 ARM 64-bit x86 64-bit Generic Linux x86 64-bit Poky Linux ARMv7a (+NEON) AArch64 macOS x86 64-bit General build requirements You can build the Alexa Auto SDK natively on a Linux or macOS host, or you can use Docker. For specific information about Docker, see Build in a Docker container . The following list describes the supported host configurations: Operating system: macOS Sierra Ubuntu 18.04 LTS (Bionic) or Ubuntu 20.04 LTS (Focal) Processor: 2.5 GHz Memory: 16 Gb Storage: 1 Gb+ available to use Build dependencies To build Auto SDK, you must install the following dependencies on your host machine: General Python 3.7 Conan 1.33 CMake 3.12 Linux GCC GStreamer (see Install GStreamer ) macOS Xcode Understand the build system Building software for multiple platforms can be complex because specific toolchains might vary depending on the build system and target platform. In general, there are two flavors of builds: native and cross-compiled. In a native build, the build system uses its own toolchain and libraries to build the software, so the compiled software can run on the platform that built it. In cross-compilation, the build system typically uses an installed toolchain to compile the software for a different target platform. It's possible that more than one toolchain is installed on a system, so extra steps are typically needed to cross-compile to those targets. Auto SDK uses Conan , along with other tools and scripts described in this section, to manage the complexities required to implement a complete build system. Conan The Auto SDK build system uses Conan as its underlying package manager and build configuration tool. For every Conan package, there is a recipe that defines the dependencies of the package and specifies how to download and build the package source code. After building a package, Conan copies the binaries and other artifacts into a cache directory so other recipes that depend on that package can use the prebuilt binaries without rebuilding them. When a Conan recipe defines a dependency, Conan finds and builds the dependency as required, taking care of complexities such as transitive requirements, package version conflicts, and managing multiple versions of a package built with different configurations. Before using a package, Conan must export or download the package into the local cache. When a package recipe exists in the same local repository as the source code it builds, as is the case when you download Auto SDK, you must run conan create or conan export before other recipes can build the package. Community servers such as Conan Center host some popular third party libraries, however, so Conan automatically downloads them to the local cache as needed. Auto SDK requires a combination of Conan packages including local recipes for Auto SDK modules and tools, local recipes for third party packages, and third party packages hosted on the Conan Center server. Once Conan copies a package into the local cache, a recipe can build or consume the package based on the specified build configuration. Conan will build a new package version if the package version is required and missing from the cache. For example, if you build Auto SDK for Linux, Conan will build all of the required packages for the specified Linux target. If you then build for an Android target, Conan will rebuild all of the required packages for the Android target and cache both the Linux and Android versions. In addition to target platform, any option or setting that you specify when building a recipe affects the package version. Auto SDK modules Auto SDK includes a base Conan recipe class that all Auto SDK modules extend. This is defined in conan/recipes/aac-sdk-tools , and must be exported before other modules since it is required by each module's recipe definition. The base recipe defines common build options, and relies on specific conventions in the module's directory structure to find source files and headers, and to generate other artifacts that are needed at build time. A simple Conan recipe is required for each module to override abstract values in the base class (such as the module name), and to define any module specific dependencies or options that are required. A module can also define it's own CMake files, unique configuration, or even custom build steps as needed. For each module, the base recipe defines common options that are used to specify which components are included in the library. The default values provided in the base recipe should be used in most cases when you are building release libraries for production. For some cases, however, you may want to enabled features such as with_sensitive_logs or with_unit_tests , to add additional information when debugging issues with the libraries. To find out which options are defined for a specific module, you can use the conan inspect command to display information about any Conan recipe. This command will display all of options and default values for a recipe, including any options that are inherited from the base module recipe. See the Specify build settings and options section in this guide, for more information. Applications integrate with Auto SDK using the MessageBroker API, by publishing and subscribing to specific message topics and actions (see Using the MessageBroker API ). Most modules provide interfaces that require these messages to be defined, in which case they will include one or more message definition files in the aasb/messages directory of the module. The model created by the message definitions are used when building Auto SDK to generate message headers that are required to build the module, and are also used to create documentation for each message interface. Third party dependencies Auto SDK has dependencies on several third party packages (libraries and build tools for example), which may themselves have dependencies on other packages. In general, managing these types of build requirements can be very complex for a large project. Conan helps by providing community hosted recipes for many common packages, as well as by allowing developers to create there own package recipes. It is important to understand that some of the packages used by Auto SDK are pulled from the Conan Center remote server, while others are defined locally in the conan/recipes directory of Auto SDK. Local recipes are typically required when the package does not already exist on Conan Center, or there are specific patches or changes to the recipe that are needed for Auto SDK. Builder Tool The Builder Tool is a script that can be used to build Auto SDK libraries for supported platforms. It improves the build process by wrapping underlying Conan commands and options with a simple command line interface. Although it is possible to use Conan by itself to build Auto SDK - see the Build with Conan directly section of this guide, it is recommended to use the Builder Tool for common build tasks. Alexa Auto Client Service Alexa Auto Client Service (AACS) is an Android service library that simplifies the process of integrating Auto SDK on Android-based devices. AACS has a dependency on Auto SDK native Android libraries, but can be built independently using standard Android development tools. For more information about building AACS, see the Building AACS with AACS Sample App section of the Alexa Auto Client Service guide. Build with Builder Tool The Builder Tool script, build.py is located in the builder directory of the SDK. It wraps underlying Conan commands, and simplifies building libraries for Auto SDK modules on supported platforms. Individual modules, components, and dependencies in the SDK are described as packages in the builder. Each package has a corresponding Conan recipe that is used to build and deploy the package to the cache located in the builder's home directory. An archive containing all of the specified build artifacts is created from the cache, and written to the deploy directory of the builder, after the build has completed. This section descibes the most common commands used to build Auto SDK. For a complete reference to the Builder Tool command line interface, see Builder Tool command reference . Auto SDK currently supports native builds for Ubuntu Linux (x86_64) and MacOS, and building for each platform follows the same steps. After cloning the Auto SDK git repository on your system, the following examples should be run with aac-sdk as the working directory. The following command will build all of the modules that are included in the Auto SDK repository, along with any dependencies that are required for the target platform: $ ./builder/build.py When you run the build command, the builder tool will export and configure any new build artifacts, such as package recipes or configuration files, that are discovered in the search path. The first time you run (or after cleaning the build cache), you'll see several log messages indicating that the build recipes are being exported to the local cache: [ BUILDER ] INFO: Python version: 3 .7.3 [ BUILDER ] INFO: Cleaning cached builder data [ BUILDER ] INFO: Builder home: ../aac-sdk/builder/.builder [ BUILDER ] INFO: Conan home: ../aac-sdk/builder/.builder/.conan [ BUILDER ] INFO: Gradle home: ../aac-sdk/builder/.builder/.gradle [ BUILDER ] INFO: Configuring Conan... [ BUILDER ] INFO: Installing Conan configuration: ../aac-sdk/conan/config [ BUILDER ] INFO: Exporting recipe: aac-sdk-tools [ BUILDER ] INFO: Exporting recipe: aac-module-core [ BUILDER ] INFO: Exporting recipe: aac-module-alexa [ BUILDER ] INFO: Exporting recipe: aac-module-cbl [ BUILDER ] INFO: Exporting recipe: android-sdk-tools [ BUILDER ] INFO: Exporting recipe: avs-device-sdk ... The builder keeps track of which recipes have already been added to the cache, so that the next time you run the build command only new recipes will be exported. It is possible, however, to tell the builder to force re-exporting a recipe (using the -f or --force option), and build it if necessary. The following command will force all Auto SDK module recipes to be re-exported: $ ./builder/build.py -f \"aac-module-*\" To explicitly force one or more recipes to be exported, you can specify the name of the module (or explicit package name) that you want. The following example will force the builder to re-export and build only the alexa and cbl modules. $ ./builder/build.py -f alexa cbl Each time the builder is run, it will also attempt to re-configure Conan settings by initializing the Conan configuration and installing any config files found in the search path. This happens every time because it is possible, using Docker for example, to re-use the Conan home path when building with a different build system configuration. This step ensures that the Conan configuration will match the build system currently being used. In the case that you want to skip the configuration step for some reason (maybe you have overridden configuration settings in the Conan home manually), you can tell the builder to skip the configuration step using the --skip-config option: $ ./builder/build.py --skip-config Specify the build target Auto SDK can be cross-compiled for supported target systems by specifying the platform and architecture with the build command. Android and QNX targets can be built on either Linux or macOS, and Poky must be built using Linux. For information about specific build target requirements, see the Platform-specific build information section of this guide. To set the target platform using the Builder Tool, specify the --platform,-p <platform> option when doing a build: $ ./builder/build.py -p android You can also set the target architecture by specifying the --arch,-a <architecture> option: $ ./builder/build.py -p android -a x86_64 The following table defines the supported platforms and architectures. platform arch android armv8, x86_64 qnx armv8, x86_64 poky armv8, armv7hf, x86_64, x86 Specify which modules to build If you are using a subset of modules in Auto SDK, you can specify which modules to build on the command line using the -m or --modules option followed by a list of modules names. Dependent modules and libraries will be included transitively when specifying which modules to build. The following example will build the core , alexa , and cbl modules, and package them into the output archive: $ ./builder/build.py -m core alexa cbl You can verify which modules were specified in the build by looking at the [requires] section or pkg_modules option value in the aac-buildinfo.txt file: [requires] aac-module-alexa/dev aac-module-cbl/dev aac-module-core/dev [options] ... pkg_modules=aac-module-core/dev,aac-module-alexa/dev,aac-module-cbl/dev You could also build the same modules by specifying the following on the command line: $ ./builder/build.py -m cbl This works because the cbl module depends on the alexa module, which depends on the core module - so even though they are not specified on the command line, core and alexa are transitively included. The aac-buildinfo.txt file will only show the cbl module under the [requires] section, however, the full list of included dependencies can be found under the [full_requires] section in the build info: [full_requires] aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 aac-module-cbl/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-core/dev:fe4587e72f3350cdb9dab53b293dfee0d5575a0a ... Clean build artifacts Conan caches binaries and artifacts for each package after it is built, so they can be used as dependencies by other packages without having to be re-built each time. If you make changes to the source code in the SDK, however, you must either explicitly force the builder to re-export and build the package (using the --force,-f <pattern> option of the builder), or remove the package entirely from the cache. To remove packages from the cache using the Builder Tool, you can use the clean command: $ ./builder/build.py clean <pattern> You must specify the package name or regex-style pattern to clean. For example, to remove all of the packages from the cache, you can use the following command: $ ./builder/build.py clean \"*\" To remove a specific module, you can either specify the package name or just the module's name: $ ./builder/build.py clean alexa Since the convention used by Auto SDK is to specify the module's package name as aac-module-<name> , you can also use the full package name as part of the pattern. One way to remove all Auto SDK modules from the cache would be to use the following command: $ ./builder/build.py clean \"aac-module-*\" If a package has been removed from the cache, the Builder Tool will automatically detect that it needs to be re-exported and built the next time you do a build, and it is not necessary to specify the package using the --force option. Build debug libraries Building debug libraries for Auto SDK can be specified by using the --debug or -g option when doing a build: $ ./builder/build.py -g When this option is used, debug libraries for all of the Auto SDK modules and dependencies will be built if required, and exported to the build archive. If you want more specific control over which debug libraries to use, you can specify the build_type option as a Conan setting instead, using the --conan-setting,-s <name>=<value> build option. For example, to use debug libraries only for Auto SDK modules, you can use the following build command: $ ./builder/build.py -s \"aac-module-*\" :build_type = Debug This is a less common use case, however, that requires you to be familiar with some of the underlying Conan build architecture. To learn more about some of the Conan specific options for building Auto SDK, see the Build with Conan directly section of this guide. Locate the build output When you run the builder tool, all of the shared libraries and dependencies will be saved in an archive file in the builder/deploy directory by default. The name of the archive file is displayed in the console when the build is completed: [ BUILDER ] INFO: Created output archive: ../aac-dev-macos_x86_64-release-210706140415.tgz The default name of the archive indicates the following information that is used to build the SDK: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz Sometimes it is helpful to tag a build with an identifier, for example, if you want to indicate a build was made for a specific purpose. If you want to add an additional identifier to the archive name, you can use --name option when running the build tool: $ ./builder/build.py --name test ... [ BUILDER ] INFO: Created output archive: ../aac-dev-test-macos_x86_64-release-210706142403.tgz It is also possible to completely override the output file name and path by specifying the -o or --output option on the command line: $ ./builder/build.py --output /mypath/custom-output.tgz ... [ BUILDER ] INFO: Created output archive: /mypath/custom-output.tgz If you don't want the builder to generate an output archive at all, you can specify the --no-output option on the command line. This is helpful if you just want to re-build one or more module, for example, to run unit tests or inspect the package libraries: $ ./builder/build.py --no-output Archive contents The output archive created by the Builder Tool includes all of the build artifacts from the modules and dependencies specified by the build command. You can extract the archive with the following command (the exact filename will be slightly different for your build): $ tar -xvzf builder/deploy/aac-dev-linux_x86_64-release.tgz After you can extract the contents of the archive, there should be a directory with contents similar to the following file structure: aac-dev-linux_x86_64-release/ \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ \u2514\u2500 aac-buildinfo.txt You can get additional information about the archive contents from a description file in the archive named aac-buildinfo.txt . The build description file can be used to identify which modules, settings, and options were used to generate the libraries by the build. The following is an example of the information found in the build description file: [settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [requires] aac-module-aasb/dev aac-module-address-book/dev aac-module-alexa/dev aac-module-car-control/dev aac-module-cbl/dev aac-module-connectivity/dev aac-module-core/dev aac-module-messaging/dev aac-module-navigation/dev aac-module-phone-control/dev aac-module-text-to-speech/dev [options] aac_version=dev with_sensitive_logs=False pkg_modules=aac-module-aasb/dev,aac-module-address-book/dev,aac-module-alexa/dev,... with_aasb=False [full_settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [full_requires] aac-module-aasb/dev:4990d7e4c95bbcae311c6d13cb0e71a09ecd2f43 aac-module-address-book/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 ... Build with Conan directly Conan can be used directly to build Auto SDK components and other package dependencies, or to use Auto SDK libraries in other Conan recipes. It's helpful to have a good general understanding of how Conan works first, and also to understand the basic Auto SDK build system. The examples in this section should be run with aac-sdk as the working directory. Export Conan recipes The following script will find all of the Conan recipes in Auto SDK and export them to the local cache. Package binaries won't actually be built until they are required by another recipe during a build operation, or explicitly built by running the conan create command. This is a convenience script and is not required if you want to export or create packages individually. $ ./conan/setup.py If you want to export a single package individually, you can run the conan export command. For example, to export the alexa module to the local cache: $ conan export modules/alexa It is important to understand that exporting a module using the conan export command does not automatically find and export any of the dependent packages specified in the recipe. Attempting to build the alexa module would fail, unless all of the requirements can be resolved in the local cache. Running the conan/setup.py script is usually the safest option to ensure all required packages are copied to the cache, however, exporting a package individually can save time after you make changes, if you have previously exported all of the packages. Build modules In most cases it shouldn't be necessary to manually build Auto SDK modules, since Conan can build missing dependencies when required by another recipe. It is possible, however, to create/build a package independently using Conan if needed. The following example shows how to create the Alexa module package from the command line: $ conan create modules/alexa --build missing The conan create command tells conan to create a new binary package from a recipe file and install it in the local cache. In the example above, modules/alexa refers to the parent directory in Auto SDK ( aac-sdk/modules/alexa ), where the conanfile.py recipe is located for the Alexa module. By specifying the --build missing option, Conan will automatically build dependencies where a binary package is missing for the specified build configuration. If the dependency has already been created it will not be built again. Using the --build flag without any additional options will force all of the dependencies to be rebuilt, even if the binary for the specified configuration already exists. Specify build settings and options When you build a Conan package, you can specify settings and options that result in different binaries when the source code is built. Conan settings are project-wide configurations, such as os , compiler , build_type , and arch . These settings should be applied to each package when selecting the correct binary. Most of the time, settings will be applied based on the selected (or default) profile. To view or modify a profile, you can use the conan profile command. To show the default profile values, you can enter the following command: $ conan profile show default Configuration for profile default: [ settings ] os = Macos os_build = Macos arch = x86_64 arch_build = x86_64 compiler = apple-clang compiler.version = 11 .0 compiler.libcxx = libc++ build_type = Release [ options ] [ build_requires ] [ env ] You usually don't need to change settings specified in the profile, but if needed, you can override any setting value when running a Conan command. For example, to build a debug version of the alexa module, you can add -s build_type=Debug to the conan create command: $ conan create modules/alexa -b missing -s build_type = Debug Individual packages can also define options which are specific to it's own build requirements. One common option that most packages define is shared , which is used to build either the static or dynamic library. Options can also be used to specify conditional features which should be included in the build, for example, libcurl defines an option called with_nghttp2 to specify that the build should include support for http2 . Inspect package recipes To see which options a recipe has defined, you can use the conan inspect command: $ conan inspect modules/alexa/conanfile.py name: aac-module-alexa version: dev url: https://github.com/alexa/alexa-auto-sdk homepage: None license: Apache-2.0 author: None description: Auto SDK module: alexa topics: None generators: cmake exports: None exports_sources: * short_paths: False apply_env: True build_policy: None revision_mode: hash settings: ( 'os' , 'compiler' , 'build_type' , 'arch' ) options: message_version: ANY shared: [ True, False ] with_aasb: [ True, False ] with_address_sanitizer: [ True, False ] with_android_libs: [ True, False ] with_coverage_tests: [ True, False ] with_docs: [ True, False ] with_engine: [ True, False ] with_jni: [ True, False ] with_latency_logs: [ True, False ] with_messages: [ True, False ] with_platform: [ True, False ] with_sensitive_logs: [ True, False ] with_unit_tests: [ True, False ] default_options: message_version: 4 .0 shared: True with_aasb: True with_address_sanitizer: False with_android_libs: True with_coverage_tests: False with_docs: True with_engine: True with_jni: True with_latency_logs: False with_messages: True with_platform: True with_sensitive_logs: False with_unit_tests: False deprecated: None This command shows different attributes of the package, including its options and the default values for each option specified in default_options . To override a default option when building a package, you can add -o [option]=[value] . If you want to override an option for a specific package, then you can specify the package name as well, -o [pkg]:[option]=[value] . For example, to build and run unit tests for the alexa module, you can add -o with_unit_tests=True to the conan create command: $ conan create modules/alexa -b missing -o with_unit_tests = True Remove packages from the cache Packages can be removed from the local cache if needed by using the conan remove command. For example, the following command can be used to remove the alexa module from the cache: $ conan remove aac-module-alexa -f The -f option is used to remove the package without confirmation. To remove all Auto SDK modules from the cache, you can specify the following pattern aac-module-* in place of a package name, or specify * to remove all packages: $ conan remove \"aac-module-*\" -f $ conan remove \"*\" Note: when specifying a wildcard in the package name, you must surround the pattern with quotes. Use Auto SDK in other recipes If you have your own project that uses Conan, to build an application or library for example, you can include Auto SDK packages in the requirements section of your Conan recipe. The following example shows how you can include Auto SDK modules that are built on the same development machine, in a conanfile.txt recipe: [requires] aac-module-core/dev aac-module-alexa/dev aac-module-cbl/dev aac-module-system-audio/dev ... When you build your package, as long as the Auto SDK packages have been exported to the local cache, Conan will include the specified modules when building your project. It is important to note the convention used by Auto SDK, where all module packages are named aac-module-<module_name> , and the default package version when building locally will be dev unless overridden at build time. You can add Auto SDK modules as a requirement to conanfile.py recipes as well, by specifying them using the requires attribute in the recipe: class ConanRecipe ( ConanFile ): requires = [ \"aac-module-core/dev\" , \"aac-module-alexa\" , \"aac-module-cbl/dev\" , \"aac-module-system-audio/dev\" ] ... Platform-specific build information Android Android can be cross-compiled on either MacOS or Linux, using the NDK toolchain build requirement specified in the aac-android profile. To build Android compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the android platform. $ ./builder/build.py -p android By default the android configuration used to build the SDK is defined in the aac-android Conan profile: [settings] os=Android os.api_level=26 arch=armv8 build_type=Release compiler=clang compiler.libcxx=libc++ compiler.version=8 [build_requires] android-sdk-tools/4.0@aac-sdk/stable You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p android --arch = x86_64 The first time you build Auto SDK for Android, the Android SDK must be downloaded and installed. This is handled by the android-sdk-tools recipe in Auto SDK when you build, however, several license agreements must be manually accepted before any of the Android tools can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:b and --profile:build,-pr:b options as part of the build command. In this case for Android, you would specify aac-android as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the x86_64 version of the Android libraries you can specify -s:h arch=x86_64 as an option: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing -s:h arch = x86_64 Ubuntu Building Auto SDK for Linux on Ubuntu requires installing some additional dependencies, such as GStreamer if you are using the system-audio module. Install GStreamer The system-audio module uses GStreamer to implement the core audio interfaces, and must be installed prior to building. The following command will install the dependencies required to build with GStreamer: $ apt install -y \\ pkg-config libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \\ libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base \\ gstreamer1.0-plugins-good gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc \\ gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl \\ gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio Update the default Conan profile You might run into an issue on Ubuntu where Conan does not detect the default libstdc++11 setting properly, so it is recommended to check this when setting up your host environment. You can run the following command to update the default Conan profile to use the libstdc++11 compiler option: $ conan profile new default --detect $ conan profile update settings.compiler.libcxx = libstdc++11 default Poky Poky can be cross compiled on Linux using the host Poky SDK toolchain. To build Poky compatible binaries with the Builder Tool, simple use the --platform or -p option to specify the poky platform. $ ./builder/build.py -p poky By default the poky configuration used to build the Auto SDK is defined in the aac-poky Conan profile: [settings] compiler.version=8.2 arch=armv7hf build_type=Release os=Linux compiler.libcxx=libstdc++11 [build_requires] poky-sdk/2.6.1 You can override default target architecture to build either the armv7hf , or armv8 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p poky --arch = armv8 The first time you build Auto SDK for Poky, the Poky SDK must be downloaded and installed. This is handled by the poky-sdk recipe in Auto SDK when you build, however, several license agreements must be manually accepted before the Poky SDK can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:h and --profile:build,-pr:b options as part of the build command. In this case for Poky, you would specify aac-poky as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-poky -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the armv8 version of the Poky libraries you can specify -s:h arch=armv8 as an option: $ conan create modules/alexa -pr:h aac-poky -pr:h default -b missing -s:h arch = armv8 QNX QNX can be cross compiled on Linux or MacOS using the host QNX SDP tools. To build QNX, you must install the QNX 7.0 SDP on your host as a prerequisite. To build QNX compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the qnx platform: $ ./builder/build.py -p qnx By default the QNX configuration used to build the Alexa Auto SDK is defined in the aac-qnx Conan profile: [settings] os=Neutrino os.version=7.0 arch=armv8 compiler=qcc compiler.version=5.4 compiler.libcxx=cxx compiler.cppstd=None [build_requires] qnx-cross-compiling/7.0.0 [options] [env] You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p qnx --arch = x86_64 The Conan recipe assumes that the QNX SDP is installed in your home director: ~/qnx700 , but you can override this by setting the qnx7sdp_path option using the --conan-option or -o argument on the command line: $ ./builder/build.py -p qnx -o qnx7-sdp:qnx7sdp_path = /path/to/qnx7sdp macOS macOS can be used as a build host for cross-compiled Android and QNX targets, as well and target for native development and testing. GStreamer build issue There is a known issue where building GStreamer can fail due to a conflict with openEXR on macOS. This may be an issue if you are seeing the following type of errors in your build output: In file included from ../source_subfolder/ext/openexr/gstopenexrdec.cpp:30: In file included from /usr/local/include/OpenEXR/ImfRgbaFile.h:23: In file included from /usr/local/include/OpenEXR/ImfHeader.h:22: In file included from /usr/local/include/Imath/ImathVec.h:17: /usr/local/include/Imath/ImathMath.h:152:36: error: expected ';' at end of declaration equalWithAbsError ( T x1, T x2, T e ) IMATH_NOEXCEPT ^ Uninstalling openEXR has been reported to solve the problem: $ brew uninstall --ignore-dependencies openEXR Windows Windows is not currently supported as a build host or target. Build in a Docker container You can use Docker for native Linux builds, or any cross-compiler target that is supported with Linux, as long as the Docker container has the required build dependencies installed. For convenience, you can use the aac-ubuntu-bionic or aac-ubuntu-focal containers provided in the conan/docker directory of the SDK. The following commands should be run with aac-sdk as the working directory. Create the aac-ubuntu-bionic docker image: $ docker build -t aac/ubuntu-bionic conan/docker/aac-ubuntu-bionic Build Auto SDK using the Builder Tool: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py\" The option -v$(pwd):/home/conan/aac-sdk specifies that we want to mount the current directory on the host machine (which should be the Auto SDK root), to /home/conan/aac-sdk in the Docker container file system. After starting the container, you will be able to build Auto SDK using Conan with the same commands used on your host machine. When the build is complete, the output archive file will be saved to the mounted aac-sdk/builder/deploy directory of your host machine. If you inspect aac-buildinfo.txt in the archive, you should see that the libraries were built for os=Linux, arch=x86_64 : [settings] arch=x86_64 build_type=Release compiler=gcc compiler.libcxx=libstdc++11 compiler.version=7 os=Linux Optimize build performance When you build Auto SDK using a Docker container it can take much longer to build than it would natively on your host computer. This is because the Builder Tool home directory is specified as aac-sdk/builder by default, which is a directory on the host file system. File operations in general are much slower when running on a mounted volume, so this will impact the build performance. One option is to specify a different home directory on the container's volume when running the build command instead. This will greatly improve the build time, however, you should be aware that when you remove the container the cached build artifacts may be lost. The Builder Tool will still write the output archive to aac-sdk/builder/deploy on the mounted volume by default, even if the home directory is changed. The following example shows how you can set the home directory using the --home option, when doing a build using Docker: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py --home /home/conan\"","title":"Build Alexa Auto SDK"},{"location":"BUILDING/#build-alexa-auto-sdk","text":"","title":"Build Alexa Auto SDK"},{"location":"BUILDING/#supported-platforms-and-architectures","text":"Auto SDK can be built for the following supported target platforms and hardware architectures: Android 5.1 Lollipop API Level 22 or higher. ARM 64-bit x86 64-bit QNX 7.0 ARM 64-bit x86 64-bit Generic Linux x86 64-bit Poky Linux ARMv7a (+NEON) AArch64 macOS x86 64-bit","title":"Supported platforms and architectures"},{"location":"BUILDING/#general-build-requirements","text":"You can build the Alexa Auto SDK natively on a Linux or macOS host, or you can use Docker. For specific information about Docker, see Build in a Docker container . The following list describes the supported host configurations: Operating system: macOS Sierra Ubuntu 18.04 LTS (Bionic) or Ubuntu 20.04 LTS (Focal) Processor: 2.5 GHz Memory: 16 Gb Storage: 1 Gb+ available to use","title":"General build requirements"},{"location":"BUILDING/#build-dependencies","text":"To build Auto SDK, you must install the following dependencies on your host machine:","title":"Build dependencies"},{"location":"BUILDING/#general","text":"Python 3.7 Conan 1.33 CMake 3.12","title":"General"},{"location":"BUILDING/#linux","text":"GCC GStreamer (see Install GStreamer )","title":"Linux"},{"location":"BUILDING/#macos","text":"Xcode","title":"macOS"},{"location":"BUILDING/#understand-the-build-system","text":"Building software for multiple platforms can be complex because specific toolchains might vary depending on the build system and target platform. In general, there are two flavors of builds: native and cross-compiled. In a native build, the build system uses its own toolchain and libraries to build the software, so the compiled software can run on the platform that built it. In cross-compilation, the build system typically uses an installed toolchain to compile the software for a different target platform. It's possible that more than one toolchain is installed on a system, so extra steps are typically needed to cross-compile to those targets. Auto SDK uses Conan , along with other tools and scripts described in this section, to manage the complexities required to implement a complete build system.","title":"Understand the build system"},{"location":"BUILDING/#conan","text":"The Auto SDK build system uses Conan as its underlying package manager and build configuration tool. For every Conan package, there is a recipe that defines the dependencies of the package and specifies how to download and build the package source code. After building a package, Conan copies the binaries and other artifacts into a cache directory so other recipes that depend on that package can use the prebuilt binaries without rebuilding them. When a Conan recipe defines a dependency, Conan finds and builds the dependency as required, taking care of complexities such as transitive requirements, package version conflicts, and managing multiple versions of a package built with different configurations. Before using a package, Conan must export or download the package into the local cache. When a package recipe exists in the same local repository as the source code it builds, as is the case when you download Auto SDK, you must run conan create or conan export before other recipes can build the package. Community servers such as Conan Center host some popular third party libraries, however, so Conan automatically downloads them to the local cache as needed. Auto SDK requires a combination of Conan packages including local recipes for Auto SDK modules and tools, local recipes for third party packages, and third party packages hosted on the Conan Center server. Once Conan copies a package into the local cache, a recipe can build or consume the package based on the specified build configuration. Conan will build a new package version if the package version is required and missing from the cache. For example, if you build Auto SDK for Linux, Conan will build all of the required packages for the specified Linux target. If you then build for an Android target, Conan will rebuild all of the required packages for the Android target and cache both the Linux and Android versions. In addition to target platform, any option or setting that you specify when building a recipe affects the package version.","title":"Conan"},{"location":"BUILDING/#auto-sdk-modules","text":"Auto SDK includes a base Conan recipe class that all Auto SDK modules extend. This is defined in conan/recipes/aac-sdk-tools , and must be exported before other modules since it is required by each module's recipe definition. The base recipe defines common build options, and relies on specific conventions in the module's directory structure to find source files and headers, and to generate other artifacts that are needed at build time. A simple Conan recipe is required for each module to override abstract values in the base class (such as the module name), and to define any module specific dependencies or options that are required. A module can also define it's own CMake files, unique configuration, or even custom build steps as needed. For each module, the base recipe defines common options that are used to specify which components are included in the library. The default values provided in the base recipe should be used in most cases when you are building release libraries for production. For some cases, however, you may want to enabled features such as with_sensitive_logs or with_unit_tests , to add additional information when debugging issues with the libraries. To find out which options are defined for a specific module, you can use the conan inspect command to display information about any Conan recipe. This command will display all of options and default values for a recipe, including any options that are inherited from the base module recipe. See the Specify build settings and options section in this guide, for more information. Applications integrate with Auto SDK using the MessageBroker API, by publishing and subscribing to specific message topics and actions (see Using the MessageBroker API ). Most modules provide interfaces that require these messages to be defined, in which case they will include one or more message definition files in the aasb/messages directory of the module. The model created by the message definitions are used when building Auto SDK to generate message headers that are required to build the module, and are also used to create documentation for each message interface.","title":"Auto SDK modules"},{"location":"BUILDING/#third-party-dependencies","text":"Auto SDK has dependencies on several third party packages (libraries and build tools for example), which may themselves have dependencies on other packages. In general, managing these types of build requirements can be very complex for a large project. Conan helps by providing community hosted recipes for many common packages, as well as by allowing developers to create there own package recipes. It is important to understand that some of the packages used by Auto SDK are pulled from the Conan Center remote server, while others are defined locally in the conan/recipes directory of Auto SDK. Local recipes are typically required when the package does not already exist on Conan Center, or there are specific patches or changes to the recipe that are needed for Auto SDK.","title":"Third party dependencies"},{"location":"BUILDING/#builder-tool","text":"The Builder Tool is a script that can be used to build Auto SDK libraries for supported platforms. It improves the build process by wrapping underlying Conan commands and options with a simple command line interface. Although it is possible to use Conan by itself to build Auto SDK - see the Build with Conan directly section of this guide, it is recommended to use the Builder Tool for common build tasks.","title":"Builder Tool"},{"location":"BUILDING/#alexa-auto-client-service","text":"Alexa Auto Client Service (AACS) is an Android service library that simplifies the process of integrating Auto SDK on Android-based devices. AACS has a dependency on Auto SDK native Android libraries, but can be built independently using standard Android development tools. For more information about building AACS, see the Building AACS with AACS Sample App section of the Alexa Auto Client Service guide.","title":"Alexa Auto Client Service"},{"location":"BUILDING/#build-with-builder-tool","text":"The Builder Tool script, build.py is located in the builder directory of the SDK. It wraps underlying Conan commands, and simplifies building libraries for Auto SDK modules on supported platforms. Individual modules, components, and dependencies in the SDK are described as packages in the builder. Each package has a corresponding Conan recipe that is used to build and deploy the package to the cache located in the builder's home directory. An archive containing all of the specified build artifacts is created from the cache, and written to the deploy directory of the builder, after the build has completed. This section descibes the most common commands used to build Auto SDK. For a complete reference to the Builder Tool command line interface, see Builder Tool command reference . Auto SDK currently supports native builds for Ubuntu Linux (x86_64) and MacOS, and building for each platform follows the same steps. After cloning the Auto SDK git repository on your system, the following examples should be run with aac-sdk as the working directory. The following command will build all of the modules that are included in the Auto SDK repository, along with any dependencies that are required for the target platform: $ ./builder/build.py When you run the build command, the builder tool will export and configure any new build artifacts, such as package recipes or configuration files, that are discovered in the search path. The first time you run (or after cleaning the build cache), you'll see several log messages indicating that the build recipes are being exported to the local cache: [ BUILDER ] INFO: Python version: 3 .7.3 [ BUILDER ] INFO: Cleaning cached builder data [ BUILDER ] INFO: Builder home: ../aac-sdk/builder/.builder [ BUILDER ] INFO: Conan home: ../aac-sdk/builder/.builder/.conan [ BUILDER ] INFO: Gradle home: ../aac-sdk/builder/.builder/.gradle [ BUILDER ] INFO: Configuring Conan... [ BUILDER ] INFO: Installing Conan configuration: ../aac-sdk/conan/config [ BUILDER ] INFO: Exporting recipe: aac-sdk-tools [ BUILDER ] INFO: Exporting recipe: aac-module-core [ BUILDER ] INFO: Exporting recipe: aac-module-alexa [ BUILDER ] INFO: Exporting recipe: aac-module-cbl [ BUILDER ] INFO: Exporting recipe: android-sdk-tools [ BUILDER ] INFO: Exporting recipe: avs-device-sdk ... The builder keeps track of which recipes have already been added to the cache, so that the next time you run the build command only new recipes will be exported. It is possible, however, to tell the builder to force re-exporting a recipe (using the -f or --force option), and build it if necessary. The following command will force all Auto SDK module recipes to be re-exported: $ ./builder/build.py -f \"aac-module-*\" To explicitly force one or more recipes to be exported, you can specify the name of the module (or explicit package name) that you want. The following example will force the builder to re-export and build only the alexa and cbl modules. $ ./builder/build.py -f alexa cbl Each time the builder is run, it will also attempt to re-configure Conan settings by initializing the Conan configuration and installing any config files found in the search path. This happens every time because it is possible, using Docker for example, to re-use the Conan home path when building with a different build system configuration. This step ensures that the Conan configuration will match the build system currently being used. In the case that you want to skip the configuration step for some reason (maybe you have overridden configuration settings in the Conan home manually), you can tell the builder to skip the configuration step using the --skip-config option: $ ./builder/build.py --skip-config","title":"Build with Builder Tool"},{"location":"BUILDING/#specify-the-build-target","text":"Auto SDK can be cross-compiled for supported target systems by specifying the platform and architecture with the build command. Android and QNX targets can be built on either Linux or macOS, and Poky must be built using Linux. For information about specific build target requirements, see the Platform-specific build information section of this guide. To set the target platform using the Builder Tool, specify the --platform,-p <platform> option when doing a build: $ ./builder/build.py -p android You can also set the target architecture by specifying the --arch,-a <architecture> option: $ ./builder/build.py -p android -a x86_64 The following table defines the supported platforms and architectures. platform arch android armv8, x86_64 qnx armv8, x86_64 poky armv8, armv7hf, x86_64, x86","title":"Specify the build target"},{"location":"BUILDING/#specify-which-modules-to-build","text":"If you are using a subset of modules in Auto SDK, you can specify which modules to build on the command line using the -m or --modules option followed by a list of modules names. Dependent modules and libraries will be included transitively when specifying which modules to build. The following example will build the core , alexa , and cbl modules, and package them into the output archive: $ ./builder/build.py -m core alexa cbl You can verify which modules were specified in the build by looking at the [requires] section or pkg_modules option value in the aac-buildinfo.txt file: [requires] aac-module-alexa/dev aac-module-cbl/dev aac-module-core/dev [options] ... pkg_modules=aac-module-core/dev,aac-module-alexa/dev,aac-module-cbl/dev You could also build the same modules by specifying the following on the command line: $ ./builder/build.py -m cbl This works because the cbl module depends on the alexa module, which depends on the core module - so even though they are not specified on the command line, core and alexa are transitively included. The aac-buildinfo.txt file will only show the cbl module under the [requires] section, however, the full list of included dependencies can be found under the [full_requires] section in the build info: [full_requires] aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 aac-module-cbl/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-core/dev:fe4587e72f3350cdb9dab53b293dfee0d5575a0a ...","title":"Specify which modules to build"},{"location":"BUILDING/#clean-build-artifacts","text":"Conan caches binaries and artifacts for each package after it is built, so they can be used as dependencies by other packages without having to be re-built each time. If you make changes to the source code in the SDK, however, you must either explicitly force the builder to re-export and build the package (using the --force,-f <pattern> option of the builder), or remove the package entirely from the cache. To remove packages from the cache using the Builder Tool, you can use the clean command: $ ./builder/build.py clean <pattern> You must specify the package name or regex-style pattern to clean. For example, to remove all of the packages from the cache, you can use the following command: $ ./builder/build.py clean \"*\" To remove a specific module, you can either specify the package name or just the module's name: $ ./builder/build.py clean alexa Since the convention used by Auto SDK is to specify the module's package name as aac-module-<name> , you can also use the full package name as part of the pattern. One way to remove all Auto SDK modules from the cache would be to use the following command: $ ./builder/build.py clean \"aac-module-*\" If a package has been removed from the cache, the Builder Tool will automatically detect that it needs to be re-exported and built the next time you do a build, and it is not necessary to specify the package using the --force option.","title":"Clean build artifacts"},{"location":"BUILDING/#build-debug-libraries","text":"Building debug libraries for Auto SDK can be specified by using the --debug or -g option when doing a build: $ ./builder/build.py -g When this option is used, debug libraries for all of the Auto SDK modules and dependencies will be built if required, and exported to the build archive. If you want more specific control over which debug libraries to use, you can specify the build_type option as a Conan setting instead, using the --conan-setting,-s <name>=<value> build option. For example, to use debug libraries only for Auto SDK modules, you can use the following build command: $ ./builder/build.py -s \"aac-module-*\" :build_type = Debug This is a less common use case, however, that requires you to be familiar with some of the underlying Conan build architecture. To learn more about some of the Conan specific options for building Auto SDK, see the Build with Conan directly section of this guide.","title":"Build debug libraries"},{"location":"BUILDING/#locate-the-build-output","text":"When you run the builder tool, all of the shared libraries and dependencies will be saved in an archive file in the builder/deploy directory by default. The name of the archive file is displayed in the console when the build is completed: [ BUILDER ] INFO: Created output archive: ../aac-dev-macos_x86_64-release-210706140415.tgz The default name of the archive indicates the following information that is used to build the SDK: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz Sometimes it is helpful to tag a build with an identifier, for example, if you want to indicate a build was made for a specific purpose. If you want to add an additional identifier to the archive name, you can use --name option when running the build tool: $ ./builder/build.py --name test ... [ BUILDER ] INFO: Created output archive: ../aac-dev-test-macos_x86_64-release-210706142403.tgz It is also possible to completely override the output file name and path by specifying the -o or --output option on the command line: $ ./builder/build.py --output /mypath/custom-output.tgz ... [ BUILDER ] INFO: Created output archive: /mypath/custom-output.tgz If you don't want the builder to generate an output archive at all, you can specify the --no-output option on the command line. This is helpful if you just want to re-build one or more module, for example, to run unit tests or inspect the package libraries: $ ./builder/build.py --no-output","title":"Locate the build output"},{"location":"BUILDING/#archive-contents","text":"The output archive created by the Builder Tool includes all of the build artifacts from the modules and dependencies specified by the build command. You can extract the archive with the following command (the exact filename will be slightly different for your build): $ tar -xvzf builder/deploy/aac-dev-linux_x86_64-release.tgz After you can extract the contents of the archive, there should be a directory with contents similar to the following file structure: aac-dev-linux_x86_64-release/ \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ \u2514\u2500 aac-buildinfo.txt You can get additional information about the archive contents from a description file in the archive named aac-buildinfo.txt . The build description file can be used to identify which modules, settings, and options were used to generate the libraries by the build. The following is an example of the information found in the build description file: [settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [requires] aac-module-aasb/dev aac-module-address-book/dev aac-module-alexa/dev aac-module-car-control/dev aac-module-cbl/dev aac-module-connectivity/dev aac-module-core/dev aac-module-messaging/dev aac-module-navigation/dev aac-module-phone-control/dev aac-module-text-to-speech/dev [options] aac_version=dev with_sensitive_logs=False pkg_modules=aac-module-aasb/dev,aac-module-address-book/dev,aac-module-alexa/dev,... with_aasb=False [full_settings] arch=x86_64 build_type=Release compiler=apple-clang compiler.libcxx=libc++ compiler.version=11.0 os=Macos [full_requires] aac-module-aasb/dev:4990d7e4c95bbcae311c6d13cb0e71a09ecd2f43 aac-module-address-book/dev:8b2bd324ad68ca44682ed4ed11f0845ef8df1a5c aac-module-alexa/dev:1de4d8ddd6d19b16b05d95052195f9556361e7b5 ...","title":"Archive contents"},{"location":"BUILDING/#build-with-conan-directly","text":"Conan can be used directly to build Auto SDK components and other package dependencies, or to use Auto SDK libraries in other Conan recipes. It's helpful to have a good general understanding of how Conan works first, and also to understand the basic Auto SDK build system. The examples in this section should be run with aac-sdk as the working directory.","title":"Build with Conan directly"},{"location":"BUILDING/#export-conan-recipes","text":"The following script will find all of the Conan recipes in Auto SDK and export them to the local cache. Package binaries won't actually be built until they are required by another recipe during a build operation, or explicitly built by running the conan create command. This is a convenience script and is not required if you want to export or create packages individually. $ ./conan/setup.py If you want to export a single package individually, you can run the conan export command. For example, to export the alexa module to the local cache: $ conan export modules/alexa It is important to understand that exporting a module using the conan export command does not automatically find and export any of the dependent packages specified in the recipe. Attempting to build the alexa module would fail, unless all of the requirements can be resolved in the local cache. Running the conan/setup.py script is usually the safest option to ensure all required packages are copied to the cache, however, exporting a package individually can save time after you make changes, if you have previously exported all of the packages.","title":"Export Conan recipes"},{"location":"BUILDING/#build-modules","text":"In most cases it shouldn't be necessary to manually build Auto SDK modules, since Conan can build missing dependencies when required by another recipe. It is possible, however, to create/build a package independently using Conan if needed. The following example shows how to create the Alexa module package from the command line: $ conan create modules/alexa --build missing The conan create command tells conan to create a new binary package from a recipe file and install it in the local cache. In the example above, modules/alexa refers to the parent directory in Auto SDK ( aac-sdk/modules/alexa ), where the conanfile.py recipe is located for the Alexa module. By specifying the --build missing option, Conan will automatically build dependencies where a binary package is missing for the specified build configuration. If the dependency has already been created it will not be built again. Using the --build flag without any additional options will force all of the dependencies to be rebuilt, even if the binary for the specified configuration already exists.","title":"Build modules"},{"location":"BUILDING/#specify-build-settings-and-options","text":"When you build a Conan package, you can specify settings and options that result in different binaries when the source code is built. Conan settings are project-wide configurations, such as os , compiler , build_type , and arch . These settings should be applied to each package when selecting the correct binary. Most of the time, settings will be applied based on the selected (or default) profile. To view or modify a profile, you can use the conan profile command. To show the default profile values, you can enter the following command: $ conan profile show default Configuration for profile default: [ settings ] os = Macos os_build = Macos arch = x86_64 arch_build = x86_64 compiler = apple-clang compiler.version = 11 .0 compiler.libcxx = libc++ build_type = Release [ options ] [ build_requires ] [ env ] You usually don't need to change settings specified in the profile, but if needed, you can override any setting value when running a Conan command. For example, to build a debug version of the alexa module, you can add -s build_type=Debug to the conan create command: $ conan create modules/alexa -b missing -s build_type = Debug Individual packages can also define options which are specific to it's own build requirements. One common option that most packages define is shared , which is used to build either the static or dynamic library. Options can also be used to specify conditional features which should be included in the build, for example, libcurl defines an option called with_nghttp2 to specify that the build should include support for http2 .","title":"Specify build settings and options"},{"location":"BUILDING/#inspect-package-recipes","text":"To see which options a recipe has defined, you can use the conan inspect command: $ conan inspect modules/alexa/conanfile.py name: aac-module-alexa version: dev url: https://github.com/alexa/alexa-auto-sdk homepage: None license: Apache-2.0 author: None description: Auto SDK module: alexa topics: None generators: cmake exports: None exports_sources: * short_paths: False apply_env: True build_policy: None revision_mode: hash settings: ( 'os' , 'compiler' , 'build_type' , 'arch' ) options: message_version: ANY shared: [ True, False ] with_aasb: [ True, False ] with_address_sanitizer: [ True, False ] with_android_libs: [ True, False ] with_coverage_tests: [ True, False ] with_docs: [ True, False ] with_engine: [ True, False ] with_jni: [ True, False ] with_latency_logs: [ True, False ] with_messages: [ True, False ] with_platform: [ True, False ] with_sensitive_logs: [ True, False ] with_unit_tests: [ True, False ] default_options: message_version: 4 .0 shared: True with_aasb: True with_address_sanitizer: False with_android_libs: True with_coverage_tests: False with_docs: True with_engine: True with_jni: True with_latency_logs: False with_messages: True with_platform: True with_sensitive_logs: False with_unit_tests: False deprecated: None This command shows different attributes of the package, including its options and the default values for each option specified in default_options . To override a default option when building a package, you can add -o [option]=[value] . If you want to override an option for a specific package, then you can specify the package name as well, -o [pkg]:[option]=[value] . For example, to build and run unit tests for the alexa module, you can add -o with_unit_tests=True to the conan create command: $ conan create modules/alexa -b missing -o with_unit_tests = True","title":"Inspect package recipes"},{"location":"BUILDING/#remove-packages-from-the-cache","text":"Packages can be removed from the local cache if needed by using the conan remove command. For example, the following command can be used to remove the alexa module from the cache: $ conan remove aac-module-alexa -f The -f option is used to remove the package without confirmation. To remove all Auto SDK modules from the cache, you can specify the following pattern aac-module-* in place of a package name, or specify * to remove all packages: $ conan remove \"aac-module-*\" -f $ conan remove \"*\" Note: when specifying a wildcard in the package name, you must surround the pattern with quotes.","title":"Remove packages from the cache"},{"location":"BUILDING/#use-auto-sdk-in-other-recipes","text":"If you have your own project that uses Conan, to build an application or library for example, you can include Auto SDK packages in the requirements section of your Conan recipe. The following example shows how you can include Auto SDK modules that are built on the same development machine, in a conanfile.txt recipe: [requires] aac-module-core/dev aac-module-alexa/dev aac-module-cbl/dev aac-module-system-audio/dev ... When you build your package, as long as the Auto SDK packages have been exported to the local cache, Conan will include the specified modules when building your project. It is important to note the convention used by Auto SDK, where all module packages are named aac-module-<module_name> , and the default package version when building locally will be dev unless overridden at build time. You can add Auto SDK modules as a requirement to conanfile.py recipes as well, by specifying them using the requires attribute in the recipe: class ConanRecipe ( ConanFile ): requires = [ \"aac-module-core/dev\" , \"aac-module-alexa\" , \"aac-module-cbl/dev\" , \"aac-module-system-audio/dev\" ] ...","title":"Use Auto SDK in other recipes"},{"location":"BUILDING/#platform-specific-build-information","text":"","title":"Platform-specific build information"},{"location":"BUILDING/#android","text":"Android can be cross-compiled on either MacOS or Linux, using the NDK toolchain build requirement specified in the aac-android profile. To build Android compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the android platform. $ ./builder/build.py -p android By default the android configuration used to build the SDK is defined in the aac-android Conan profile: [settings] os=Android os.api_level=26 arch=armv8 build_type=Release compiler=clang compiler.libcxx=libc++ compiler.version=8 [build_requires] android-sdk-tools/4.0@aac-sdk/stable You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p android --arch = x86_64 The first time you build Auto SDK for Android, the Android SDK must be downloaded and installed. This is handled by the android-sdk-tools recipe in Auto SDK when you build, however, several license agreements must be manually accepted before any of the Android tools can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:b and --profile:build,-pr:b options as part of the build command. In this case for Android, you would specify aac-android as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the x86_64 version of the Android libraries you can specify -s:h arch=x86_64 as an option: $ conan create modules/alexa -pr:h aac-android -pr:b default -b missing -s:h arch = x86_64","title":"Android"},{"location":"BUILDING/#ubuntu","text":"Building Auto SDK for Linux on Ubuntu requires installing some additional dependencies, such as GStreamer if you are using the system-audio module.","title":"Ubuntu"},{"location":"BUILDING/#install-gstreamer","text":"The system-audio module uses GStreamer to implement the core audio interfaces, and must be installed prior to building. The following command will install the dependencies required to build with GStreamer: $ apt install -y \\ pkg-config libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev \\ libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base \\ gstreamer1.0-plugins-good gstreamer1.0-plugins-bad \\ gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc \\ gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl \\ gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio","title":"Install GStreamer"},{"location":"BUILDING/#update-the-default-conan-profile","text":"You might run into an issue on Ubuntu where Conan does not detect the default libstdc++11 setting properly, so it is recommended to check this when setting up your host environment. You can run the following command to update the default Conan profile to use the libstdc++11 compiler option: $ conan profile new default --detect $ conan profile update settings.compiler.libcxx = libstdc++11 default","title":"Update the default Conan profile"},{"location":"BUILDING/#poky","text":"Poky can be cross compiled on Linux using the host Poky SDK toolchain. To build Poky compatible binaries with the Builder Tool, simple use the --platform or -p option to specify the poky platform. $ ./builder/build.py -p poky By default the poky configuration used to build the Auto SDK is defined in the aac-poky Conan profile: [settings] compiler.version=8.2 arch=armv7hf build_type=Release os=Linux compiler.libcxx=libstdc++11 [build_requires] poky-sdk/2.6.1 You can override default target architecture to build either the armv7hf , or armv8 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p poky --arch = armv8 The first time you build Auto SDK for Poky, the Poky SDK must be downloaded and installed. This is handled by the poky-sdk recipe in Auto SDK when you build, however, several license agreements must be manually accepted before the Poky SDK can be used. These agreements will need to be accepted anytime you change the builder home directory, or clean the builder cache as well. You can optionally accept all of the license agreements by specifying -y or --accept-licenses when running the builder from the command line. If you are using Conan directly to build Auto SDK libraries, you must specify the --profile:host,-pr:h and --profile:build,-pr:b options as part of the build command. In this case for Poky, you would specify aac-poky as the host (target) profile in your build command, in addition to explicitly specifying default as the build profile: $ conan create modules/alexa -pr:h aac-poky -pr:b default -b missing You can override any setting for the target platform on the command line, for example, to build the armv8 version of the Poky libraries you can specify -s:h arch=armv8 as an option: $ conan create modules/alexa -pr:h aac-poky -pr:h default -b missing -s:h arch = armv8","title":"Poky"},{"location":"BUILDING/#qnx","text":"QNX can be cross compiled on Linux or MacOS using the host QNX SDP tools. To build QNX, you must install the QNX 7.0 SDP on your host as a prerequisite. To build QNX compatible binaries with the Builder Tool, simply use the --platform or -p option to specify the qnx platform: $ ./builder/build.py -p qnx By default the QNX configuration used to build the Alexa Auto SDK is defined in the aac-qnx Conan profile: [settings] os=Neutrino os.version=7.0 arch=armv8 compiler=qcc compiler.version=5.4 compiler.libcxx=cxx compiler.cppstd=None [build_requires] qnx-cross-compiling/7.0.0 [options] [env] You can override default target architecture to build either the armv8 , or x86_64 version of the binaries by specifying the --arch or -a option on the command line: $ ./builder/build.py -p qnx --arch = x86_64 The Conan recipe assumes that the QNX SDP is installed in your home director: ~/qnx700 , but you can override this by setting the qnx7sdp_path option using the --conan-option or -o argument on the command line: $ ./builder/build.py -p qnx -o qnx7-sdp:qnx7sdp_path = /path/to/qnx7sdp","title":"QNX"},{"location":"BUILDING/#macos_1","text":"macOS can be used as a build host for cross-compiled Android and QNX targets, as well and target for native development and testing.","title":"macOS"},{"location":"BUILDING/#gstreamer-build-issue","text":"There is a known issue where building GStreamer can fail due to a conflict with openEXR on macOS. This may be an issue if you are seeing the following type of errors in your build output: In file included from ../source_subfolder/ext/openexr/gstopenexrdec.cpp:30: In file included from /usr/local/include/OpenEXR/ImfRgbaFile.h:23: In file included from /usr/local/include/OpenEXR/ImfHeader.h:22: In file included from /usr/local/include/Imath/ImathVec.h:17: /usr/local/include/Imath/ImathMath.h:152:36: error: expected ';' at end of declaration equalWithAbsError ( T x1, T x2, T e ) IMATH_NOEXCEPT ^ Uninstalling openEXR has been reported to solve the problem: $ brew uninstall --ignore-dependencies openEXR","title":"GStreamer build issue"},{"location":"BUILDING/#windows","text":"Windows is not currently supported as a build host or target.","title":"Windows"},{"location":"BUILDING/#build-in-a-docker-container","text":"You can use Docker for native Linux builds, or any cross-compiler target that is supported with Linux, as long as the Docker container has the required build dependencies installed. For convenience, you can use the aac-ubuntu-bionic or aac-ubuntu-focal containers provided in the conan/docker directory of the SDK. The following commands should be run with aac-sdk as the working directory. Create the aac-ubuntu-bionic docker image: $ docker build -t aac/ubuntu-bionic conan/docker/aac-ubuntu-bionic Build Auto SDK using the Builder Tool: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py\" The option -v$(pwd):/home/conan/aac-sdk specifies that we want to mount the current directory on the host machine (which should be the Auto SDK root), to /home/conan/aac-sdk in the Docker container file system. After starting the container, you will be able to build Auto SDK using Conan with the same commands used on your host machine. When the build is complete, the output archive file will be saved to the mounted aac-sdk/builder/deploy directory of your host machine. If you inspect aac-buildinfo.txt in the archive, you should see that the libraries were built for os=Linux, arch=x86_64 : [settings] arch=x86_64 build_type=Release compiler=gcc compiler.libcxx=libstdc++11 compiler.version=7 os=Linux","title":"Build in a Docker container"},{"location":"BUILDING/#optimize-build-performance","text":"When you build Auto SDK using a Docker container it can take much longer to build than it would natively on your host computer. This is because the Builder Tool home directory is specified as aac-sdk/builder by default, which is a directory on the host file system. File operations in general are much slower when running on a mounted volume, so this will impact the build performance. One option is to specify a different home directory on the container's volume when running the build command instead. This will greatly improve the build time, however, you should be aware that when you remove the container the cached build artifacts may be lost. The Builder Tool will still write the output archive to aac-sdk/builder/deploy on the mounted volume by default, even if the home directory is changed. The following example shows how you can set the home directory using the --home option, when doing a build using Docker: $ docker run -it -v $( pwd ) :/home/conan/aac-sdk --rm \\ aac/ubuntu-bionic /bin/bash -c \"aac-sdk/builder/build.py --home /home/conan\"","title":"Optimize build performance"},{"location":"CHANGELOG/","text":"Change Log v4.0.0 released on 2021-12-15 Enhancements Deprecated the C++ and Java platform interfaces in favor of an asynchronous message-based API. Auto SDK client applications use the new MessageBroker to publish and subscribe to Alexa Auto Services Bridge (AASB) messages. The C++ sample app is refactored to use the new API to provide a reference implementation for Linux platforms. The Alexa Auto Client Service (AACS) sample app provides the reference implementation for Android platforms. See the Auto SDK Migration Guide for help migrating your application to use the new API. Enhanced the Auto SDK build system with the Conan package manager. The new build system introduces modular builds, better dependency management, and simpler build artifacts. The Auto SDK build system includes the Auto SDK Builder Tool script, which wraps the Conan build commands with a simple interface similar to the previous version of Auto SDK Builder. See the Build Alexa Auto SDK documentation for details about the build system and the Migration Guide for help migrating your build to the new version of Builder Tool. Extended the features of Alexa Presentation Language (APL) support for automotive. The APL module provides messages to report vehicle properties such as the display theme, driving state, and ambient light conditions. The property settings affect how APL documents render on screen; for example, some APL content is automatically hidden when the vehicle starts moving, and the display contrast updates with the day or night mode setting. Auto SDK 4.0 supports APL 1.9. For more information about the Auto SDK APL interface, see the APL module documentation. Added the CustomDomain interface, which establishes a bidirectional communication channel between your Auto SDK client application and your custom cloud skill. CustomDomain includes messages for exchanging directives, events, and context between the vehicle and your skill, achieving a fully customizable experience. For more information about the Auto SDK CustomDomain interface, See the Custom Domain module documentation. Added the MediaPlaybackRequestor interface, which enables Alexa to play the user\u2019s favorite media content as soon as they start their vehicle. MediaPlaybackRequestor simplifies content selection for the user by removing the need for the user to use buttons or voice commands to resume the Alexa media content that was playing when they stopped the vehicle. For more information about the Auto SDK MediaPlaybackRequestor interface, See the Alexa module documentation. Extended the AudioOutput interface and added configuration to allow ducking Alexa media. Your application can use this feature for enhanced control of Alexa content audio focus according to your platform requirements. For more information about audio ducking, see the Core module documentation. Updated the Auto SDK to use AVS Device SDK Version 1.25.0. For information about this version of AVS Device SDK, see the AVS Device SDK release notes. Added LVC support for Alexa Custom Assistant specialized handoffs. You can configure the default fallback and self-introduction prompts for your custom assistant while offline. For more information, see the Alexa Custom Assistant extension documentation. Integrated the Auto SDK Conan build system enhancements to AACS and the AACS sample app. You can use a single Gradle command to build AACS and the AACS sample app. For build instructions, see the AACS documentation. Added the following enhancements to the AACS sample app: Additional languages\u2014 The AACS sample app supports the following languages: US English ( en-US ), Australian English ( en-AU ), Canadian English ( en-CA ), Indian English ( en-IN ), British English ( en-GB ), German (d e-DE ), Spanish ( es-ES ), Mexican Spanish ( es-MX ), US Spanish ( es-US ), French ( fr-FR ), Canadian French ( fr-CA ), Hindi ( hi-IN ), Italian ( it-IT ), Japanese ( ja-JP ), and Brazilian Portuguese ( pr-BR ). The sample app language setting matches the device\u2019s system language setting and syncs the with Alexa as long as the setting is in the supported language list. If Alexa does not support the system language, the sample app GUI defaults to en-US and presents a list of languages for the user to choose from. Once the user selects the language override, the system language does not sync with the sample app again until the user logs out or disables Alexa. Network error prompts\u2014 You can configure the sample app to provide feedback to the user when Alexa cannot respond due internet connection issues. The feedback is a voice prompt or an error screen depending on the user action. Alexa app assets\u2014 The sample app can show Alexa logos (assets) on the setup screen and display cards instead of showing placeholder assets. Comms UI improvements\u2014 Updated the contacts uploading logic in the Comms UI AACS app component to ensure the sample app only uploads the contacts for the primary phone. Updated the AACS Telephony library to get the outgoing phone account using the Android standard API getDefaultOutgoingPhoneAccount . AACS Telephony no longer sends an account query intent when receiving the PhoneCallController.Dial message from the Auto SDK Engine. Added a new intent com.amazon.aacstelephony.bluetooth.connectionCheckCompleted , which AACS Telephony service broadcasts when it finishes the initial bluetooth connection check. Updated the alexa-auto-lwa-auth app component to use the Authorization Auto SDK interface for CBL authorization. Other changes Moved several source code directories within the aac-sdk root directory to support the enhanced build system. Removed aac-sdk/platforms/android/ . The deprecated Java platform interfaces and JNI are in their respective modules. For example, the Alexa module Java interfaces and JNI are moved from aac-sdk/platforms/android/modules/alexa/ to aac-sdk/modules/alexa/android/ Removed aac-sdk/extensions/aasb/ because using AASB messages with MessageBroker is the primary Auto SDK API. AASB code for each module is in the respective module directory. For example, the AASB code for the Alexa module is in aac-sdk/modules/alexa/aasb/ . Note that the AASB message headers to include in your application are not in this directory since they are generated as part of the Auto SDK build output. Moved aac-sdk/extensions/system-audio/ to aac-sdk/modules/system-audio/ Moved aac-sdk/extensions/bluetooth/ to aac-sdk/modules/bluetooth/ Moved aac-sdk/extensions/loopback-detector/ to aac-sdk/modules/loopback-detector/ Moved aac-sdk/platforms/android/alexa-auto-client-service/ to aac-sdk/aacs/android/ Moved aac-sdk/platforms/android/alexa-auto-client-service/app-components/ to aac-sdk/aacs/android/app-components/ Moved aac-sdk/samples/android-aacs-sample-app/ to aac-sdk/aacs/android/sample-app/ Moved aac-sdk/platforms/android/alexa-auto-client-service /commonutils/ , /ipc/ , and /constants/ to aac-sdk/aacs/android/common/ Moved AACS media player files to a directory audioOutput within aac-sdk/platforms/android/alexa-auto-client-service/service/ Moved the Media App Command and Control Android library from aac-sdk/platforms/android/maccandroid/ to aac-sdk/aacs/android/service/modules/maccandroid/ In the LVC extension, the LocalSearchProvider AASB messages now have topic LocalNavigation . For example, the existing message LocalSearchProvider.SearchRequest in 3.3 is LocalNavigation.SearchRequest in 4.0. The next major release version of Auto SDK will change the topic back to LocalSearchProvider . Deprecated the option to build AACS as an APK. Starting from Auto SDK 4.0, you can only build AACS as an AAR. Removed the Android sample app based on the Java platform interfaces. The AACS sample app demonstrates using Auto SDK on Android. Resolved issues Fixed an issue preventing the generic DEFAULT type LocalMediaSource from working in offline mode with LVC. Fixed a race condition in SpeechRecognizer in which enabling wake word detection immediately after calling startCapture() resulted in a missing call to stopAudioInput() when wake word detection was later disabled. Fixed a deadlock that could occur in an application that uses the deprecated AuthProvider interface and starts, stops, and restarts the Engine in quick succession. Fixed an issue in which Spotify playback commands were delayed on QNX. Fixed an issue in which the Engine added malformed PhoneCallController context to PhoneCallController events sent to Alexa. Fixed an issue in which AACS did not acquire audio focus prior to playing Alexa speech. Known issues General If you do not specify the deviceSettings.locales field of the Alexa module configuration, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not automatically declare support for default locale combinations if you assign an empty value to the locales field. The Engine does not persist the aace.alexa.wakewordEnabled Engine property setting across device reboots. Your application has to persist the setting and set the property again at each Engine start. AACS implements persisting this property and hence does not have this issue. If your Linux platform does not use AVX2 instructions, the Amazonlite wake word library initialization causes an illegal instruction error. When using LVC and stopping the Engine, the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your application should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED . The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. When the user requests to view their list of timers on an APL-enabled application, they cannot use an utterance such as \u201cAlexa, scroll up\u201d to scroll through the list shown on the APL card. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. On the Poky Linux 32-bit platform, the C++ sample app shuts down with an error on launch. In offline mode with LVC, you might not see the AlexaClient.DialogStateChanged THINKING state transition if the user invokes Alexa with hold-to-talk and your application provides the audio input data in one large chunk. In offline mode with LVC, Alexa gets stuck in the THINKING state and does not respond after changing the locale setting. The state recovers after a few minutes. The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the Engine attempts the refresh, it might take up to a minute to refresh the token after the internet connection is restored. Some Core module messages published by the Engine do not have a corresponding message for the application to report a handling failure. For example, if the user invokes Alexa by tap-to-talk, and the application cannot handle the AudioInput.StartAudioInput message, the Engine assumes the application handled the message properly and will provide audio data. As a result, the Engine state and application state might become out of sync. The affected messages are the following: AudioInput : StartAudioInput AudioOutput : SetPosition VolumeChanged MutedStateChanged Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications Alexa does not understand DTMF utterances that include letters. For example, \"press A\" and \"dial 3*#B\" do not result in the correct DTMF directives. The user might experience unexpected results by trying to dial or place calls in the following ways: Using utterances that include \u201cdouble\u201d, \u201ctriple\u201d, \u201chundred\u201d, or \u201cthousand.\u201d For example, calling a number such as 1-800-xxx-xxxx by saying \u201cAlexa call one eight double oh ...\u201d Pressing special characters such has \u201c#\u201d or \u201c*\u201d by saying \"Alexa press * #.\" The user cannot accept or reject incoming Alexa-to-Alexa calls by voice while playing a skill with extended multi-turn dialogs, such as Jeopardy or Skyrim. Entertainment If the user requests Alexa to read notifications while music is playing, they might hear the music play for a split second between the end of one notification and the start of the next. When an external media player authorization is in progress during Engine shutdown, a rare race condition might cause the Engine to crash. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. When using the System Audio module, Audible and Amazon music might not play correctly on i.MX8 boards. Local search and navigation In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize followup requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. AACS If you do not use the default audio output implementation (i.e., your application handles AudioOutput AASB messages), your application will not receive the AudioOutput.Stop message if Alexa media is playing when AACS shuts down. As a workaround, your application can listen to AASB.StopService or adopt AACSPinger to listen to the STOPPED state of AACS and stop the media accordingly. AACS Sample App The AACS Sample App does not show the language selection screen when the app is built with Preview Mode. The AACS Sample App only shows the language selection screen if there is a language mismatch with the system language setting at the first app launch. v3.3.0 released on 2021-09-30 Enhancements Added the DeviceUsage platform interface to provide the Alexa application network usage data to the Auto SDK Engine. The Auto SDK Engine emits this data as a metric to Amazon if Auto SDK is built with the Device Client Metrics extension. For more information, see the Core module README for C++ or Android . Extended the features of the Local Navigation module for the Local Voice Control (LVC) extension. The LocalSearchProvider platform interface now enables you to provide customers with offline navigation to street addresses, cities, and neighborhoods in addition to the existing support for local search and navigation to points of interest. See the Local Navigation module README for information about integrating the features. Note: There are updates to the LocalSearchProvider APIs. See the Migration Guide for details. Added a new generic DEFAULT media source to the list of sources supported by the LocalMediaSource platform interface. The DEFAULT source can be used for voice playback control of any arbitrary media sources on the infotainment system outside of deep-linked MACC applications using the ExternalMediaAdapter interface and existing sources supported by name through the LocalMediaSource interface. For details about integrating a default media source, see the Alexa module README for C++ or Android . Added offline LVC support for tuning to station names on terrestrial radio and SiriusXM. E.g., \u201cPlay CNN on Sirius XM\u201d and \u201cPlay KISS FM\u201d. This feature is already available in online mode. Enhancements for AACS: Added an app component called alexa-auto-carcontrol that deeply integrates Auto SDK car control features into the Android Automotive OS. For more information about AACS deep integration to Car Control, please refer to this README . Added an enhancement in which AACS can automatically sync Alexa\u2019s timezone and locale properties with the device system settings when you set the syncSystemPropertyChange field to true in your AACS configuration file. If you set the field to false or omit it, you still have flexibility to change the properties in your own implementation. Enhancements for AACS Sample App: Added a location sharing consent screen in Alexa setup and settings wherein the user has the option to enable or disable location sharing. Added support for rendering for TemplateRuntime display cards for the weather domain. Added support for rendering Amazon Presentation Language (APL) documents. Added media player transport control improvements. For example, shuffle and loop transport controls are added, and disabled transport controls are displayed. Added support for setup and setting menu specific to the Alexa Custom Assistant extension. Resolved Issues Android 11 requires the attribute android:foregroundServiceType to be defined in services that require permissions such as microphone and location. This is added to the AACS Android Manifest file. Also, the compileSdkVersion and targetSdkVersion to are updated to 30 in build.gradle . Added a UserIdentity value in AACS AuthStatus when the user finishes CBL login. Made the 'stateOrRegion' field optional in the AACS StartNavigation directive JSON parser. Implemented the AASB SetUserProfile message in the CBL module to ensure the user email and username will be sent to the client application after user login when enableUserProfile is set to true. Fixed an issue that blocked a valid transition from the THINKING to LISTENING AlexaClient dialog states. Updated the PhoneCallControllerCapabilityAgent to include context in PhoneCallController events per the PhoneCallController API specification. Fixed a memory leak observed during Engine shutdown in the Local Voice Control extension. Fixed a rare deadlock issue during Engine stop and start when using the AuthProvider interface. Fixed an issue in which the Engine erroneously allowed 3,000 coordinates in the \"shapes\" array of navigation state queried via Navigation::getNavigationState() . The limit is updated to 100 coordinates. Known Issues General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. The automotive HMI guidelines for display cards state that actionable display cards should be dismissed automatically after 30 seconds, and non-actionable display cards should be dismissed automatically after 8 seconds. This guideline is not descriptive enough since it does not clarify what is actionable and non-actionable content. The UX team is working on correcting the guideline to specify specific template types. The current automatic dismissal time for all Template Runtime display cards is 8 seconds. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. The generic DEFAULT LocalMediaSource type is not supported offline with LVC. If user gives a generic playback control request like \"Alexa, play\" when the Alexa application is operating in the offline mode with LVC, Alexa responds \"Sorry, something went wrong\". Other named players like USB work as expected in the offline mode. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. Local Search and Navigation When using LVC in offline mode, after requesting a list of POIs (e.g., \"find Starbucks nearby\"), Alexa does not recognize utterances like \"select the first one\" and does not display or read detailed information about the requested selection. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) If you are not using the default audio output implementation (i.e. your application handles AudioOutput AASB messages) and even though you are playing the Alexa pushed media content, Stop message would not be sent from AACS when AACS shuts down. e.g. If you are playing an audio stream for AmazonMusic, if AACS is stopped, AASB AudioOutput.Stop message would not be received. As a result, the media playing from your application would not be stopped. This issue will be fixed in the next release. As a workaround, your application can listen to [AASB.StopService]( extensions/aasb/docs/AASB/StopServiceMessage.html ) message or adopt AACSPinger (See README ) to listen to the STOPPED state of AACS and stop the media accordingly. v3.2.1 released on 2021-08-06 Note: All Auto SDK 3.2 extensions are compatible with 3.2.1. Enhancements Added additional APIs to the Connectivity module, which enable the voice up-sell conversation between the user and Alexa to activate a trial data plan or a paid subscription plan. Your implementation should call AlexaConnectivity::sendConnectivityEvent() to notify the Engine of the data plan type. To respond, the Engine calls AlexaConnectivity::connectivityEventResponse() . Added the configuration field aace.addressBook.cleanAllAddressBooksAtStart to Engine configuration. This field specifies whether to automatically delete address books each time the Engine starts. Resolved Issues Fixed an issue in which wake words cannot be detected correctly when using the SpeechRecognizer::startCapture() API with an external wake word engine. Known Issues General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) v3.2.0 released on 2021-05-19 Enhancements Added the DeviceSetup platform interface that handles events and directives related to device setup during or after an out-of-the-box experience (OOBE). After the user login, Alexa is informed that device setup is complete and starts the on-boarding experience, for example, by starting a short first-time conversation. For more information, see the Alexa module README for C++ or Android . Added support in the Connectivity module to provide the network identifier from the vehicle to Alexa, which enables automakers to offer full connectivity plans to customers. For connectivity status, the module supports sending the version of the terms and conditions through a field called termsVersion . Also, the termsStatus field accepts DEFERRED , which means Alexa can remind users to respond to the terms and conditions at a later time. Added the Mobile Authorization extension, which enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone, instead of opening a web browser and entering a code. Added the Bluetooth extension, which allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Added the Geolocation extension, which provides geolocation consent support. The user can grant consent to location sharing with Alexa from your application. Added the locationServiceAccessChanged(LocationServiceAccess access) API in the LocationProvider interface, which allows the Engine not to query the device location when the location service access is turned off on the device. Added the APL Render module, which enables APL rendering capabilities in an Android application. Note: This module is for you to experiment with APL document rendering on an automotive device. Do not use the module to render APL documents in a production vehicle. Added support in the Address Book module for a phonetic field. The phonetic field is required for resolving the name of a contact or navigation favorite if the name uses Kanji characters in Japanese. Updated the Docker container for the Auto SDK builder script to use OpenSSL 1.1.1k by default. Added an environment variable for you to change the OpenSSL version, if desired. For information about the OpenSSL version, see the Builder README . Updated the Auto SDK to use AVS Device SDK Version 1.22.0. For information about the AVS Device SDK, see the AVS Device SDK Release Notes . Enhancements for AACS: Added AACS instrumentation, which enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. For information about AACS instrumentation, see the README . Added an app component called alexa-auto-telephony , which enables you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. Added an app component called alexa-auto-contacts to enable AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information. Added the AACS AAR, which you can include in your application. The timeout for AASB synchronous messages is now configurable. For information about configuring the timeout, see the README . Enhancements for AACS Sample App: Added support for new features in the AACS Sample App. For example, it includes a menu for the user to select a language if the in-vehicle infotainment (IVI) language is not supported by Alexa, and it supports authorization with Preview Mode. Added support for the Alexa Custom Assistant extension to the Alexa Auto Client Service (AACS) Sample App. The sample app demonstrates how an application can use AACS with this extension. With app components included with the sample app, you can develop an application that handles assistant handoff and displays custom animation for your custom assistant. > Note: In order to use Alexa Custom Assistant extension with the AACS Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Enhancements for metrics uploading: The Auto SDK emits only registration metrics before user login is complete. Other metrics are emitted after user login. The Device Client Metrics (DCM) extension supports uploading more metrics from the vehicle than in previous versions. The DCM extension supports anonymizing all Auto SDK metrics. Enhancements for car control: Added prompt improvements. Alexa can provide a recommendation or ask for clarification after receiving an invalid or ambiguous user request. Suppose a user request targets the wrong mode, setting, or value for an appliance, such as \"Alexa, set fan speed to 100\", Alexa responds, \"Sorry, you can only set the fan between 1 and 10\". When the target in a user request is ambiguous, Alexa prompts for more information to determine the exact meaning of the request. For example, when a user says, \"Turn on fan\" (when the fan's default zone is not set), Alexa responds, \"For the driver, the passenger, or the rear?\" This feature is supported online and offline. Improved asset management for car control, which enables Alexa to accept utterances only a few seconds after the user logs in. Previously, the user had to wait up to 20 seconds for Alexa to accept utterances. Improved the Auto SDK Voice Chrome extension to allow the height and width of the linear voice chrome to be controlled by the parent layout. Previously, the dimensions were fixed. Resolved Issues Disabled APL by default in AACS to make sure utterances like \"tell me a joke\" work correctly without handling APL. If your platform wants to implement APL, see the AACS Configuration README to enable it. An SMS message can be sent to an Alexa contact correctly. A user request to send an SMS message to an Alexa contact no longer results in an Alexa-to-Alexa message. For car control, there is no longer a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). After the AmazonLite Wake Word locale model is switched from the default (en-US) to another locale model (e.g., de-DE), the newly selected locale remains in effect after the user quits and then restarts the application. Numeric weather IDs are passed to AVS for the TemplateRunTime API, making it easier for you to display weather icons that are consistent with your user interface. After the user disconnects the phone, if the user tries to use Alexa to make a call, Alexa responds correctly by reminding the user to connect the phone. Previously, Alexa tried to dial the number. After the user pauses on Spotify and presses \u201cPlay\u201d to resume, the player starts correctly from the point where the player stops. Previously the player skipped ahead, resuming from an incorrect place. AutoVoiceChromeController and StateChangeAnimationScheduler of the Voice Chrome extension are thread-safe now, preventing the Alexa app from crashing in different scenarios (e.g. when changing to the previous music track). Fixed a race condition in AuthorizationManager during the Engine shutdown. Known Issues General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) v3.1.0 released on 2020-12-15 Enhancements Added the Authorization platform interface that replaces the CBL platform interface and the AuthProvider platform interface. For information about how the Alexa Auto SDK Engine handles authorization with the Authorization platform interface, see the Core module README . Note: Logging out from CBL or Auth Provider authorization clears the databases that store user data, such as alerts and settings. For example, when the user logs out, pending alerts in the database are cleared to ensure that the next user who logs in does not receive the alerts. In addition, upon logout, the locale setting is reset to the default value in the Engine configuration. Therefore, if the current device locale is different from the default locale, you must set the locale before starting an authorization flow. Added the Text To Speech module that exposes the platform interface for requesting synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. Added the Text To Speech Provider module that synthesizes the Alexa speech. The Text to Speech provider requires Auto SDK to be built with the Local Voice Control extension. For information about these modules, see the Text To Speech module README and Text To Speech Provider README . Note: This feature may only be used with voice-guided turn-by-turn navigation. Added the Connectivity module that creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. For information about the Connectivity module, see the README . Added the Local Navigation module for the Local Voice Control (LVC) extension. This module enables you to provide customers with offline search and navigation to points of interest (POI) by leveraging the POI data of an onboard navigation provider. The POIs include categories, chains, and entities. The Local Voice Control (LVC) extension is required for the Local Navigation module. Note: Offline search with the Local Navigation module is only supported in the en-US locale. Added the Alexa Auto Client Service (AACS) Sample App that demonstrates how an application uses AACS. The Auto SDK includes the app components used by the AACS Sample App, which you can also use when developing an application that communicates with AACS. For information about the AACS Sample App, see the README . Added support for Digital Audio Broadcasting (DAB) radio. For more information about the DAB local media source, see the Alexa module README . Enhancements for AACS: Enhanced the file sharing protocol of AACS by using Android's FileProvider. This enhancement grants AACS permission to access files within your AACS client application, which are required by configuration fields for the Auto SDK. Added support for the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. For information about how AACS uses FileProvider and ContentProvider , see the README . Added support for a ping broadcast to check the AACS connection state. For more information about how to use ping , see the README . Added support for caching AASB message intent targets based on AASB Action. This enables you to define an intent filter with a subset of the possible actions for an AASB topic. For more information on specifying intent targets, see the README . Added support for Text-to-Speech Service, which allows Android applications to interact with Android TTS APIs to convert text to speech. For information about the Text-to-Speech Service, see the README . Resolved Issues On Android, the Engine returns the correct value ( UNDEFINED ) for requests to LocationProvider.getLocation() when the device does not have access to location. Previously the Engine populated the user geolocation with a default value when Location.UNDEFINED was returned in LocationProvider.getLocation() . In the AACS commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime could only parse the payload field of the AASB RenderPlayerInfo message payload. Now it can parse the overall AASB payload. Notifications sound plays correctly. Previously, the sound did not play as expected due to improper channel configuration. The CBL module code request flow correctly applies the locale setting to the Login With Amazon (LWA) code request. Previously, the URL returned by LWA was always in the en-US locale. If you log out and log in, the client-side Do Not Disturb (DND) state is synchronized with Alexa. Known Issues General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However, \u2018send message\u2019 instead of \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) AACS enables APL by default, but it does not have a default implementation for APL. AACS expects the client application to handle the messages or directives from the Engine. If APL is not handled on the client side, utterances that trigger APL capabilities, such as \"tell me a joke,\" fail. To disable APL, add the lines below to the AACS configuration file . \"aasb.apl\": { \"APL\": { \"enabled\" : false } } Additional Changes Starting with v3.1.0, the Local Voice Control (LVC) extension is no longer supported on ARM32 platforms. v3.0.0 released on 2020-10-09 Enhancements Added Alexa Auto Client Service (AACS), which enables OEMs of Android-based devices to simplify the process of integrating the Auto SDK. For more information about AACS, see the AACS README . Added support for removing local media sources at runtime, such as a USB drive or a Bluetooth device. Previously, if a user removed a USB drive and then requested to play music from the USB drive, the Auto SDK would attempt to play and not return an appropriate error message. This feature is enabled with an existing field in the LocalMediaSource platform interface state. For information about the platform interface state, see the alexa module README . Resolved Issues On QNX, when a portion of music on Spotify is skipped, either by the user saying, \"Skip forward,\" or by the user skipping to a different song, the volume is no longer reset to the default level. A user barging in when music is playing no longer hears an Alexa response to the barge-in request. Previously, this issue happened if the System Audio extension was used. When streaming music from Alexa, the user can switch to a local media source by using one utterance, such as \"Alexa, play radio.\" Previously, Alexa would not switch to the local media source after the first utterance. The user needed to issue the request again before Alexa could play from the local media source. Known Issues General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) In the commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime can only parse the payload field of the AASB RenderPlayerInfo message payload. The payload field of RenderPlayerInfo is the inner payload of the nested payload structure. When using TemplateRuntime.parseRenderInfo(String json) , provide it with the embedded JSON as a string of the string value whose key is payload in the RenderPlayerInfo message\u2019s payload instead of the overall AASB payload. Additional Changes Starting with Auto SDK v3.0, we no longer support the Automotive Grade Linux (AGL) Alexa Voice agent in the Auto SDK. If you intend to use the AGL Alexa Voice Agent, continue using Auto SDK v2.3.0, which is the last version that provides AGL support. v2.3.0 released on 2020-07-31 Enhancements Added a new Messaging module that provides support for Short Message Service (SMS) to allow a user to send, reply to, and read messages through Alexa. Added support for zones to car control for online-only devices so the customer can target endpoints by location (e.g., \u201cset the front fan to 7\u201d). This feature was supported only with the Local Voice Control (LVC) extension, and endpoints belonged to exactly one zone. The features for online-only and LVC devices are at parity and now include assigning an endpoint to multiple zones and setting a default zone. Endpoints in the default zone take higher priority than endpoints not in the default zone when no zone is specified in an utterance. Added support for \u201csemantics\u201d for car control to enable \u201copen\u201d, \u201cclose\u201d, \u201craise\u201d, and \u201clower\u201d utterances to control endpoints. Added a method to the 'AlexaClient' platform interface to stop foreground-focused Alexa activity on the device (e.g., locally canceling ongoing TTS when the user selects a list item or presses a cancel button). Added support for Dynamic Language Switching. Previously, Alexa could only understand and respond in one language at a time. Now Alexa supports two languages at once and automatically detects the user's spoken language and responds in the same language as the utterance. The supported locale pairs are the following: [ \"en-US\", \"es-US\" ] [ \"es-US\", \"en-US\" ] [ \"en-IN\", \"hi-IN\" ] [ \"hi-IN\", \"en-IN\" ] [ \"en-CA\", \"fr-CA\" ] [ \"fr-CA\", \"en-CA\" ] Note: Dynamic Language Switching works online only. For hybrid systems using the LVC extension, offline Alexa understands and responds in the language of the primary locale. * Updated radio tuning increments for \u201cAM_RADIO\u201d and \u201cFM_RADIO\u201d Local Media Source types to support the en_IN locale. * Alexa Voice Agent now supports AGL Itchy Icefish v9.0.2. * Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binary. Resolved Issues Fixed an issue in which navigation road regulation and maneuver events resulted in \u201cINVALID_REQUEST_EXCEPTION\" or \"INTERNAL_SERVICE_EXCEPTION\" error logs. Fixed several failing car control utterances including those for offline AC controls and those using the words \u201cmy\u201d or \u201clights.\u201d Fixed an issue in External Media Player that caused the \u201cNEXT\u201d play control request to be issued twice for ExternalMediaAdapter (e.g., MACC) and LocalMediaSource platform interface handlers. Fixed an issue in which the Engine did not stop music playback after user logout. Fixed an issue that caused Spotify to play at an increased and unsteady rate on QNX. Fixed an issue with the --use-mbedtls build option that caused a crash in the Android sample app at startup. Fixed an issue in the Engine metrics implementation in which regular expression matching with a large number of data points caused a crash. Fixed an issue in MACC in which players removed while the Engine was running (such as by the uninstallation of a linked MACC-compliant app) could not be rediscovered properly and used again, even if the player was restored (such as by the reinstallation of the app and user login). Previously, the rediscovery logic left insufficient time to process the player removal event before trying to discover players again, resulting in a loop. Now the rediscovery step runs at 5-minute intervals. Fixed an issue with the Engine's SQLite local storage database in which concurrent access to the database caused a crash. Fixed various memory leaks and intermittent crashes caused by race conditions at Engine shutdown. Fixed an issue on Android API 25 in which a large number of emitted logs could cause a crash due to a JNI local reference table overflow. Fixed an issue in which you experienced unexpected results if the local timezone of your device differed from the timezone configured through the Alexa companion app. Known Issues General A user barging in when music is playing sometimes hears the Alexa response to the barge-in request and the music at the same time if System Audio extension is used. If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The user must enunciate \u201cline-in\u201d in utterances targeting the \u201cLINE_IN\u201d Local Media Source type in order for Alexa to recognize the intent. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. On QNX, when a portion of music on Spotify is skipped, either by the user saying \"Skip forward\" or by the user skipping to a different song, the volume is reset to the default level. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. v2.2.1 released on 2020-05-29 Enhancements Added enhancements to the maccandroid module to allow SupportedOperations to be overridden to support custom actions. Enhanced the TemplateRuntime platform interface to support focus and audio player metadata in renderTemplate and renderPlayerInfo methods. This is a backward compatible change, see the migration guide for details. SpeakerManager is now a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\". Resolved Issues Fixed issues in the maccandroid module to a) rediscover media apps after getting the app removed callback, and b) change the behavior to only report unauthorized when the user specifically asks to play a media app. On the QNX platform, prevent unnecessary flushing for audio output. Known Issues On the Android Sample App, media playback gets into \"No Content Playing\" state where all GUI playback control breaks, when pressing next after force closing an external media app. Playback controls in the C++ Sample App Playback Controller Menu are static text items and do not change visual state (e.g. add/remove, hilite, select) based on audio player metadata. v2.2.0 released on 2020-04-15 Enhancements Added a Car Control module to support online-only car control use cases without the optional Local Voice Control (LVC) extension. The Car Control module provides the car control functionality introduced in Auto SDK 2.0.0 but does not require the LVC extension. Made various enhancements to the External Media Player (EMP) Adapter to improve EMP behavior and facilitate implementation of Alexa audio focus. Introduced the Property Manager, a new platform interface that allows you to set and retrieve Engine property values and be notified of property value changes. Added support for setting the timezone of a vehicle. The AlexaProperties.h and AlexaProperties.java files now include a TIMEZONE property setting that is registered with the Property Manager during initialization and which you can manage using the Property Manager platform interface. Added support for specifying a custom volume range for voice interactions in implementations that use the optional Local Voice Control (LVC) extension. Separated the LVC language models into independent APKs rather than providing them directly in the LVC APK as was done in previous releases. One language model APK is provided for each supported locale (currently en-US, en-CA, and fr-CA). Resolved Issues Fixed an issue where the CBL state did not change to stopped when you cancelled login with CBL::cancel() . Fixed an issue where volume adjustments were lost when pausing and resuming music. Fixed an External Media Player (EMP) Engine implementation that caused an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession. Fixed an issue where the Engine might hang during shutdown if it was shut down while TTS was being played or read. Fixed an issue where Auto SDK initialization failed at startup when applications using the optional LVC extension didn't register a NetworkInfoProvider platform interface. Fixed an issue where building the Auto SDK with sensitive logging enabled was not working as expected. Added alerts error enums ( DELETED and SCHEDULED_FOR_LATER ) to the Alerts.h and Alerts.java files. With the exception of road regulation and maneuver events, the Alexa cloud no longer returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to navigation events sent by the Auto SDK. Alexa now prompts or notifies the clients and rejects the ping packet when the user deregisters from the companion app. Known Issues General If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". Auto SDK v2.2.0 adds support for setting the timezone of the vehicle, which allows your device to synchronize with the timezone set in the Alexa companion app; however, the Auto SDK currently does not receive a SetTimeZone directive when the timezone is changed from the companion app. Navigation The Alexa cloud currently returns an INTERNAL_SERVICE_EXCEPTION in response to any navigation road regulation or maneuver event sent by the Auto SDK (triggered by an utterance such as \"which lane should I take\", for example). You may see a harmless error/exception in the logs. Car Control Certain car control utterances return errors. Problematic utterances include natural versions of certain test utterances (for example, \u201cturn on the light\u201c instead of \u201cplease turn on the light in the car\u201d); utterances that include the words \u201clights\u201d or \u201cmy\u201d; and utterances to control the defroster or defogger that use \u201cput on\u201d or \u201cset on\u201d rather than \u201cturn on\u201d or \u201cswitch on\u201d. Setting the air conditioner using range controller control capabilities (for example \u201cset the air conditioner to 65\u201d or \u201cset the air conditioner to low\u201d) is not currently supported. In offline mode, the utterances \"turn ac on\u201d, \u201cturn off ac\u201d, \u201cturn ac off\u201d, and \u201cturn up ac\" return errors. Communications When using LVC in online mode, users can redial a call when the phone connection state has been switched to OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. Entertainment A user playing any skill with extended multi-turn dialogues (such as Jeopardy or Skyrim) cannot accept or reject incoming Alexa-to-Alexa calls using voice. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d Authentication The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. v2.1.0 released on 2019-12-19: Enhancements Added Navigation enhancements to support the following features: Add a waypoint - Enables users to search and add waypoints to their current route along the way or start a new route with a given set of waypoints. Cancel a waypoint - Enables users to cancel a waypoint with voice. Show/Navigate to previous destinations - Enables users to view previous destinations and navigate to any of their previous destinations.. Turn and Lane Guidance - Enables users to ask Alexa for details about their next navigation instruction. Control Display - Enables users to interact with their onscreen map applications. Note: The Navigation enhancements are not backward-compatible with previous versions of the Auto SDK. The startNavigation() method supersedes the setDestination() method, and many new methods have been implemented. See the Migration Guide for details. Added support for Alexa Presentation Language (APL) rendering to present visual information and manage user interactions with Alexa. Note: In order to use APL rendering with the Android Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. * Added support for the Alexa DoNotDisturb (DND) interface, which allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . Note: Alexa does not notify the user of the DND state. * Added a System Audio extension to provide the default audio capturing and playback functionality for various platforms, including audio input/output on QNX platforms. The Alexa Auto SDK Builder automatically includes the System Audio extension when you build the Auto SDK. * Added local media sources (LMS) and hybrid car control support to the Automotive Grade Linux (AGL) Alexa Voice Agent. * Added onAuthFailure() to the AuthProvider platform interface and an AUTHORIZATION_EXPIRED argument to the cblStateChanged() method of the CBL platform interface to expose 403 unauthorized request exceptions from Alexa Voice Service (AVS). These may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. * Added support for call display information change notifications (caller ID) to the optional Alexa Communication extension. Resolved Issues Fixed an issue where contact uploading failed for contacts without addresses. Fixed an issue where if the user rejected an incoming Alexa-to-Alexa call via voice, ringtones did not sound for subsequent incoming calls until the user either answered an incoming call via voice or made an outbound call. Fixed an issue that required you to assign unique entry IDs to contacts and navigation favorites to ensure that the ID space used for contacts and navigation favorites did not collide. Fixed an issue where multiple automotive devices using the same account at the same time could access contacts from phones paired across those devices. Fixed an issue where uttering \"stop\" when a timer sounded during an Alexa-to-Alexa call ended the call, not the timer. Added enhancements to the maccandroid module (Spotify) to simplify the MACCPlayer handler implementation. Rediscovery now occurs automatically, and the authorization TTS error events no longer occur repeatedly. Known Issues The Alexa cloud currently returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to any navigation event sent by the Auto SDK. You may see a harmless error/exception in the logs. The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If the user deregisters from the companion app, Alexa does not prompt or notify the clients and does not reject the ping packet. If you log out and log in, the Do Not Disturb (DND) state is not synchronized with Alexa. When you cancel login with CBL::cancel() , the CBL state does not change to stopped. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or* using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. The Engine may sometimes stop abruptly on shutdown due to a race condition. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d A user playing Jeopardy or Skyrim cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". When pausing and resuming music, volume adjustments are lost. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession. v2.0.0 released on 2019-09-10: Enhancements Added offline enhancements to improve offline car control support and add support for: offline car control enhancements - to support generic controls that represent what can be controlled in a vehicle; for example: interior lighting, fans, temperature zone (driver and passenger), vent position, defroster, air conditioner, and recirculation. > Note : The car control enhancements are not backward compatible with previous versions of car control. The configuration and platform interface have changed. offline entertainment - to support tuning to a specific frequency or SiriusXM channel, tuning to radio presets, switching between car audio sources (bluetooth, radio, satellite radio, CD player, etc.), and controlling local audio sources (pause, shuffle, loop, etc.) offline communications - to support uploading contacts, calling a number or a contact, answering, declining, redialing, or ending a call, and dialing digits during a call offline navigation - to support navigating to favorite locations and canceling navigation Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets. Added online navigation enhancements to support navigating to favorite locations and answering ETA and time to destination questions. Introduced the Address Book module , which includes a common platform interface that you can implement to either upload user data to the Alexa cloud or allow the local communications and navigation capabilities to access user data for offline use cases (supported by the optional Local Voice Control (LVC) module). The Address Book module supersedes the Contacts Uploader module, which supports only phone contacts and only online use cases. Introduced a new core Audio service and API to implement audio input and output providers, and deprecated the existing MediaPlayer and Speaker platform interfaces in the Alexa module. This redesign simplifies integration with platform-specific audio capabilities and enables implementation of new, advanced audio features. NOTE: The new core Audio service and APIs are not backward compatible with previous versions of the Alexa Auto SDK (prior to version 2.0.0). Added a library to support the Device Client Metrics (DCM) extension for additional platforms such as Linux and QNX in addition to Android, which was supported in release 1.5. This library is required to upload metrics and vehicle information to the Amazon cloud. Added support for Voice Chrome for Android , an extension available through your Solutions Architect or Partner Manager that provides a Voice Chrome library for the Android platform. This library allows you to display voice chrome animations of different Alexa states to the user on screen. Added an integrated wake word enhancement to ignore Alexa waking itself up . In order to implement this enhancement, you must provide audio loopback via the platform or application. Added local pause handling to the PlaybackController to allow non-voice interactions to pause media playback from the AudioPlayer source immediately, without waiting for a response from the cloud. Added Geolocation support to the Navigation module. Geolocation support enables location-based services (which are used to answer questions such as \u201cwhere am I\u201d or \u201cwhat\u2019s the weather\u201d) to use the location information provided by the platform. Note: In order to make use of this functionality, you must register the Navigation platform interface for Geolocation support. * Enhanced the builder scripts to simplify the build process by removing unnecessary options and including the default components for different targets. For details see the Builder README . * Refactored the Java Native Interface (JNI) code used for Android platform interfaces for more modular deployment. In place of a single AAR including all Auto SDK native libraries, the Alexa Auto SDK now generates multiple AARs (one per module). Please see the builder README and the Android Sample App README for details. Resolved Issues Fixed an issue where music streaming from online music service providers continued to play when the user switched to a local media source. Fixed an issue where an MACC app (Spotify) could automatically play after the first utterance. Fixed a race condition in the Navigation module that occasionally caused Cancel Navigation to fail. Fixed broken links in the documentation. Known Issues Calling numbers such as 1800xxxxxxx using utterances such as \"Alexa call one eight double oh...\" may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore, when requesting Alexa to call or press digits, we recommend that your client application ignore special characters, dots, and non-numeric characters if not relevant to the context. The Engine may crash during shutdown due to a race condition in the Local Media Source Engine implementation. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. In online mode, Alexa does not recognize the utterance \"Switch to line in.\" A user interacting with multiturn skills such as Jeopardy cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the user rejects an incoming Alexa-to-Alexa call via voice, ringtones do not sound for subsequent incoming calls until the user either answers an incoming call via the VUI or makes an outbound call. If you change your Car Control configuration or custom assets during development after Local Voice Control (LVC) was previously running, you should stop your application and LVC, change the configuration or custom assets, uninstall and reinstall LVC, and relaunch your application to ensure the changes are applied. To ensure that the ID space used for contacts and navigation favorites does not collide, you must assign unique entryId s to contacts and navigation data. If you use the same entryId , re-uploading contacts may cause navigation favorites to become unavailable to Alexa, and re-uploading navigation favorites may cause contacts to become unavailable. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\" Alexa uses different audio channels, such as dialog (user utterance or TTS) and content (music), and shuffles between them to respond to user requests. As a result of this shuffling, content (such as music playback) that gets paused to accommodate higher priority channels may regain foreground audio focus and resume content in bursts between the outputs of higher priority channels (such as Alexa TTS or ongoing alerts). To avoid this, platforms should maintain the audio focus for a few extra milliseconds. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.6.3 released on 2019-12-02: Enhancements This release is for bug fixes only. There are no new features or enhancements. Resolved Issues Fixed a race condition that could cause follow-ons to a TTS request (for example asking for movies nearby) not to play while Alexa is speaking or playing something. Known Issues All known issues from v1.6.0. v1.6.2 released on 2019-10-11: Enhancements Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets. Resolved Issues n/a Known Issues All known issues from v1.6.0. v1.6.1 released on 2019-06-21: Enhancements This release of Alexa Auto SDK includes updates for music certification. Resolved Issues Resolved issues are limited to music certification updates: Added fixes from AVS Device SDK v1.12.1 for music certification. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Documentation updates. Known Issues All known issues from v1.6.0. v1.6.0 released on 2019-05-16: Enhancements General availability for Linux target platforms, including: Linux x86-64, Linux ARM 64 (armv8a), and Linux ARM 32 (armv7a). Alexa Auto SDK v1.6.0 enhances the C++ Sample App by improving the reference implementation for Linux platforms. Read more about the C++ Sample App here . Resolved Issues Fixed an issue where Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. Made changes to External Media Player events to send the service id and agent details, which are now mandated by the Alexa Music service. If you are using previous versions with Local Media Source switching or third-party app with MACC, you should upgrade to Alexa Auto SDK v1.6.0 to continue using the corresponding functionality. Known Issues If the local timezone of the device differs from the timezone that was configured through the Alexa companion app, you may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\u201d If you play your notifications while music is playing, you will hear the music for a split second between the end of one notification and the start of the next. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.5.0 released on 2019-03-06: Enhancements Added a C++ sample application to demonstrate use cases that the Alexa Auto SDK supports. Read more about the C++ Sample App here . Released the code for the AGL Alexa Voice Agent, a binding for Automotive Grade Linux powered by Alexa Auto SDK v1.5. The software is shipped as a standard AGL binding that exposes an API for speech recognition using the Alexa Voice Service. Please refer to the AGL Alexa Voice Agent documentation for instructions to build, install, and test the binding on an R-Car M3 board. Added support for runtime selection of the AmazonLite wake word locale. The AmazonLite locale will automatically switch when the AVS locale is switched. Added support for optionally logging and uploading Alexa Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and UPL between the request and Alexa\u2019s response. Please contact your SA or Partner Manager for details or to request this package for Android. Added support for an optional platform interface EqualizerController . The Equalizer Controller enables Alexa voice control of device audio equalizer settings by making gain adjustments to three frequency bands (\u201cBASS\u201d, \u201cMIDRANGE\u201d, and/or \u201cTREBLE\u201d). Added an optional Code-Based Linking (CBL) authorization implementation in the Engine. With the new cbl module, the Engine handles acquiring access tokens. A CBL platform implementation should be registered with the Engine in place of an AuthProvider implementation to use this method for authorization. Improved the usage and deployment of the Local Voice Control extension on Android. Please contact your SA or Partner Manager for more information. Updated the vehicle information configuration API to include a vehicle identifier. An aace.vehicle.info.vehicleIdentifier property of vehicle configuration is now available through the existing VehicleConfiguration . Resolved Issues Fixed an issue where barging in while many unprocessed Speak directives are queued could cause SpeechSynthesizer to become unresponsive or crash Added an EXPECTING state to the AlexaClient DialogState to accommodate multi-turn for hold-to-talk interactions. When more user input is required during an interaction, tap-to-talk interactions will transition directly from EXPECTING to LISTENING whereas hold-to-talk will remain in the EXPECTING state until listening is manually triggered. Fixed an issue where the Android Sample App could get stuck in a loop of INVALID_REQUEST_EXCEPTION errors being thrown repeatedly after MACCAndroidClient reported an error. Note: To fix this, the C++ ExternalMediaAdapter::getState method signature changed to allow the implementation to say whether the state it provides is valid. This change is not backward compatible. Fixed an issue where the Android Sample App created a syslog sink and logged VERBOSE in release builds. Note: As part of the fix, the default Engine logger sink id changed from console to default . Existing calls to LoggerConfiguration::createLoggerRuleConfig with sink id \"console\" should be changed to sink id \"default\" . Known Issues The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.4.0 released on 2018-12-17: Enhancements The Alexa Auto SDK now supports the Local Voice Control extension. The Local Voice Control extension enhances the Alexa Auto experience by providing voice-based car controls whether connected to the internet or not. In this release, the Local Voice Control extension will provision access only to the car\u2019s climate control. Note : This extension is available on request - Please contact your Amazon Solutions Architect (SA) or Partner Manager for more information. Resolved Issues No resolved issues. Known Issues The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.3.1 released on 2019-06-21: Enhancements This release of Alexa Auto SDK includes updates for music certification. Resolved Issues Resolved issues are limited to music certification updates: Migrated to AVS Device SDK v1.12.1 for music certification. As part of the migration there is a new dependency on openssl . Developers using their own build system may need to make changes in order to accommodate this new dependency when linking AVS Device SDK. Fixed ExternalMediaPlayerAdapter getState() failure that triggered INVALID_REQUEST_EXCEPTION/Bad Request exceptions. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Updated the Android Sample App log view implementation for improved stability and performance. Bug fixes and documentation updates: Additional test in AuthProviderEngineImpl::doShutdown() to avoid null pointer exception. Fixed an issue with SQLiteStorage::removeKey() where the DELETE FROM statement repeated the FROM . Fixed a race condition in AudioChannelEngineImpl::setSource() with back to back TTS. Internal calls to AudioChannelEngineImpl::executePlaybackFinished() now save the player offset. Internal calls to AudioPlayerEngineImpl::removeObserver() now remove an AudioPlayerObserverInterface observer instance instead of adding it. Use static_cast<unsigned char> for upper/lower character conversions. The platform interfaces have not changed, however the following C++ and Android enums are updated: * The enum class DialogState inserts the EXPECTING enum constant. * The enum class ConnectionChangedReason inserts NONE , SUCCESS , and UNRECOVERABLE_ERROR enum constants. Known Issues All known issues from v1.3.0. v1.3.0 released on 2018-11-20: Enhancements Android 8 and ARM v8a platform support. Making calls to contacts from a locally-paired mobile phone as long as the Alexa Auto SDK has a valid auth token. Read more about Contact Uploader API . Redial, answer, terminate, and decline calls using voice. End users can also send dual-tone multi-frequency (DTMF) via voice to interact with Interactive Voice Responders (IVRs). Read more here Phone Call Controller . Switching to local media sources, generic controls and deep linking into 3rd party media applications compatible with the Amazon Media App Command and Control (MACC) specification using the External Media Player Interface 1.1. This allows customers to switch between a CD player, AM/FM player, and auxiliary input that is MACC-compliant. Read more here Handling External Media Adapter with MACCAndroidClient . Enhancement for 3rd party wake word engine to enable cloud based verification. Provides a way to override Template Runtime display card timeout values for RenderTemplate and RenderPlayerInfo by updating the templateRuntimeCapabilityAgent Engine configuration values. Resolved Issues No resolved issues. Known Issues The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices. v1.2.0 released on 2018-10-15: Enhancements Additional information related to the presentation of alerts is now available. The extended interface now includes Alert token, type, rendering time, and label if applicable when an alert is set and notification when an alert is deleted. In the Navigation platform interface, SetDestination now provides business hours and contact information for a returned location when available. Resolved Issues If a location is not available, the location state is set to unavailable . Previously it was treated as (0,0) , which was a valid value for longitude and latitude. Fixed an issue related to stopping an alert where there could be up to a 10 second delay before the alert completely stopped. Fixed issue where the TemplateRuntime platform interface could not be registered before AudioPlayer . Known Issues There are no known issues in this release. v1.1.1 released on 2018-09-10: Enhancements This release is for bug fixes only. There are no new features or enhancements. Resolved Issues Updated a dependency build recipe to skip the checksum verification to allow for document changes in the current tag. Known Issues There are no known issues in this release. v1.1.0 released on 2018-08-31: Enhancements Added support for choosing one of multiple network adaptors before starting the Engine. Added support for the latest Amazon Wakeword Engine. Added custom volume control support for infotainment system's native input volume range. The range that comes down to the device will be 0 to 100. Added support for encoding the utterance in OPUS format with the Amazon Wakeword Engine as well as PTT. Our builder pulls the libopus source code as a part of build process. Added Locale API to return the list of Alexa-supported locales. Updated Vehicle Information API to capture the microphone details. Added support for routines, music alarms, timers and alarms volume management, and deleting all timers and alarms. Added support for TemplateRuntime Interface 1.1, which provides visual playback control for Alexa-enabled products with TemplateRuntime Interface support. This includes upgrades to PlaybackController Interface 1.1 and TemplateRuntime Interface 1.1. Note : The older button-press APIs ( playButtonPressed() , nextButtonPressed() , etc.) have been deprecated in favor of the new generic buttonPressed(PlaybackButtonType) . Updated the builder script to confirm compliance with open source component licenses. Resolved Issues There are no resolved issues in this release. Known Issues There are no known issues in this release. v1.0.2 released on 2018-08-08: Enhancements This release is only for documentation updates. There are no new features or enhancements. Resolved Issues Only name change updates were made to the documentation. There are no resolved issues in this release. Known Issues There are no known issues in this release. v1.0.1 released on 2018-07-31: Enhancements This release is for bug fixes only. There are no new features or enhancements. Resolved Issues The Engine now reconnects to Alexa when the NetworkInfoProvider updates the network status. All shared memory objects are now freed when the Engine object is disposed. We fixed a media playback state issue in the Engine that caused an unexpected pause and resume for a media stream that was already stopped. We added AudioPlayer::playerActivityChanged to the Android APIs. Updated the AuthError enumeration with additional error types. Removed deprecated createAuthConfig() configuration method. Fixed issue in the JNI where trying to create a UTF-8 string with invalid characters caused a crash, seen when sensitive logging is enabled. Improved JNI thread handling. Enabled capability registration for phone call control. We fixed an issue where the Android platform build failed on the initial attempt when using clean code. Known Issues There are no known issues in this release. v1.0.0 released on 2018-06-29: Enhancements Alexa Auto SDK now supports two Navigation directives. SetDestination CancelNavigation Added support for phone control APIs. The PhoneCallController platform interface supports the Dial directive with three events: CallActivated CallTerminated CallFailed Support for Amazon Wake Word Engine (WWE) Known Issues The Engine doesn't immediately reconnect to AVS when the NetworkInfoProvider updates network status. Some shared memory objects are not freed when the Engine object is disposed. Sample App issues are documented in the Sample App README . v1.0.0 Beta released on 2018-04-29: Enhancements The following enhancements were added to the Alexa Auto SDK since the last Alpha release (binary). SetDestination() API added to the Navigation module (see the Modules sections in the \"Alexa Auto SDK\" readme.) Android Sample Application updated with a number of features such as rendering of Display Cards (Shopping List, Coffee Shops Nearby, etc), handling of the SetDestination() API, Notifications, LWA (Login with Amazon) Known Issues SDK: While the SDK does build against Android API22 and above and runs successfully on Android O devices, our current testing shows a native-code linking error when actually running on API22 devices. Android Sample App: M3U and PLS based stream URLs are not parsed before sent to the Android Mediaplayer. Affects live streams typically coming from TuneIn and IHeartRadio services Media playback can take a long time to start sometimes for iHeartRadio and TuneIn The Android Alexa Auto SDK Sample App was developed on an Android tablet with 2048 x 1536 resolution screen size. It can run on smaller devices, but some of the display cards may not display correctly During Playing Media in the Sample App we see the following messages (none of these will cause any issues): E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=streamFormat E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=progressReportDelayInMilliseconds E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=expectedPreviousToken E/AAC:aace.alexa.AudioChannelEngineImpl:validateSource:reason=invalidSource E/AAC:aace.alexa.AudioChannelEngineImpl:pause:reason=invalidSource,expectedState=X On App startup we see the following messages (none of these will cause any issues): E/AVS:SQLiteAlertStorage:openFailed::File specified does not exist.:file path=/data/user/0/com.amazon.sampleapp/cache/appdata/alerts.sqlite Several minor documentation issues that will be addressed in the GA release","title":"CHANGELOG"},{"location":"CHANGELOG/#change-log","text":"","title":"Change Log"},{"location":"CHANGELOG/#v400-released-on-2021-12-15","text":"","title":"v4.0.0 released on 2021-12-15"},{"location":"CHANGELOG/#enhancements","text":"Deprecated the C++ and Java platform interfaces in favor of an asynchronous message-based API. Auto SDK client applications use the new MessageBroker to publish and subscribe to Alexa Auto Services Bridge (AASB) messages. The C++ sample app is refactored to use the new API to provide a reference implementation for Linux platforms. The Alexa Auto Client Service (AACS) sample app provides the reference implementation for Android platforms. See the Auto SDK Migration Guide for help migrating your application to use the new API. Enhanced the Auto SDK build system with the Conan package manager. The new build system introduces modular builds, better dependency management, and simpler build artifacts. The Auto SDK build system includes the Auto SDK Builder Tool script, which wraps the Conan build commands with a simple interface similar to the previous version of Auto SDK Builder. See the Build Alexa Auto SDK documentation for details about the build system and the Migration Guide for help migrating your build to the new version of Builder Tool. Extended the features of Alexa Presentation Language (APL) support for automotive. The APL module provides messages to report vehicle properties such as the display theme, driving state, and ambient light conditions. The property settings affect how APL documents render on screen; for example, some APL content is automatically hidden when the vehicle starts moving, and the display contrast updates with the day or night mode setting. Auto SDK 4.0 supports APL 1.9. For more information about the Auto SDK APL interface, see the APL module documentation. Added the CustomDomain interface, which establishes a bidirectional communication channel between your Auto SDK client application and your custom cloud skill. CustomDomain includes messages for exchanging directives, events, and context between the vehicle and your skill, achieving a fully customizable experience. For more information about the Auto SDK CustomDomain interface, See the Custom Domain module documentation. Added the MediaPlaybackRequestor interface, which enables Alexa to play the user\u2019s favorite media content as soon as they start their vehicle. MediaPlaybackRequestor simplifies content selection for the user by removing the need for the user to use buttons or voice commands to resume the Alexa media content that was playing when they stopped the vehicle. For more information about the Auto SDK MediaPlaybackRequestor interface, See the Alexa module documentation. Extended the AudioOutput interface and added configuration to allow ducking Alexa media. Your application can use this feature for enhanced control of Alexa content audio focus according to your platform requirements. For more information about audio ducking, see the Core module documentation. Updated the Auto SDK to use AVS Device SDK Version 1.25.0. For information about this version of AVS Device SDK, see the AVS Device SDK release notes. Added LVC support for Alexa Custom Assistant specialized handoffs. You can configure the default fallback and self-introduction prompts for your custom assistant while offline. For more information, see the Alexa Custom Assistant extension documentation. Integrated the Auto SDK Conan build system enhancements to AACS and the AACS sample app. You can use a single Gradle command to build AACS and the AACS sample app. For build instructions, see the AACS documentation. Added the following enhancements to the AACS sample app: Additional languages\u2014 The AACS sample app supports the following languages: US English ( en-US ), Australian English ( en-AU ), Canadian English ( en-CA ), Indian English ( en-IN ), British English ( en-GB ), German (d e-DE ), Spanish ( es-ES ), Mexican Spanish ( es-MX ), US Spanish ( es-US ), French ( fr-FR ), Canadian French ( fr-CA ), Hindi ( hi-IN ), Italian ( it-IT ), Japanese ( ja-JP ), and Brazilian Portuguese ( pr-BR ). The sample app language setting matches the device\u2019s system language setting and syncs the with Alexa as long as the setting is in the supported language list. If Alexa does not support the system language, the sample app GUI defaults to en-US and presents a list of languages for the user to choose from. Once the user selects the language override, the system language does not sync with the sample app again until the user logs out or disables Alexa. Network error prompts\u2014 You can configure the sample app to provide feedback to the user when Alexa cannot respond due internet connection issues. The feedback is a voice prompt or an error screen depending on the user action. Alexa app assets\u2014 The sample app can show Alexa logos (assets) on the setup screen and display cards instead of showing placeholder assets. Comms UI improvements\u2014 Updated the contacts uploading logic in the Comms UI AACS app component to ensure the sample app only uploads the contacts for the primary phone. Updated the AACS Telephony library to get the outgoing phone account using the Android standard API getDefaultOutgoingPhoneAccount . AACS Telephony no longer sends an account query intent when receiving the PhoneCallController.Dial message from the Auto SDK Engine. Added a new intent com.amazon.aacstelephony.bluetooth.connectionCheckCompleted , which AACS Telephony service broadcasts when it finishes the initial bluetooth connection check. Updated the alexa-auto-lwa-auth app component to use the Authorization Auto SDK interface for CBL authorization.","title":"Enhancements"},{"location":"CHANGELOG/#other-changes","text":"Moved several source code directories within the aac-sdk root directory to support the enhanced build system. Removed aac-sdk/platforms/android/ . The deprecated Java platform interfaces and JNI are in their respective modules. For example, the Alexa module Java interfaces and JNI are moved from aac-sdk/platforms/android/modules/alexa/ to aac-sdk/modules/alexa/android/ Removed aac-sdk/extensions/aasb/ because using AASB messages with MessageBroker is the primary Auto SDK API. AASB code for each module is in the respective module directory. For example, the AASB code for the Alexa module is in aac-sdk/modules/alexa/aasb/ . Note that the AASB message headers to include in your application are not in this directory since they are generated as part of the Auto SDK build output. Moved aac-sdk/extensions/system-audio/ to aac-sdk/modules/system-audio/ Moved aac-sdk/extensions/bluetooth/ to aac-sdk/modules/bluetooth/ Moved aac-sdk/extensions/loopback-detector/ to aac-sdk/modules/loopback-detector/ Moved aac-sdk/platforms/android/alexa-auto-client-service/ to aac-sdk/aacs/android/ Moved aac-sdk/platforms/android/alexa-auto-client-service/app-components/ to aac-sdk/aacs/android/app-components/ Moved aac-sdk/samples/android-aacs-sample-app/ to aac-sdk/aacs/android/sample-app/ Moved aac-sdk/platforms/android/alexa-auto-client-service /commonutils/ , /ipc/ , and /constants/ to aac-sdk/aacs/android/common/ Moved AACS media player files to a directory audioOutput within aac-sdk/platforms/android/alexa-auto-client-service/service/ Moved the Media App Command and Control Android library from aac-sdk/platforms/android/maccandroid/ to aac-sdk/aacs/android/service/modules/maccandroid/ In the LVC extension, the LocalSearchProvider AASB messages now have topic LocalNavigation . For example, the existing message LocalSearchProvider.SearchRequest in 3.3 is LocalNavigation.SearchRequest in 4.0. The next major release version of Auto SDK will change the topic back to LocalSearchProvider . Deprecated the option to build AACS as an APK. Starting from Auto SDK 4.0, you can only build AACS as an AAR. Removed the Android sample app based on the Java platform interfaces. The AACS sample app demonstrates using Auto SDK on Android.","title":"Other changes"},{"location":"CHANGELOG/#resolved-issues","text":"Fixed an issue preventing the generic DEFAULT type LocalMediaSource from working in offline mode with LVC. Fixed a race condition in SpeechRecognizer in which enabling wake word detection immediately after calling startCapture() resulted in a missing call to stopAudioInput() when wake word detection was later disabled. Fixed a deadlock that could occur in an application that uses the deprecated AuthProvider interface and starts, stops, and restarts the Engine in quick succession. Fixed an issue in which Spotify playback commands were delayed on QNX. Fixed an issue in which the Engine added malformed PhoneCallController context to PhoneCallController events sent to Alexa. Fixed an issue in which AACS did not acquire audio focus prior to playing Alexa speech.","title":"Resolved issues"},{"location":"CHANGELOG/#known-issues","text":"General If you do not specify the deviceSettings.locales field of the Alexa module configuration, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not automatically declare support for default locale combinations if you assign an empty value to the locales field. The Engine does not persist the aace.alexa.wakewordEnabled Engine property setting across device reboots. Your application has to persist the setting and set the property again at each Engine start. AACS implements persisting this property and hence does not have this issue. If your Linux platform does not use AVX2 instructions, the Amazonlite wake word library initialization causes an illegal instruction error. When using LVC and stopping the Engine, the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your application should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED . The Alexa Automotive UX guidelines specify when to automatically dismiss a TemplateRuntime display card for each template type. The Engine publishes the TemplateRuntime interface messages ClearTemplate and ClearPlayerInfo based on the timeouts configured in the aace.alexa.templateRuntimeCapabilityAgent Engine configuration. However, the configuration does not provide enough granularity to specify timeouts for different types of display cards. Consequently, there is no way for your application to configure automatically dismissing local search templates (e.g., LocalSearchListTemplate2 ) with a different timeout than other templates (e.g., WeatherTemplate ). The configuration also does not provide a way for you to specify infinite timeout for NowPlaying cards. You must implement your application\u2019s dismissal logic for display cards and media info accordingly. When the user requests to view their list of timers on an APL-enabled application, they cannot use an utterance such as \u201cAlexa, scroll up\u201d to scroll through the list shown on the APL card. There is a rare race condition in which publishing the AlexaClient.StopForegroundActivity message does not cancel the active Alexa interaction. The race condition can happen when the application publishes the message at the beginning of the THINKING state AlexaClient.DialogStateChanged transition. On the Poky Linux 32-bit platform, the C++ sample app shuts down with an error on launch. In offline mode with LVC, you might not see the AlexaClient.DialogStateChanged THINKING state transition if the user invokes Alexa with hold-to-talk and your application provides the audio input data in one large chunk. In offline mode with LVC, Alexa gets stuck in the THINKING state and does not respond after changing the locale setting. The state recovers after a few minutes. The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the Engine attempts the refresh, it might take up to a minute to refresh the token after the internet connection is restored. Some Core module messages published by the Engine do not have a corresponding message for the application to report a handling failure. For example, if the user invokes Alexa by tap-to-talk, and the application cannot handle the AudioInput.StartAudioInput message, the Engine assumes the application handled the message properly and will provide audio data. As a result, the Engine state and application state might become out of sync. The affected messages are the following: AudioInput : StartAudioInput AudioOutput : SetPosition VolumeChanged MutedStateChanged Car control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in the set from Alexa. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, Alexa retains endpoint 1 from set A, which might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications Alexa does not understand DTMF utterances that include letters. For example, \"press A\" and \"dial 3*#B\" do not result in the correct DTMF directives. The user might experience unexpected results by trying to dial or place calls in the following ways: Using utterances that include \u201cdouble\u201d, \u201ctriple\u201d, \u201chundred\u201d, or \u201cthousand.\u201d For example, calling a number such as 1-800-xxx-xxxx by saying \u201cAlexa call one eight double oh ...\u201d Pressing special characters such has \u201c#\u201d or \u201c*\u201d by saying \"Alexa press * #.\" The user cannot accept or reject incoming Alexa-to-Alexa calls by voice while playing a skill with extended multi-turn dialogs, such as Jeopardy or Skyrim. Entertainment If the user requests Alexa to read notifications while music is playing, they might hear the music play for a split second between the end of one notification and the start of the next. When an external media player authorization is in progress during Engine shutdown, a rare race condition might cause the Engine to crash. If your application cancels an Alexa interaction by sending the AlexaClient.StopForegroundActivity message to the Engine during music playback, the Engine might erroneously request your application to dismiss the NowPlaying media info by publishing the TemplateRuntime.ClearPlayerInfo message. Your application should not dismiss the media info in this scenario. When using the System Audio module, Audible and Amazon music might not play correctly on i.MX8 boards. Local search and navigation In offline mode with LVC, after the user requests a list of POIs with an utterance such as \u201cAlexa, find a nearby Starbucks\u201d, Alexa does not recognize followup requests such as \"Alexa, select the first one\" and does not display or read detailed information about the requested selection. AACS If you do not use the default audio output implementation (i.e., your application handles AudioOutput AASB messages), your application will not receive the AudioOutput.Stop message if Alexa media is playing when AACS shuts down. As a workaround, your application can listen to AASB.StopService or adopt AACSPinger to listen to the STOPPED state of AACS and stop the media accordingly. AACS Sample App The AACS Sample App does not show the language selection screen when the app is built with Preview Mode. The AACS Sample App only shows the language selection screen if there is a language mismatch with the system language setting at the first app launch.","title":"Known issues"},{"location":"CHANGELOG/#v330-released-on-2021-09-30","text":"","title":"v3.3.0 released on 2021-09-30"},{"location":"CHANGELOG/#enhancements_1","text":"Added the DeviceUsage platform interface to provide the Alexa application network usage data to the Auto SDK Engine. The Auto SDK Engine emits this data as a metric to Amazon if Auto SDK is built with the Device Client Metrics extension. For more information, see the Core module README for C++ or Android . Extended the features of the Local Navigation module for the Local Voice Control (LVC) extension. The LocalSearchProvider platform interface now enables you to provide customers with offline navigation to street addresses, cities, and neighborhoods in addition to the existing support for local search and navigation to points of interest. See the Local Navigation module README for information about integrating the features. Note: There are updates to the LocalSearchProvider APIs. See the Migration Guide for details. Added a new generic DEFAULT media source to the list of sources supported by the LocalMediaSource platform interface. The DEFAULT source can be used for voice playback control of any arbitrary media sources on the infotainment system outside of deep-linked MACC applications using the ExternalMediaAdapter interface and existing sources supported by name through the LocalMediaSource interface. For details about integrating a default media source, see the Alexa module README for C++ or Android . Added offline LVC support for tuning to station names on terrestrial radio and SiriusXM. E.g., \u201cPlay CNN on Sirius XM\u201d and \u201cPlay KISS FM\u201d. This feature is already available in online mode. Enhancements for AACS: Added an app component called alexa-auto-carcontrol that deeply integrates Auto SDK car control features into the Android Automotive OS. For more information about AACS deep integration to Car Control, please refer to this README . Added an enhancement in which AACS can automatically sync Alexa\u2019s timezone and locale properties with the device system settings when you set the syncSystemPropertyChange field to true in your AACS configuration file. If you set the field to false or omit it, you still have flexibility to change the properties in your own implementation. Enhancements for AACS Sample App: Added a location sharing consent screen in Alexa setup and settings wherein the user has the option to enable or disable location sharing. Added support for rendering for TemplateRuntime display cards for the weather domain. Added support for rendering Amazon Presentation Language (APL) documents. Added media player transport control improvements. For example, shuffle and loop transport controls are added, and disabled transport controls are displayed. Added support for setup and setting menu specific to the Alexa Custom Assistant extension.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_1","text":"Android 11 requires the attribute android:foregroundServiceType to be defined in services that require permissions such as microphone and location. This is added to the AACS Android Manifest file. Also, the compileSdkVersion and targetSdkVersion to are updated to 30 in build.gradle . Added a UserIdentity value in AACS AuthStatus when the user finishes CBL login. Made the 'stateOrRegion' field optional in the AACS StartNavigation directive JSON parser. Implemented the AASB SetUserProfile message in the CBL module to ensure the user email and username will be sent to the client application after user login when enableUserProfile is set to true. Fixed an issue that blocked a valid transition from the THINKING to LISTENING AlexaClient dialog states. Updated the PhoneCallControllerCapabilityAgent to include context in PhoneCallController events per the PhoneCallController API specification. Fixed a memory leak observed during Engine shutdown in the Local Voice Control extension. Fixed a rare deadlock issue during Engine stop and start when using the AuthProvider interface. Fixed an issue in which the Engine erroneously allowed 3,000 coordinates in the \"shapes\" array of navigation state queried via Navigation::getNavigationState() . The limit is updated to 100 coordinates.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_1","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. The automotive HMI guidelines for display cards state that actionable display cards should be dismissed automatically after 30 seconds, and non-actionable display cards should be dismissed automatically after 8 seconds. This guideline is not descriptive enough since it does not clarify what is actionable and non-actionable content. The UX team is working on correcting the guideline to specify specific template types. The current automatic dismissal time for all Template Runtime display cards is 8 seconds. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. The generic DEFAULT LocalMediaSource type is not supported offline with LVC. If user gives a generic playback control request like \"Alexa, play\" when the Alexa application is operating in the offline mode with LVC, Alexa responds \"Sorry, something went wrong\". Other named players like USB work as expected in the offline mode. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. Local Search and Navigation When using LVC in offline mode, after requesting a list of POIs (e.g., \"find Starbucks nearby\"), Alexa does not recognize utterances like \"select the first one\" and does not display or read detailed information about the requested selection. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) If you are not using the default audio output implementation (i.e. your application handles AudioOutput AASB messages) and even though you are playing the Alexa pushed media content, Stop message would not be sent from AACS when AACS shuts down. e.g. If you are playing an audio stream for AmazonMusic, if AACS is stopped, AASB AudioOutput.Stop message would not be received. As a result, the media playing from your application would not be stopped. This issue will be fixed in the next release. As a workaround, your application can listen to [AASB.StopService]( extensions/aasb/docs/AASB/StopServiceMessage.html ) message or adopt AACSPinger (See README ) to listen to the STOPPED state of AACS and stop the media accordingly.","title":"Known Issues"},{"location":"CHANGELOG/#v321-released-on-2021-08-06","text":"Note: All Auto SDK 3.2 extensions are compatible with 3.2.1.","title":"v3.2.1 released on 2021-08-06"},{"location":"CHANGELOG/#enhancements_2","text":"Added additional APIs to the Connectivity module, which enable the voice up-sell conversation between the user and Alexa to activate a trial data plan or a paid subscription plan. Your implementation should call AlexaConnectivity::sendConnectivityEvent() to notify the Engine of the data plan type. To respond, the Engine calls AlexaConnectivity::connectivityEventResponse() . Added the configuration field aace.addressBook.cleanAllAddressBooksAtStart to Engine configuration. This field specifies whether to automatically delete address books each time the Engine starts.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_2","text":"Fixed an issue in which wake words cannot be detected correctly when using the SpeechRecognizer::startCapture() API with an external wake word engine.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_2","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state)","title":"Known Issues"},{"location":"CHANGELOG/#v320-released-on-2021-05-19","text":"","title":"v3.2.0 released on 2021-05-19"},{"location":"CHANGELOG/#enhancements_3","text":"Added the DeviceSetup platform interface that handles events and directives related to device setup during or after an out-of-the-box experience (OOBE). After the user login, Alexa is informed that device setup is complete and starts the on-boarding experience, for example, by starting a short first-time conversation. For more information, see the Alexa module README for C++ or Android . Added support in the Connectivity module to provide the network identifier from the vehicle to Alexa, which enables automakers to offer full connectivity plans to customers. For connectivity status, the module supports sending the version of the terms and conditions through a field called termsVersion . Also, the termsStatus field accepts DEFERRED , which means Alexa can remind users to respond to the terms and conditions at a later time. Added the Mobile Authorization extension, which enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone, instead of opening a web browser and entering a code. Added the Bluetooth extension, which allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Added the Geolocation extension, which provides geolocation consent support. The user can grant consent to location sharing with Alexa from your application. Added the locationServiceAccessChanged(LocationServiceAccess access) API in the LocationProvider interface, which allows the Engine not to query the device location when the location service access is turned off on the device. Added the APL Render module, which enables APL rendering capabilities in an Android application. Note: This module is for you to experiment with APL document rendering on an automotive device. Do not use the module to render APL documents in a production vehicle. Added support in the Address Book module for a phonetic field. The phonetic field is required for resolving the name of a contact or navigation favorite if the name uses Kanji characters in Japanese. Updated the Docker container for the Auto SDK builder script to use OpenSSL 1.1.1k by default. Added an environment variable for you to change the OpenSSL version, if desired. For information about the OpenSSL version, see the Builder README . Updated the Auto SDK to use AVS Device SDK Version 1.22.0. For information about the AVS Device SDK, see the AVS Device SDK Release Notes . Enhancements for AACS: Added AACS instrumentation, which enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. For information about AACS instrumentation, see the README . Added an app component called alexa-auto-telephony , which enables you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. Added an app component called alexa-auto-contacts to enable AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information. Added the AACS AAR, which you can include in your application. The timeout for AASB synchronous messages is now configurable. For information about configuring the timeout, see the README . Enhancements for AACS Sample App: Added support for new features in the AACS Sample App. For example, it includes a menu for the user to select a language if the in-vehicle infotainment (IVI) language is not supported by Alexa, and it supports authorization with Preview Mode. Added support for the Alexa Custom Assistant extension to the Alexa Auto Client Service (AACS) Sample App. The sample app demonstrates how an application can use AACS with this extension. With app components included with the sample app, you can develop an application that handles assistant handoff and displays custom animation for your custom assistant. > Note: In order to use Alexa Custom Assistant extension with the AACS Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. Enhancements for metrics uploading: The Auto SDK emits only registration metrics before user login is complete. Other metrics are emitted after user login. The Device Client Metrics (DCM) extension supports uploading more metrics from the vehicle than in previous versions. The DCM extension supports anonymizing all Auto SDK metrics. Enhancements for car control: Added prompt improvements. Alexa can provide a recommendation or ask for clarification after receiving an invalid or ambiguous user request. Suppose a user request targets the wrong mode, setting, or value for an appliance, such as \"Alexa, set fan speed to 100\", Alexa responds, \"Sorry, you can only set the fan between 1 and 10\". When the target in a user request is ambiguous, Alexa prompts for more information to determine the exact meaning of the request. For example, when a user says, \"Turn on fan\" (when the fan's default zone is not set), Alexa responds, \"For the driver, the passenger, or the rear?\" This feature is supported online and offline. Improved asset management for car control, which enables Alexa to accept utterances only a few seconds after the user logs in. Previously, the user had to wait up to 20 seconds for Alexa to accept utterances. Improved the Auto SDK Voice Chrome extension to allow the height and width of the linear voice chrome to be controlled by the parent layout. Previously, the dimensions were fixed.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_3","text":"Disabled APL by default in AACS to make sure utterances like \"tell me a joke\" work correctly without handling APL. If your platform wants to implement APL, see the AACS Configuration README to enable it. An SMS message can be sent to an Alexa contact correctly. A user request to send an SMS message to an Alexa contact no longer results in an Alexa-to-Alexa message. For car control, there is no longer a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). After the AmazonLite Wake Word locale model is switched from the default (en-US) to another locale model (e.g., de-DE), the newly selected locale remains in effect after the user quits and then restarts the application. Numeric weather IDs are passed to AVS for the TemplateRunTime API, making it easier for you to display weather icons that are consistent with your user interface. After the user disconnects the phone, if the user tries to use Alexa to make a call, Alexa responds correctly by reminding the user to connect the phone. Previously, Alexa tried to dial the number. After the user pauses on Spotify and presses \u201cPlay\u201d to resume, the player starts correctly from the point where the player stops. Previously the player skipped ahead, resuming from an incorrect place. AutoVoiceChromeController and StateChangeAnimationScheduler of the Voice Chrome extension are thread-safe now, preventing the Alexa app from crashing in different scenarios (e.g. when changing to the previous music track). Fixed a race condition in AuthorizationManager during the Engine shutdown.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_3","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. For Linux platforms, if your hardware does not use AVX2 instructions, the wake word library initialization causes an illegal instruction error. When using LVC and calling Engine::stop(), the AlexaClient connection status remains CONNECTED because the connection to LVC is not disabled. Your implementation should not accept user utterances while the Engine is stopped despite the connection status showing CONNECTED. Car Control If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. Communications DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. If your application displays the NowPlaying TemplateRuntime display card when Alexa plays media, the card might be erroneously dismissed by the Auto SDK Engine with a call to TemplateRuntime::clearPlayerInfo() if your application calls AlexaClient::stopForegroundActivity() to cancel an Alexa interaction. For example, the user might initiate an Alexa interaction during music playback and then cancel it by pressing a cancel button while Alexa is listening, thinking, or speaking. The media display card should not be dismissed in this scenario Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state)","title":"Known Issues"},{"location":"CHANGELOG/#v310-released-on-2020-12-15","text":"","title":"v3.1.0 released on 2020-12-15"},{"location":"CHANGELOG/#enhancements_4","text":"Added the Authorization platform interface that replaces the CBL platform interface and the AuthProvider platform interface. For information about how the Alexa Auto SDK Engine handles authorization with the Authorization platform interface, see the Core module README . Note: Logging out from CBL or Auth Provider authorization clears the databases that store user data, such as alerts and settings. For example, when the user logs out, pending alerts in the database are cleared to ensure that the next user who logs in does not receive the alerts. In addition, upon logout, the locale setting is reset to the default value in the Engine configuration. Therefore, if the current device locale is different from the default locale, you must set the locale before starting an authorization flow. Added the Text To Speech module that exposes the platform interface for requesting synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. Added the Text To Speech Provider module that synthesizes the Alexa speech. The Text to Speech provider requires Auto SDK to be built with the Local Voice Control extension. For information about these modules, see the Text To Speech module README and Text To Speech Provider README . Note: This feature may only be used with voice-guided turn-by-turn navigation. Added the Connectivity module that creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. For information about the Connectivity module, see the README . Added the Local Navigation module for the Local Voice Control (LVC) extension. This module enables you to provide customers with offline search and navigation to points of interest (POI) by leveraging the POI data of an onboard navigation provider. The POIs include categories, chains, and entities. The Local Voice Control (LVC) extension is required for the Local Navigation module. Note: Offline search with the Local Navigation module is only supported in the en-US locale. Added the Alexa Auto Client Service (AACS) Sample App that demonstrates how an application uses AACS. The Auto SDK includes the app components used by the AACS Sample App, which you can also use when developing an application that communicates with AACS. For information about the AACS Sample App, see the README . Added support for Digital Audio Broadcasting (DAB) radio. For more information about the DAB local media source, see the Alexa module README . Enhancements for AACS: Enhanced the file sharing protocol of AACS by using Android's FileProvider. This enhancement grants AACS permission to access files within your AACS client application, which are required by configuration fields for the Auto SDK. Added support for the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. For information about how AACS uses FileProvider and ContentProvider , see the README . Added support for a ping broadcast to check the AACS connection state. For more information about how to use ping , see the README . Added support for caching AASB message intent targets based on AASB Action. This enables you to define an intent filter with a subset of the possible actions for an AASB topic. For more information on specifying intent targets, see the README . Added support for Text-to-Speech Service, which allows Android applications to interact with Android TTS APIs to convert text to speech. For information about the Text-to-Speech Service, see the README .","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_4","text":"On Android, the Engine returns the correct value ( UNDEFINED ) for requests to LocationProvider.getLocation() when the device does not have access to location. Previously the Engine populated the user geolocation with a default value when Location.UNDEFINED was returned in LocationProvider.getLocation() . In the AACS commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime could only parse the payload field of the AASB RenderPlayerInfo message payload. Now it can parse the overall AASB payload. Notifications sound plays correctly. Previously, the sound did not play as expected due to improper channel configuration. The CBL module code request flow correctly applies the locale setting to the Login With Amazon (LWA) code request. Previously, the URL returned by LWA was always in the en-US locale. If you log out and log in, the client-side Do Not Disturb (DND) state is synchronized with Alexa.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_4","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. The wakewordEnabled property is not persistent across device reboots. If you use AACS, however, this issue does not occur. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However, \u2018send message\u2019 instead of \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) AACS enables APL by default, but it does not have a default implementation for APL. AACS expects the client application to handle the messages or directives from the Engine. If APL is not handled on the client side, utterances that trigger APL capabilities, such as \"tell me a joke,\" fail. To disable APL, add the lines below to the AACS configuration file . \"aasb.apl\": { \"APL\": { \"enabled\" : false } }","title":"Known Issues"},{"location":"CHANGELOG/#additional-changes","text":"Starting with v3.1.0, the Local Voice Control (LVC) extension is no longer supported on ARM32 platforms.","title":"Additional Changes"},{"location":"CHANGELOG/#v300-released-on-2020-10-09","text":"","title":"v3.0.0 released on 2020-10-09"},{"location":"CHANGELOG/#enhancements_5","text":"Added Alexa Auto Client Service (AACS), which enables OEMs of Android-based devices to simplify the process of integrating the Auto SDK. For more information about AACS, see the AACS README . Added support for removing local media sources at runtime, such as a USB drive or a Bluetooth device. Previously, if a user removed a USB drive and then requested to play music from the USB drive, the Auto SDK would attempt to play and not return an appropriate error message. This feature is enabled with an existing field in the LocalMediaSource platform interface state. For information about the platform interface state, see the alexa module README .","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_5","text":"On QNX, when a portion of music on Spotify is skipped, either by the user saying, \"Skip forward,\" or by the user skipping to a different song, the volume is no longer reset to the default level. A user barging in when music is playing no longer hears an Alexa response to the barge-in request. Previously, this issue happened if the System Audio extension was used. When streaming music from Alexa, the user can switch to a local media source by using one utterance, such as \"Alexa, play radio.\" Previously, Alexa would not switch to the local media source after the first utterance. The user needed to issue the request again before Alexa could play from the local media source.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_5","text":"General If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The word, \"line-in,\" in an utterance is sometimes misinterpreted as \"line\" or other words. For example, if the user says, \"Switch to line-in,\" the misinterpretation of \"line-in\" might cause an incorrect response. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud. AACS For some platform interface APIs in the Core module, when an application fails to handle a directive, there is no way to report the failure to the Engine. This is because AASB assumes that the application always handles messages correctly. When AASB incorrectly reports how the application handles the message, the Engine state might become inconsistent with the application state. For example, suppose the Engine sends a directive to the application to set the audio volume but the application fails to make the change. AASB does not report the failure to the Engine. As a result, the Engine's and the application's settings become out of sync. The following list shows the affected APIs: AudioInput : startAudioInput() AudioOutput : setPosition(int64_t position) volumeChanged(float volume) mutedStateChanged(MutedState state) In the commonutils library, the JSON parser ( RenderPlayerInfo.kt ) for the renderPlayerInfo message of templateRuntime can only parse the payload field of the AASB RenderPlayerInfo message payload. The payload field of RenderPlayerInfo is the inner payload of the nested payload structure. When using TemplateRuntime.parseRenderInfo(String json) , provide it with the embedded JSON as a string of the string value whose key is payload in the RenderPlayerInfo message\u2019s payload instead of the overall AASB payload.","title":"Known Issues"},{"location":"CHANGELOG/#additional-changes_1","text":"Starting with Auto SDK v3.0, we no longer support the Automotive Grade Linux (AGL) Alexa Voice agent in the Auto SDK. If you intend to use the AGL Alexa Voice Agent, continue using Auto SDK v2.3.0, which is the last version that provides AGL support.","title":"Additional Changes"},{"location":"CHANGELOG/#v230-released-on-2020-07-31","text":"","title":"v2.3.0 released on 2020-07-31"},{"location":"CHANGELOG/#enhancements_6","text":"Added a new Messaging module that provides support for Short Message Service (SMS) to allow a user to send, reply to, and read messages through Alexa. Added support for zones to car control for online-only devices so the customer can target endpoints by location (e.g., \u201cset the front fan to 7\u201d). This feature was supported only with the Local Voice Control (LVC) extension, and endpoints belonged to exactly one zone. The features for online-only and LVC devices are at parity and now include assigning an endpoint to multiple zones and setting a default zone. Endpoints in the default zone take higher priority than endpoints not in the default zone when no zone is specified in an utterance. Added support for \u201csemantics\u201d for car control to enable \u201copen\u201d, \u201cclose\u201d, \u201craise\u201d, and \u201clower\u201d utterances to control endpoints. Added a method to the 'AlexaClient' platform interface to stop foreground-focused Alexa activity on the device (e.g., locally canceling ongoing TTS when the user selects a list item or presses a cancel button). Added support for Dynamic Language Switching. Previously, Alexa could only understand and respond in one language at a time. Now Alexa supports two languages at once and automatically detects the user's spoken language and responds in the same language as the utterance. The supported locale pairs are the following: [ \"en-US\", \"es-US\" ] [ \"es-US\", \"en-US\" ] [ \"en-IN\", \"hi-IN\" ] [ \"hi-IN\", \"en-IN\" ] [ \"en-CA\", \"fr-CA\" ] [ \"fr-CA\", \"en-CA\" ] Note: Dynamic Language Switching works online only. For hybrid systems using the LVC extension, offline Alexa understands and responds in the language of the primary locale. * Updated radio tuning increments for \u201cAM_RADIO\u201d and \u201cFM_RADIO\u201d Local Media Source types to support the en_IN locale. * Alexa Voice Agent now supports AGL Itchy Icefish v9.0.2. * Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binary.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_6","text":"Fixed an issue in which navigation road regulation and maneuver events resulted in \u201cINVALID_REQUEST_EXCEPTION\" or \"INTERNAL_SERVICE_EXCEPTION\" error logs. Fixed several failing car control utterances including those for offline AC controls and those using the words \u201cmy\u201d or \u201clights.\u201d Fixed an issue in External Media Player that caused the \u201cNEXT\u201d play control request to be issued twice for ExternalMediaAdapter (e.g., MACC) and LocalMediaSource platform interface handlers. Fixed an issue in which the Engine did not stop music playback after user logout. Fixed an issue that caused Spotify to play at an increased and unsteady rate on QNX. Fixed an issue with the --use-mbedtls build option that caused a crash in the Android sample app at startup. Fixed an issue in the Engine metrics implementation in which regular expression matching with a large number of data points caused a crash. Fixed an issue in MACC in which players removed while the Engine was running (such as by the uninstallation of a linked MACC-compliant app) could not be rediscovered properly and used again, even if the player was restored (such as by the reinstallation of the app and user login). Previously, the rediscovery logic left insufficient time to process the player removal event before trying to discover players again, resulting in a loop. Now the rediscovery step runs at 5-minute intervals. Fixed an issue with the Engine's SQLite local storage database in which concurrent access to the database caused a crash. Fixed various memory leaks and intermittent crashes caused by race conditions at Engine shutdown. Fixed an issue on Android API 25 in which a large number of emitted logs could cause a crash due to a JNI local reference table overflow. Fixed an issue in which you experienced unexpected results if the local timezone of your device differed from the timezone configured through the Alexa companion app.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_6","text":"General A user barging in when music is playing sometimes hears the Alexa response to the barge-in request and the music at the same time if System Audio extension is used. If the \"locales\" field of the \"deviceSettings\" node of the Alexa module configuration JSON is not specified, the Engine automatically declares support for the following locale combinations: [\"en-US\", \"es-US\"], [\"es-US\", \"en-US\"], [\"en-IN\", \"hi-IN\"], [\"hi-IN\", \"en-IN\"], [\"fr-CA\", \"en-CA\"], [\"en-CA\", \"fr-CA\"]. The Engine does not declare support for locale combinations if the \"locales\" field is assigned an empty value. Car Control For car control, there is a limit of two Device Serial Numbers (DSN) per account or Customer ID (CID). Limit the number of devices for testing with a single account accordingly. If you use the Android sample app, be sure to configure a specific DSN. It can take up to 20 seconds from the time of user login to the time Alexa is available to accept utterances. The cloud uses this time to ingest the car control endpoint configurations sent by Auto SDK after login. If you configure the Auto SDK Engine and connect to Alexa using a set of endpoint configurations, you cannot delete any endpoint in a set in the cloud. For example, after you configure set A with endpoints 1, 2, and 3, if you change your car control configuration during development to set B with endpoints 2, 3, and 4, endpoint 1 from set A remains in the cloud and might interfere with resolving the correct endpoint ID for your utterances. However, any endpoint configurations with matching IDs override previous configurations. For example, the configuration of endpoint 2 in set B replaces endpoint 2 in set A. During development, limit configuration changes to create only supersets of previous endpoint configurations. Work with your Solutions Architect or Partner Manager to produce the correct configuration on the first try. Car control utterances that are variations of supported utterances but do not follow the supported utterance patterns return errors. Examples include \u201cplease turn on the light in the car\u201d instead of the supported \u201cturn on the light\u201c, and \u201dput on the defroster\u201c or \u201cdefrost the windshield\u201d instead of the supported \u201dturn on the defroster\u201d. The air conditioner endpoint supports only Power Controller and Mode Controller capabilities, not Range Controller for numeric settings. Communications A user request to send an SMS to an Alexa contact results in an Alexa-to-Alexa message instead. However \u2018send message\u2019 instead \u2018send SMS\u2019 to a contact works. When using LVC in online mode, users can redial a call when the phone connection state is OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1-800-xxx-xxxx by using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, when you call numbers by using utterances that include \"triple,\" \"hundred,\" and \"thousand,\" or press special characters such as # or * by saying \"Alexa press *#\", you may experience unexpected results. We recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. A user playing any skill with extended multi-turn dialogs (such as Jeopardy or Skyrim) cannot use voice to accept or reject incoming Alexa-to-Alexa calls. Entertainment A user playing notifications while music is playing hears the music for a split second between the end of one notification and the start of the next. The user must enunciate \u201cline-in\u201d in utterances targeting the \u201cLINE_IN\u201d Local Media Source type in order for Alexa to recognize the intent. When an external player authorization is in progress at the exact moment of shutdown, a very rare race condition might occur, causing the Engine to crash. On QNX, when a portion of music on Spotify is skipped, either by the user saying \"Skip forward\" or by the user skipping to a different song, the volume is reset to the default level. Authentication The CBL module uses a backoff when refreshing the access token after expiry. If the internet is disconnected when the refresh is attempted, it could take up to a minute to refresh the token when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.","title":"Known Issues"},{"location":"CHANGELOG/#v221-released-on-2020-05-29","text":"","title":"v2.2.1 released on 2020-05-29"},{"location":"CHANGELOG/#enhancements_7","text":"Added enhancements to the maccandroid module to allow SupportedOperations to be overridden to support custom actions. Enhanced the TemplateRuntime platform interface to support focus and audio player metadata in renderTemplate and renderPlayerInfo methods. This is a backward compatible change, see the migration guide for details. SpeakerManager is now a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\".","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_7","text":"Fixed issues in the maccandroid module to a) rediscover media apps after getting the app removed callback, and b) change the behavior to only report unauthorized when the user specifically asks to play a media app. On the QNX platform, prevent unnecessary flushing for audio output.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_7","text":"On the Android Sample App, media playback gets into \"No Content Playing\" state where all GUI playback control breaks, when pressing next after force closing an external media app. Playback controls in the C++ Sample App Playback Controller Menu are static text items and do not change visual state (e.g. add/remove, hilite, select) based on audio player metadata.","title":"Known Issues"},{"location":"CHANGELOG/#v220-released-on-2020-04-15","text":"","title":"v2.2.0 released on 2020-04-15"},{"location":"CHANGELOG/#enhancements_8","text":"Added a Car Control module to support online-only car control use cases without the optional Local Voice Control (LVC) extension. The Car Control module provides the car control functionality introduced in Auto SDK 2.0.0 but does not require the LVC extension. Made various enhancements to the External Media Player (EMP) Adapter to improve EMP behavior and facilitate implementation of Alexa audio focus. Introduced the Property Manager, a new platform interface that allows you to set and retrieve Engine property values and be notified of property value changes. Added support for setting the timezone of a vehicle. The AlexaProperties.h and AlexaProperties.java files now include a TIMEZONE property setting that is registered with the Property Manager during initialization and which you can manage using the Property Manager platform interface. Added support for specifying a custom volume range for voice interactions in implementations that use the optional Local Voice Control (LVC) extension. Separated the LVC language models into independent APKs rather than providing them directly in the LVC APK as was done in previous releases. One language model APK is provided for each supported locale (currently en-US, en-CA, and fr-CA).","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_8","text":"Fixed an issue where the CBL state did not change to stopped when you cancelled login with CBL::cancel() . Fixed an issue where volume adjustments were lost when pausing and resuming music. Fixed an External Media Player (EMP) Engine implementation that caused an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession. Fixed an issue where the Engine might hang during shutdown if it was shut down while TTS was being played or read. Fixed an issue where Auto SDK initialization failed at startup when applications using the optional LVC extension didn't register a NetworkInfoProvider platform interface. Fixed an issue where building the Auto SDK with sensitive logging enabled was not working as expected. Added alerts error enums ( DELETED and SCHEDULED_FOR_LATER ) to the Alerts.h and Alerts.java files. With the exception of road regulation and maneuver events, the Alexa cloud no longer returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to navigation events sent by the Auto SDK. Alexa now prompts or notifies the clients and rejects the ping packet when the user deregisters from the companion app.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_8","text":"General If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". Auto SDK v2.2.0 adds support for setting the timezone of the vehicle, which allows your device to synchronize with the timezone set in the Alexa companion app; however, the Auto SDK currently does not receive a SetTimeZone directive when the timezone is changed from the companion app. Navigation The Alexa cloud currently returns an INTERNAL_SERVICE_EXCEPTION in response to any navigation road regulation or maneuver event sent by the Auto SDK (triggered by an utterance such as \"which lane should I take\", for example). You may see a harmless error/exception in the logs. Car Control Certain car control utterances return errors. Problematic utterances include natural versions of certain test utterances (for example, \u201cturn on the light\u201c instead of \u201cplease turn on the light in the car\u201d); utterances that include the words \u201clights\u201d or \u201cmy\u201d; and utterances to control the defroster or defogger that use \u201cput on\u201d or \u201cset on\u201d rather than \u201cturn on\u201d or \u201cswitch on\u201d. Setting the air conditioner using range controller control capabilities (for example \u201cset the air conditioner to 65\u201d or \u201cset the air conditioner to low\u201d) is not currently supported. In offline mode, the utterances \"turn ac on\u201d, \u201cturn off ac\u201d, \u201cturn ac off\u201d, and \u201cturn up ac\" return errors. Communications When using LVC in online mode, users can redial a call when the phone connection state has been switched to OFF. DTMF utterances that include the letters \"A\", \"B\", \"C\", or \"D\" (for example \"press A\" or \"dial 3*#B\") are ignored. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. Entertainment A user playing any skill with extended multi-turn dialogues (such as Jeopardy or Skyrim) cannot accept or reject incoming Alexa-to-Alexa calls using voice. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d Authentication The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If you log out and log in, the client-side Do Not Disturb (DND) state may not be synchronized with the Alexa cloud.","title":"Known Issues"},{"location":"CHANGELOG/#v210-released-on-2019-12-19","text":"","title":"v2.1.0 released on 2019-12-19:"},{"location":"CHANGELOG/#enhancements_9","text":"Added Navigation enhancements to support the following features: Add a waypoint - Enables users to search and add waypoints to their current route along the way or start a new route with a given set of waypoints. Cancel a waypoint - Enables users to cancel a waypoint with voice. Show/Navigate to previous destinations - Enables users to view previous destinations and navigate to any of their previous destinations.. Turn and Lane Guidance - Enables users to ask Alexa for details about their next navigation instruction. Control Display - Enables users to interact with their onscreen map applications. Note: The Navigation enhancements are not backward-compatible with previous versions of the Auto SDK. The startNavigation() method supersedes the setDestination() method, and many new methods have been implemented. See the Migration Guide for details. Added support for Alexa Presentation Language (APL) rendering to present visual information and manage user interactions with Alexa. Note: In order to use APL rendering with the Android Sample App, you must install an extra component in the Auto SDK. Contact your Amazon Solutions Architect (SA) or Partner Manager for details. * Added support for the Alexa DoNotDisturb (DND) interface, which allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . Note: Alexa does not notify the user of the DND state. * Added a System Audio extension to provide the default audio capturing and playback functionality for various platforms, including audio input/output on QNX platforms. The Alexa Auto SDK Builder automatically includes the System Audio extension when you build the Auto SDK. * Added local media sources (LMS) and hybrid car control support to the Automotive Grade Linux (AGL) Alexa Voice Agent. * Added onAuthFailure() to the AuthProvider platform interface and an AUTHORIZATION_EXPIRED argument to the cblStateChanged() method of the CBL platform interface to expose 403 unauthorized request exceptions from Alexa Voice Service (AVS). These may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. * Added support for call display information change notifications (caller ID) to the optional Alexa Communication extension.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_9","text":"Fixed an issue where contact uploading failed for contacts without addresses. Fixed an issue where if the user rejected an incoming Alexa-to-Alexa call via voice, ringtones did not sound for subsequent incoming calls until the user either answered an incoming call via voice or made an outbound call. Fixed an issue that required you to assign unique entry IDs to contacts and navigation favorites to ensure that the ID space used for contacts and navigation favorites did not collide. Fixed an issue where multiple automotive devices using the same account at the same time could access contacts from phones paired across those devices. Fixed an issue where uttering \"stop\" when a timer sounded during an Alexa-to-Alexa call ended the call, not the timer. Added enhancements to the maccandroid module (Spotify) to simplify the MACCPlayer handler implementation. Rediscovery now occurs automatically, and the authorization TTS error events no longer occur repeatedly.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_9","text":"The Alexa cloud currently returns an INVALID_REQUEST_EXCEPTION or INTERNAL_SERVICE_EXCEPTION in response to any navigation event sent by the Auto SDK. You may see a harmless error/exception in the logs. The CBL module uses a backoff when refreshing the access token after expiry. If internet is disconnected when the refresh is attempted, it could take up to a minute for the token to refresh when the internet connection is restored. If the user deregisters from the companion app, Alexa does not prompt or notify the clients and does not reject the ping packet. If you log out and log in, the Do Not Disturb (DND) state is not synchronized with Alexa. When you cancel login with CBL::cancel() , the CBL state does not change to stopped. Calling numbers such as 1800xxxxxxx using utterances such as \u201cAlexa call one eight double oh...\u201d may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or* using utterances such as \"Alexa press *#\" may return unexpected results. Therefore we recommend that your client application ignore special characters, dots, and non-numeric characters when requesting Alexa to call or press digits. The Engine may sometimes stop abruptly on shutdown due to a race condition. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. When online, Alexa does not recognize the utterance \u201cSwitch to line In.\u201d A user playing Jeopardy or Skyrim cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past\". When pausing and resuming music, volume adjustments are lost. A user playing notifications while music is playing will hear the music for a split second between the end of one notification and the start of the next. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession.","title":"Known Issues"},{"location":"CHANGELOG/#v200-released-on-2019-09-10","text":"","title":"v2.0.0 released on 2019-09-10:"},{"location":"CHANGELOG/#enhancements_10","text":"Added offline enhancements to improve offline car control support and add support for: offline car control enhancements - to support generic controls that represent what can be controlled in a vehicle; for example: interior lighting, fans, temperature zone (driver and passenger), vent position, defroster, air conditioner, and recirculation. > Note : The car control enhancements are not backward compatible with previous versions of car control. The configuration and platform interface have changed. offline entertainment - to support tuning to a specific frequency or SiriusXM channel, tuning to radio presets, switching between car audio sources (bluetooth, radio, satellite radio, CD player, etc.), and controlling local audio sources (pause, shuffle, loop, etc.) offline communications - to support uploading contacts, calling a number or a contact, answering, declining, redialing, or ending a call, and dialing digits during a call offline navigation - to support navigating to favorite locations and canceling navigation Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets. Added online navigation enhancements to support navigating to favorite locations and answering ETA and time to destination questions. Introduced the Address Book module , which includes a common platform interface that you can implement to either upload user data to the Alexa cloud or allow the local communications and navigation capabilities to access user data for offline use cases (supported by the optional Local Voice Control (LVC) module). The Address Book module supersedes the Contacts Uploader module, which supports only phone contacts and only online use cases. Introduced a new core Audio service and API to implement audio input and output providers, and deprecated the existing MediaPlayer and Speaker platform interfaces in the Alexa module. This redesign simplifies integration with platform-specific audio capabilities and enables implementation of new, advanced audio features. NOTE: The new core Audio service and APIs are not backward compatible with previous versions of the Alexa Auto SDK (prior to version 2.0.0). Added a library to support the Device Client Metrics (DCM) extension for additional platforms such as Linux and QNX in addition to Android, which was supported in release 1.5. This library is required to upload metrics and vehicle information to the Amazon cloud. Added support for Voice Chrome for Android , an extension available through your Solutions Architect or Partner Manager that provides a Voice Chrome library for the Android platform. This library allows you to display voice chrome animations of different Alexa states to the user on screen. Added an integrated wake word enhancement to ignore Alexa waking itself up . In order to implement this enhancement, you must provide audio loopback via the platform or application. Added local pause handling to the PlaybackController to allow non-voice interactions to pause media playback from the AudioPlayer source immediately, without waiting for a response from the cloud. Added Geolocation support to the Navigation module. Geolocation support enables location-based services (which are used to answer questions such as \u201cwhere am I\u201d or \u201cwhat\u2019s the weather\u201d) to use the location information provided by the platform. Note: In order to make use of this functionality, you must register the Navigation platform interface for Geolocation support. * Enhanced the builder scripts to simplify the build process by removing unnecessary options and including the default components for different targets. For details see the Builder README . * Refactored the Java Native Interface (JNI) code used for Android platform interfaces for more modular deployment. In place of a single AAR including all Auto SDK native libraries, the Alexa Auto SDK now generates multiple AARs (one per module). Please see the builder README and the Android Sample App README for details.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_10","text":"Fixed an issue where music streaming from online music service providers continued to play when the user switched to a local media source. Fixed an issue where an MACC app (Spotify) could automatically play after the first utterance. Fixed a race condition in the Navigation module that occasionally caused Cancel Navigation to fail. Fixed broken links in the documentation.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_10","text":"Calling numbers such as 1800xxxxxxx using utterances such as \"Alexa call one eight double oh...\" may return unexpected results. Similarly, calling numbers using utterances that include \"triple\", \"hundred\" and \"thousand\" and pressing special characters such as # or * using utterances such as \"Alexa press *#\" may return unexpected results. Therefore, when requesting Alexa to call or press digits, we recommend that your client application ignore special characters, dots, and non-numeric characters if not relevant to the context. The Engine may crash during shutdown due to a race condition in the Local Media Source Engine implementation. However, since shutdown is triggered when the car ignition is turned off, no direct customer impact is expected. The Engine may hang during shutdown if it is shut down while TTS is being played or read. Therefore, you should avoid calling the shutdown method while loading or playing SpeechSynthesizer audio. In online mode, Alexa does not recognize the utterance \"Switch to line in.\" A user interacting with multiturn skills such as Jeopardy cannot accept or reject incoming Alexa-to-Alexa calls using voice. If the user rejects an incoming Alexa-to-Alexa call via voice, ringtones do not sound for subsequent incoming calls until the user either answers an incoming call via the VUI or makes an outbound call. If you change your Car Control configuration or custom assets during development after Local Voice Control (LVC) was previously running, you should stop your application and LVC, change the configuration or custom assets, uninstall and reinstall LVC, and relaunch your application to ensure the changes are applied. To ensure that the ID space used for contacts and navigation favorites does not collide, you must assign unique entryId s to contacts and navigation data. If you use the same entryId , re-uploading contacts may cause navigation favorites to become unavailable to Alexa, and re-uploading navigation favorites may cause contacts to become unavailable. If the local timezone of your device differs from the timezone that was configured through the Alexa companion app, the user may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\" Alexa uses different audio channels, such as dialog (user utterance or TTS) and content (music), and shuffles between them to respond to user requests. As a result of this shuffling, content (such as music playback) that gets paused to accommodate higher priority channels may regain foreground audio focus and resume content in bursts between the outputs of higher priority channels (such as Alexa TTS or ongoing alerts). To avoid this, platforms should maintain the audio focus for a few extra milliseconds. The External Media Player (EMP) Engine implementation does not wait for a dialog channel focus change to complete, such as after TTS, before executing an EMP directive, such as playing the CD player. As a result, you may see an unexpected sequence of Local Media Source playControl() method invocations such as play, then pause, followed by play again in quick succession When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"CHANGELOG/#v163-released-on-2019-12-02","text":"","title":"v1.6.3 released on 2019-12-02:"},{"location":"CHANGELOG/#enhancements_11","text":"This release is for bug fixes only. There are no new features or enhancements.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_11","text":"Fixed a race condition that could cause follow-ons to a TTS request (for example asking for movies nearby) not to play while Alexa is speaking or playing something.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_11","text":"All known issues from v1.6.0.","title":"Known Issues"},{"location":"CHANGELOG/#v162-released-on-2019-10-11","text":"","title":"v1.6.2 released on 2019-10-11:"},{"location":"CHANGELOG/#enhancements_12","text":"Added online entertainment enhancements to support tuning to a specific frequency or SiriusXM channel and tuning to radio presets.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_12","text":"n/a","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_12","text":"All known issues from v1.6.0.","title":"Known Issues"},{"location":"CHANGELOG/#v161-released-on-2019-06-21","text":"","title":"v1.6.1 released on 2019-06-21:"},{"location":"CHANGELOG/#enhancements_13","text":"This release of Alexa Auto SDK includes updates for music certification.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_13","text":"Resolved issues are limited to music certification updates: Added fixes from AVS Device SDK v1.12.1 for music certification. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Documentation updates.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_13","text":"All known issues from v1.6.0.","title":"Known Issues"},{"location":"CHANGELOG/#v160-released-on-2019-05-16","text":"","title":"v1.6.0 released on 2019-05-16:"},{"location":"CHANGELOG/#enhancements_14","text":"General availability for Linux target platforms, including: Linux x86-64, Linux ARM 64 (armv8a), and Linux ARM 32 (armv7a). Alexa Auto SDK v1.6.0 enhances the C++ Sample App by improving the reference implementation for Linux platforms. Read more about the C++ Sample App here .","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_14","text":"Fixed an issue where Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. Made changes to External Media Player events to send the service id and agent details, which are now mandated by the Alexa Music service. If you are using previous versions with Local Media Source switching or third-party app with MACC, you should upgrade to Alexa Auto SDK v1.6.0 to continue using the corresponding functionality.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_14","text":"If the local timezone of the device differs from the timezone that was configured through the Alexa companion app, you may experience unexpected behavior. For example, if your device shows 12pm PST, but the device on the Alexa companion app is configured with an EST timezone, then asking \"Alexa set an alarm for 1pm today,\" will return, \"Sorry I can't set alarms in the past.\u201d If you play your notifications while music is playing, you will hear the music for a split second between the end of one notification and the start of the next. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"CHANGELOG/#v150-released-on-2019-03-06","text":"","title":"v1.5.0 released on 2019-03-06:"},{"location":"CHANGELOG/#enhancements_15","text":"Added a C++ sample application to demonstrate use cases that the Alexa Auto SDK supports. Read more about the C++ Sample App here . Released the code for the AGL Alexa Voice Agent, a binding for Automotive Grade Linux powered by Alexa Auto SDK v1.5. The software is shipped as a standard AGL binding that exposes an API for speech recognition using the Alexa Voice Service. Please refer to the AGL Alexa Voice Agent documentation for instructions to build, install, and test the binding on an R-Car M3 board. Added support for runtime selection of the AmazonLite wake word locale. The AmazonLite locale will automatically switch when the AVS locale is switched. Added support for optionally logging and uploading Alexa Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and UPL between the request and Alexa\u2019s response. Please contact your SA or Partner Manager for details or to request this package for Android. Added support for an optional platform interface EqualizerController . The Equalizer Controller enables Alexa voice control of device audio equalizer settings by making gain adjustments to three frequency bands (\u201cBASS\u201d, \u201cMIDRANGE\u201d, and/or \u201cTREBLE\u201d). Added an optional Code-Based Linking (CBL) authorization implementation in the Engine. With the new cbl module, the Engine handles acquiring access tokens. A CBL platform implementation should be registered with the Engine in place of an AuthProvider implementation to use this method for authorization. Improved the usage and deployment of the Local Voice Control extension on Android. Please contact your SA or Partner Manager for more information. Updated the vehicle information configuration API to include a vehicle identifier. An aace.vehicle.info.vehicleIdentifier property of vehicle configuration is now available through the existing VehicleConfiguration .","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_15","text":"Fixed an issue where barging in while many unprocessed Speak directives are queued could cause SpeechSynthesizer to become unresponsive or crash Added an EXPECTING state to the AlexaClient DialogState to accommodate multi-turn for hold-to-talk interactions. When more user input is required during an interaction, tap-to-talk interactions will transition directly from EXPECTING to LISTENING whereas hold-to-talk will remain in the EXPECTING state until listening is manually triggered. Fixed an issue where the Android Sample App could get stuck in a loop of INVALID_REQUEST_EXCEPTION errors being thrown repeatedly after MACCAndroidClient reported an error. Note: To fix this, the C++ ExternalMediaAdapter::getState method signature changed to allow the implementation to say whether the state it provides is valid. This change is not backward compatible. Fixed an issue where the Android Sample App created a syslog sink and logged VERBOSE in release builds. Note: As part of the fix, the default Engine logger sink id changed from console to default . Existing calls to LoggerConfiguration::createLoggerRuleConfig with sink id \"console\" should be changed to sink id \"default\" .","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_15","text":"The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"CHANGELOG/#v140-released-on-2018-12-17","text":"","title":"v1.4.0 released on 2018-12-17:"},{"location":"CHANGELOG/#enhancements_16","text":"The Alexa Auto SDK now supports the Local Voice Control extension. The Local Voice Control extension enhances the Alexa Auto experience by providing voice-based car controls whether connected to the internet or not. In this release, the Local Voice Control extension will provision access only to the car\u2019s climate control. Note : This extension is available on request - Please contact your Amazon Solutions Architect (SA) or Partner Manager for more information.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_16","text":"No resolved issues.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_16","text":"The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"CHANGELOG/#v131-released-on-2019-06-21","text":"","title":"v1.3.1 released on 2019-06-21:"},{"location":"CHANGELOG/#enhancements_17","text":"This release of Alexa Auto SDK includes updates for music certification.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_17","text":"Resolved issues are limited to music certification updates: Migrated to AVS Device SDK v1.12.1 for music certification. As part of the migration there is a new dependency on openssl . Developers using their own build system may need to make changes in order to accommodate this new dependency when linking AVS Device SDK. Fixed ExternalMediaPlayerAdapter getState() failure that triggered INVALID_REQUEST_EXCEPTION/Bad Request exceptions. Fixed live radio offset for stations that use a dynamic window ( mime=audio/mp4a-latm ). Updated the Android Sample App log view implementation for improved stability and performance. Bug fixes and documentation updates: Additional test in AuthProviderEngineImpl::doShutdown() to avoid null pointer exception. Fixed an issue with SQLiteStorage::removeKey() where the DELETE FROM statement repeated the FROM . Fixed a race condition in AudioChannelEngineImpl::setSource() with back to back TTS. Internal calls to AudioChannelEngineImpl::executePlaybackFinished() now save the player offset. Internal calls to AudioPlayerEngineImpl::removeObserver() now remove an AudioPlayerObserverInterface observer instance instead of adding it. Use static_cast<unsigned char> for upper/lower character conversions. The platform interfaces have not changed, however the following C++ and Android enums are updated: * The enum class DialogState inserts the EXPECTING enum constant. * The enum class ConnectionChangedReason inserts NONE , SUCCESS , and UNRECOVERABLE_ERROR enum constants.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_17","text":"All known issues from v1.3.0.","title":"Known Issues"},{"location":"CHANGELOG/#v130-released-on-2018-11-20","text":"","title":"v1.3.0 released on 2018-11-20:"},{"location":"CHANGELOG/#enhancements_18","text":"Android 8 and ARM v8a platform support. Making calls to contacts from a locally-paired mobile phone as long as the Alexa Auto SDK has a valid auth token. Read more about Contact Uploader API . Redial, answer, terminate, and decline calls using voice. End users can also send dual-tone multi-frequency (DTMF) via voice to interact with Interactive Voice Responders (IVRs). Read more here Phone Call Controller . Switching to local media sources, generic controls and deep linking into 3rd party media applications compatible with the Amazon Media App Command and Control (MACC) specification using the External Media Player Interface 1.1. This allows customers to switch between a CD player, AM/FM player, and auxiliary input that is MACC-compliant. Read more here Handling External Media Adapter with MACCAndroidClient . Enhancement for 3rd party wake word engine to enable cloud based verification. Provides a way to override Template Runtime display card timeout values for RenderTemplate and RenderPlayerInfo by updating the templateRuntimeCapabilityAgent Engine configuration values.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_18","text":"No resolved issues.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_18","text":"The Alexa Auto SDK Engine becomes unresponsive if it receives a Play directive during shutdown. However, since shutdown is triggered when car ignition is turned off, there is no direct customer impact expected. When a timer sounds during an Alexa-to-Alexa call, uttering \"stop\" ends the call, not the timer. Multiple automotive devices using the same account at the same time can access contacts from phones paired across those devices.","title":"Known Issues"},{"location":"CHANGELOG/#v120-released-on-2018-10-15","text":"","title":"v1.2.0 released on 2018-10-15:"},{"location":"CHANGELOG/#enhancements_19","text":"Additional information related to the presentation of alerts is now available. The extended interface now includes Alert token, type, rendering time, and label if applicable when an alert is set and notification when an alert is deleted. In the Navigation platform interface, SetDestination now provides business hours and contact information for a returned location when available.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_19","text":"If a location is not available, the location state is set to unavailable . Previously it was treated as (0,0) , which was a valid value for longitude and latitude. Fixed an issue related to stopping an alert where there could be up to a 10 second delay before the alert completely stopped. Fixed issue where the TemplateRuntime platform interface could not be registered before AudioPlayer .","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_19","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"CHANGELOG/#v111-released-on-2018-09-10","text":"","title":"v1.1.1 released on 2018-09-10:"},{"location":"CHANGELOG/#enhancements_20","text":"This release is for bug fixes only. There are no new features or enhancements.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_20","text":"Updated a dependency build recipe to skip the checksum verification to allow for document changes in the current tag.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_20","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"CHANGELOG/#v110-released-on-2018-08-31","text":"","title":"v1.1.0 released on 2018-08-31:"},{"location":"CHANGELOG/#enhancements_21","text":"Added support for choosing one of multiple network adaptors before starting the Engine. Added support for the latest Amazon Wakeword Engine. Added custom volume control support for infotainment system's native input volume range. The range that comes down to the device will be 0 to 100. Added support for encoding the utterance in OPUS format with the Amazon Wakeword Engine as well as PTT. Our builder pulls the libopus source code as a part of build process. Added Locale API to return the list of Alexa-supported locales. Updated Vehicle Information API to capture the microphone details. Added support for routines, music alarms, timers and alarms volume management, and deleting all timers and alarms. Added support for TemplateRuntime Interface 1.1, which provides visual playback control for Alexa-enabled products with TemplateRuntime Interface support. This includes upgrades to PlaybackController Interface 1.1 and TemplateRuntime Interface 1.1. Note : The older button-press APIs ( playButtonPressed() , nextButtonPressed() , etc.) have been deprecated in favor of the new generic buttonPressed(PlaybackButtonType) . Updated the builder script to confirm compliance with open source component licenses.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_21","text":"There are no resolved issues in this release.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_21","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"CHANGELOG/#v102-released-on-2018-08-08","text":"","title":"v1.0.2 released on 2018-08-08:"},{"location":"CHANGELOG/#enhancements_22","text":"This release is only for documentation updates. There are no new features or enhancements.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_22","text":"Only name change updates were made to the documentation. There are no resolved issues in this release.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_22","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"CHANGELOG/#v101-released-on-2018-07-31","text":"","title":"v1.0.1 released on 2018-07-31:"},{"location":"CHANGELOG/#enhancements_23","text":"This release is for bug fixes only. There are no new features or enhancements.","title":"Enhancements"},{"location":"CHANGELOG/#resolved-issues_23","text":"The Engine now reconnects to Alexa when the NetworkInfoProvider updates the network status. All shared memory objects are now freed when the Engine object is disposed. We fixed a media playback state issue in the Engine that caused an unexpected pause and resume for a media stream that was already stopped. We added AudioPlayer::playerActivityChanged to the Android APIs. Updated the AuthError enumeration with additional error types. Removed deprecated createAuthConfig() configuration method. Fixed issue in the JNI where trying to create a UTF-8 string with invalid characters caused a crash, seen when sensitive logging is enabled. Improved JNI thread handling. Enabled capability registration for phone call control. We fixed an issue where the Android platform build failed on the initial attempt when using clean code.","title":"Resolved Issues"},{"location":"CHANGELOG/#known-issues_23","text":"There are no known issues in this release.","title":"Known Issues"},{"location":"CHANGELOG/#v100-released-on-2018-06-29","text":"","title":"v1.0.0 released on 2018-06-29:"},{"location":"CHANGELOG/#enhancements_24","text":"Alexa Auto SDK now supports two Navigation directives. SetDestination CancelNavigation Added support for phone control APIs. The PhoneCallController platform interface supports the Dial directive with three events: CallActivated CallTerminated CallFailed Support for Amazon Wake Word Engine (WWE)","title":"Enhancements"},{"location":"CHANGELOG/#known-issues_24","text":"The Engine doesn't immediately reconnect to AVS when the NetworkInfoProvider updates network status. Some shared memory objects are not freed when the Engine object is disposed. Sample App issues are documented in the Sample App README .","title":"Known Issues"},{"location":"CHANGELOG/#v100-beta-released-on-2018-04-29","text":"","title":"v1.0.0 Beta released on 2018-04-29:"},{"location":"CHANGELOG/#enhancements_25","text":"The following enhancements were added to the Alexa Auto SDK since the last Alpha release (binary). SetDestination() API added to the Navigation module (see the Modules sections in the \"Alexa Auto SDK\" readme.) Android Sample Application updated with a number of features such as rendering of Display Cards (Shopping List, Coffee Shops Nearby, etc), handling of the SetDestination() API, Notifications, LWA (Login with Amazon)","title":"Enhancements"},{"location":"CHANGELOG/#known-issues_25","text":"SDK: While the SDK does build against Android API22 and above and runs successfully on Android O devices, our current testing shows a native-code linking error when actually running on API22 devices. Android Sample App: M3U and PLS based stream URLs are not parsed before sent to the Android Mediaplayer. Affects live streams typically coming from TuneIn and IHeartRadio services Media playback can take a long time to start sometimes for iHeartRadio and TuneIn The Android Alexa Auto SDK Sample App was developed on an Android tablet with 2048 x 1536 resolution screen size. It can run on smaller devices, but some of the display cards may not display correctly During Playing Media in the Sample App we see the following messages (none of these will cause any issues): E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=streamFormat E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=progressReportDelayInMilliseconds E/AVS:JsonUtils:findNodeFailed:reason=missingDirectChild,child=expectedPreviousToken E/AAC:aace.alexa.AudioChannelEngineImpl:validateSource:reason=invalidSource E/AAC:aace.alexa.AudioChannelEngineImpl:pause:reason=invalidSource,expectedState=X On App startup we see the following messages (none of these will cause any issues): E/AVS:SQLiteAlertStorage:openFailed::File specified does not exist.:file path=/data/user/0/com.amazon.sampleapp/cache/appdata/alerts.sqlite Several minor documentation issues that will be addressed in the GA release","title":"Known Issues"},{"location":"CODE_OF_CONDUCT/","text":"Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"CONTRIBUTING/","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Reporting Bugs/Feature Requests We are not using the GitHub issue tracker at this time. Read the section \" Reporting an issue \" in NEED_HELP for details about reporting issues. Contributing via Pull Requests At this time we are not accepting any pull requests. Code of Conduct This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments. Security Issue Notifications If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue. Licensing See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Contributing"},{"location":"CONTRIBUTING/#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.","title":"Contributing Guidelines"},{"location":"CONTRIBUTING/#reporting-bugsfeature-requests","text":"We are not using the GitHub issue tracker at this time. Read the section \" Reporting an issue \" in NEED_HELP for details about reporting issues.","title":"Reporting Bugs/Feature Requests"},{"location":"CONTRIBUTING/#contributing-via-pull-requests","text":"At this time we are not accepting any pull requests.","title":"Contributing via Pull Requests"},{"location":"CONTRIBUTING/#code-of-conduct","text":"This project has adopted the Amazon Open Source Code of Conduct . For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.","title":"Code of Conduct"},{"location":"CONTRIBUTING/#security-issue-notifications","text":"If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page . Please do not create a public github issue.","title":"Security Issue Notifications"},{"location":"CONTRIBUTING/#licensing","text":"See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution. We may ask you to sign a Contributor License Agreement (CLA) for larger changes.","title":"Licensing"},{"location":"GETSTARTED/","text":"Getting Started with the Alexa Auto SDK This document assumes that you have read the README to understand the basic Auto SDK concepts. Complete the steps in this document to get started with the Auto SDK and to follow security best practices. Table of Contents Before You Start Getting Started Downloading Optional Extensions Before You Start Complete the following steps before you get started with the Auto SDK: Register for an Amazon Developer Account and create an Alexa device and security profile to use the Auto SDK. Make sure that you meet the requirements for building the Auto SDK and understand the dependencies, as described in the SDK builder README . Getting Started Follow these steps to get started with the Auto SDK: Clone the alexa-auto-sdk repository into your project. If you want to use the optional Auto SDK modules, download the modules from the locations listed in Downloading Optional Extensions . Build the Auto SDK as described in the builder README . Note: If your target platform is Android and you want to implement any optional modules (such as wake word support and Alexa Communications), you must use the Android Archive (AAR) files generated by the Auto SDK Builder. Do not use the prebuilt platform AARs and sample-core AAR available in the Maven central repository; they are for the default Auto SDK modules only. Install the built package on your device as described in the builder README . Create and configure an instance of the Engine. For details, see the Core module documentation. Extend the Auto SDK interfaces by creating a custom handler for each interface that you want to implement and registering the handler with the Engine. Start the Engine using the start() command. Use the Sample App ( C++ or Android ) to see how the Auto SDK works and to test end-to-end functionality. Downloading Optional Extensions NOTE : The version of the optional extension archive must match the version of the Auto SDK that you are using. For example, if you are using Auto SDK 3.0 and want to install the Local Voice Control extension, you must download version 3.0 of the Local Voice Control extension archive. Click the link in the following list to go to the directory where the extension archive is located: AmazonLite Wake Word extension Alexa Communications extension Local Voice Control extension Device Client Metrics (DCM) extension Voice Chrome for Android extension","title":"Getting Started"},{"location":"GETSTARTED/#getting-started-with-the-alexa-auto-sdk","text":"This document assumes that you have read the README to understand the basic Auto SDK concepts. Complete the steps in this document to get started with the Auto SDK and to follow security best practices.","title":"Getting Started with the Alexa Auto SDK"},{"location":"GETSTARTED/#table-of-contents","text":"Before You Start Getting Started Downloading Optional Extensions","title":"Table of Contents"},{"location":"GETSTARTED/#before-you-start","text":"Complete the following steps before you get started with the Auto SDK: Register for an Amazon Developer Account and create an Alexa device and security profile to use the Auto SDK. Make sure that you meet the requirements for building the Auto SDK and understand the dependencies, as described in the SDK builder README .","title":"Before You Start"},{"location":"GETSTARTED/#getting-started","text":"Follow these steps to get started with the Auto SDK: Clone the alexa-auto-sdk repository into your project. If you want to use the optional Auto SDK modules, download the modules from the locations listed in Downloading Optional Extensions . Build the Auto SDK as described in the builder README . Note: If your target platform is Android and you want to implement any optional modules (such as wake word support and Alexa Communications), you must use the Android Archive (AAR) files generated by the Auto SDK Builder. Do not use the prebuilt platform AARs and sample-core AAR available in the Maven central repository; they are for the default Auto SDK modules only. Install the built package on your device as described in the builder README . Create and configure an instance of the Engine. For details, see the Core module documentation. Extend the Auto SDK interfaces by creating a custom handler for each interface that you want to implement and registering the handler with the Engine. Start the Engine using the start() command. Use the Sample App ( C++ or Android ) to see how the Auto SDK works and to test end-to-end functionality.","title":"Getting Started"},{"location":"GETSTARTED/#downloading-optional-extensions","text":"NOTE : The version of the optional extension archive must match the version of the Auto SDK that you are using. For example, if you are using Auto SDK 3.0 and want to install the Local Voice Control extension, you must download version 3.0 of the Local Voice Control extension archive. Click the link in the following list to go to the directory where the extension archive is located: AmazonLite Wake Word extension Alexa Communications extension Local Voice Control extension Device Client Metrics (DCM) extension Voice Chrome for Android extension","title":"Downloading Optional Extensions"},{"location":"LINUX_INTEGRATION/","text":"Auto SDK Integration Guide for Linux-based platforms The Message Broker API in Auto SDK provides a way for your application to interact with the Engine for a particular functionality, such as audio input, media streaming or location services. The Engine publishes messages when it needs to query data or delegate handling, such as rendering visual elements or placing a phone call to your custom implementation. Your application must publish messages to the Engine to provide a proactive notification of a state change or error. This loosely coupled MessageBroker API to subscribe to and publish messages allows you to have a lot more flexibility with how you design the application. The following architecture diagram illustrates a common design used for integrating the Auto SDK in Linux platforms. To integrate your application with Auto SDK using the MessageBroker interface, follow these steps: Creating the Engine To create an instance of the Engine, call the static function aace::core::Engine::create() : auto engine = aace::core::Engine::create(); Configuring the Engine Before you can start the Engine, you must configure it using the required aace::core::config::EngineConfiguration object(s) for the services you will be using: Generate the EngineConfiguration object(s). You can do this using a JSON configuration file, programmatically (using factory functions), or using a combination of both approaches. Note: You can generate a single EngineConfiguration object that includes all configuration data for the services you will be using, or you can break the configuration data into logical sections and generate multiple EngineConfiguration objects. For example, you might generate one EngineConfiguration object for each module. Please refer to the respective module README for details. Call the Engine's configure() function, passing in the EngineConfiguration object(s): For a single EngineConfiguration object, use: engine->configure( config ); For multiple EngineConfiguration objects, use: engine->configure( { xConfig, yConfig, zConfig, ... } ); replacing xConfig, yConfig, zConfig with logical names to identify the EngineConfiguration objects you generated; for example: coreConfig, alexaConfig, navigationConfig Note : You can call the Engine's configure() function only once, and you must call it before you subscribe to any messages or start the Engine. Subscribing to messages from Engine Get a reference to the message broker from the Engine. auto messageBroker = engine->getMessageBroker(); 2. Use the following MessageBroker subscribe() function, passing in a message handler (a function that will handle the messages published by the Engine), the topic and action for which you want to receive messages from the Engine. void subscribe(MessageHandler handler, const std::string& topic = \"\", const std::string& action = \"\"); Note : If no topic or action is specified, then the application will receive messages for all topics and all actions. Publishing messages to Engine Messages are published to the Engine to provide a proactive notification of a state change or an error. Use the MessageBroker publish() function to send a specific message to the Engine. void publish(const std::string& message) Handling synchronous-style messages Most messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special reply message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message. Replying to messages from the Engine Some messages that are sent to the application require a special reply message type to be sent back. In most cases the engine will block other messages from being sent until the reply is received (or until a timeout occurs), so it is important to send the reply message right away. To reply to a message: Set the replyToId in the reply message to the ID of the original message. Use the MessageBroker publish() function to send the reply. Receiving reply messages from the Engine For some messages published by the application, the Engine may send a reply back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The replyToId in the reply message will contain the message ID for which the reply is sent. Handling audio and stream based interface Stream based interfaces, such as AudioInput and AudioOutput, require the application to read from or write to a stream. For such messages, a stream ID is included in the message payload. Use the MessageBroker openStream() function to fetch the MessageStream corresponding to the stream ID. Specify the operation mode when opening the stream using the MessageStream::Mode enumeration. Streams can either be read-only, write-only, or support both input and output operations. std::shared_ptr<MessageStream> openStream(const std::string& streamId, MessageStream::Mode mode) Note : If a stream can not be opened for the specified operation, the openStream() call will fail and return a null object","title":"Linux Integration"},{"location":"LINUX_INTEGRATION/#auto-sdk-integration-guide-for-linux-based-platforms","text":"The Message Broker API in Auto SDK provides a way for your application to interact with the Engine for a particular functionality, such as audio input, media streaming or location services. The Engine publishes messages when it needs to query data or delegate handling, such as rendering visual elements or placing a phone call to your custom implementation. Your application must publish messages to the Engine to provide a proactive notification of a state change or error. This loosely coupled MessageBroker API to subscribe to and publish messages allows you to have a lot more flexibility with how you design the application. The following architecture diagram illustrates a common design used for integrating the Auto SDK in Linux platforms. To integrate your application with Auto SDK using the MessageBroker interface, follow these steps:","title":"Auto SDK Integration Guide for Linux-based platforms"},{"location":"LINUX_INTEGRATION/#creating-the-engine","text":"To create an instance of the Engine, call the static function aace::core::Engine::create() : auto engine = aace::core::Engine::create();","title":"Creating the Engine"},{"location":"LINUX_INTEGRATION/#configuring-the-engine","text":"Before you can start the Engine, you must configure it using the required aace::core::config::EngineConfiguration object(s) for the services you will be using: Generate the EngineConfiguration object(s). You can do this using a JSON configuration file, programmatically (using factory functions), or using a combination of both approaches. Note: You can generate a single EngineConfiguration object that includes all configuration data for the services you will be using, or you can break the configuration data into logical sections and generate multiple EngineConfiguration objects. For example, you might generate one EngineConfiguration object for each module. Please refer to the respective module README for details. Call the Engine's configure() function, passing in the EngineConfiguration object(s): For a single EngineConfiguration object, use: engine->configure( config ); For multiple EngineConfiguration objects, use: engine->configure( { xConfig, yConfig, zConfig, ... } ); replacing xConfig, yConfig, zConfig with logical names to identify the EngineConfiguration objects you generated; for example: coreConfig, alexaConfig, navigationConfig Note : You can call the Engine's configure() function only once, and you must call it before you subscribe to any messages or start the Engine.","title":"Configuring the Engine"},{"location":"LINUX_INTEGRATION/#subscribing-to-messages-from-engine","text":"Get a reference to the message broker from the Engine. auto messageBroker = engine->getMessageBroker(); 2. Use the following MessageBroker subscribe() function, passing in a message handler (a function that will handle the messages published by the Engine), the topic and action for which you want to receive messages from the Engine. void subscribe(MessageHandler handler, const std::string& topic = \"\", const std::string& action = \"\"); Note : If no topic or action is specified, then the application will receive messages for all topics and all actions.","title":"Subscribing to messages from Engine"},{"location":"LINUX_INTEGRATION/#publishing-messages-to-engine","text":"Messages are published to the Engine to provide a proactive notification of a state change or an error. Use the MessageBroker publish() function to send a specific message to the Engine. void publish(const std::string& message)","title":"Publishing messages to Engine"},{"location":"LINUX_INTEGRATION/#handling-synchronous-style-messages","text":"Most messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special reply message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message.","title":"Handling synchronous-style messages"},{"location":"LINUX_INTEGRATION/#replying-to-messages-from-the-engine","text":"Some messages that are sent to the application require a special reply message type to be sent back. In most cases the engine will block other messages from being sent until the reply is received (or until a timeout occurs), so it is important to send the reply message right away. To reply to a message: Set the replyToId in the reply message to the ID of the original message. Use the MessageBroker publish() function to send the reply.","title":"Replying to messages from the Engine"},{"location":"LINUX_INTEGRATION/#receiving-reply-messages-from-the-engine","text":"For some messages published by the application, the Engine may send a reply back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The replyToId in the reply message will contain the message ID for which the reply is sent.","title":"Receiving reply messages from the Engine"},{"location":"LINUX_INTEGRATION/#handling-audio-and-stream-based-interface","text":"Stream based interfaces, such as AudioInput and AudioOutput, require the application to read from or write to a stream. For such messages, a stream ID is included in the message payload. Use the MessageBroker openStream() function to fetch the MessageStream corresponding to the stream ID. Specify the operation mode when opening the stream using the MessageStream::Mode enumeration. Streams can either be read-only, write-only, or support both input and output operations. std::shared_ptr<MessageStream> openStream(const std::string& streamId, MessageStream::Mode mode) Note : If a stream can not be opened for the specified operation, the openStream() call will fail and return a null object","title":"Handling audio and stream based interface"},{"location":"MIGRATION/","text":"Alexa Auto SDK Migration Guide This guide outlines the changes you need to make to migrate from Auto SDK v2.0 to later versions of the Auto SDK. Note: If you migrate from a version earlier than v2.3, be sure to read the relevant sections of this guide to understand all changes introduced between your current version and v3.3. The information helps you decide what changes you must include. For example, if you migrate from v2.0, include the changes described in Migrating from Auto SDK v2.0 to v2.1 , the changes described in Migrating from Auto SDK v2.1 to v2.2 , and so on, taking into consideration the deprecated or removed features in each version. Table of Contents Migrating from Auto SDK v3.3.0 to v4.0.0 Platform Interface Deprecation Migrating from Auto SDK v3.2.1 to v3.3.0 Local Media Source and Global Preset Enhancements Migrating the Local Navigation Module APIs Migrating from Auto SDK v3.1.0 to v3.2.0 Using the Alexa Communication Extension Using the Device Client Metrics (DCM) Extension Migrating from Auto SDK v3.0.0 to v3.1.0 Migrating to the Authorization Platform Interface Deprecated Features Removed in Auto SDK v3.0.0 Using the Address Book Module Migrating from Auto SDK v2.2.1 to v2.3.0 Car Control Enhancements and Breaking Changes Language Model Packaging Android Clang Formatting Migrating from Auto SDK v2.2 to v2.2.1 TemplateRuntime Enhancements Migrating from Auto SDK v2.1 to v2.2 Implementing the Property Manager Interface Car Control Changes Migrating from Auto SDK v2.0 to v2.1 Build Changes Engine Configuration File Updates Navigation Enhancements Car Control Source File Relocation Code-Based-Linking (CBL) Handler in the Sample Apps Migrating from Auto SDK v3.3.0 to v4.0.0 This section provides the information you need to migrate from Auto SDK v3.3.0 to Auto SDK v4.0.0 Platform Interface Deprecation The C++ and Java platform interfaces are deprecated in favor of Alexa Auto Services Bridge (AASB). Auto SDK 4.0 replaces the platform interfaces with a new MessageBroker API for subscribing to and publishing AASB messages. Details to migrate your application to the MessageBroker API are here. Migrating from Auto SDK v3.2.1 to v3.3.0 This section provides the information you need to migrate from Auto SDK v3.2.1 to Auto SDK v3.3.0 Local Media Source and Global Preset Enhancements GlobalPreset is deprecated The GlobalPreset platform interface is deprecated because its feature set is supported by the new DEFAULT LocalMediaSource type. To preserve functionality for utterances targetting generic presets like \"Alexa, play preset 1\", implement and register a LocalMediaSource handler of Source::DEFAULT type. The user utterances that cause the Engine to invoke GlobalPreset::setGlobalPreset() will cause the Engine to invoke LocalMediaSource::play() with ContentSelector::PRESET instead. The GlobalPreset platform interface will be removed in a future version of Auto SDK. Addtional LocalMediaSource playerEvent calls are needed Previous Auto SDK documentation stated that you must call LocalMediaSource::playerEvent() to report events \"PlaybackStated\" and \"PlaybackStopped\" only. Please update your implementation to call playerEvent() with states \"PlaybackSessionStarted\" and \"PlaybackSessionEnded\" as well. See the Reporting Playback Events section in the Alexa module README for information about when to report these events. setFocus is deprecated The API LocalMediaSource::setFocus() is deprecated because its functionality is equivalent to calling LocalMediaSource::playerEvent() with event name \"PlaybackSessionStarted\" when a player is brought into focus or \"PlaybackSessionEnded\" when a player is removed from focus. Please replace your calls to setFocus(true) and setFocus(false) with calls to playerEvent(\"PlaybackSessionStarted\") and playerEvent(\"PlaybackSessionEnded\") , respectively. setFocus will be removed in a future version of Auto SDK. Reporting playback session ID is needed The Alexa cloud requires ExternalMediaPlayer events and context for a particular player to include the playback session ID of a player's active session. To support this, the LocalMediaSource::play() function signature is updated to include a parameter for session ID for an Alexa-initiated session, which you must use when reporting player events for the player. The playerEvent and playerError signatures are also updated to include session ID. You must generate your own session ID when the playback is initiated by the user without Alexa. See the Reporting Playback Events section in the Alexa module README for more details about the sessionId . The versions of APIs without the session ID will be removed in a future version of Auto SDK. Migrating the Local Navigation Module APIs The local search features of the Local Voice Control Extension's Local Navigation module are extended to support offline navigation to addresses, cities, and neighborhoods. To support the new feature set, the existing APIs are updated to a more general name. The changes are backward compatible, but the old APIs are deprecated and will be removed in a future version. Use the following steps to assist the migration to the new APIs: LocalSearchProvider Platform Interface Changes We have deprecated the functions poiSearchRequest , poiLookupRequest , poiSearchResponse , and poiLookupResponse in favor of searchRequest , lookupRequest , searchResponse , and lookupResponse , respectively. Override LocalSearchProvider::searchRequest() instead of LocalSearchProvider::poiSearchRequest() . Override LocalSearchProvider::lookupRequest() instead of LocalSearchProvider::poiLookupRequest() . Call LocalSearchProvider::searchResponse() instead of LocalSearchProvider::poiSearchResponse() . Call LocalSearchProvider::lookupResponse() instead of LocalSearchProvider::poiLookupResponse() . We have also deprecated the AASB messages PoiSearchRequestMessage , PoiLookupRequestMessage , PoiSearchResponseMessage , and PoiLookupResponseMessage in favor of SearchRequestMessage , LookupRequestMessage , SearchResponseMessage , and LookupResponseMessage , respectively. Subscribe to SearchRequestMessage instead of PoiSearchRequestMessage . Subscribe to LookupRequestMessage instead of PoiLookupRequestMessage . Publish to SearchResponseMessage instead of PoiSearchResponseMessage . Publish to LookupResponseMessage instead of PoiLookupResponseMessage . The JSON schemas of search and response are still the same. Note: Do not use/implement a mix of the old APIs and the new APIs Local Navigation Module Engine Configuration Changes The aace.localNavigation.localSearch configuration keys navigationPOISocketPath and poiEERSocketPath are renamed to navigationLocalSearchSocketPath and localSearchEERSocketPath , respectively. For example, if your configuration was this { \"aace.localNavigation\": { \"localSearch\": { \"navigationPOISocketPath\": \"/opt/LVC/data/poi-er-service/poi_navigation.socket\", \"poiEERSocketPath\": \"/opt/LVC/data/poi-er-service/poi_eer.socket\" } } } change it to this { \"aace.localNavigation\": { \"localSearch\": { \"navigationLocalSearchSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_navigation.socket\", \"localSearchEERSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_eer.socket\" } } } If you are using the LocalNavigationConfiguration::createLocalSearchConfig() factory function to generate the configuration, your usage does not have to change because the signature is the same and implementation of this function generates the new JSON. Note: the socket paths in the Linux default sample configuration file are updated, so if you use different values, ensure you update your LVC app configuration accordingly LVC APK Configuration Changes If you use LVC on Android, update the configuration returned by your implementation of the interface ILVCClient.getConfiguration() . The paths NavigationPOISocketDir and POIEERSocketDir have been deprecated in favor of NavigationLocalSearchSocketDir and LocalSearchEERSocketDir , respectively. The socket names NavigationPOISocketName and POIEERSocketName have been deprecated in favor of NavigationLocalSearchSocketName and LocalSearchEERSocketName , respectively. LVC Linux App Configuration Changes The LVC configuration file lvc-config.json installed at /opt/LVC/config by the installation script LVC.sh has no changes to its JSON configuration schema since Auto SDK 3.2. However, the socket directories and names used by default in this file are updated to use more general names. Migrating from Auto SDK v3.1.0 to v3.2.0 This section provides the information you need to migrate from Auto SDK v3.1.0 to Auto SDK 3.2.0. All information about 3.2.0 is also applicable to 3.2.1. Using the Alexa Communication Extension The Alexa Comms library in Auto SDK v3.2.0 uses Device Client Metrics (DCM) instead of AWS IoT for uploading metrics. Therefore, remove the iotCertificateDirPath , iotHostAddress , and deviceTypeId fields from the communication configuration file. For information about the configuration file format, see the Alexa Communication extension README. If you build the Alexa Comms module configuration using the programmatic factory function AlexaCommsConfiguration::createCommsConfig() (C++) or AlexaCommsConfiguration.createCommsConfig() (Java), remove the parameters that are no longer present in the signature. Using the Device Client Metrics (DCM) Extension The Device Client Metrics extension in Auto SDK v3.2.0 requires a field called metricsTag to be defined in the DCM configuration. The value of metricsTag is used for generating a unique identifier for anonymous registration metrics. Note: You must not use the vehicle identification number (VIN) or device serial number (DSN) as metricsTag . For information about how to use this field, see the Device Client Metric extension README. If you build the DCM module configuration using the programmatic factory function DCMConfiguration::createDCMConfig() (C++) or DCMConfiguration.createDCMConfig() (Java), add the metricsTag parameter as instructed in the API documentation. Migrating from Auto SDK v3.0.0 to v3.1.0 This section provides the information you need to migrate from Auto SDK v3.0.0 to Auto SDK v3.1.0. Migrating to the Authorization Platform Interface Auto SDK v3.1.0 introduces the Authorization module that provides a single platform interface to manage different types of authorizations supported by the Engine. This single platform interface works with the Engine services that carry out the actual authorization process or flow. For more information about how authorization works, see the Core module README . This section provides the information you need for migrating to the Authorization platform interface from the CBL or AuthProvider platform interface, which are deprecated in v3.1.0 Migrating from the CBL Platform Interface To migrate from the CBL platform interface to the Authorization platform interface, follow the instructions in the CBL README , which describes the Authorization APIs for CBL authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the CBL platform interface, as shown in the following table: CBL Authorization Description ERROR UNKNOWN_ERROR Unknown error occurs during the authorization flow. TIMEOUT TIMEOUT Request for the the CBL code from LWA times out. CODE_PAIR_EXPIRED CODE_PAIR_EXPIRED The code pair obtained has expired. AUTHORIZATION_EXPIRED AUTHORIZATION_EXPIRED Refresh token is expired or revoked. START_AUTHORIZATION_FAILED Authorization fails to start. LOGOUT_FAILED Logout fails. Migrating from the AuthProvider Platform Interface To migrate from the AuthProvider platform interface to the Authorization platform interface, follow the instructions in the Alexa README , which describes the Authorization APIs for Auth Provider authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the AuthProvider platform interface, as shown in the following table: AuthProvider Authorization Description authFailure AUTH_FAILURE Invalid or expired access token was provided. NOT PRESENT UNKNOWN_ERROR Unknown error occurs during the authorization flow. NOT PRESENT START_AUTHORIZATION_FAILED Authorization fails to start. NOT PRESENT LOGOUT_FAILED Logout fails. Deprecated Features Removed in Auto SDK v3.0.0 The following asset IDs for Car Control have been removed: \"Alexa.Automotive.DeviceName.DriverSeat\", \"Alexa.Automotive.DeviceName.LeftSeat\", \"Alexa.Automotive.DeviceName.PassengerSeat\", \"Alexa.Automotive.DeviceName.RightSeat\". The createControl() method has been removed. Use createEndpoint() instead. Support for the \"isMemberOf\" relationship for endpoint definition has been removed. You must list member endpoints in a zone definition. Implicit zone definitions have been removed. The following TemplateRuntime methods have been removed: The renderTemplate(const std::string& payload) method has been removed. Use renderTemplate(const std::string& payload, FocusState focusState) instead. The renderPlayerInfo(const std::string& payload) method has been removed. Use renderPlayerInfo(const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState) instead. In the Alexa module, AlexaProperties::SUPPORTED_LOCALES has been removed. For Alexa to recognize the locale setting, specify one of these values: de-DE, en-AU, en-CA, en-GB, en-IN, en-US, es-ES, es-MX, es-US, fr-CA, fr-FR, hi-IN, it-IT, ja-JP, pt-BR. Engine::setProperty() and Engine::getProperty() have been removed. Use PropertyManager::setProperty() and PropertyManager::getProperty() instead. For details about the Property Manager platform interface, see \"Managing Runtime Properties with the Property Manager\" ( for C++ or for Android ). The SpeechRecognizer::enableWakeWordDetection() , SpeechRecognizer::disableWakeWordDetection() , and SpeechRecognizer::isWakewordDetectionEnabled() methods have been removed. The Contact Uploader module has been removed. Use the Address Book module instead. Using the Address Book Module Address Book module enables the user to upload contacts from the phone that is paired with the car or the navigation favorites from the car head unit to Alexa cloud. For more information about how this module works, see the Address Book README . Both the Android and C++ sample apps demonstrate the use of the AddressBook platform interface. See the sample app source code for specific implementation details. The following Address Book API descriptions help you transition from the Contact Uploader module to the Address Book module: addAddressBook bool addAddressBook(const std::string& addressBookSourceId, const std::string& name, AddressBookType type); Use addAddressBook instead of ContactUploader::addContactsBegin . In addition, addAddressBook requires you to specify the source id to identify the address book, the friendly name of the address book, and the type of address book. removeAddressBook bool removeAddressBook(const std::string& addressBookSourceId); Use removeAddressBook instead of ContactUploader:: removeUploadedContacts . You must specify the id of the address book to be removed. getEntries bool getEntries( const std::string& addressBookSourceId, std::weak_ptr<IAddressBookEntriesFactory> factory) When using the Address Book module, the Engine pulls the address book contents from the platform implementation. You must upload the address book contents through the factory class, IAddressBookEntriesFactory , for the specified address book source id. Migrating from Auto SDK v2.2.1 to v2.3.0 This section outlines the changes you will need to make to migrate from Auto SDK v2.2.1 to Auto SDK v2.3. Car Control Enhancements and Breaking Changes Read the updated Car Control module README (for C++ platforms or Android ) to get a complete understanding of all supported features and the current format of the \"aace.carControl\" configuration schema. Read the updated API documentation for the CarControlConfiguration builder class (for C++ platforms or Android ) if you construct your configuration programmatically. The changes to the \"aace.carControl\" configuration for v2.3 are backward-compatible, meaning your previous configuration (regardless of whether it was file-based or built programmatically with the CarControlConfiguration class) will still compile and produce a valid configuration to input to Auto SDK. However, several updates are recommended to ensure expected behavior, even if you do not want new features. 1. Zones configuration schema update Prior to v2.3, to assign an endpoint to exactly one zone, you would specify an \"isMemberOf\" relationship in the definition of the endpoint and specify no information about endpoints in the zone definition. { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ], \"relationships\": { \"isMemberOf\": { \"zoneId\": \"zone.all\" } } } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] } } In 2.3, the \"isMemberOf\" relationship is removed from endpoint definitions so that endpoints need not belong to zones and the zone definition can be the source of truth for all its member endpoints. The zone definition now includes a list of member endpoints: { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ] } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] }, \"members\" : [ { \"endpointId\": \"all.fan\" }, ... ] } You should update your configuration accordingly. The Auto SDK Engine translates the old format to the new format internally, but this will be deprecated in later versions. When updating to the new format, you must not combine usage of the \"isMemberOf\" format with the \"members\" list format. Fully migrate all definitions in your configuration. 2. Deprecated implicit creation of zone definitions If you construct your configuration programmatically with the CarControlConfiguration builder class, your implementation prior to v2.3 might not have explicitly specified definitions for the set of zones considered \"official\", but you still used them in your endpoint configurations anyway. The builder class added these definitions to the \"aace.carControl\" configuration automatically without requiring you to call CarControlConfiguration::createZone() . In v2.3, CarControlConfiguration still includes this logic for the old \"official\" zones, but it does not implicitly create any new zones, and it is recommended to define every zone you use by calling CarControlConfiguration::createZone() . Implicit zone definitions will be removed in a later version. 3. New default zone feature Specifying a \"default\" zone ID is an optional new feature, but it is highly recommended that you use it. See the Car Control module README for details about why this feature is important. 4. Deprecated \"DriverSeat\" and related assets in favor of zones Prior to v2.3, the default automotive catalog of assets introduced several asset IDs so that online-only systems could mock zones support for heaters on seat endpoints. The asset IDs are the following: Alexa.Automotive.DeviceName.DriverSeat , Alexa.Automotive.DeviceName.LeftSeat , Alexa.Automotive.DeviceName.PassengerSeat , Alexa.Automotive.DeviceName.RightSeat . Now that the cloud supports zones, you must stop using these asset IDs and properly model the endpoints using zones so that Alexa resolves user utterance intents as expected. These assets will be removed in a later version of Auto SDK. See the Car Control module README for sample configuration. 5. New default assets The Car Control module is updated to include many new assets in the default automotive catalog to support a wider range of utterances. If you previously defined custom assets to support any of the features introduced to the v2.3 assets, it is recommended that you use the new default assets instead of your previous custom ones. See the Car Control module README for details about assets. 6. Reset your account when changing from 2.2 to 2.3 configuration It is a known issue that you cannot delete any previously configured endpoint IDs associated with your customer account in the cloud. When upgrading your configuration from v2.2 to v2.3, contact your SA or Partner Manager for help to reset your account's endpoint database in the cloud. This is especially important if you are updating to use new features. It is also recommended that your v2.3 configuration follows the configuration sample of supported features shown in the Car Control README. Refer to this document for reference. Language Model Packaging Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binaries. If you use the Local Voice Control extension, you must install the language models to successfully migrate to v2.3.0. Download the language model tar files. Installation instructions are provided in the Local Voice Control extension. Android Gradle The gradle plugin has been updated to v3.6.2. This requires gradle v5.6.4 or above in order to build the Auto SDK for Android targets. Sample App The Android sample app supports overriding the client configuration by pushing a file named app_config.json to the /sdcard folder on the device. If the /sdcard/app_config.json file existed on the device before you migrate to v2.3.0, the file overrides the client configuration included in the v2.3.0 Android sample app APK. Clang Formatting Auto SDK code has been formatted with clang-format version 9.0.0. This may lead to merge conflicts if changes have been made to v2.2.1 source code files and you migrate to v2.3. Migrating from Auto SDK v2.2 to v2.2.1 This section outlines the changes you will need to make to migrate from Auto SDK v2.2 to Auto SDK v2.2.1. TemplateRuntime Enhancements Auto SDK v2.2.1 introduces additional TemplateRuntime platform interface features that you can integrate in your application to enrich the user's experience with Now Playing cards for AudioPlayer and ExternalMediaPlayer implementations. Now Playing cards are a form of display cards \u2014 visual aids that complement the Alexa voice experience \u2014 that contain media metadata, player controls and album art delivered in the TemplateRuntime RenderPlayerInfo directive. Migration is only required to support the new features, but is highly recommended for the following reasons: 1. AudioPlayer and TemplateRuntime are now decoupled. 2. The following TemplateRuntime methods are now deprecated: 1. The renderTemplate( const std::string& payload ) method is deprecated. Use renderTemplate( const std::string& payload, FocusState focusState ) instead. 2. The renderPlayerInfo( const std::string& payload ) method is deprecated. Use renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) instead. renderTemplate Method renderTemplate( const std::string& payload, FocusState focusState ) The new renderTemplate method provides visual metadata associated with a user request to Alexa. The platform implementation should parse the template metadata and render a display card for the user. Parameters - payload Renderable template metadata in structured JSON format - focusState The FocusState of the channel used by TemplateRuntime interface - FOREGROUND Represents the highest focus a Channel can have - BACKGROUND Represents the intermediate level focus a Channel can have renderPlayerInfo Method renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) The new renderPlayerInfo method provides visual metadata associated with a user request to Alexa for audio playback. The platform implementation should parse the player info metadata and render a display card for the user. The audioPlayerState and offset are useful for implementing the progress bar in the display card. It is assumed that the client is responsible for progressing the progress bar when the AudioPlayer is in PLAYING state. Parameters - payload Renderable player info metadata in structured JSON format - audioPlayerState The state of the AudioPlayer - IDLE Audio playback has not yet begun - PLAYING Audio is currently playing - STOPPED Audio playback is stopped, either from a stop directive or playback error - PAUSED Audio playback is paused - BUFFER_UNDERRUN Audio playback is stalled because a buffer underrun has occurred - FINISHED Audio playback is finished - offset The offset in millisecond of the media that AudioPlayer is handling - focusState The FocusState of the channel used by TemplateRuntime interface - FOREGROUND Represents the highest focus a Channel can have - BACKGROUND Represents the intermediate level focus a Channel can have Sample Apps The Android Sample App demonstrates the new features in TemplateRuntimeHandler.java in GUI form. Refer to sample app source code and Alexa Voice Service documentation for specific implementation details. The C++ Sample App simply demonstrates the new features by printing audioPlayerState , offset , and focusState to the console in the TemplateRuntimeHandler::renderPlayerInfo() method of TemplateRuntimeHandler.cpp . Migrating from Auto SDK v2.1 to v2.2 This section outlines the changes you will need to make to migrate from Auto SDK v2.1 to Auto SDK v2.2. Implementing the Property Manager Interface Auto SDK v2.2 introduces the Property Manager, a component that maintains runtime properties by storing property values and listeners and delegating the setProperty() and getProperty() calls from your application to the respective Engine services. The Engine invokes the PropertyManager platform interface method propertyChanged() to notify your application about property value changes originating internally. The property values may be set by Auto SDK modules that define constants (for example FIRMWARE_VERSION and LOCALE ), or they may be initiated from the Alexa Voice Service (AVS), such as when the user changes the TIMEZONE setting in the Alexa Companion App. PropertyManager::setProperty() and PropertyManager::getProperty() replace deprecated Engine::setProperty() and Engine::getProperty() . For details about the Property Manager platform interface, see \"Managing Runtime Properties with the Property Manager\" ( for C++ or for Android ). Car Control Changes This section documents the changes you will need to make to migrate your Car Control implementation to Auto SDK v2.2. New Asset ID Prefix The asset ID prefix for default assets has been changed from \"Alexa.\" to \"Alexa.Automotive.\" . This change requires a code or configuration change only if your existing car control implementation uses the CarControlConfiguration configuration builder with the literal strings of asset IDs. If your existing car control implementation uses the predefined constants in CarControlAssets.h or CarControlAssets.java , then no change is required. Specifying the Path to Custom Car Control Assets If your implementation using the Local Voice Control (LVC) extension uses custom assets for car control, you must specify the path to the custom assets in both the aace.carControl Auto SDK car control configuration and the LVC configuration, not just the LVC configuration as in Auto SDK v2.0. For C++ implementations: The default LVC configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the assets.customAssetsPath field in the Auto SDK car control configuration, or provide a path to an assets file with equivalent content. For Android implementations: The file at the path you provide in the assets.customAssetsPath field of the Auto SDK car control configuration must be the same as the custom assets file you configure for your ILVCClient using the LVC APK. Car Control Config Builder Asset Methods Two new CarControlConfiguration methods are now implemented in the Engine: CarControlConfiguration::addCustomAssetsPath() CarControlConfiguration::addDefaultAssetsPath() Note: These methods were also present in Auto SDK v2.1; however they didn't function as designed. They have been updated to function correctly in Auto SDK v2.2. This implementation populates the \"aace.carControl\" configuration object with the \"assets.customAssetsPath\" and \"assets.defaultAssetsPath\" nodes. Migrating from Auto SDK v2.0 to v2.1 This section outlines the changes you will need to make to migrate from Auto SDK v2.0 to Auto SDK v2.1. Build Changes The following build changes have been introduced in Auto SDK v2.1: The builder script usage has changed for Linux targets. All Linux targets now use the same platform name ( linux ), and -t <target> is mandatory. For example, to build for a Linux native target, use: builder/build.sh linux -t native to build for Linux native, pokyarm, and pokyarm64 targets, use: builder/build.sh linux -t native,pokyarm,pokyarm64 See the Builder README for details about supported platforms and targets. For QNX targets, you must cross-compile with the QNX multimedia software for the system audio extension (which is built by default for QNX targets). This requires a QNX Multimedia Suite license. See the System Audio extension README for details. Engine Configuration File Updates The AVS Device SDK portion of the Auto SDK Engine configuration (the aace.alexa.avsDeviceSDK node) has been updated. See the config.json.in file for details. The \"deviceInfo\" node includes two new elements: \"manufacturerName\" and \"description\" . A path to the capabilities database is now required. Use the \"capabilitiesDelegate\" element to specify this path. The \"settings\" element has changed to \"deviceSettings\" , and it includes these changes: The default locale setting has been moved from \"defaultAVSClientSettings/locale\" to \"defaultLocale\" . \"deviceSettings\" now requires a \"defaultTimezone\" . Navigation Enhancements Auto SDK v2.1 introduces additional navigation features that you can integrate in your application to enrich the user's experience: add/cancel a waypoint, show/navigate to a previous destination, turn and lane guidance, and map display control. Implementing these enhancements required deprecating the setDestination() interface in favor of the startNavigation() interface and adding several additional interfaces. To migrate from Auto SDK v2.0 to Auto SDK v2.1, you must update your platform implementation to use the startNavigation() method instead of the setDestination() method, modify the payload for the getNavigationState() method, and implement the new navigation methods. This guide takes you through these steps. Please see the Navigation module README for C++ or Android for additional information and resources. What's New The following abstract methods have been added to the Navigation platform interface: startNavigation() showPreviousWaypoints() navigateToPreviousWaypoint() showAlternativeRoutes() controlDisplay() announceManeuver() announceRoadRegulation() The following methods have been added as well: navigationEvent() navigationError() showAlternativeRoutesSucceeded() The following method has been removed from the Navigation module: setDestination() The following method now returns a different payload: getNavigationState() Implementing the New Navigation Features To implement the new navigation features, follow these steps: STEP 1: Replace the setDestination() method with the startNavigation() method. The payload meaning of startNavigation() is different than that of deprecated setDestination() . setDestination() corresponded to adding a destination to the navigation system context. startNavigation() , on the other hand, corresponds to using the route information provided in the payload to start navigation, with one or more waypoints. In response to startNavigation() , your implementation should also call either the navigationEvent() method or the navigationError() method. Java (Android) - click to expand or collapse // NavigationHandler.java @Override *public void *startNavigation( String payload ) { ... // success navigationEvent( EventName.NAVIGATION_STARTED ); ... // failure navigationError( ErrorType.NAVIGATION_START_FAILED, ErrorCode.INTERNAL_SERVICE_ERROR, \"\" ); C++ - click to expand or collapse // NavigationHandler.cpp void NavigationHandler::startNavigation(const std::string& payload ) { ... // success navigationEvent( aace::navigation::NavigationEngineInterface::EventName::NAVIGATION_STARTED ); ... // failure navigationError( aace::navigation::NavigationEngineInterface::ErrorType::NAVIGATION_START_FAILED, aace::navigation::NavigationEngineInterface::ErrorCode::INTERNAL_SERVICE_ERROR, \"\" ); STEP 2: Modify the payload for the getNavigationState() method. The functionality of the getNavigationState() and cancelNavigationState() methods is unchanged from Auto SDK v2.0, but the getNavigationState() payload has changed. The NavigationState context has been updated to contain more information than in Auto SDK v2.0. The address field has been updated from a string to the following object: ... \"address\": { \"addressLine1\": \"{{STRING}}\", //Address line 1 \"addressLine2\": \"{{STRING}}\", //Address line 2 \"addressLine3\": \"{{STRING}}\", //Address line 3 \"city\": \"{{STRING}}\", //City \"districtOrCounty\": \"{{STRING}}\", //district or county \"stateOrRegion\": \"{{STRING}}\", //state or region \"countryCode\": \"{{STRING}}\", //3 letter country code \"postalCode\": \"{{STRING}}\", //postal code }, ... The name field has been added to the waypoint payload: \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks Here is an example of a full NavigationState context payload - click to expand or collapse ..., { \"header\": { \"namespace\": \"Navigation\", \"name\": \"NavigationState\" }, \"payload\": { \"state\": \"{{STRING}}\", //NAVIGATING or NOT_NAVIGATING \"waypoints\": [ { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //City ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", //state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", //postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], }, { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //city ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", // state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", // postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], \"pointOfInterest\": { \"id\": \"{{STRING}}\", //POI lookup Id vended from Alexa \"hoursOfOperation\": [ { \"dayOfWeek\": \"{{STRING}}\", \"hours\": [ { \"open\": \"{{STRING}}\", // ISO-8601 time with timezone format \"close\": \"{{STRING}}\" // ISO-8601 time with timezone format } ], \"type\": \"{{STRING}}\" // Can be: OPEN_DURING_HOURS, OPEN_24_HOURS, etc. } ], \"phoneNumber\": \"{{STRING}}\" } }, ... ], \"shapes\": [ [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], ... ] } } ..., STEP 3: Implement the new navigation abstract methods. The new navigation methods are all called in response to navigation-based user utterances such as \u201cshow my previous route\u201d or \u201cwhat\u2019s the speed limit here?\u201d. At a minimum, your implementation should report a navigationError() to inform the user when the navigation system does not support that information. Note: The navigationEvent() , showAlternativeRoutesSucceeded() and navigationError() methods have been implemented in the Auto SDK but are not yet implemented on the cloud side. Sending the events will not affect navigation functionality, but the Alexa cloud will return an INVALID_REQUEST_EXCEPTION or INVALID_SERVICE_EXCEPTION until these events are implemented on the cloud side. Java (Android) - click to expand or collapse @Override public void showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, ErrorCode.NOT_SUPPORTED, *\"\"** *); } ... @Override public void navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( ErrorType.PREVIOUS_NAVIGATION_START_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void showAlternativeRoutes( AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void controlDisplay ( ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( ErrorType.ROUTE_OVERVIEW_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( ErrorType.TURN_GUIDANCE_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceRoadRegulation( RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( ErrorType.SPEED_LIMIT_REGULATION_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } C++ - click to expand or collapse void NavigationHandler::showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( aace::navigation::Navigation::ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\"* *); } ... void NavigationHandler::navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( aace::navigation::Navigation::ErrorType.PREVIOUS_NAVIGATION_START_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::showAlternativeRoutes( aace::navigation::Navigation::AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( aace::navigation::Navigation::ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::controlDisplay ( aace::navigation::Navigation::ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( aace::navigation::Navigation::ErrorType.ROUTE_OVERVIEW_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( aace::navigation::Navigation::ErrorType.TURN_GUIDANCE_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceRoadRegulation( aace::navigation::Navigation::RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( aace::navigation::Navigation::ErrorType.SPEED_LIMIT_REGULATION_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } New TemplateRuntime Interface Version The Auto SDK now implements version 1.2 of the TemplateRuntime interface to handle display card templates. If you support TemplateRuntime in your implementation, you must update your implementation to support the new card types. The TemplateRuntime interface remains the same, but the LocalSearchListTemplate1 template has been deprecated in favor of the new LocalSearchListTemplate2 template. In addition, two new templates ( TrafficDetailsTemplate and LocalSearchDetailTemplate1 ), are now supported. The TrafficDetailsTemplate includes commute information to favorite destinations such as home or work. The LocalSearchDetailTemplate1 template includes information about specific locations or information in response to users asking for details about locations presented in the LocalSearchListTemplate2 template. For details about the TemplateRuntime interface, see the Alexa Voice Service (AVS) documentation . For details about implementing TemplateRuntime in your Auto SDK implementation see the Alexa module README for C++ or Android . Car Control Source File Relocation The Car Control module platform interface files and documentation are now located in aac-sdk/modules/car-control for C++ and aac-sdk/platforms/android/modules/car-control for Android, rather than in the Local Voice Control (LVC) extension directory structure. Note: In addition, if you use custom assets for car control in an implementation with the optional Local Voice Control (LVC) extension, you must specify the path to the custom assets in both the Auto SDK car control configuration and the LVC configuration, not just the LVC configuration. For details, see Path to Custom Car Control Assets for LVC Implementations . Code-Based-Linking (CBL) Handler in the Sample Apps Both of the Auto SDK Sample Apps now include the Code-Based Linking (CBL) handler implementation (in favor of the AuthProvider handler implementation ) to handle obtaining access tokens from Login with Amazon (LWA). Changing from the AuthProvider handler to the CBL handler is not a required change , but we recommend that you use the Auto SDK CBL interface for ease of implementation. For details about the CBL handler, please see the CBL module README for C++ or for Android . If you want to continue using the AuthProvider interface, we recommend that you implement the new onAuthFailure() method that exposes 403 \"unauthorized request\" exceptions from Alexa Voice Service (AVS). This method may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. In the Sample Apps, you can override the interface and unset your login credentials as if the user had done so with your GUI interface: Java (Android) - click to expand or collapse @Override public void authFailure( String token ) { // handle user de-authorize scenario C++ - click to expand or collapse void AuthProviderHandler::authFailure( const std::string& token ) { // handle user de-authorize scenario","title":"General Migration"},{"location":"MIGRATION/#alexa-auto-sdk-migration-guide","text":"This guide outlines the changes you need to make to migrate from Auto SDK v2.0 to later versions of the Auto SDK. Note: If you migrate from a version earlier than v2.3, be sure to read the relevant sections of this guide to understand all changes introduced between your current version and v3.3. The information helps you decide what changes you must include. For example, if you migrate from v2.0, include the changes described in Migrating from Auto SDK v2.0 to v2.1 , the changes described in Migrating from Auto SDK v2.1 to v2.2 , and so on, taking into consideration the deprecated or removed features in each version.","title":"Alexa Auto SDK Migration Guide"},{"location":"MIGRATION/#table-of-contents","text":"Migrating from Auto SDK v3.3.0 to v4.0.0 Platform Interface Deprecation Migrating from Auto SDK v3.2.1 to v3.3.0 Local Media Source and Global Preset Enhancements Migrating the Local Navigation Module APIs Migrating from Auto SDK v3.1.0 to v3.2.0 Using the Alexa Communication Extension Using the Device Client Metrics (DCM) Extension Migrating from Auto SDK v3.0.0 to v3.1.0 Migrating to the Authorization Platform Interface Deprecated Features Removed in Auto SDK v3.0.0 Using the Address Book Module Migrating from Auto SDK v2.2.1 to v2.3.0 Car Control Enhancements and Breaking Changes Language Model Packaging Android Clang Formatting Migrating from Auto SDK v2.2 to v2.2.1 TemplateRuntime Enhancements Migrating from Auto SDK v2.1 to v2.2 Implementing the Property Manager Interface Car Control Changes Migrating from Auto SDK v2.0 to v2.1 Build Changes Engine Configuration File Updates Navigation Enhancements Car Control Source File Relocation Code-Based-Linking (CBL) Handler in the Sample Apps","title":"Table of Contents"},{"location":"MIGRATION/#migrating-from-auto-sdk-v330-to-v400","text":"This section provides the information you need to migrate from Auto SDK v3.3.0 to Auto SDK v4.0.0","title":"Migrating from Auto SDK v3.3.0 to v4.0.0"},{"location":"MIGRATION/#platform-interface-deprecation","text":"The C++ and Java platform interfaces are deprecated in favor of Alexa Auto Services Bridge (AASB). Auto SDK 4.0 replaces the platform interfaces with a new MessageBroker API for subscribing to and publishing AASB messages. Details to migrate your application to the MessageBroker API are here.","title":"Platform Interface Deprecation"},{"location":"MIGRATION/#migrating-from-auto-sdk-v321-to-v330","text":"This section provides the information you need to migrate from Auto SDK v3.2.1 to Auto SDK v3.3.0","title":"Migrating from Auto SDK v3.2.1 to v3.3.0"},{"location":"MIGRATION/#local-media-source-and-global-preset-enhancements","text":"","title":"Local Media Source and Global Preset Enhancements"},{"location":"MIGRATION/#globalpreset-is-deprecated","text":"The GlobalPreset platform interface is deprecated because its feature set is supported by the new DEFAULT LocalMediaSource type. To preserve functionality for utterances targetting generic presets like \"Alexa, play preset 1\", implement and register a LocalMediaSource handler of Source::DEFAULT type. The user utterances that cause the Engine to invoke GlobalPreset::setGlobalPreset() will cause the Engine to invoke LocalMediaSource::play() with ContentSelector::PRESET instead. The GlobalPreset platform interface will be removed in a future version of Auto SDK.","title":"GlobalPreset is deprecated"},{"location":"MIGRATION/#addtional-localmediasource-playerevent-calls-are-needed","text":"Previous Auto SDK documentation stated that you must call LocalMediaSource::playerEvent() to report events \"PlaybackStated\" and \"PlaybackStopped\" only. Please update your implementation to call playerEvent() with states \"PlaybackSessionStarted\" and \"PlaybackSessionEnded\" as well. See the Reporting Playback Events section in the Alexa module README for information about when to report these events.","title":"Addtional LocalMediaSource playerEvent calls are needed"},{"location":"MIGRATION/#setfocus-is-deprecated","text":"The API LocalMediaSource::setFocus() is deprecated because its functionality is equivalent to calling LocalMediaSource::playerEvent() with event name \"PlaybackSessionStarted\" when a player is brought into focus or \"PlaybackSessionEnded\" when a player is removed from focus. Please replace your calls to setFocus(true) and setFocus(false) with calls to playerEvent(\"PlaybackSessionStarted\") and playerEvent(\"PlaybackSessionEnded\") , respectively. setFocus will be removed in a future version of Auto SDK.","title":"setFocus is deprecated"},{"location":"MIGRATION/#reporting-playback-session-id-is-needed","text":"The Alexa cloud requires ExternalMediaPlayer events and context for a particular player to include the playback session ID of a player's active session. To support this, the LocalMediaSource::play() function signature is updated to include a parameter for session ID for an Alexa-initiated session, which you must use when reporting player events for the player. The playerEvent and playerError signatures are also updated to include session ID. You must generate your own session ID when the playback is initiated by the user without Alexa. See the Reporting Playback Events section in the Alexa module README for more details about the sessionId . The versions of APIs without the session ID will be removed in a future version of Auto SDK.","title":"Reporting playback session ID is needed"},{"location":"MIGRATION/#migrating-the-local-navigation-module-apis","text":"The local search features of the Local Voice Control Extension's Local Navigation module are extended to support offline navigation to addresses, cities, and neighborhoods. To support the new feature set, the existing APIs are updated to a more general name. The changes are backward compatible, but the old APIs are deprecated and will be removed in a future version. Use the following steps to assist the migration to the new APIs:","title":"Migrating the Local Navigation Module APIs"},{"location":"MIGRATION/#localsearchprovider-platform-interface-changes","text":"We have deprecated the functions poiSearchRequest , poiLookupRequest , poiSearchResponse , and poiLookupResponse in favor of searchRequest , lookupRequest , searchResponse , and lookupResponse , respectively. Override LocalSearchProvider::searchRequest() instead of LocalSearchProvider::poiSearchRequest() . Override LocalSearchProvider::lookupRequest() instead of LocalSearchProvider::poiLookupRequest() . Call LocalSearchProvider::searchResponse() instead of LocalSearchProvider::poiSearchResponse() . Call LocalSearchProvider::lookupResponse() instead of LocalSearchProvider::poiLookupResponse() . We have also deprecated the AASB messages PoiSearchRequestMessage , PoiLookupRequestMessage , PoiSearchResponseMessage , and PoiLookupResponseMessage in favor of SearchRequestMessage , LookupRequestMessage , SearchResponseMessage , and LookupResponseMessage , respectively. Subscribe to SearchRequestMessage instead of PoiSearchRequestMessage . Subscribe to LookupRequestMessage instead of PoiLookupRequestMessage . Publish to SearchResponseMessage instead of PoiSearchResponseMessage . Publish to LookupResponseMessage instead of PoiLookupResponseMessage . The JSON schemas of search and response are still the same. Note: Do not use/implement a mix of the old APIs and the new APIs","title":"LocalSearchProvider Platform Interface Changes"},{"location":"MIGRATION/#local-navigation-module-engine-configuration-changes","text":"The aace.localNavigation.localSearch configuration keys navigationPOISocketPath and poiEERSocketPath are renamed to navigationLocalSearchSocketPath and localSearchEERSocketPath , respectively. For example, if your configuration was this { \"aace.localNavigation\": { \"localSearch\": { \"navigationPOISocketPath\": \"/opt/LVC/data/poi-er-service/poi_navigation.socket\", \"poiEERSocketPath\": \"/opt/LVC/data/poi-er-service/poi_eer.socket\" } } } change it to this { \"aace.localNavigation\": { \"localSearch\": { \"navigationLocalSearchSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_navigation.socket\", \"localSearchEERSocketPath\": \"/opt/LVC/data/local-search-er-service/local_search_eer.socket\" } } } If you are using the LocalNavigationConfiguration::createLocalSearchConfig() factory function to generate the configuration, your usage does not have to change because the signature is the same and implementation of this function generates the new JSON. Note: the socket paths in the Linux default sample configuration file are updated, so if you use different values, ensure you update your LVC app configuration accordingly","title":"Local Navigation Module Engine Configuration Changes"},{"location":"MIGRATION/#lvc-apk-configuration-changes","text":"If you use LVC on Android, update the configuration returned by your implementation of the interface ILVCClient.getConfiguration() . The paths NavigationPOISocketDir and POIEERSocketDir have been deprecated in favor of NavigationLocalSearchSocketDir and LocalSearchEERSocketDir , respectively. The socket names NavigationPOISocketName and POIEERSocketName have been deprecated in favor of NavigationLocalSearchSocketName and LocalSearchEERSocketName , respectively.","title":"LVC APK Configuration Changes"},{"location":"MIGRATION/#lvc-linux-app-configuration-changes","text":"The LVC configuration file lvc-config.json installed at /opt/LVC/config by the installation script LVC.sh has no changes to its JSON configuration schema since Auto SDK 3.2. However, the socket directories and names used by default in this file are updated to use more general names.","title":"LVC Linux App Configuration Changes"},{"location":"MIGRATION/#migrating-from-auto-sdk-v310-to-v320","text":"This section provides the information you need to migrate from Auto SDK v3.1.0 to Auto SDK 3.2.0. All information about 3.2.0 is also applicable to 3.2.1.","title":"Migrating from Auto SDK v3.1.0 to v3.2.0"},{"location":"MIGRATION/#using-the-alexa-communication-extension","text":"The Alexa Comms library in Auto SDK v3.2.0 uses Device Client Metrics (DCM) instead of AWS IoT for uploading metrics. Therefore, remove the iotCertificateDirPath , iotHostAddress , and deviceTypeId fields from the communication configuration file. For information about the configuration file format, see the Alexa Communication extension README. If you build the Alexa Comms module configuration using the programmatic factory function AlexaCommsConfiguration::createCommsConfig() (C++) or AlexaCommsConfiguration.createCommsConfig() (Java), remove the parameters that are no longer present in the signature.","title":"Using the Alexa Communication Extension"},{"location":"MIGRATION/#using-the-device-client-metrics-dcm-extension","text":"The Device Client Metrics extension in Auto SDK v3.2.0 requires a field called metricsTag to be defined in the DCM configuration. The value of metricsTag is used for generating a unique identifier for anonymous registration metrics. Note: You must not use the vehicle identification number (VIN) or device serial number (DSN) as metricsTag . For information about how to use this field, see the Device Client Metric extension README. If you build the DCM module configuration using the programmatic factory function DCMConfiguration::createDCMConfig() (C++) or DCMConfiguration.createDCMConfig() (Java), add the metricsTag parameter as instructed in the API documentation.","title":"Using the Device Client Metrics (DCM) Extension"},{"location":"MIGRATION/#migrating-from-auto-sdk-v300-to-v310","text":"This section provides the information you need to migrate from Auto SDK v3.0.0 to Auto SDK v3.1.0.","title":"Migrating from Auto SDK v3.0.0 to v3.1.0"},{"location":"MIGRATION/#migrating-to-the-authorization-platform-interface","text":"Auto SDK v3.1.0 introduces the Authorization module that provides a single platform interface to manage different types of authorizations supported by the Engine. This single platform interface works with the Engine services that carry out the actual authorization process or flow. For more information about how authorization works, see the Core module README . This section provides the information you need for migrating to the Authorization platform interface from the CBL or AuthProvider platform interface, which are deprecated in v3.1.0 Migrating from the CBL Platform Interface To migrate from the CBL platform interface to the Authorization platform interface, follow the instructions in the CBL README , which describes the Authorization APIs for CBL authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the CBL platform interface, as shown in the following table: CBL Authorization Description ERROR UNKNOWN_ERROR Unknown error occurs during the authorization flow. TIMEOUT TIMEOUT Request for the the CBL code from LWA times out. CODE_PAIR_EXPIRED CODE_PAIR_EXPIRED The code pair obtained has expired. AUTHORIZATION_EXPIRED AUTHORIZATION_EXPIRED Refresh token is expired or revoked. START_AUTHORIZATION_FAILED Authorization fails to start. LOGOUT_FAILED Logout fails. Migrating from the AuthProvider Platform Interface To migrate from the AuthProvider platform interface to the Authorization platform interface, follow the instructions in the Alexa README , which describes the Authorization APIs for Auth Provider authorization. The Engine notifies the application of any errors during the authorization process via the authorizationError API. The errors reported when you use the Authorization platform interface are different from the ones reported with the AuthProvider platform interface, as shown in the following table: AuthProvider Authorization Description authFailure AUTH_FAILURE Invalid or expired access token was provided. NOT PRESENT UNKNOWN_ERROR Unknown error occurs during the authorization flow. NOT PRESENT START_AUTHORIZATION_FAILED Authorization fails to start. NOT PRESENT LOGOUT_FAILED Logout fails.","title":"Migrating to the Authorization Platform Interface"},{"location":"MIGRATION/#deprecated-features-removed-in-auto-sdk-v300","text":"The following asset IDs for Car Control have been removed: \"Alexa.Automotive.DeviceName.DriverSeat\", \"Alexa.Automotive.DeviceName.LeftSeat\", \"Alexa.Automotive.DeviceName.PassengerSeat\", \"Alexa.Automotive.DeviceName.RightSeat\". The createControl() method has been removed. Use createEndpoint() instead. Support for the \"isMemberOf\" relationship for endpoint definition has been removed. You must list member endpoints in a zone definition. Implicit zone definitions have been removed. The following TemplateRuntime methods have been removed: The renderTemplate(const std::string& payload) method has been removed. Use renderTemplate(const std::string& payload, FocusState focusState) instead. The renderPlayerInfo(const std::string& payload) method has been removed. Use renderPlayerInfo(const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState) instead. In the Alexa module, AlexaProperties::SUPPORTED_LOCALES has been removed. For Alexa to recognize the locale setting, specify one of these values: de-DE, en-AU, en-CA, en-GB, en-IN, en-US, es-ES, es-MX, es-US, fr-CA, fr-FR, hi-IN, it-IT, ja-JP, pt-BR. Engine::setProperty() and Engine::getProperty() have been removed. Use PropertyManager::setProperty() and PropertyManager::getProperty() instead. For details about the Property Manager platform interface, see \"Managing Runtime Properties with the Property Manager\" ( for C++ or for Android ). The SpeechRecognizer::enableWakeWordDetection() , SpeechRecognizer::disableWakeWordDetection() , and SpeechRecognizer::isWakewordDetectionEnabled() methods have been removed. The Contact Uploader module has been removed. Use the Address Book module instead.","title":"Deprecated Features Removed in Auto SDK v3.0.0"},{"location":"MIGRATION/#using-the-address-book-module","text":"Address Book module enables the user to upload contacts from the phone that is paired with the car or the navigation favorites from the car head unit to Alexa cloud. For more information about how this module works, see the Address Book README . Both the Android and C++ sample apps demonstrate the use of the AddressBook platform interface. See the sample app source code for specific implementation details. The following Address Book API descriptions help you transition from the Contact Uploader module to the Address Book module: addAddressBook bool addAddressBook(const std::string& addressBookSourceId, const std::string& name, AddressBookType type); Use addAddressBook instead of ContactUploader::addContactsBegin . In addition, addAddressBook requires you to specify the source id to identify the address book, the friendly name of the address book, and the type of address book. removeAddressBook bool removeAddressBook(const std::string& addressBookSourceId); Use removeAddressBook instead of ContactUploader:: removeUploadedContacts . You must specify the id of the address book to be removed. getEntries bool getEntries( const std::string& addressBookSourceId, std::weak_ptr<IAddressBookEntriesFactory> factory) When using the Address Book module, the Engine pulls the address book contents from the platform implementation. You must upload the address book contents through the factory class, IAddressBookEntriesFactory , for the specified address book source id.","title":"Using the Address Book Module"},{"location":"MIGRATION/#migrating-from-auto-sdk-v221-to-v230","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.2.1 to Auto SDK v2.3.","title":"Migrating from Auto SDK v2.2.1 to v2.3.0"},{"location":"MIGRATION/#car-control-enhancements-and-breaking-changes","text":"Read the updated Car Control module README (for C++ platforms or Android ) to get a complete understanding of all supported features and the current format of the \"aace.carControl\" configuration schema. Read the updated API documentation for the CarControlConfiguration builder class (for C++ platforms or Android ) if you construct your configuration programmatically. The changes to the \"aace.carControl\" configuration for v2.3 are backward-compatible, meaning your previous configuration (regardless of whether it was file-based or built programmatically with the CarControlConfiguration class) will still compile and produce a valid configuration to input to Auto SDK. However, several updates are recommended to ensure expected behavior, even if you do not want new features.","title":"Car Control Enhancements and Breaking Changes"},{"location":"MIGRATION/#1-zones-configuration-schema-update","text":"Prior to v2.3, to assign an endpoint to exactly one zone, you would specify an \"isMemberOf\" relationship in the definition of the endpoint and specify no information about endpoints in the zone definition. { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ], \"relationships\": { \"isMemberOf\": { \"zoneId\": \"zone.all\" } } } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] } } In 2.3, the \"isMemberOf\" relationship is removed from endpoint definitions so that endpoints need not belong to zones and the zone definition can be the source of truth for all its member endpoints. The zone definition now includes a list of member endpoints: { \"endpointId\": \"all.fan\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.DeviceName.Fan\" } } ] }, \"capabilities\": [ ... ] } ... { \"zoneId\": \"zone.all\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"Alexa.Automotive.Location.All\" } } ] }, \"members\" : [ { \"endpointId\": \"all.fan\" }, ... ] } You should update your configuration accordingly. The Auto SDK Engine translates the old format to the new format internally, but this will be deprecated in later versions. When updating to the new format, you must not combine usage of the \"isMemberOf\" format with the \"members\" list format. Fully migrate all definitions in your configuration.","title":"1. Zones configuration schema update"},{"location":"MIGRATION/#2-deprecated-implicit-creation-of-zone-definitions","text":"If you construct your configuration programmatically with the CarControlConfiguration builder class, your implementation prior to v2.3 might not have explicitly specified definitions for the set of zones considered \"official\", but you still used them in your endpoint configurations anyway. The builder class added these definitions to the \"aace.carControl\" configuration automatically without requiring you to call CarControlConfiguration::createZone() . In v2.3, CarControlConfiguration still includes this logic for the old \"official\" zones, but it does not implicitly create any new zones, and it is recommended to define every zone you use by calling CarControlConfiguration::createZone() . Implicit zone definitions will be removed in a later version.","title":"2. Deprecated implicit creation of zone definitions"},{"location":"MIGRATION/#3-new-default-zone-feature","text":"Specifying a \"default\" zone ID is an optional new feature, but it is highly recommended that you use it. See the Car Control module README for details about why this feature is important.","title":"3. New default zone feature"},{"location":"MIGRATION/#4-deprecated-driverseat-and-related-assets-in-favor-of-zones","text":"Prior to v2.3, the default automotive catalog of assets introduced several asset IDs so that online-only systems could mock zones support for heaters on seat endpoints. The asset IDs are the following: Alexa.Automotive.DeviceName.DriverSeat , Alexa.Automotive.DeviceName.LeftSeat , Alexa.Automotive.DeviceName.PassengerSeat , Alexa.Automotive.DeviceName.RightSeat . Now that the cloud supports zones, you must stop using these asset IDs and properly model the endpoints using zones so that Alexa resolves user utterance intents as expected. These assets will be removed in a later version of Auto SDK. See the Car Control module README for sample configuration.","title":"4. Deprecated \"DriverSeat\" and related assets in favor of zones"},{"location":"MIGRATION/#5-new-default-assets","text":"The Car Control module is updated to include many new assets in the default automotive catalog to support a wider range of utterances. If you previously defined custom assets to support any of the features introduced to the v2.3 assets, it is recommended that you use the new default assets instead of your previous custom ones. See the Car Control module README for details about assets.","title":"5. New default assets"},{"location":"MIGRATION/#6-reset-your-account-when-changing-from-22-to-23-configuration","text":"It is a known issue that you cannot delete any previously configured endpoint IDs associated with your customer account in the cloud. When upgrading your configuration from v2.2 to v2.3, contact your SA or Partner Manager for help to reset your account's endpoint database in the cloud. This is especially important if you are updating to use new features. It is also recommended that your v2.3 configuration follows the configuration sample of supported features shown in the Car Control README. Refer to this document for reference.","title":"6. Reset your account when changing from 2.2 to 2.3 configuration"},{"location":"MIGRATION/#language-model-packaging","text":"Language models for the Local Voice Control extension are now decoupled from the LVC.sh (Linux) binaries. If you use the Local Voice Control extension, you must install the language models to successfully migrate to v2.3.0. Download the language model tar files. Installation instructions are provided in the Local Voice Control extension.","title":"Language Model Packaging"},{"location":"MIGRATION/#android","text":"","title":"Android"},{"location":"MIGRATION/#gradle","text":"The gradle plugin has been updated to v3.6.2. This requires gradle v5.6.4 or above in order to build the Auto SDK for Android targets.","title":"Gradle"},{"location":"MIGRATION/#sample-app","text":"The Android sample app supports overriding the client configuration by pushing a file named app_config.json to the /sdcard folder on the device. If the /sdcard/app_config.json file existed on the device before you migrate to v2.3.0, the file overrides the client configuration included in the v2.3.0 Android sample app APK.","title":"Sample App"},{"location":"MIGRATION/#clang-formatting","text":"Auto SDK code has been formatted with clang-format version 9.0.0. This may lead to merge conflicts if changes have been made to v2.2.1 source code files and you migrate to v2.3.","title":"Clang Formatting"},{"location":"MIGRATION/#migrating-from-auto-sdk-v22-to-v221","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.2 to Auto SDK v2.2.1.","title":"Migrating from Auto SDK v2.2 to v2.2.1"},{"location":"MIGRATION/#templateruntime-enhancements","text":"Auto SDK v2.2.1 introduces additional TemplateRuntime platform interface features that you can integrate in your application to enrich the user's experience with Now Playing cards for AudioPlayer and ExternalMediaPlayer implementations. Now Playing cards are a form of display cards \u2014 visual aids that complement the Alexa voice experience \u2014 that contain media metadata, player controls and album art delivered in the TemplateRuntime RenderPlayerInfo directive. Migration is only required to support the new features, but is highly recommended for the following reasons: 1. AudioPlayer and TemplateRuntime are now decoupled. 2. The following TemplateRuntime methods are now deprecated: 1. The renderTemplate( const std::string& payload ) method is deprecated. Use renderTemplate( const std::string& payload, FocusState focusState ) instead. 2. The renderPlayerInfo( const std::string& payload ) method is deprecated. Use renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) instead.","title":"TemplateRuntime Enhancements"},{"location":"MIGRATION/#rendertemplate","text":"Method renderTemplate( const std::string& payload, FocusState focusState ) The new renderTemplate method provides visual metadata associated with a user request to Alexa. The platform implementation should parse the template metadata and render a display card for the user. Parameters - payload Renderable template metadata in structured JSON format - focusState The FocusState of the channel used by TemplateRuntime interface - FOREGROUND Represents the highest focus a Channel can have - BACKGROUND Represents the intermediate level focus a Channel can have","title":"renderTemplate"},{"location":"MIGRATION/#renderplayerinfo","text":"Method renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) The new renderPlayerInfo method provides visual metadata associated with a user request to Alexa for audio playback. The platform implementation should parse the player info metadata and render a display card for the user. The audioPlayerState and offset are useful for implementing the progress bar in the display card. It is assumed that the client is responsible for progressing the progress bar when the AudioPlayer is in PLAYING state. Parameters - payload Renderable player info metadata in structured JSON format - audioPlayerState The state of the AudioPlayer - IDLE Audio playback has not yet begun - PLAYING Audio is currently playing - STOPPED Audio playback is stopped, either from a stop directive or playback error - PAUSED Audio playback is paused - BUFFER_UNDERRUN Audio playback is stalled because a buffer underrun has occurred - FINISHED Audio playback is finished - offset The offset in millisecond of the media that AudioPlayer is handling - focusState The FocusState of the channel used by TemplateRuntime interface - FOREGROUND Represents the highest focus a Channel can have - BACKGROUND Represents the intermediate level focus a Channel can have","title":"renderPlayerInfo"},{"location":"MIGRATION/#sample-apps","text":"The Android Sample App demonstrates the new features in TemplateRuntimeHandler.java in GUI form. Refer to sample app source code and Alexa Voice Service documentation for specific implementation details. The C++ Sample App simply demonstrates the new features by printing audioPlayerState , offset , and focusState to the console in the TemplateRuntimeHandler::renderPlayerInfo() method of TemplateRuntimeHandler.cpp .","title":"Sample Apps"},{"location":"MIGRATION/#migrating-from-auto-sdk-v21-to-v22","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.1 to Auto SDK v2.2.","title":"Migrating from Auto SDK v2.1 to v2.2"},{"location":"MIGRATION/#implementing-the-property-manager-interface","text":"Auto SDK v2.2 introduces the Property Manager, a component that maintains runtime properties by storing property values and listeners and delegating the setProperty() and getProperty() calls from your application to the respective Engine services. The Engine invokes the PropertyManager platform interface method propertyChanged() to notify your application about property value changes originating internally. The property values may be set by Auto SDK modules that define constants (for example FIRMWARE_VERSION and LOCALE ), or they may be initiated from the Alexa Voice Service (AVS), such as when the user changes the TIMEZONE setting in the Alexa Companion App. PropertyManager::setProperty() and PropertyManager::getProperty() replace deprecated Engine::setProperty() and Engine::getProperty() . For details about the Property Manager platform interface, see \"Managing Runtime Properties with the Property Manager\" ( for C++ or for Android ).","title":"Implementing the Property Manager Interface"},{"location":"MIGRATION/#car-control-changes","text":"This section documents the changes you will need to make to migrate your Car Control implementation to Auto SDK v2.2.","title":"Car Control Changes"},{"location":"MIGRATION/#new-asset-id-prefix","text":"The asset ID prefix for default assets has been changed from \"Alexa.\" to \"Alexa.Automotive.\" . This change requires a code or configuration change only if your existing car control implementation uses the CarControlConfiguration configuration builder with the literal strings of asset IDs. If your existing car control implementation uses the predefined constants in CarControlAssets.h or CarControlAssets.java , then no change is required.","title":"New Asset ID Prefix"},{"location":"MIGRATION/#specifying-the-path-to-custom-car-control-assets","text":"If your implementation using the Local Voice Control (LVC) extension uses custom assets for car control, you must specify the path to the custom assets in both the aace.carControl Auto SDK car control configuration and the LVC configuration, not just the LVC configuration as in Auto SDK v2.0. For C++ implementations: The default LVC configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the assets.customAssetsPath field in the Auto SDK car control configuration, or provide a path to an assets file with equivalent content. For Android implementations: The file at the path you provide in the assets.customAssetsPath field of the Auto SDK car control configuration must be the same as the custom assets file you configure for your ILVCClient using the LVC APK.","title":"Specifying the Path to Custom Car Control Assets"},{"location":"MIGRATION/#car-control-config-builder-asset-methods","text":"Two new CarControlConfiguration methods are now implemented in the Engine: CarControlConfiguration::addCustomAssetsPath() CarControlConfiguration::addDefaultAssetsPath() Note: These methods were also present in Auto SDK v2.1; however they didn't function as designed. They have been updated to function correctly in Auto SDK v2.2. This implementation populates the \"aace.carControl\" configuration object with the \"assets.customAssetsPath\" and \"assets.defaultAssetsPath\" nodes.","title":"Car Control Config Builder Asset Methods"},{"location":"MIGRATION/#migrating-from-auto-sdk-v20-to-v21","text":"This section outlines the changes you will need to make to migrate from Auto SDK v2.0 to Auto SDK v2.1.","title":"Migrating from Auto SDK v2.0 to v2.1"},{"location":"MIGRATION/#build-changes","text":"The following build changes have been introduced in Auto SDK v2.1: The builder script usage has changed for Linux targets. All Linux targets now use the same platform name ( linux ), and -t <target> is mandatory. For example, to build for a Linux native target, use: builder/build.sh linux -t native to build for Linux native, pokyarm, and pokyarm64 targets, use: builder/build.sh linux -t native,pokyarm,pokyarm64 See the Builder README for details about supported platforms and targets. For QNX targets, you must cross-compile with the QNX multimedia software for the system audio extension (which is built by default for QNX targets). This requires a QNX Multimedia Suite license. See the System Audio extension README for details.","title":"Build Changes"},{"location":"MIGRATION/#engine-configuration-file-updates","text":"The AVS Device SDK portion of the Auto SDK Engine configuration (the aace.alexa.avsDeviceSDK node) has been updated. See the config.json.in file for details. The \"deviceInfo\" node includes two new elements: \"manufacturerName\" and \"description\" . A path to the capabilities database is now required. Use the \"capabilitiesDelegate\" element to specify this path. The \"settings\" element has changed to \"deviceSettings\" , and it includes these changes: The default locale setting has been moved from \"defaultAVSClientSettings/locale\" to \"defaultLocale\" . \"deviceSettings\" now requires a \"defaultTimezone\" .","title":"Engine Configuration File Updates"},{"location":"MIGRATION/#navigation-enhancements","text":"Auto SDK v2.1 introduces additional navigation features that you can integrate in your application to enrich the user's experience: add/cancel a waypoint, show/navigate to a previous destination, turn and lane guidance, and map display control. Implementing these enhancements required deprecating the setDestination() interface in favor of the startNavigation() interface and adding several additional interfaces. To migrate from Auto SDK v2.0 to Auto SDK v2.1, you must update your platform implementation to use the startNavigation() method instead of the setDestination() method, modify the payload for the getNavigationState() method, and implement the new navigation methods. This guide takes you through these steps. Please see the Navigation module README for C++ or Android for additional information and resources.","title":"Navigation Enhancements"},{"location":"MIGRATION/#whats-new","text":"The following abstract methods have been added to the Navigation platform interface: startNavigation() showPreviousWaypoints() navigateToPreviousWaypoint() showAlternativeRoutes() controlDisplay() announceManeuver() announceRoadRegulation() The following methods have been added as well: navigationEvent() navigationError() showAlternativeRoutesSucceeded() The following method has been removed from the Navigation module: setDestination() The following method now returns a different payload: getNavigationState()","title":"What's New"},{"location":"MIGRATION/#implementing-the-new-navigation-features","text":"To implement the new navigation features, follow these steps: STEP 1: Replace the setDestination() method with the startNavigation() method. The payload meaning of startNavigation() is different than that of deprecated setDestination() . setDestination() corresponded to adding a destination to the navigation system context. startNavigation() , on the other hand, corresponds to using the route information provided in the payload to start navigation, with one or more waypoints. In response to startNavigation() , your implementation should also call either the navigationEvent() method or the navigationError() method. Java (Android) - click to expand or collapse // NavigationHandler.java @Override *public void *startNavigation( String payload ) { ... // success navigationEvent( EventName.NAVIGATION_STARTED ); ... // failure navigationError( ErrorType.NAVIGATION_START_FAILED, ErrorCode.INTERNAL_SERVICE_ERROR, \"\" ); C++ - click to expand or collapse // NavigationHandler.cpp void NavigationHandler::startNavigation(const std::string& payload ) { ... // success navigationEvent( aace::navigation::NavigationEngineInterface::EventName::NAVIGATION_STARTED ); ... // failure navigationError( aace::navigation::NavigationEngineInterface::ErrorType::NAVIGATION_START_FAILED, aace::navigation::NavigationEngineInterface::ErrorCode::INTERNAL_SERVICE_ERROR, \"\" ); STEP 2: Modify the payload for the getNavigationState() method. The functionality of the getNavigationState() and cancelNavigationState() methods is unchanged from Auto SDK v2.0, but the getNavigationState() payload has changed. The NavigationState context has been updated to contain more information than in Auto SDK v2.0. The address field has been updated from a string to the following object: ... \"address\": { \"addressLine1\": \"{{STRING}}\", //Address line 1 \"addressLine2\": \"{{STRING}}\", //Address line 2 \"addressLine3\": \"{{STRING}}\", //Address line 3 \"city\": \"{{STRING}}\", //City \"districtOrCounty\": \"{{STRING}}\", //district or county \"stateOrRegion\": \"{{STRING}}\", //state or region \"countryCode\": \"{{STRING}}\", //3 letter country code \"postalCode\": \"{{STRING}}\", //postal code }, ... The name field has been added to the waypoint payload: \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks Here is an example of a full NavigationState context payload - click to expand or collapse ..., { \"header\": { \"namespace\": \"Navigation\", \"name\": \"NavigationState\" }, \"payload\": { \"state\": \"{{STRING}}\", //NAVIGATING or NOT_NAVIGATING \"waypoints\": [ { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //City ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", //state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", //postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], }, { \"type\": \"{{STRING}}\", //Type of the waypoint - SOURCE, DESTINATION or INTERIM \"estimatedTimeOfArrival\": { \"ideal\": {{STRING}}, //Expected clock time ETA based on the ideal conditions. ISO 8601 UTC format \"predicted\": {{STRING}} //predicted clock time ETA based on traffic conditions. ISO 8601 UTC format }, \"address\": { ++ \"addressLine1\": \"{{STRING}}\", //Address line 1 ++ \"addressLine2\": \"{{STRING}}\", //Address line 2 ++ \"addressLine3\": \"{{STRING}}\", //Address line 3 ++ \"city\": \"{{STRING}}\", //city ++ \"districtOrCounty\": \"{{STRING}}\", //district or county ++ \"stateOrRegion\": \"{{STRING}}\", // state or region ++ \"countryCode\": \"{{STRING}}\", //3 letter country code ++ \"postalCode\": \"{{STRING}}\", // postal code }, ++ \"name\": \"{{STRING}}\", // name of the waypoint such as home or Starbucks \"coordinate\": [{{LATITUDE_DOUBLE}},{{LONGITUDE_DOUBLE}}], \"pointOfInterest\": { \"id\": \"{{STRING}}\", //POI lookup Id vended from Alexa \"hoursOfOperation\": [ { \"dayOfWeek\": \"{{STRING}}\", \"hours\": [ { \"open\": \"{{STRING}}\", // ISO-8601 time with timezone format \"close\": \"{{STRING}}\" // ISO-8601 time with timezone format } ], \"type\": \"{{STRING}}\" // Can be: OPEN_DURING_HOURS, OPEN_24_HOURS, etc. } ], \"phoneNumber\": \"{{STRING}}\" } }, ... ], \"shapes\": [ [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], ... ] } } ..., STEP 3: Implement the new navigation abstract methods. The new navigation methods are all called in response to navigation-based user utterances such as \u201cshow my previous route\u201d or \u201cwhat\u2019s the speed limit here?\u201d. At a minimum, your implementation should report a navigationError() to inform the user when the navigation system does not support that information. Note: The navigationEvent() , showAlternativeRoutesSucceeded() and navigationError() methods have been implemented in the Auto SDK but are not yet implemented on the cloud side. Sending the events will not affect navigation functionality, but the Alexa cloud will return an INVALID_REQUEST_EXCEPTION or INVALID_SERVICE_EXCEPTION until these events are implemented on the cloud side. Java (Android) - click to expand or collapse @Override public void showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, ErrorCode.NOT_SUPPORTED, *\"\"** *); } ... @Override public void navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( ErrorType.PREVIOUS_NAVIGATION_START_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void showAlternativeRoutes( AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void controlDisplay ( ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( ErrorType.ROUTE_OVERVIEW_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( ErrorType.TURN_GUIDANCE_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } ... @Override public void announceRoadRegulation( RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( ErrorType.SPEED_LIMIT_REGULATION_FAILED, ErrorCode.NOT_SUPPORTED, \"\" ); } C++ - click to expand or collapse void NavigationHandler::showPreviousWaypoints() { //handle showing information about previous waypoints... navigationError( aace::navigation::Navigation::ErrorType.SHOW_PREVIOUS_WAYPOINTS_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\"* *); } ... void NavigationHandler::navigateToPreviousWaypoint() { //handle navigation to previous waypoint navigationError( aace::navigation::Navigation::ErrorType.PREVIOUS_NAVIGATION_START_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::showAlternativeRoutes( aace::navigation::Navigation::AlternateRouteType alternateRouteType ) { //pass AlternateRouteType enum navigationError( aace::navigation::Navigation::ErrorType.DEFAULT_ALTERNATE_ROUTES_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::controlDisplay ( aace::navigation::Navigation::ControlDisplay controlDisplay ) { //pass ControlDisplay enum navigationError( aace::navigation::Navigation::ErrorType.ROUTE_OVERVIEW_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceManeuver( String payload ) { //pass the JSON string payload from AnnounceManeuver directive navigationError( aace::navigation::Navigation::ErrorType.TURN_GUIDANCE_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); } ... void NavigationHandler::announceRoadRegulation( aace::navigation::Navigation::RoadRegulation roadRegulation ) { //pass RoadRegulation enum navigationError( aace::navigation::Navigation::ErrorType.SPEED_LIMIT_REGULATION_FAILED, aace::navigation::Navigation::ErrorCode.NOT_SUPPORTED, \"\" ); }","title":"Implementing the New Navigation Features"},{"location":"MIGRATION/#new-templateruntime-interface-version","text":"The Auto SDK now implements version 1.2 of the TemplateRuntime interface to handle display card templates. If you support TemplateRuntime in your implementation, you must update your implementation to support the new card types. The TemplateRuntime interface remains the same, but the LocalSearchListTemplate1 template has been deprecated in favor of the new LocalSearchListTemplate2 template. In addition, two new templates ( TrafficDetailsTemplate and LocalSearchDetailTemplate1 ), are now supported. The TrafficDetailsTemplate includes commute information to favorite destinations such as home or work. The LocalSearchDetailTemplate1 template includes information about specific locations or information in response to users asking for details about locations presented in the LocalSearchListTemplate2 template. For details about the TemplateRuntime interface, see the Alexa Voice Service (AVS) documentation . For details about implementing TemplateRuntime in your Auto SDK implementation see the Alexa module README for C++ or Android .","title":"New TemplateRuntime Interface Version"},{"location":"MIGRATION/#car-control-source-file-relocation","text":"The Car Control module platform interface files and documentation are now located in aac-sdk/modules/car-control for C++ and aac-sdk/platforms/android/modules/car-control for Android, rather than in the Local Voice Control (LVC) extension directory structure. Note: In addition, if you use custom assets for car control in an implementation with the optional Local Voice Control (LVC) extension, you must specify the path to the custom assets in both the Auto SDK car control configuration and the LVC configuration, not just the LVC configuration. For details, see Path to Custom Car Control Assets for LVC Implementations .","title":"Car Control Source File Relocation"},{"location":"MIGRATION/#code-based-linking-cbl-handler-in-the-sample-apps","text":"Both of the Auto SDK Sample Apps now include the Code-Based Linking (CBL) handler implementation (in favor of the AuthProvider handler implementation ) to handle obtaining access tokens from Login with Amazon (LWA). Changing from the AuthProvider handler to the CBL handler is not a required change , but we recommend that you use the Auto SDK CBL interface for ease of implementation. For details about the CBL handler, please see the CBL module README for C++ or for Android . If you want to continue using the AuthProvider interface, we recommend that you implement the new onAuthFailure() method that exposes 403 \"unauthorized request\" exceptions from Alexa Voice Service (AVS). This method may be invoked, for example, when your product makes a request to AVS using an access token obtained for a device which has been deregistered from the Alexa companion app. In the Sample Apps, you can override the interface and unset your login credentials as if the user had done so with your GUI interface: Java (Android) - click to expand or collapse @Override public void authFailure( String token ) { // handle user de-authorize scenario C++ - click to expand or collapse void AuthProviderHandler::authFailure( const std::string& token ) { // handle user de-authorize scenario","title":"Code-Based-Linking (CBL) Handler in the Sample Apps"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/","text":"Migration Guide to Use MessageBroker API Table of Contents Overview Application architecture Migrating existing platform interface handlers Handling audio and stream based interfaces Handling synchronous-style messages Migrating existing AASB platform interface handler implementation Hybrid or incremental migration Overview Auto SDK 4.0 introduces a new MessageBroker API for applications to subscribe to and publish AASB messages. This API replaces the existing platform interfaces that developers use to integrate platform-specific functionality such as audio, location, and Alexa capabilities. MessageBroker also replaces the deprecated AASB interface used in previous Auto SDK versions. Developers integrating with Auto SDK for the first time should only use the MessageBroker API. Developers who upgrade to Auto SDK 4.0 (and plan to continue to upgrade beyond 4.0), should migrate their existing applications as soon as possible. The next major release of Auto SDK will remove the platform interface API without maintaining backward compatibility with older versions of the SDK. Application architecture In most cases, the interface changes in Auto SDK do not require modifying the architecture of the existing Auto SDK client application. The following diagram shows an application with a typical architecture based on Auto SDK 3.3 next to the same application using the Auto SDK 4.0 MessageBroker API: In the example above, the key difference is that rather than creating handlers that extend platform interfaces, the new implementation uses a loosely coupled MessageBroker API to subscribe to and publish messages. It is straightforward to adapt the existing application handlers to MessageBroker by using a simple adapter pattern that does not require completely redesigning the application. Migrating existing platform interface handlers The following diagram highlights the core differences between using the old platform interfaces and the new MessageBroker API. The left side shows the steps for creating the Engine and handlers and invoking interface methods in Auto SDK 3.3. The right side shows the equivalent steps using the MessageBroker API required for Auto SDK 4.0. Even though the MessageBroker API provides flexibility for how to design an application, it may be easier to adapt an existing implementation rather than redesigning it. The following example demonstrates how to modify a DoNotDisturb platform interface handler to use MessageBroker. Example implementation of a DoNotDisturb handler in Auto SDK 3.3: In Auto SDK 3.3, the DoNotDisturb platform interface has the following methods: /** * Handle setting of DND directive. * * @param [in] doNotDisturb setting state */ virtual void setDoNotDisturb ( const bool doNotDisturb ) = 0 ; /** * Notifies the Engine of a platform request to set the DND State * * @param [in] doNotDisturb setting state * @return true if successful, false if change was rejected */ bool doNotDisturbChanged ( const bool doNotDisturb ); The implementation overrides the setDoNotDisturb() platform interface method to provide application-specific behavior (in this case, logging a message to the console) and calls the Engine interface method doNotDisturbChanged to request a change to the DoNotDisturb setting. #include <AACE/Alexa/DoNotDisturb.h> class DoNotDisturbHandler : public DoNotDisturb { public : DoNotDisturbHandler () = default ; void setDoNotDisturb ( bool doNotDisturb ) override ; void notifyDoNotDisturbSettingChange ( bool doNotDisturb ); }; void DoNotDisturbHandler::setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler::notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by calling // the Engine interface method implemented in the DoNotDisturb base class doNotDisturbChanged ( bool doNotDisturb ); } Example implementation of a DoNotDisturb handler in Auto SDK 4.0: In Auto SDK 4.0 the SetDoNotDisturbMessage and the DoNotDisturbChangedMessage replace setDoNotDisturb the doNotDisturbChanged methods, respectively. The following example shows the same core logic in the handler, but it uses the MessageBroker API instead of extending a platform interface. #include <AASB/Message/Alexa/DoNotDisturb/SetDoNotDisturbMessage.h> #include <AASB/Message/Alexa/DoNotDisturb/DoNotDisturbChangedMessage.h> #include <AACE/Core/MessageBroker.h> class DoNotDisturbHandler { public : DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void setDoNotDisturb ( bool doNotDisturb ); void doNotDisturbChanged ( bool doNotDisturb ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; DoNotDisturbHandler :: DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to the \"SetDoNotDisturb\" message m_messageBroker -> subscribe ( [ = ]( const std :: string & msg ) { SetDoNotDisturbMessage _msg = json :: parse ( msg ); setDoNotDisturb ( _msg . payload . doNotDisturb ); }, SetDoNotDisturbMessage :: topic (), SetDoNotDisturbMessage :: action ()); } void DoNotDisturbHandler :: setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler :: notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by publishing // a \"DoNotDisturbChanged\" message DoNotDisturbChangedMessage _msg ; _msg . payload . doNotDisturb = doNotDisturb ; m_messageBroker -> publish ( _msg . toString ()); // publish is fire and forget } A reference to the MessageBroker is required. This can be accessed from the Engine object and provided when creating the DoNotDisturbHandler instance in the main application code: auto handler = std :: make_shared < DoNotDisturbHandler > ( engine -> getMessageBroker ()); Handling audio and stream based interfaces Auto SDK 4.0 replaces audio stream platform interfaces AudioInput and AudioOutput with the MessageBroker's MessageStream API and corresponding AASB messages with \"AudioInput\" and \"AudioOutput\" topics. When the application receives a message that requires it to read from or write to a stream, the message payload includes a stream ID. The application uses the stream ID to \u201copen\u201d the stream for I/O. Developers with existing handlers for media players or microphone, for example, should migrate their handlers to use the new MessageBroker and MessageStream API. Note In previous versions of Auto SDK, the Engine \"opened\" audio channels through the AudioInputProvider and AudioOutputProvider platform interfaces prior to requesting audio input or output through the AudioInput and AudioOutput platform interface instances representing each channel. In Auto SDK 4.0, there is no AASB message equivalent of AudioInputProvider or AudioOutputProvider . When the Engine needs audio input from a particular channel, it sends the AudioInput.StartAudioInput message with the channel type specified in the payload. Similarly, when the Engine needs to play audio for a particular channel, it sends the AudioOutput.Prepare message with the channel type specified in the payload. The following example demonstrates how the application would open an input stream after receiving the StartAudioInput message, and write data to the stream until a StopAudioInput message is received: #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); // open the stream for writing auto streamId = _msg . payload . streamId ; auto stream = messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); startAudioInput ( streamId , stream ) }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; stopAudioInput ( streamId ); }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } A MessageStream can be read-only, write-only, or support both read and write operations. It is required to specify the operation mode when opening the stream using the MessageStream::Mode enumeration. If the MessageBroker cannot open a stream for the specified operation, the openStream() call will fail and return a null object. Handling synchronous-style messages Most AASB messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special reply message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message. Replying to messages from the Engine In most cases in which a message requires a reply, the Engine will block sending other messages until it receives the reply (or until a timeout occurs), so it is important to send the reply message right away. The following example demonstrates how to subscribe to the GetLocation message from the LocationProvider interface and send a reply back to the Engine: #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> // subscribe to GetLocation message m_messageBroker -> subscribe ([ = ]( const std :: string & msg ) { GetLocationMessageReply _reply ; // set the reply message \"replyToId\" to the id of the // original message: _reply . header . messageDescription . replyToId = _msg . header . id ; // populate the reply message payload data _reply . payload . location . latitude = m_latitude ; _reply . payload . location . longitude = m_longitude ; // publish ther reply m_messageBroker -> publish ( _reply . toString ()); }, GetLocationMessage :: topic (), GetLocationMessage :: action ()); Receiving reply messages from the Engine For some messages published by the application, the Engine may send a reply back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The \"replyToId\" in the reply message will contain the message ID for which the reply is sent. The following example demonstrates how subscribe to GetPropertyReply message from the Engine. m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); // Publish GetPropertyMessage void publishGetProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // Engine sends the GetProperty message reply with the requested property // The \"replyToId\" in the reply message will contain the ID of this published message } void handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); // Get the property value from the reply and handle in the implementation const std :: string & propertyValue = msg . payload . value } Migrating existing AASB platform interface handler implementation Auto SDK 3.3 supports AASB as an optional extension and platform interface. Developers using the AASB platform interface need to migrate the AASB platform interface handler to use the new MessageBroker API instead. This can be accomplished by following a similar pattern as described in the sections above; however, use MessageBroker to subscribe to ALL messages in order to provide the same functionality as the existing AASB platform interface. class AASBHandler { public : AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void messageReceived ( const std :: string & message ); // engine interface implementation void publish ( const std :: string & message ); std :: shared_ptr < MessageStream > openStream ( const std :: string & streamId , MessageStream :: Mode mode ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; AASBHandler :: AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to ALL messages and bind to the messageReceived() function // since it has the same method signature as the message handler m_messageBroker -> subscribe ( std :: bind ( & AASBHandler :: messageReceived , this , std :: placeholders :: _1 ) ); } void AASBHandler :: messageReceived ( const std :: string & message ){ // application logic for handling AASB messages std :: cout << message << std :: endl ; } void AASBHandler :: publish ( const std :: string & message ){ // invoke the MessageBroker publish method m_messageBroker -> publish ( message ); } std :: shared_ptr < MessageStream > AASBHandler :: openStream ( const std :: string & streamId , MessageStream :: Mode mode ){ // invoke the MessageBroker openStream method return m_messageBroker -> openStream ( mode ); } Hybrid or incremental migration Although Amazon recommends migrating the entire application to MessageBroker when upgrading to Auto SDK 4.0, it is possible to use a hybrid implementation of platform interface handlers and MessageBroker until Auto SDK removes the platform interface API. New interfaces added in Auto SDK 4.0 are enabled to use the MessageBroker API by default. The following diagram illustrates the architecture for a hybrid application:","title":"Migration to AASB MessageBroker"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#migration-guide-to-use-messagebroker-api","text":"","title":"Migration Guide to Use MessageBroker API"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#table-of-contents","text":"Overview Application architecture Migrating existing platform interface handlers Handling audio and stream based interfaces Handling synchronous-style messages Migrating existing AASB platform interface handler implementation Hybrid or incremental migration","title":"Table of Contents"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#overview","text":"Auto SDK 4.0 introduces a new MessageBroker API for applications to subscribe to and publish AASB messages. This API replaces the existing platform interfaces that developers use to integrate platform-specific functionality such as audio, location, and Alexa capabilities. MessageBroker also replaces the deprecated AASB interface used in previous Auto SDK versions. Developers integrating with Auto SDK for the first time should only use the MessageBroker API. Developers who upgrade to Auto SDK 4.0 (and plan to continue to upgrade beyond 4.0), should migrate their existing applications as soon as possible. The next major release of Auto SDK will remove the platform interface API without maintaining backward compatibility with older versions of the SDK.","title":"Overview"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#application-architecture","text":"In most cases, the interface changes in Auto SDK do not require modifying the architecture of the existing Auto SDK client application. The following diagram shows an application with a typical architecture based on Auto SDK 3.3 next to the same application using the Auto SDK 4.0 MessageBroker API: In the example above, the key difference is that rather than creating handlers that extend platform interfaces, the new implementation uses a loosely coupled MessageBroker API to subscribe to and publish messages. It is straightforward to adapt the existing application handlers to MessageBroker by using a simple adapter pattern that does not require completely redesigning the application.","title":"Application architecture"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#migrating-existing-platform-interface-handlers","text":"The following diagram highlights the core differences between using the old platform interfaces and the new MessageBroker API. The left side shows the steps for creating the Engine and handlers and invoking interface methods in Auto SDK 3.3. The right side shows the equivalent steps using the MessageBroker API required for Auto SDK 4.0. Even though the MessageBroker API provides flexibility for how to design an application, it may be easier to adapt an existing implementation rather than redesigning it. The following example demonstrates how to modify a DoNotDisturb platform interface handler to use MessageBroker. Example implementation of a DoNotDisturb handler in Auto SDK 3.3: In Auto SDK 3.3, the DoNotDisturb platform interface has the following methods: /** * Handle setting of DND directive. * * @param [in] doNotDisturb setting state */ virtual void setDoNotDisturb ( const bool doNotDisturb ) = 0 ; /** * Notifies the Engine of a platform request to set the DND State * * @param [in] doNotDisturb setting state * @return true if successful, false if change was rejected */ bool doNotDisturbChanged ( const bool doNotDisturb ); The implementation overrides the setDoNotDisturb() platform interface method to provide application-specific behavior (in this case, logging a message to the console) and calls the Engine interface method doNotDisturbChanged to request a change to the DoNotDisturb setting. #include <AACE/Alexa/DoNotDisturb.h> class DoNotDisturbHandler : public DoNotDisturb { public : DoNotDisturbHandler () = default ; void setDoNotDisturb ( bool doNotDisturb ) override ; void notifyDoNotDisturbSettingChange ( bool doNotDisturb ); }; void DoNotDisturbHandler::setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler::notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by calling // the Engine interface method implemented in the DoNotDisturb base class doNotDisturbChanged ( bool doNotDisturb ); } Example implementation of a DoNotDisturb handler in Auto SDK 4.0: In Auto SDK 4.0 the SetDoNotDisturbMessage and the DoNotDisturbChangedMessage replace setDoNotDisturb the doNotDisturbChanged methods, respectively. The following example shows the same core logic in the handler, but it uses the MessageBroker API instead of extending a platform interface. #include <AASB/Message/Alexa/DoNotDisturb/SetDoNotDisturbMessage.h> #include <AASB/Message/Alexa/DoNotDisturb/DoNotDisturbChangedMessage.h> #include <AACE/Core/MessageBroker.h> class DoNotDisturbHandler { public : DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void setDoNotDisturb ( bool doNotDisturb ); void doNotDisturbChanged ( bool doNotDisturb ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; DoNotDisturbHandler :: DoNotDisturbHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to the \"SetDoNotDisturb\" message m_messageBroker -> subscribe ( [ = ]( const std :: string & msg ) { SetDoNotDisturbMessage _msg = json :: parse ( msg ); setDoNotDisturb ( _msg . payload . doNotDisturb ); }, SetDoNotDisturbMessage :: topic (), SetDoNotDisturbMessage :: action ()); } void DoNotDisturbHandler :: setDoNotDisturb ( bool doNotDisturb ) { std :: cout << \"setDoNotDisturb: \" << doNotDisturb << std :: endl ; } void DoNotDisturbHandler :: notifyDoNotDisturbSettingChange ( bool doNotDisturb ) { // Notify the Engine of a request to change the DND setting by publishing // a \"DoNotDisturbChanged\" message DoNotDisturbChangedMessage _msg ; _msg . payload . doNotDisturb = doNotDisturb ; m_messageBroker -> publish ( _msg . toString ()); // publish is fire and forget } A reference to the MessageBroker is required. This can be accessed from the Engine object and provided when creating the DoNotDisturbHandler instance in the main application code: auto handler = std :: make_shared < DoNotDisturbHandler > ( engine -> getMessageBroker ());","title":"Migrating existing platform interface handlers"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#handling-audio-and-stream-based-interfaces","text":"Auto SDK 4.0 replaces audio stream platform interfaces AudioInput and AudioOutput with the MessageBroker's MessageStream API and corresponding AASB messages with \"AudioInput\" and \"AudioOutput\" topics. When the application receives a message that requires it to read from or write to a stream, the message payload includes a stream ID. The application uses the stream ID to \u201copen\u201d the stream for I/O. Developers with existing handlers for media players or microphone, for example, should migrate their handlers to use the new MessageBroker and MessageStream API. Note In previous versions of Auto SDK, the Engine \"opened\" audio channels through the AudioInputProvider and AudioOutputProvider platform interfaces prior to requesting audio input or output through the AudioInput and AudioOutput platform interface instances representing each channel. In Auto SDK 4.0, there is no AASB message equivalent of AudioInputProvider or AudioOutputProvider . When the Engine needs audio input from a particular channel, it sends the AudioInput.StartAudioInput message with the channel type specified in the payload. Similarly, when the Engine needs to play audio for a particular channel, it sends the AudioOutput.Prepare message with the channel type specified in the payload. The following example demonstrates how the application would open an input stream after receiving the StartAudioInput message, and write data to the stream until a StopAudioInput message is received: #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); // open the stream for writing auto streamId = _msg . payload . streamId ; auto stream = messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); startAudioInput ( streamId , stream ) }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; stopAudioInput ( streamId ); }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } A MessageStream can be read-only, write-only, or support both read and write operations. It is required to specify the operation mode when opening the stream using the MessageStream::Mode enumeration. If the MessageBroker cannot open a stream for the specified operation, the openStream() call will fail and return a null object.","title":"Handling audio and stream based interfaces"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#handling-synchronous-style-messages","text":"Most AASB messages are either fire-and-forget, or they have a separate message that the application or Engine sends as an asynchronous response. However, some messages exchanged between the Engine and the application require a special reply message type. Typically these messages retrieve data that the requester requires \"synchronously\", such as application states retrieved for Alexa events. The Engine may either require a reply in response to a published message, or may send a reply to the application in response to a published message.","title":"Handling synchronous-style messages"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#replying-to-messages-from-the-engine","text":"In most cases in which a message requires a reply, the Engine will block sending other messages until it receives the reply (or until a timeout occurs), so it is important to send the reply message right away. The following example demonstrates how to subscribe to the GetLocation message from the LocationProvider interface and send a reply back to the Engine: #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> // subscribe to GetLocation message m_messageBroker -> subscribe ([ = ]( const std :: string & msg ) { GetLocationMessageReply _reply ; // set the reply message \"replyToId\" to the id of the // original message: _reply . header . messageDescription . replyToId = _msg . header . id ; // populate the reply message payload data _reply . payload . location . latitude = m_latitude ; _reply . payload . location . longitude = m_longitude ; // publish ther reply m_messageBroker -> publish ( _reply . toString ()); }, GetLocationMessage :: topic (), GetLocationMessage :: action ());","title":"Replying to messages from the Engine"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#receiving-reply-messages-from-the-engine","text":"For some messages published by the application, the Engine may send a reply back to the application. In such cases, your application must subscribe to and handle the reply from the Engine. The \"replyToId\" in the reply message will contain the message ID for which the reply is sent. The following example demonstrates how subscribe to GetPropertyReply message from the Engine. m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); // Publish GetPropertyMessage void publishGetProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // Engine sends the GetProperty message reply with the requested property // The \"replyToId\" in the reply message will contain the ID of this published message } void handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); // Get the property value from the reply and handle in the implementation const std :: string & propertyValue = msg . payload . value }","title":"Receiving reply messages from the Engine"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#migrating-existing-aasb-platform-interface-handler-implementation","text":"Auto SDK 3.3 supports AASB as an optional extension and platform interface. Developers using the AASB platform interface need to migrate the AASB platform interface handler to use the new MessageBroker API instead. This can be accomplished by following a similar pattern as described in the sections above; however, use MessageBroker to subscribe to ALL messages in order to provide the same functionality as the existing AASB platform interface. class AASBHandler { public : AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ); void messageReceived ( const std :: string & message ); // engine interface implementation void publish ( const std :: string & message ); std :: shared_ptr < MessageStream > openStream ( const std :: string & streamId , MessageStream :: Mode mode ); private : std :: shared_ptr < MessageBroker > m_messageBroker ; }; AASBHandler :: AASBHandler ( std :: shared_ptr < MessageBroker > messageBroker ) : m_messageBroker ( messageBroker ) { // subscribe to ALL messages and bind to the messageReceived() function // since it has the same method signature as the message handler m_messageBroker -> subscribe ( std :: bind ( & AASBHandler :: messageReceived , this , std :: placeholders :: _1 ) ); } void AASBHandler :: messageReceived ( const std :: string & message ){ // application logic for handling AASB messages std :: cout << message << std :: endl ; } void AASBHandler :: publish ( const std :: string & message ){ // invoke the MessageBroker publish method m_messageBroker -> publish ( message ); } std :: shared_ptr < MessageStream > AASBHandler :: openStream ( const std :: string & streamId , MessageStream :: Mode mode ){ // invoke the MessageBroker openStream method return m_messageBroker -> openStream ( mode ); }","title":"Migrating existing AASB platform interface handler implementation"},{"location":"MIGRATION_TO_AASB_MESSAGEBROKER/#hybrid-or-incremental-migration","text":"Although Amazon recommends migrating the entire application to MessageBroker when upgrading to Auto SDK 4.0, it is possible to use a hybrid implementation of platform interface handlers and MessageBroker until Auto SDK removes the platform interface API. New interfaces added in Auto SDK 4.0 are enabled to use the MessageBroker API by default. The following diagram illustrates the architecture for a hybrid application:","title":"Hybrid or incremental migration"},{"location":"NEED_HELP/","text":"Need Help? Registering a Product and Creating a Security Profile Requesting Additional Functionality Reporting an Issue Existing Alexa Auto SDK Customers New Alexa Auto SDK Customers Making Pull Requests Registering a Product and Creating a Security Profile After creating an Amazon developer account, you'll need to register a product and create a security profile on the Alexa Voice Service (AVS) developer portal. When you follow the instructions to fill in the product information : Use your own custom information, taking note of the Product ID . Be sure to select Automotive from the Product category pull-down. When you follow the instructions to set up your security profile , take note of the generated Client ID . Requesting Additional Functionality The following additional functionality is available with help from your designated Amazon Solutions Architect (SA) or Partner Manager: Address Book contact and navigation favorites uploading Amazon Music and other music service providers Wake Word support Alexa Communication Local Voice Control Device Client Metrics Voice Chrome for Android Alexa Presentation Language (APL) component required for APL rendering on the Android Sample App To use this functionality, your product must be placed on an allow list by Amazon. Contact your SA or Partner Manager, provide the Amazon ID of your development device, and request the functionality you want to add. Note: If you would like to request additional functionality but don't have a designated SA or Partner Manager, please reach out using the \"Request More Information\" form at the end of the Alexa Auto Software Development Kit page on the developer portal. To find the Amazon ID for your development device: Log in to the AVS Developer Portal . Click PRODUCTS . Take note of the Amazon ID for your device. Reporting an Issue Existing Alexa Auto SDK Customers Please reach out to the designated Amazon Solutions Architect (SA) or Partner Manager for your company, and include the following information: Overview - provide a brief overview of the issue Steps to reproduce - provide details of how to reproduce the issue Logs - include relevant logs Platform and environment - provide details about your hardware platform, operating system, compiler, API level, etc. New Alexa Auto SDK Customers Please fill out the form \"Request more information\" at the bottom of the Alexa Auto Software Development Kit (SDK) page. Once you have submitted your request, someone from Amazon will contact you. Making Pull Requests We are not accepting pull requests or community contributed bug fixes at this time.","title":"Need Help?"},{"location":"NEED_HELP/#need-help","text":"Registering a Product and Creating a Security Profile Requesting Additional Functionality Reporting an Issue Existing Alexa Auto SDK Customers New Alexa Auto SDK Customers Making Pull Requests","title":"Need Help?"},{"location":"NEED_HELP/#registering-a-product-and-creating-a-security-profile","text":"After creating an Amazon developer account, you'll need to register a product and create a security profile on the Alexa Voice Service (AVS) developer portal. When you follow the instructions to fill in the product information : Use your own custom information, taking note of the Product ID . Be sure to select Automotive from the Product category pull-down. When you follow the instructions to set up your security profile , take note of the generated Client ID .","title":"Registering a Product and Creating a Security Profile"},{"location":"NEED_HELP/#requesting-additional-functionality","text":"The following additional functionality is available with help from your designated Amazon Solutions Architect (SA) or Partner Manager: Address Book contact and navigation favorites uploading Amazon Music and other music service providers Wake Word support Alexa Communication Local Voice Control Device Client Metrics Voice Chrome for Android Alexa Presentation Language (APL) component required for APL rendering on the Android Sample App To use this functionality, your product must be placed on an allow list by Amazon. Contact your SA or Partner Manager, provide the Amazon ID of your development device, and request the functionality you want to add. Note: If you would like to request additional functionality but don't have a designated SA or Partner Manager, please reach out using the \"Request More Information\" form at the end of the Alexa Auto Software Development Kit page on the developer portal. To find the Amazon ID for your development device: Log in to the AVS Developer Portal . Click PRODUCTS . Take note of the Amazon ID for your device.","title":"Requesting Additional Functionality"},{"location":"NEED_HELP/#reporting-an-issue","text":"","title":"Reporting an Issue"},{"location":"NEED_HELP/#existing-alexa-auto-sdk-customers","text":"Please reach out to the designated Amazon Solutions Architect (SA) or Partner Manager for your company, and include the following information: Overview - provide a brief overview of the issue Steps to reproduce - provide details of how to reproduce the issue Logs - include relevant logs Platform and environment - provide details about your hardware platform, operating system, compiler, API level, etc.","title":"Existing Alexa Auto SDK Customers"},{"location":"NEED_HELP/#new-alexa-auto-sdk-customers","text":"Please fill out the form \"Request more information\" at the bottom of the Alexa Auto Software Development Kit (SDK) page. Once you have submitted your request, someone from Amazon will contact you.","title":"New Alexa Auto SDK Customers"},{"location":"NEED_HELP/#making-pull-requests","text":"We are not accepting pull requests or community contributed bug fixes at this time.","title":"Making Pull Requests"},{"location":"SDK_MODULES/","text":"Auto SDK Modules and Extensions The Auto SDK is organized into logically related groups of functionality called \u201cmodules,\u201d which enable you to select only the features you want to include in your integration. Each module includes \"AASB\", \u201cPlatform\u201d and \u201cEngine\u201d libraries. The AASB library includes the AASB messages supported for the module, the Platform library includes the configuration options required for a feature, and the Engine library augments the base functionality of the Engine with the underlying implementation of the feature. Core Module The Core module (see README ) provides the infrastructure for audio input and output, authorization, logging, location reporting, metrics, property management, network monitoring services, local storage, and vehicle information services. The infrastructure is necessary for any module that uses the messaging interfaces (for example, the Alexa module). Alexa Module The Alexa module (see README ) supports Alexa features such as speech input and output, authorization, volume control, media playback, equalizer control, template and state rendering, local media sources, alerts, notifications, and do not disturb. Navigation Module The Navigation module (see README ) provides support for Alexa to interface with the onboard navigation system. Phone Call Controller Module The Phone Call Controller module (see README ) provides support for Alexa to interface with the onboard telephony system. Address Book Module The Address Book module (see README ) augments the communications and navigation capabilities of Alexa with user data such as phone contacts and navigation favorites (\"home\", \"work\", etc.). Code-Based Linking (CBL) Module The CBL module (see README ) implements the CBL mechanism of acquiring Login with Amazon (LWA) access tokens. For information about the CBL mechanism, see the Code-Based Linking documentation . Alexa Presentation Language (APL) Module The APL module (see README ) enables devices to support a visual Alexa experience. Note: The APL Render module is provided to enable APL rendering capabilities in an Android application. Messaging Module The Messaging module (see README ) provides support for Short Message Service (SMS) capabilities of Alexa such as sending and reading text messages. Car Control Module The Car Control module (see README ) enables your application to build a custom vehicle-control experience that allows the user to voice-control vehicle features using Alexa. Connectivity Module The Connectivity module (see README ) creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. Text To Speech (TTS) Module The TTS module (see README ) enables a platform implementation to request synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. Text To Speech (TTS) Provider Module The TTS provider module (see README ) synthesizes Alexa speech on demand. This module requires Auto SDK to be built with the Local Voice Control extension. Custom Domain Module The Custom Domain module (see README ) creates a bi-directional communication channel between the device and your custom cloud skills, allowing customized experience with the voice assistant. AmazonLite Wake Word Extension Wake Word enables hands-free, voice-initiated interactions with Alexa. The Wake Word extension enables AmazonLite Wake Word support in the Auto SDK. Alexa Communications Extension The Alexa Communications extension enables integration with Alexa-to-Alexa calling, Alexa-to-PSTN calling, and messaging capabilities. Alexa Custom Assistant Extension The Alexa Custom Assistant extension provides the functionality for toggling the settings of Alexa and the automaker's voice assistant, and notifies the IVI system at runtime about updates to the acting assistant for a specific interaction. Bluetooth Extension The Bluetooth extension allows the Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features to users of Android or iOS smartphones. Device Client Metrics (DCM) Extension The Device Client Metrics (DCM) extension enables logging and uploading Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and user perceived latency (UPL) between the request and Alexa\u2019s response. Geolocation Extension The Geolocation extension adds geolocation consent support to the Auto SDK, enabling the user to grant consent to location sharing with Alexa from your application. Local Voice Control (LVC) Extension The LVC extension provides car control, communication, navigation, local search, and entertainment functionality, without an internet connection. It includes components that run an Alexa endpoint inside the vehicle's head unit. Local Voice Control Module The Local Voice Control module adds core functionality to Auto SDK to enable offline features. The module infrastructure bridges the Auto SDK Engine to the offline Alexa endpoint running in the head unit and is necessary for all other modules in the LVC extension. Local Skill Service Module The Local Skill Service module provides a multipurpose service to the Auto SDK Engine that enables components running alongside the offline Alexa endpoint to communicate with the Auto SDK Engine. The module infrastructure is necessary for other modules in the LVC extension. Local Navigation Module The Local Navigation module enables you to provide customers with offline Alexa local search and navigation to points of interest (i.e., categories, chains, and entities) and addresses. Address Book Local Service Module The Address Book Local Service module works with the Address Book module and the Local Skill Service module to augment the offline communications and navigation capabilities of Alexa with user data such as phone contacts and navigation favorites. Car Control Local Service Module The Car Control Local Service module works with the Car Control module and the Local Skill Service module to enable users to control vehicle features offline with Alexa. Mobile Authorization Extension The Mobile Authorization extension enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone instead of opening a web browser and entering a code. Voice Chrome for Android Extension The Voice Chrome extension adds Voice Chrome support to the Auto SDK for Android x86 64-bit and Android ARM 32/64-bit platforms. Voice Chrome provides a consistent set of visual cues representing Alexa attention state across a range of Alexa-enabled devices. The Voice Chrome extension includes a prebuilt Android AAR library for easy integration with your applications, as well as a patch to the Android Sample App that adds the Voice Chrome functionality.","title":"Auto SDK Modules and Extensions"},{"location":"SDK_MODULES/#auto-sdk-modules-and-extensions","text":"The Auto SDK is organized into logically related groups of functionality called \u201cmodules,\u201d which enable you to select only the features you want to include in your integration. Each module includes \"AASB\", \u201cPlatform\u201d and \u201cEngine\u201d libraries. The AASB library includes the AASB messages supported for the module, the Platform library includes the configuration options required for a feature, and the Engine library augments the base functionality of the Engine with the underlying implementation of the feature.","title":"Auto SDK Modules and Extensions"},{"location":"SDK_MODULES/#core-module","text":"The Core module (see README ) provides the infrastructure for audio input and output, authorization, logging, location reporting, metrics, property management, network monitoring services, local storage, and vehicle information services. The infrastructure is necessary for any module that uses the messaging interfaces (for example, the Alexa module).","title":"Core Module"},{"location":"SDK_MODULES/#alexa-module","text":"The Alexa module (see README ) supports Alexa features such as speech input and output, authorization, volume control, media playback, equalizer control, template and state rendering, local media sources, alerts, notifications, and do not disturb.","title":"Alexa Module"},{"location":"SDK_MODULES/#navigation-module","text":"The Navigation module (see README ) provides support for Alexa to interface with the onboard navigation system.","title":"Navigation Module"},{"location":"SDK_MODULES/#phone-call-controller-module","text":"The Phone Call Controller module (see README ) provides support for Alexa to interface with the onboard telephony system.","title":"Phone Call Controller Module"},{"location":"SDK_MODULES/#address-book-module","text":"The Address Book module (see README ) augments the communications and navigation capabilities of Alexa with user data such as phone contacts and navigation favorites (\"home\", \"work\", etc.).","title":"Address Book Module"},{"location":"SDK_MODULES/#code-based-linking-cbl-module","text":"The CBL module (see README ) implements the CBL mechanism of acquiring Login with Amazon (LWA) access tokens. For information about the CBL mechanism, see the Code-Based Linking documentation .","title":"Code-Based Linking (CBL) Module"},{"location":"SDK_MODULES/#alexa-presentation-language-apl-module","text":"The APL module (see README ) enables devices to support a visual Alexa experience. Note: The APL Render module is provided to enable APL rendering capabilities in an Android application.","title":"Alexa Presentation Language (APL) Module"},{"location":"SDK_MODULES/#messaging-module","text":"The Messaging module (see README ) provides support for Short Message Service (SMS) capabilities of Alexa such as sending and reading text messages.","title":"Messaging Module"},{"location":"SDK_MODULES/#car-control-module","text":"The Car Control module (see README ) enables your application to build a custom vehicle-control experience that allows the user to voice-control vehicle features using Alexa.","title":"Car Control Module"},{"location":"SDK_MODULES/#connectivity-module","text":"The Connectivity module (see README ) creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans.","title":"Connectivity Module"},{"location":"SDK_MODULES/#text-to-speech-tts-module","text":"The TTS module (see README ) enables a platform implementation to request synthesis of Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string.","title":"Text To Speech (TTS) Module"},{"location":"SDK_MODULES/#text-to-speech-tts-provider-module","text":"The TTS provider module (see README ) synthesizes Alexa speech on demand. This module requires Auto SDK to be built with the Local Voice Control extension.","title":"Text To Speech (TTS) Provider Module"},{"location":"SDK_MODULES/#custom-domain-module","text":"The Custom Domain module (see README ) creates a bi-directional communication channel between the device and your custom cloud skills, allowing customized experience with the voice assistant.","title":"Custom Domain Module"},{"location":"SDK_MODULES/#amazonlite-wake-word-extension","text":"Wake Word enables hands-free, voice-initiated interactions with Alexa. The Wake Word extension enables AmazonLite Wake Word support in the Auto SDK.","title":"AmazonLite Wake Word Extension"},{"location":"SDK_MODULES/#alexa-communications-extension","text":"The Alexa Communications extension enables integration with Alexa-to-Alexa calling, Alexa-to-PSTN calling, and messaging capabilities.","title":"Alexa Communications Extension"},{"location":"SDK_MODULES/#alexa-custom-assistant-extension","text":"The Alexa Custom Assistant extension provides the functionality for toggling the settings of Alexa and the automaker's voice assistant, and notifies the IVI system at runtime about updates to the acting assistant for a specific interaction.","title":"Alexa Custom Assistant Extension"},{"location":"SDK_MODULES/#bluetooth-extension","text":"The Bluetooth extension allows the Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features to users of Android or iOS smartphones.","title":"Bluetooth Extension"},{"location":"SDK_MODULES/#device-client-metrics-dcm-extension","text":"The Device Client Metrics (DCM) extension enables logging and uploading Auto SDK metrics to the Amazon cloud. Voice request metrics, for example, include start and end timestamps of user and Alexa speech and user perceived latency (UPL) between the request and Alexa\u2019s response.","title":"Device Client Metrics (DCM) Extension"},{"location":"SDK_MODULES/#geolocation-extension","text":"The Geolocation extension adds geolocation consent support to the Auto SDK, enabling the user to grant consent to location sharing with Alexa from your application.","title":"Geolocation Extension"},{"location":"SDK_MODULES/#local-voice-control-lvc-extension","text":"The LVC extension provides car control, communication, navigation, local search, and entertainment functionality, without an internet connection. It includes components that run an Alexa endpoint inside the vehicle's head unit.","title":"Local Voice Control (LVC) Extension"},{"location":"SDK_MODULES/#local-voice-control-module","text":"The Local Voice Control module adds core functionality to Auto SDK to enable offline features. The module infrastructure bridges the Auto SDK Engine to the offline Alexa endpoint running in the head unit and is necessary for all other modules in the LVC extension.","title":"Local Voice Control Module"},{"location":"SDK_MODULES/#local-skill-service-module","text":"The Local Skill Service module provides a multipurpose service to the Auto SDK Engine that enables components running alongside the offline Alexa endpoint to communicate with the Auto SDK Engine. The module infrastructure is necessary for other modules in the LVC extension.","title":"Local Skill Service Module"},{"location":"SDK_MODULES/#local-navigation-module","text":"The Local Navigation module enables you to provide customers with offline Alexa local search and navigation to points of interest (i.e., categories, chains, and entities) and addresses.","title":"Local Navigation Module"},{"location":"SDK_MODULES/#address-book-local-service-module","text":"The Address Book Local Service module works with the Address Book module and the Local Skill Service module to augment the offline communications and navigation capabilities of Alexa with user data such as phone contacts and navigation favorites.","title":"Address Book Local Service Module"},{"location":"SDK_MODULES/#car-control-local-service-module","text":"The Car Control Local Service module works with the Car Control module and the Local Skill Service module to enable users to control vehicle features offline with Alexa.","title":"Car Control Local Service Module"},{"location":"SDK_MODULES/#mobile-authorization-extension","text":"The Mobile Authorization extension enables applications running on the vehicle's head unit to simplify the login experience. To log in to Alexa, the user uses the Alexa mobile app on a paired smartphone instead of opening a web browser and entering a code.","title":"Mobile Authorization Extension"},{"location":"SDK_MODULES/#voice-chrome-for-android-extension","text":"The Voice Chrome extension adds Voice Chrome support to the Auto SDK for Android x86 64-bit and Android ARM 32/64-bit platforms. Voice Chrome provides a consistent set of visual cues representing Alexa attention state across a range of Alexa-enabled devices. The Voice Chrome extension includes a prebuilt Android AAR library for easy integration with your applications, as well as a patch to the Android Sample App that adds the Voice Chrome functionality.","title":"Voice Chrome for Android Extension"},{"location":"SECURITY/","text":"Security Policy for Device SDKs Amazon has updated the AVS API to add a new consent screen during device registration for new users if the device has not been not certified by Amazon. Once the device has completed the testing process including obtaining a security assessment from Authorized Security Lab and receiving an Alexa Built-in badge, this consent screen will be removed and developers will be able to offer the full Alexa experience on their Alexa Built-in devices. To learn more about device testing and certification, please visit here . Reporting a Vulnerability If you discover a potential security issue in this project we ask that you notify Alexa Voice Services Security team by sending an email to avs-security@amazon.com . Please do not create a public GitHub issue.","title":"Security"},{"location":"SECURITY/#security-policy-for-device-sdks","text":"Amazon has updated the AVS API to add a new consent screen during device registration for new users if the device has not been not certified by Amazon. Once the device has completed the testing process including obtaining a security assessment from Authorized Security Lab and receiving an Alexa Built-in badge, this consent screen will be removed and developers will be able to offer the full Alexa experience on their Alexa Built-in devices. To learn more about device testing and certification, please visit here .","title":"Security Policy for Device SDKs"},{"location":"SECURITY/#reporting-a-vulnerability","text":"If you discover a potential security issue in this project we ask that you notify Alexa Voice Services Security team by sending an email to avs-security@amazon.com . Please do not create a public GitHub issue.","title":"Reporting a Vulnerability"},{"location":"SEQUENCE_DIAGRAMS/","text":"Alexa Module Sequence Diagrams for Alexa Auto SDK The following sequence diagrams illustrate two of the basic flows used in the Alexa Auto SDK. Table of Contents Tap to Talk Sequence Diagram Wake Word Enabled Sequence Diagram Tap to Talk Sequence Diagram This sequence diagram illustrates the initial sequence followed to access Alexa through the automotive tap to talk flow. The driver initiates the action by pushing the voice button located in the car. Once the driver pushes the voice button, Alexa is brought to a listening state ready for voice input, processing, and playback. This diagram includes the actual names and syntax for the methods and functions used in the Alexa Auto SDK. Note : Tap to Talk can be used with PCM and OPUS audio formats. Tip : Tap to Talk can be used to initiate speech recognition from external services such as external wake word engines, physical voice command buttons, and on screen buttons from the In-vehicle Voice Infotainment (IVI) system. Tap to Talk Flow Summary The driver pushes the voice button in the car. This specific human action puts Alexa into a listening state. There should be a visual indication to the driver that Alexa is now ready for audio input. The car's microphone is now actively receiving voice input and preparing an audio buffer to send to the Alexa Auto SDK Engine. The Alexa Auto SDK Engine audio input function loops until a directive is returned indicating that the audio input has finished. A visual indication should be displayed on the head unit screen indicating that Alexa is in a thinking state. In this state, Alexa is processing the input buffer and creating an appropriate response type. In this example Alexa is creating an audio out file that is sent to the cars head unit to play. Wake Word Enabled Sequence Diagram This sequence diagram illustrates the initial sequence followed to access Alexa with the wake word enabled. The driver initiates the action by uttering the Alexa wake word. This diagram includes the actual names and syntax for the methods and functions used in the Alexa Auto SDK. Note : WWE can be used with PCM audio format only. Wake Word Enabled Flow Summary startAudioInput() is called when wake word detection is enabled. This occurs when the Engine is started if wake word is enabled by default, or when enabledWakewordDetection() is explicitly called by the application. When this happens, the application must start sending audio samples from the microphone to the Engine. Audio is processed locally by the wake word engine until the wake word is detected. Once the wake word is detected, the Engine notifies the application that the dialog state has changed to \"listening\" and initiates a Recognize event with Alexa. While in the listening state, audio data is sent to Alexa until the end of speech is detected. Once the end of speech is detected, Alexa sends a StopCapture directive to the Engine and the dialog state is changed to \"thinking.\" Alexa then respond with additional directives in response to the speech request. The application should continue to send audio to the Engine until stopAudioInput() is received. When wake word is enabled, this happens when the Engine is stopped, or when wakeword detection is disabled explicitly by the application.","title":"Alexa Module Sequence Diagrams for Alexa Auto SDK"},{"location":"SEQUENCE_DIAGRAMS/#alexa-module-sequence-diagrams-for-alexa-auto-sdk","text":"The following sequence diagrams illustrate two of the basic flows used in the Alexa Auto SDK. Table of Contents Tap to Talk Sequence Diagram Wake Word Enabled Sequence Diagram","title":"Alexa Module Sequence Diagrams for Alexa Auto SDK"},{"location":"SEQUENCE_DIAGRAMS/#tap-to-talk-sequence-diagram","text":"This sequence diagram illustrates the initial sequence followed to access Alexa through the automotive tap to talk flow. The driver initiates the action by pushing the voice button located in the car. Once the driver pushes the voice button, Alexa is brought to a listening state ready for voice input, processing, and playback. This diagram includes the actual names and syntax for the methods and functions used in the Alexa Auto SDK. Note : Tap to Talk can be used with PCM and OPUS audio formats. Tip : Tap to Talk can be used to initiate speech recognition from external services such as external wake word engines, physical voice command buttons, and on screen buttons from the In-vehicle Voice Infotainment (IVI) system.","title":"Tap to Talk Sequence Diagram "},{"location":"SEQUENCE_DIAGRAMS/#tap-to-talk-flow-summary","text":"The driver pushes the voice button in the car. This specific human action puts Alexa into a listening state. There should be a visual indication to the driver that Alexa is now ready for audio input. The car's microphone is now actively receiving voice input and preparing an audio buffer to send to the Alexa Auto SDK Engine. The Alexa Auto SDK Engine audio input function loops until a directive is returned indicating that the audio input has finished. A visual indication should be displayed on the head unit screen indicating that Alexa is in a thinking state. In this state, Alexa is processing the input buffer and creating an appropriate response type. In this example Alexa is creating an audio out file that is sent to the cars head unit to play.","title":"Tap to Talk Flow Summary"},{"location":"SEQUENCE_DIAGRAMS/#wake-word-enabled-sequence-diagram","text":"This sequence diagram illustrates the initial sequence followed to access Alexa with the wake word enabled. The driver initiates the action by uttering the Alexa wake word. This diagram includes the actual names and syntax for the methods and functions used in the Alexa Auto SDK. Note : WWE can be used with PCM audio format only.","title":"Wake Word Enabled Sequence Diagram "},{"location":"SEQUENCE_DIAGRAMS/#wake-word-enabled-flow-summary","text":"startAudioInput() is called when wake word detection is enabled. This occurs when the Engine is started if wake word is enabled by default, or when enabledWakewordDetection() is explicitly called by the application. When this happens, the application must start sending audio samples from the microphone to the Engine. Audio is processed locally by the wake word engine until the wake word is detected. Once the wake word is detected, the Engine notifies the application that the dialog state has changed to \"listening\" and initiates a Recognize event with Alexa. While in the listening state, audio data is sent to Alexa until the end of speech is detected. Once the end of speech is detected, Alexa sends a StopCapture directive to the Engine and the dialog state is changed to \"thinking.\" Alexa then respond with additional directives in response to the speech request. The application should continue to send audio to the Engine until stopAudioInput() is received. When wake word is enabled, this happens when the Engine is stopped, or when wakeword detection is disabled explicitly by the application.","title":"Wake Word Enabled Flow Summary"},{"location":"aacs/android/","text":"Alexa Auto Client Service (AACS) Alexa Auto Client Service (AACS) is an Alexa Auto SDK feature packaged in an Android archive library (AAR). By providing a common service framework, AACS simplifies the integration of the Auto SDK with your Android device and supports all the Auto SDK extensions. Your application communicates with AACS through an intent, which is a messaging object on an Android device. AACS provides the platform implementation for certain interfaces, which speeds up Alexa integration for in-vehicle infotainment (IVI). Without AACS, typical integration of the Auto SDK in the IVI involves the implementation of abstract interfaces provided by each Auto SDK module to handle platform-specific functionality. To implement all required platform interfaces, the Auto SDK is integrated to an event-based system that converts from direct method APIs to an event-based architecture. This document assumes that you understand how the Auto SDK works, as described in the Auto SDK README . When this document uses the term \"application,\" it refers to the application you develop on the Android platform. Information for your application in this document also applies to your Android service. Table of Contents AACS Architecture Obtaining the AACS AAR Using AACS with Your Application AACS as Foreground Service or System Service AACS Initialization and Configuration Default Platform Implementation Property Content Provider Implementation (Optional) Enabling AACS to synchronize Alexa's Time Zone and Locale with Device Settings (Optional) Using Custom Domain Module with CustomDomainMessageDispatcher Enabled (Optional) Specifying the Intent Targets for Handling Messages Using Android Manifest Using AACS Configuration File Platform Implementation in Your Application Initial Authentication Sequence Diagram Wake Word Enabled Sequence Diagram Client Utility Library Device Settings Required for AACS Checking AACS Connection State Request list of extras from AACS Using Instrumentation Including App Components with AACS AAR in your application AACS Sample App AACS Architecture The following diagram shows the high-level architecture of AACS on the Android platform. The shaded boxes in the diagram represent components developed by Amazon that are packaged in AACS. The following list describes the components in the AACS service layer, as illustrated in the diagram, and how they interact with one another and with the Auto SDK: 1) AlexaAutoClientService is a persistent service that can start automatically after device boot-up or be manually started by an application through a startService() call. The service performs the following functions: Instantiating the Auto SDK Engine. Creating and registering the AASB message handler with the AASB MessageBroker. Setting the required Engine configuration. Managing the notifications displayed in the system notification area. 2) PhoneControlMessagingImpl and NavigationMessagingImpl are messaging implementations that serialize direct API calls into a standardized message format. The PhoneControlMessagingImpl or NavigationMessagingImpl converts platform interface method parameters into the message payload of the respective messaging implementation. The message is then sent to the service layer by using the AASB MessageBroker with a specific message topic and action. The messaging implementation also subscribes to message topics that are sent from the human-machine interface (HMI) application to the Auto SDK. 3) AudioInputImpl , AudioOutputImpl , ExternalMediaPlayerImpl , and AdditionalPlatformImpl are the direct implementations of Auto SDK platform interfaces. You can enable or disable the implementations in the AACS AAR through the configuration file. If an implementation is disabled, the platform message handler must be provided by a client application. 4) AASB MessageBroker is an abstraction built on top of the Auto SDK core. MessageBroker routes messages between the application and the Auto SDK core. When the application responds to MessageBroker with an event, the event is routed back through the platform interface implementation. 5) AASB MessageHandler implements the platform-specific logic to send and receive AASB messages. 6) Mediaplayer handles the default AudioOutput actions, such as prepare, play, and pause for a TTS channel. 7) IPCLibrary defines the protocol for the communication between the HMI application and AACS. It provides the APIs for sending and receiving AASB Messages over the Android Intent/Binder interface and supports streaming audio data to and from an external application. It builds into an Android archive (AAR) file, which you can include in other apps that need to communicate with AACS. For more information about the IPC, see this README . 1) LVCInteractionProvider implements APIs defined by the ILVCClient Android Interface Definition Language (AIDL) file to connect with ILVCService , which is implemented by the Local Voice Control (LVC) application. This connection also enables the LVC APK to provide the configuration for LVC. 2) The core of the HMI application that holds the business logic need not change with AlexaAutoClientService . However, you must modify the application so that it can interface with the APIs defined by AACS. Obtaining the AACS AAR AACS is packaged as an Android library (AAR). You can obtain the AACS AAR in one of two ways: To obtain the pre-built AACS AAR and the other dependency AARs which are required for using AACS, contact your Amazon Solutions Architect (SA) or Partner Manager for more information. To build the AACS AAR from source code, following the steps below. 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/service 2) Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds AACS core service, as well as all the other needed dependencies (such as Auto SDK) required for AACS to function. It also generates AAR files that are used for communicating with AACS from your application. To install all the generated AARs to your application, add the `installDeps` task after the build command. Specify the path you want the artifacts to be installed to by using the `-PinstallPath` option. If `-PinstallPath` is not specified, the artifacts will be copied to `alexa-auto-sdk/aacs/android/service/deploy` by default. ~~~ ./gradlew assembleLocalRelease installDeps -PinstallPath=<path/to/your/application/directory> ~~~ Using AACS with Your Application This section provides information about how AACS works with your application. To build your application with AACS, you can either include AACS and the other dependencies as local sub-projects, or you can build them as AARs and copy to the libs folder of your application. Using AACS as a local module Include AACS and the other dependency libraries as sub-projects in the settings.gradle file of your project. In the build.gradle file of your application, add the following implementation statements: implementation project(':aacs') implementation project(':aacs-extra') implementation project(':aacs-maccandroid') implementation project(':aacsconstants') implementation project(':aacsipc') implementation project(':aacscommonutils') implementation project(':alexa-auto-tts') // replace the <path/to/Auto/SDK/AARs> placeholder with your path implementation fileTree(include: ['*.aar'], dir: <path/to/Auto/SDK/AARs>) See the settings.gradle and the build.gradle of AACS Sample App for more information. 2) Using AACS as a local binary Include the AARs in the libs folder of your application. See Obtaining the AACS AAR for instructions of how to obtain the AACS AARs. Add the following implementation statement to the build.gradle file of your application: implementation fileTree(dir: 'libs', include: ['*.aar']) AACS as Foreground Service or System Service AACS runs as a started service on Android. The Initialization section describes how it is started; this section describes what you do to run AACS as a foreground service or a system service. As Foreground Service Typically, AACS is started as a foreground service, which has higher priority and continues running unless it is under memory constraints. In addition, the service displays notifications to alert the user that it is running. To run AACS as a foreground service, in the AACS configuration, set persistentSystemService under aacs.general to false . Then your application can use the startForegroundService() function to initialize AACS. If AACS is started properly, a notification is displayed. Since Android 8.0 (API level 26), foreground services have had some changes in how they are initialized. The following code checks the Android version and calls the correct API: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.O) { startForegroundService(intent); } else { startService(intent); } As Persistent System Service If you have root access on the device and your application containing AACS AAR is a system application, you can configure AACS to run as a system service. In the AACS configuration, set persistentSystemService under aacs.general to true . \"aacs.general\" : { \"persistentSystemService\": true, ... } This setting is equivalent to setting the 'persistent' flag to true within the application element of the Android Manifest file. This flag indicates that the service runs at all times, and should only be set to true by system applications. Your application no longer needs to start AACS in the foreground, and no notifications appear to show that the service is running. The following example shows an application starting AACS as a system service: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); startService(intent); AACS Initialization and Configuration Initializing AACS means getting AACS ready to communicate with other applications. However, Alexa functionality is not available until AACS receives the configuration. Initialization There are two ways to initialize AACS: Start AACS from an application: AACS includes a permission that determines whether an application can start or stop the service. For an application to start or stop AACS, specify the permission name in the application's AndroidManifest.xml file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice\"/> For an example of starting AACS from an application, see example for starting AACS as a system service . Start AACS upon device boot: If you want AACS to start every time the user turns on the device, set startOnDeviceBootEnabled in aacs.general of your configuration to true . Due to this setting, AACS initiates a startService() call on itself when it receives the BOOT_COMPLETED intent, which the device broadcasts when it is finished booting. Important! The device considers AACS inactive until AACS is run at least once. AACS does not start automatically on device boot unless AACS is considered active. Simply run AACS at least once after installation, and AACS will start each time the device is restarted. Whether startOnDeviceBootEnabled is set to true or false , the application can always send a startService() or stopService() call to start or stop AACS. Configuration Schema This section describes the configuration schema, which includes Auto SDK engine configuration, general service behavioral settings, and definitions for how AACS interfaces with applications. For more information about AACS configuration, see Configuration Reference documentation . Important! Some configuration fields may require you to provide filepaths. These filepaths must be absolute paths that are accessible to AACS. AACS will not accept filepaths to public locations (such as SD card) for security reasons. The sample configuration JSON file in this section illustrates the AACS configuration structure. Be sure to fill out the following required sections under deviceInfo of aacs.alexa : * clientId * productId * deviceSerialNumber The following documents provide more information about configuration: Auto SDK class list Complete configuration file { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"name\", \"description\": \"description\" }, \"localMediaSource\": { \"types\": [] }, \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 50000 } }, \"aacs.vehicle\": { \"info\": { \"make\": \"Amazon\", \"model\": \"AACE\", \"year\": \"2020\", \"trim\": \"aac\", \"geography\": \"US\", \"version\": \"1.2.3\", \"os\": \"Sample OS 1.0\", \"arch\": \"Sample Arch 1.0\", \"language\": \"en-US\", \"microphone\": \"SingleArray\", \"countries\": \"US,GB,IE,CA,DE,AT,IN,JP,AU,NZ,FR\", \"vehicleIdentifier\": \"Sample Identifier ABC\" }, \"operatingCountry\": \"US\" }, \"aacs.cbl\": { \"enableUserProfile\": false }, \"aacs.carControl\": { \"endpoints\":[], \"zones\":[] }, \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"intentTargets\" : { \"AASB\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, ... (Other topics omitted) } }, \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } } } Sending a Configuration Message Sending the configuration relies on the provided IPC library . This section describes the configuration's basic syntax. The message structure consists of two fields, configFilepaths and configStrings . configFilepaths is a String array containing paths to files which hold full or partial configuration JSON. configStrings is a String array containing full or partial configurations in the form of escaped JSON Strings. All partial configurations (from filepath or String) will be reconstructed by AACS to be a single, full configuration. We recommend using the configStrings option. See the Important note on filepaths in the beginning of the Configuration section. The following code shows an empty configMessage : { \"configFilepaths: [], \"configStrings\": [] } Using an instance of AACSSender , the sendConfigMessageEmbedded() or sendConfigMessageAnySize() method ensures that the configuration message can be sent to AACS. The following example shows how to construct and send the configuration message: try { String config = \"...\"; // configuration read from file JSONObject configJson = new JSONObject(config); JSONArray configStringsArray = new JSONArray(); configStringsArray.put(configJson.toString()); // add escaped JSON string JSONObject configMessage = new JSONObject(); configMessage.put(\"configFilepaths\", new JSONArray()); configMessage.put(\"configStrings\", configStringsArray); aacsSender.sendConfigMessageAnySize(configMessage.toString(), target, getApplicationContext()); } catch (JSONException e) { ... } File Sharing and Permissions Some configurable fields for the Auto SDK require paths to files in your application, which is inaccessible to AACS. To enable the Auto SDK to get the file paths, AACS provides a protocol for applications to grant the Auto SDK URI permissions for these files. AACS then creates a local copy of the file in its internal storage and configures the fields for the Auto SDK, using the file path to the local copy to ensure accessibility. Fields that require file sharing are described in documentation. Currently, only installed extensions have configurable fields that need file sharing. See the AACS README for your extension for more information about file sharing. AACS's file sharing protocol uses Android's FileProvider class to securely receive the URIs of files in applications. See the Android documentation on how to set up FileProvider in your application. Your FileProvider is functional after the application includes a <provider> element in its AndroidManifest and a filepaths.xml file for specifying shareable paths. After FileProvider is set up, AACS expects to receive an intent with action Intent.ACTION_SEND_MULTIPLE to include the URIs of files to be shared. Send the intent after service initialization but before the configuration message is sent. It requires the following structure: * Action: Intent.ACTION_SEND_MULTIPLE - The standard Android intent for sharing multiple pieces of content * Type: The MIME type of a URI * Extra: AACSConstants.CONFIG_MODULE or configModule - A String representing the module to be configured by the shared files * ParcelableArrayListExtra: Intent.EXTRA_STREAM - An ArrayList<Uri> containing URIs of files to be shared Before sending the intent, be sure to grant the Intent.FLAG_GRANT_READ_URI_PERMISSION to AACS for each URI being sent. Also, because the intent holds multiple file URIs for a single configuration module at a time, if there are multiple files for separate modules, send multiple intents, as shown in the following example implementation: private void shareFilePermissionsOfSameModule(File parent, String[] filenames, String module) { ArrayList<Uri> fileUris = new ArrayList<>(); for (String name : filenames) { File file = new File(parent, name); Uri fileUri = FileProvider.getUriForFile( MainActivity.this, <your-application's-provider>, file); grantUriPermission(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), fileUri, Intent.FLAG_GRANT_READ_URI_PERMISSION); fileUris.add(fileUri); } Intent shareFileIntent = new Intent(); shareFileIntent.setComponent( new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), AACSConstants.AACS_CLASS_NAME)); shareFileIntent.setAction(Intent.ACTION_SEND_MULTIPLE); shareFileIntent.setType(getContentResolver().getType(fileUris.get(0))); shareFileIntent.putExtra(AACSConstants.CONFIG_MODULE, module); shareFileIntent.putParcelableArrayListExtra(Intent.EXTRA_STREAM, fileUris); startForegroundService(shareFileIntent); } Note: AACSConstants.AACS_PACKAGE_NAME is deprecated and it shall be removed from the future Alexa Auto SDK versions. Use AACSConstants.getAACSPackageName(Context) instead. Initialization Protocol After starting the service, send file sharing intents for any files outside of AACS's access that will be needed for configuration. Then, send the configuration message. If there are no files to be shared, the configuration can be sent immediately after AACS is initialized. The configuration is not part of the initial intent to start the service because intents in Android have size limits, which the configuration might exceed. Using the provided IPC library allows for sending configuration of any size. Because AACS stores the last configuration received, the only requirement is that the configuration is sent the first time AACS is run after installation. At any subsequent start, AACS uses the stored configuration. Similarly for shared files, AACS retains local copies of the files, so file sharing intents do not have to be re-sent in subsequent launches. However, updating the stored configuration (without uninstalling the application containing AACS AAR) requires that the startService intent include an Extras field called newConfig . newConfig holds a boolean value that alerts AACS not to start running with the stored configuration, but wait for a new configuration message. In addition, whenever the newConfig field is set to true , AACS clears all local copies of shared files and expect new file sharing intents, if necessary for the new configuration. Note : The old configuration is overwritten by the new configuration. For your application to start AACS with a new configuration, make sure your intent includes newConfig , as shown in the following example: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); intentStartService.putExtra(\"newConfig\", true); Omitting newConfig is the same as setting it to false , which causes AACS to use the stored configuration. Important : Sending a new configuration is allowed only once per service run. After AACS is configured and running, AACS ignores subsequent attempts to update the configuration, even if the newConfig field is true . To update an existing configuration, you must stop the service and restart it with newConfig set to true . This same rule applies to file sharing intents. Initialization Sequence Diagram The following diagram shows an example of initializing AACS from an app used by a driver. Default Platform Implementation Default platform implementations refer to implementations of Auto SDK platform interfaces that AACS provides to replace the normal protocol of using AASB messages. By enabling a default platform implementation in AACS, you no longer have to handle messages for a particular platform interface and can rely on AACS to provide the necessary functionality. AACS provides a default implementation for these platform interfaces: * AudioInput (audioType: VOICE, COMMS) * AudioOutput (audioType: TTS, ALARM, NOTIFICATIONS, EARCON, RINGTONE) * LocationProvider * NetworkInfoProvider * ExternalMediaAdapter for Media App Command and Control (MACC) * LocalMediaSource * PropertyManager The platform implementations for these interfaces are disabled by default; the AASB messages for these interfaces are routed to the client app to be handled . To enable the default platform implementation in AACS, you must set the aacs.defaultPlatformHandlers configuration flags. In the following example, you use aacs.defaultPlatformHandlers in the configuration file to instruct AACS to handle LocationProvider and NetworkInfoProvider , AudioInput for VOICE , and AudioOutput for TTS . Specific apps handle the other messages. \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, ... other audio types } } } Property Content Provider Implementation (Optional) AACS supports the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. Using a content provider offers the following advantages: AACS can consistently provide the properties across multiple launches. Because properties are persistent, your application does not need to reset the properties after each AACS restart. AACS messages are asynchronous, which might cause timeouts and subsequently incorrect or error states. Using a content provider to retrieve state data makes the retrieval process synchronous, thus guaranteeing that the request for state information reaches its destination and a response is received. ContentProvider is the standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. Sequence Diagram and Overview The following sequence diagram illustrates the workflow for the default property manager implementation in AACS. This implementation provides the interface, based on the Android ContentProvider , for OEM apps to get and set Auto SDK properties. aace.alexa.wakewordSupported aace.alexa.system.firmwareVersion aace.alexa.setting.locale aace.alexa.countrySupported aace.alexa.timezone aace.alexa.wakewordEnabled aace.vehicle.operatingCountry aace.core.version aace.network.networkInterface By using the native Android ContentProvider class, you can initiate query and update operations. query retrieves and returns the current String value of an Auto SDK property. update sets an Auto SDK property in the Engine and returns a boolean value based on the success of the operation. Insert and Delete operations are disabled for Auto SDK properties. Implementation Examples Add useDefaultPropertyManager in the config.json file and set it to true , as shown in the following example: ... \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, --> \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { ... Add READ_USER_DICTIONARY permission to AndroidManifest.xml in your application, as shown in the following example: <uses-permission... <uses-permission android:name=\"android.permission.READ_USER_DICTIONARY\" /> <uses-permission... In the application implementation, set the URI for getting the ContentResolver instance as follows: private final Uri uri = Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI); Register ContentObserver for monitoring any Auto SDK property changes that are initiated by the engine. ContentObserver is a native Android class which observes changes to data and will call its onChange() method to perform callbacks when a content change occurs. It includes the changed content Uri when available. To register ContentObserver , first register your application with ContentObserver // PropertyHandler is an example class using ContentProvider API to query and update properties in your application PropertyHandler alexaPropertyHandler = new PropertyHandler(this); // PropertyContentObserver is an example implementation of the callback for property changes PropertyContentObserver propertyObserver = new PropertyContentObserver(alexaPropertyHandler, this); getContentResolver().registerContentObserver(Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI), true, propertyObserver); Then implement the PropertyContentObserver class and add the desired callback behavior in method onChange() : public class PropertyContentObserver extends ContentObserver { private static Activity mActivity; public PropertyContentObserver(Handler handler, Activity activity) { super(handler); mActivity = activity; } @Override public void onChange(boolean changed) { this.onChange(changed, null); } @Override public void onChange(boolean changed, Uri uri) { // Do something when content change occurs } } Perform query() and update() operation within application using the previously set URI: query() Cursor cursor = getContentResolver().query(uri, null, propertyName, null, null); cursor.moveToFirst(); String propertyValue = cursor.getString(1); update() must be called in its own thread, not the main UI thread since update() calls setProperty and receive the result asynchronously. ExecutorService mExecutor; ContentValues cv = new ContentValues(); cv.put(propertyName, propertyValue); if (mExecutor == null ) { mExecutor = Executors.newSingleThreadExecutor(); } else { synchronized (OEMApplication.class) { if (mExecutor.isShutdown()) { // Log warning that Executor has already been shut down for update. Not updating property. } mExecutor.submit(() -> { getContentResolver().update(uri, cv, propertyName, null); }); } } Important Considerations for Using ContentProvider AACS Property Content Provider does not support the insert and delete APIs in Property ContentProvider; You must use AACS with the AmazonLite Wake Word extension if you want to update aace.alexa.wakewordEnabled property; aace.alexa.countrySupported is a deprecated property and cannot be get/set; aace.alexa.wakewordSupported and aace.core.version are read-only properties acquired when building Auto SDK and cannot be set. Valid property value for aace.alexa.wakewordEnabled is true or false . All the other Auto SDK properties will be validated by Auto SDK. Auto SDK will provide value validation for aace.alexa.wakewordEnabled in the future. Enabling AACS to synchronize Alexa's Time Zone and Locale with Device Settings (Optional) AACS supports synchronizing Alexa's time zone and locale properties with the ones in device settings. To enable the functionality, refer to this README for proper configuration. Once enabled, AACS will synchronize the time zone and/or locale properties of Alexa with the device settings in the following conditions: * When Auto SDK engine is initialized, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. * When the authorization state is refreshed, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. * When AACS gets android.intent.action.LOCALE_CHANGED intent as a result of device locale setting change, Alexa locale property will be updated if the locale is supported by Alexa. * When AACS gets android.intent.action.TIMEZONE_CHANGED intent as a result of device time zone setting change, Alexa time zone property will be updated. You can also disable the automatic synchronization for specific properties. This is particularly useful when your application wants to disable/enable the synchronization at runtime. For example, after the user manually selects a locale, you may want to disable the synchronization to allow the user's selection to override the system setting changes. To achieve this use case, your application can send intents with the metadata below to AACS: * Action: * Disable: com.amazon.aacs.syncSystemPropertyChange.disable * Enable: com.amazon.aacs.syncSystemPropertyChange.enable * Category: com.amazon.aacs.syncSystemPropertyChange * Extra: \"property\": <alexa_property_name> If this feature is not enabled, your application can still have the full flexibility in changing the two properties by handling AASB Property Manager messages. Additionally, you can configure AACS to update the system time zone if the user changes the Alexa's time zone for the device (e.g. the user can change the property on their Alexa mobile app). To enable the functionality, refer to this README for proper configuration. Your application with AACS needs to be a system application with android permission android.permission.SET_TIME_ZONE obtained. Note: Always provide the system permission android.permission.SET_TIME_ZONE when AACS AAR is in a system application. Refer to Privileged Permission Allowlisting in Android documentation. Using Custom Domain Module with CustomDomainMessageDispatcher Enabled (Optional) To use Custom Domain module with AACS, you need to explicitly enable it first by adding module enablement configuration. Please refer to AACS Configuration README to enable the Custom Domain module. By default, all the Custom Domain intents share the same com.amazon.aacs.aasb.customDomain intent category. If CustomDomainMessageDispatcher is enabled, the intent category will be the namespace of the custom interface prefixed with com.amazon.aacs.customDomain , which allows AACS to dispatch the Custom Domain AASB messages from the engine to the proper components in your system based on the custom namespace. Below is the intent schema of the intents sent from the dispatcher. All the intents are sent with our IPC library . You can use AACSReceiver to receive and process the AASB Custom Domain messages in the intents. Intent for handling/canceling a custom directive: Action: com.amazon.aacs.customDomain.<custom-directive-name> . Category: com.amazon.aacs.customDomain.<custom-directive-namespace> . Intent for getting the context for a custom namespace: Action: com.amazon.aacs.customDomain.GetContext Category: com.amazon.aacs.customDomain.<custom-context-namespace> . You can define intent filters in the Android Manifest of your applications to subscribe to the specific Custom Domain intents. See Specifying the Intent Targets for Handling Messages Using Android Manifest to learn more about specifying intent targets. Please refer to this README on enabling CustomDomainMessageDispatcher. Note : CustomDomainMessageDispatcher does not process any custom directives. Your application is responsible for handling any custom directives, sending custom events, and providing custom contexts following the Custom Domain AASB Documentation . If the dispatcher is not enabled, your application will be responsible for receiving all the Custom Domain AASB Messages (as intents) at one place. Specifying the Intent Targets for Handling Messages The AASB message intent targets can be ACTIVITY , RECEIVER , or SERVICE . There are two ways to specify the intent targets for AASB message intents from AACS. Using Android Manifest You can define intent filters in your application's Android Manifest. The intent filter must exactly match the intents' categories and actions. In the intent filter for an intent that wraps an AASB message, specify the category as com.amazon.aacs.aasb.<AASB_Message_Topic> and action as com.amazon.aacs.aasb.<AASB_Message_Action> . The following example shows an intent filter of all the CBL message intents for a broadcast receiver target: <intent-filter> <action android:name=\"com.amazon.aacs.aasb.CBLStateChanged\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairReceived\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairExpired\"/> <action android:name=\"com.amazon.aacs.aasb.SetProfileName\"/> <action android:name=\"com.amazon.aacs.aasb.GetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.SetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.ClearRefreshToken\"/> <category android:name=\"com.amazon.aacs.aasb.CBL\" /> </intent-filter> To receive the message specified through the Android Manifest, the application must also have com.amazon.alexaautoclientservice permission in its Android Manifest. <uses-permission android:name=\"com.amazon.alexaautoclientservice\" /> Follow these important guidelines if the intent target is an activity: You must add <category android:name=\"android.intent.category.DEFAULT\" /> to the intent filter as explained here . Be aware that if you start applications with AACS (for example, by specifying Activity as the intent targets from AACS), the target Activity will move to the foreground or become in focus, causing distraction or confusion to the user. AACS does not request SYSTEM_ALERT_WINDOW permission to directly create windows on top of all other apps. Amazon recommends using VIS (VoiceInteractionService) to launch activities, and using Android Services or Broadcast Receivers to receive intents from AACS. Using AACS Configuration File You can use the AACS configuration file to specify the app that can handle AASB messages with a specific \"topic\". This method of specifying intent targets has the highest priority, meaning it can override the ones specified through intent filters in manifests. After you use the AACS configuration to specify the app, intents with all the actions belonging to the topic go to the specified targets. Fill the optional fields in intentTargets in the AACS configuration file as needed. See the Configuration Reference documentation for information about intentTargets . The following sample configuration shows how to populate intentTargets for each topic. The field type accepts RECEIVER , ACTIVITY , and SERVICE , depending on the type of the target that handles the intents with the topic. The targets can be broadcast receiver, application activity, and service. The format for specifying AASB message intent targets for an AASB message topic is as follows: \"<topic>\" : { \"type\": [<target_1_type>, <target_2_type>, ...], \"package\": [\"<target_1_package_name>\", \"<target_2_package_name>\", ...], \"class\": [\"<target_1_class_name>\", \"<target_2_class_name>\", ...] }, The following example shows two topics, which are AASB and APL : \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\": [\"ACTIVITY\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\"com.amazon.aacstestapp.MainActivity\"] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\".IntentReceiver\"] // short version of class name is also accepted. }, // In this case, the class must be in the package specified in \"package\". // ... other topics } } NOTE : If a given \"topic\" is specified both in the configuration file and the Android Manifest, the configuration file takes priority and the targets with intent filters are ignored. Amazon recommends intent filters when possible. Use the configuration approach only if you need to override the existing intent filters. AACS first searches for targets for an intent with a topic in the configuration file. If nothing is found, the package manager scans the intent filters on the device to locate a match. AACS also caches the scan results based on both topic and action. The cache is cleared every time AACS is restarted. Platform Implementation in Your Application Your applications can register for specific AASB messages and provide a platform implementation. For example, an application (\u201cLogin app\") can register for Authorization messages. For information about the Authorization module, see the Core Module README . Initial Authentication Sequence Diagram The following sequence diagram illustrates how an application (\u201cLogin app\") exchanges messages with AACS over Android Intents to log in the user for Alexa. Wake Word Enabled Sequence Diagram The sequence diagram illustrates the sequence for the user to access Alexa if you use the default implementation of AudioInput in AACS. In this diagram, the driver is logged in and wake word is enabled. The driver initiates the action by uttering the Alexa wake word. Audio is processed locally by the wake word engine in AACS until the wake word is detected. Upon wake word detection, AACS notifies the application that the dialog state has changed to \"listening\" and initiates a Recognize event with Alexa. While in the listening state, audio data is sent to Alexa. When the end of speech is detected, Alexa sends a StopCapture directive to AACS, and the dialog state is changed to \"thinking.\" Alexa then responds with additional directives in response to the speech request. For information about other messages to provide your implementation in the client APK, please refer to the README for each Auto SDK module. Client Utility Library AACS also provides an optional library, AACS Common Utils . It contains useful methods to make messaging with AACS easier. You can use it as-is or as a reference to facilitate the integration of the Auto SDK with AACS. For information about the library, see AACS Common Utils README and in-code documentation in the library. Device Settings Required for AACS AACS requires microphone and location permissions when the default implementation is used for AudioInput and Location. If AACS runs in a system application, you can grant these permissions so that the application users do not have to set the permissions. Otherwise, be sure to instruct your users to grant the following permissions on the app info page under Settings on their device: Location: Enable android.permission.ACCESS_FINE_LOCATION to give AACS access the current location. Microphone: Enable android.permission.RECORD_AUDIO to give permission to AACS to record audio. Microphone must be enabled if you configure AudioInput to use the default implementation of AACS. Checking AACS Connection State Your application or service can check the status of AACS by using ping , which returns a response as long as AACS is running. The AACSPinger utility class from the IPC library enables you to use ping . To ping AACS, specify the ping permission name in your application's Android Manifest file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice.ping\"/> The following example shows how to use AACSPinger : AACSPinger aacsPinger = new AACSPinger(getApplicationContext(), \"com.amazon.alexaautoclientservice.ping\"); Future<AACSPinger.AACSPingResponse> fut = aacsPinger.pingAACS(); AACSPinger.AACSPingResponse response = fut.get(); if (response.hasResponse) { // Ping was responded to by AACS String state = response.AACSState; ... } else { // Ping timed out without an AACS response } If AACS responds to the ping request, the AACSPingResponse.AACSState string returned by AACSPinger.pingAACS() has one of the following values: STARTED WAIT_FOR_LVC_CONFIG CONFIGURED ENGINE_INITIALIZED CONNECTED STOPPED If AACS does not respond within the default timeout of 1 second, AACSPingResponse.hasResponse is false . Request list of extras from AACS Your application can receive the list of AACS extra modules by sending an intent with the action AACSConstants.IntentAction.GET_SERVICE_METADATA and the category AACSConstants.IntentCategory.GET_SERVICE_METADATA , which returns a response by receiving an intent AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . To get the extras list from AACS- Specify the permission name in your application's Android Manifest file as follows: <uses-permission android:name= \"com.amazon.alexaautoclientservice.getservicemetadata\" /> Register a receiver in you application's Android Manifest file as follows: Following block shows an example of requesting list of extras: <receiver android:name= \".<Receiver Class>\" android:enabled= \"true\" android:exported= \"true\" /> Send a request intent to AACS. Following code snippet shows an example Intent intent = new Intent (); intent . setAction ( AACSConstants . IntentAction . GET_SERVICE_METADATA ); intent . addCategory ( AACSConstants . IntentCategory . GET_SERVICE_METADATA ); intent . putExtra ( AACSConstants . REPLY_TO_PACKAGE , getPackageName ()); intent . putExtra ( AACSConstants . REPLY_TO_CLASS , < Receiver_Class_Name > . class . getName ()); intent . putExtra ( AACSConstants . REPLY_TYPE , \"RECEIVER\" ); sendBroadcast ( intent ); Your receiver class will receive an intent with the following payload { \"metaData\" : { \"extrasModuleList\" : [] } } You can get the payload from the received intent with action AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . Following code snippet shows the example: String payload = intent . getStringExtra ( AACSConstants . PAYLOAD ); Using Instrumentation You can use AACS instrumentation to log AASB messages for debugging purposes. For more information about how to use instrumentation, see the AACS Instrumentation README . Note: You can use instrumentation only if you use the debug option when building the Auto SDK with AACS. Including App Components with AACS AAR in your application The Auto SDK provides packages (also called \"app components\") in the $AAC_SDK_HOME/aacs/android/app-components directory. App components could be included in your application along with AACS AAR to speed up the Alexa integration. Note: Some app components implement the handling of AASB messages for certain topics, allowing your applications to interface with AACS by using standard Android APIs. If you include such app components in your application with AACS AAR, your application does not need to handle the AASB messages for those particular AASB topics. AACS Sample App The Auto SDK includes an Android-based application that demonstrates how an application uses AACS. For more information about the AACS Sample App, see the AACS Sample App README .","title":"Alexa Auto Client Service (AACS)"},{"location":"aacs/android/#alexa-auto-client-service-aacs","text":"Alexa Auto Client Service (AACS) is an Alexa Auto SDK feature packaged in an Android archive library (AAR). By providing a common service framework, AACS simplifies the integration of the Auto SDK with your Android device and supports all the Auto SDK extensions. Your application communicates with AACS through an intent, which is a messaging object on an Android device. AACS provides the platform implementation for certain interfaces, which speeds up Alexa integration for in-vehicle infotainment (IVI). Without AACS, typical integration of the Auto SDK in the IVI involves the implementation of abstract interfaces provided by each Auto SDK module to handle platform-specific functionality. To implement all required platform interfaces, the Auto SDK is integrated to an event-based system that converts from direct method APIs to an event-based architecture. This document assumes that you understand how the Auto SDK works, as described in the Auto SDK README . When this document uses the term \"application,\" it refers to the application you develop on the Android platform. Information for your application in this document also applies to your Android service.","title":"Alexa Auto Client Service (AACS)"},{"location":"aacs/android/#table-of-contents","text":"AACS Architecture Obtaining the AACS AAR Using AACS with Your Application AACS as Foreground Service or System Service AACS Initialization and Configuration Default Platform Implementation Property Content Provider Implementation (Optional) Enabling AACS to synchronize Alexa's Time Zone and Locale with Device Settings (Optional) Using Custom Domain Module with CustomDomainMessageDispatcher Enabled (Optional) Specifying the Intent Targets for Handling Messages Using Android Manifest Using AACS Configuration File Platform Implementation in Your Application Initial Authentication Sequence Diagram Wake Word Enabled Sequence Diagram Client Utility Library Device Settings Required for AACS Checking AACS Connection State Request list of extras from AACS Using Instrumentation Including App Components with AACS AAR in your application AACS Sample App","title":"Table of Contents"},{"location":"aacs/android/#aacs-architecture","text":"The following diagram shows the high-level architecture of AACS on the Android platform. The shaded boxes in the diagram represent components developed by Amazon that are packaged in AACS. The following list describes the components in the AACS service layer, as illustrated in the diagram, and how they interact with one another and with the Auto SDK: 1) AlexaAutoClientService is a persistent service that can start automatically after device boot-up or be manually started by an application through a startService() call. The service performs the following functions: Instantiating the Auto SDK Engine. Creating and registering the AASB message handler with the AASB MessageBroker. Setting the required Engine configuration. Managing the notifications displayed in the system notification area. 2) PhoneControlMessagingImpl and NavigationMessagingImpl are messaging implementations that serialize direct API calls into a standardized message format. The PhoneControlMessagingImpl or NavigationMessagingImpl converts platform interface method parameters into the message payload of the respective messaging implementation. The message is then sent to the service layer by using the AASB MessageBroker with a specific message topic and action. The messaging implementation also subscribes to message topics that are sent from the human-machine interface (HMI) application to the Auto SDK. 3) AudioInputImpl , AudioOutputImpl , ExternalMediaPlayerImpl , and AdditionalPlatformImpl are the direct implementations of Auto SDK platform interfaces. You can enable or disable the implementations in the AACS AAR through the configuration file. If an implementation is disabled, the platform message handler must be provided by a client application. 4) AASB MessageBroker is an abstraction built on top of the Auto SDK core. MessageBroker routes messages between the application and the Auto SDK core. When the application responds to MessageBroker with an event, the event is routed back through the platform interface implementation. 5) AASB MessageHandler implements the platform-specific logic to send and receive AASB messages. 6) Mediaplayer handles the default AudioOutput actions, such as prepare, play, and pause for a TTS channel. 7) IPCLibrary defines the protocol for the communication between the HMI application and AACS. It provides the APIs for sending and receiving AASB Messages over the Android Intent/Binder interface and supports streaming audio data to and from an external application. It builds into an Android archive (AAR) file, which you can include in other apps that need to communicate with AACS. For more information about the IPC, see this README . 1) LVCInteractionProvider implements APIs defined by the ILVCClient Android Interface Definition Language (AIDL) file to connect with ILVCService , which is implemented by the Local Voice Control (LVC) application. This connection also enables the LVC APK to provide the configuration for LVC. 2) The core of the HMI application that holds the business logic need not change with AlexaAutoClientService . However, you must modify the application so that it can interface with the APIs defined by AACS.","title":"AACS Architecture"},{"location":"aacs/android/#obtaining-the-aacs-aar","text":"AACS is packaged as an Android library (AAR). You can obtain the AACS AAR in one of two ways: To obtain the pre-built AACS AAR and the other dependency AARs which are required for using AACS, contact your Amazon Solutions Architect (SA) or Partner Manager for more information. To build the AACS AAR from source code, following the steps below. 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/service 2) Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds AACS core service, as well as all the other needed dependencies (such as Auto SDK) required for AACS to function. It also generates AAR files that are used for communicating with AACS from your application. To install all the generated AARs to your application, add the `installDeps` task after the build command. Specify the path you want the artifacts to be installed to by using the `-PinstallPath` option. If `-PinstallPath` is not specified, the artifacts will be copied to `alexa-auto-sdk/aacs/android/service/deploy` by default. ~~~ ./gradlew assembleLocalRelease installDeps -PinstallPath=<path/to/your/application/directory> ~~~","title":"Obtaining the AACS AAR"},{"location":"aacs/android/#using-aacs-with-your-application","text":"This section provides information about how AACS works with your application. To build your application with AACS, you can either include AACS and the other dependencies as local sub-projects, or you can build them as AARs and copy to the libs folder of your application. Using AACS as a local module Include AACS and the other dependency libraries as sub-projects in the settings.gradle file of your project. In the build.gradle file of your application, add the following implementation statements: implementation project(':aacs') implementation project(':aacs-extra') implementation project(':aacs-maccandroid') implementation project(':aacsconstants') implementation project(':aacsipc') implementation project(':aacscommonutils') implementation project(':alexa-auto-tts') // replace the <path/to/Auto/SDK/AARs> placeholder with your path implementation fileTree(include: ['*.aar'], dir: <path/to/Auto/SDK/AARs>) See the settings.gradle and the build.gradle of AACS Sample App for more information. 2) Using AACS as a local binary Include the AARs in the libs folder of your application. See Obtaining the AACS AAR for instructions of how to obtain the AACS AARs. Add the following implementation statement to the build.gradle file of your application: implementation fileTree(dir: 'libs', include: ['*.aar'])","title":"Using AACS with Your Application"},{"location":"aacs/android/#aacs-as-foreground-service-or-system-service","text":"AACS runs as a started service on Android. The Initialization section describes how it is started; this section describes what you do to run AACS as a foreground service or a system service.","title":"AACS as Foreground Service or System Service"},{"location":"aacs/android/#as-foreground-service","text":"Typically, AACS is started as a foreground service, which has higher priority and continues running unless it is under memory constraints. In addition, the service displays notifications to alert the user that it is running. To run AACS as a foreground service, in the AACS configuration, set persistentSystemService under aacs.general to false . Then your application can use the startForegroundService() function to initialize AACS. If AACS is started properly, a notification is displayed. Since Android 8.0 (API level 26), foreground services have had some changes in how they are initialized. The following code checks the Android version and calls the correct API: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.O) { startForegroundService(intent); } else { startService(intent); }","title":"As Foreground Service"},{"location":"aacs/android/#as-persistent-system-service","text":"If you have root access on the device and your application containing AACS AAR is a system application, you can configure AACS to run as a system service. In the AACS configuration, set persistentSystemService under aacs.general to true . \"aacs.general\" : { \"persistentSystemService\": true, ... } This setting is equivalent to setting the 'persistent' flag to true within the application element of the Android Manifest file. This flag indicates that the service runs at all times, and should only be set to true by system applications. Your application no longer needs to start AACS in the foreground, and no notifications appear to show that the service is running. The following example shows an application starting AACS as a system service: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); startService(intent);","title":"As Persistent System Service"},{"location":"aacs/android/#aacs-initialization-and-configuration","text":"Initializing AACS means getting AACS ready to communicate with other applications. However, Alexa functionality is not available until AACS receives the configuration.","title":"AACS Initialization and Configuration"},{"location":"aacs/android/#initialization","text":"There are two ways to initialize AACS: Start AACS from an application: AACS includes a permission that determines whether an application can start or stop the service. For an application to start or stop AACS, specify the permission name in the application's AndroidManifest.xml file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice\"/> For an example of starting AACS from an application, see example for starting AACS as a system service . Start AACS upon device boot: If you want AACS to start every time the user turns on the device, set startOnDeviceBootEnabled in aacs.general of your configuration to true . Due to this setting, AACS initiates a startService() call on itself when it receives the BOOT_COMPLETED intent, which the device broadcasts when it is finished booting. Important! The device considers AACS inactive until AACS is run at least once. AACS does not start automatically on device boot unless AACS is considered active. Simply run AACS at least once after installation, and AACS will start each time the device is restarted. Whether startOnDeviceBootEnabled is set to true or false , the application can always send a startService() or stopService() call to start or stop AACS.","title":"Initialization"},{"location":"aacs/android/#configuration-schema","text":"This section describes the configuration schema, which includes Auto SDK engine configuration, general service behavioral settings, and definitions for how AACS interfaces with applications. For more information about AACS configuration, see Configuration Reference documentation . Important! Some configuration fields may require you to provide filepaths. These filepaths must be absolute paths that are accessible to AACS. AACS will not accept filepaths to public locations (such as SD card) for security reasons. The sample configuration JSON file in this section illustrates the AACS configuration structure. Be sure to fill out the following required sections under deviceInfo of aacs.alexa : * clientId * productId * deviceSerialNumber The following documents provide more information about configuration: Auto SDK class list Complete configuration file { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"name\", \"description\": \"description\" }, \"localMediaSource\": { \"types\": [] }, \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 50000 } }, \"aacs.vehicle\": { \"info\": { \"make\": \"Amazon\", \"model\": \"AACE\", \"year\": \"2020\", \"trim\": \"aac\", \"geography\": \"US\", \"version\": \"1.2.3\", \"os\": \"Sample OS 1.0\", \"arch\": \"Sample Arch 1.0\", \"language\": \"en-US\", \"microphone\": \"SingleArray\", \"countries\": \"US,GB,IE,CA,DE,AT,IN,JP,AU,NZ,FR\", \"vehicleIdentifier\": \"Sample Identifier ABC\" }, \"operatingCountry\": \"US\" }, \"aacs.cbl\": { \"enableUserProfile\": false }, \"aacs.carControl\": { \"endpoints\":[], \"zones\":[] }, \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"intentTargets\" : { \"AASB\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [], \"class\": [] }, ... (Other topics omitted) } }, \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } } }","title":"Configuration Schema"},{"location":"aacs/android/#sending-a-configuration-message","text":"Sending the configuration relies on the provided IPC library . This section describes the configuration's basic syntax. The message structure consists of two fields, configFilepaths and configStrings . configFilepaths is a String array containing paths to files which hold full or partial configuration JSON. configStrings is a String array containing full or partial configurations in the form of escaped JSON Strings. All partial configurations (from filepath or String) will be reconstructed by AACS to be a single, full configuration. We recommend using the configStrings option. See the Important note on filepaths in the beginning of the Configuration section. The following code shows an empty configMessage : { \"configFilepaths: [], \"configStrings\": [] } Using an instance of AACSSender , the sendConfigMessageEmbedded() or sendConfigMessageAnySize() method ensures that the configuration message can be sent to AACS. The following example shows how to construct and send the configuration message: try { String config = \"...\"; // configuration read from file JSONObject configJson = new JSONObject(config); JSONArray configStringsArray = new JSONArray(); configStringsArray.put(configJson.toString()); // add escaped JSON string JSONObject configMessage = new JSONObject(); configMessage.put(\"configFilepaths\", new JSONArray()); configMessage.put(\"configStrings\", configStringsArray); aacsSender.sendConfigMessageAnySize(configMessage.toString(), target, getApplicationContext()); } catch (JSONException e) { ... }","title":"Sending a Configuration Message"},{"location":"aacs/android/#file-sharing-and-permissions","text":"Some configurable fields for the Auto SDK require paths to files in your application, which is inaccessible to AACS. To enable the Auto SDK to get the file paths, AACS provides a protocol for applications to grant the Auto SDK URI permissions for these files. AACS then creates a local copy of the file in its internal storage and configures the fields for the Auto SDK, using the file path to the local copy to ensure accessibility. Fields that require file sharing are described in documentation. Currently, only installed extensions have configurable fields that need file sharing. See the AACS README for your extension for more information about file sharing. AACS's file sharing protocol uses Android's FileProvider class to securely receive the URIs of files in applications. See the Android documentation on how to set up FileProvider in your application. Your FileProvider is functional after the application includes a <provider> element in its AndroidManifest and a filepaths.xml file for specifying shareable paths. After FileProvider is set up, AACS expects to receive an intent with action Intent.ACTION_SEND_MULTIPLE to include the URIs of files to be shared. Send the intent after service initialization but before the configuration message is sent. It requires the following structure: * Action: Intent.ACTION_SEND_MULTIPLE - The standard Android intent for sharing multiple pieces of content * Type: The MIME type of a URI * Extra: AACSConstants.CONFIG_MODULE or configModule - A String representing the module to be configured by the shared files * ParcelableArrayListExtra: Intent.EXTRA_STREAM - An ArrayList<Uri> containing URIs of files to be shared Before sending the intent, be sure to grant the Intent.FLAG_GRANT_READ_URI_PERMISSION to AACS for each URI being sent. Also, because the intent holds multiple file URIs for a single configuration module at a time, if there are multiple files for separate modules, send multiple intents, as shown in the following example implementation: private void shareFilePermissionsOfSameModule(File parent, String[] filenames, String module) { ArrayList<Uri> fileUris = new ArrayList<>(); for (String name : filenames) { File file = new File(parent, name); Uri fileUri = FileProvider.getUriForFile( MainActivity.this, <your-application's-provider>, file); grantUriPermission(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), fileUri, Intent.FLAG_GRANT_READ_URI_PERMISSION); fileUris.add(fileUri); } Intent shareFileIntent = new Intent(); shareFileIntent.setComponent( new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), AACSConstants.AACS_CLASS_NAME)); shareFileIntent.setAction(Intent.ACTION_SEND_MULTIPLE); shareFileIntent.setType(getContentResolver().getType(fileUris.get(0))); shareFileIntent.putExtra(AACSConstants.CONFIG_MODULE, module); shareFileIntent.putParcelableArrayListExtra(Intent.EXTRA_STREAM, fileUris); startForegroundService(shareFileIntent); } Note: AACSConstants.AACS_PACKAGE_NAME is deprecated and it shall be removed from the future Alexa Auto SDK versions. Use AACSConstants.getAACSPackageName(Context) instead.","title":"File Sharing and Permissions"},{"location":"aacs/android/#initialization-protocol","text":"After starting the service, send file sharing intents for any files outside of AACS's access that will be needed for configuration. Then, send the configuration message. If there are no files to be shared, the configuration can be sent immediately after AACS is initialized. The configuration is not part of the initial intent to start the service because intents in Android have size limits, which the configuration might exceed. Using the provided IPC library allows for sending configuration of any size. Because AACS stores the last configuration received, the only requirement is that the configuration is sent the first time AACS is run after installation. At any subsequent start, AACS uses the stored configuration. Similarly for shared files, AACS retains local copies of the files, so file sharing intents do not have to be re-sent in subsequent launches. However, updating the stored configuration (without uninstalling the application containing AACS AAR) requires that the startService intent include an Extras field called newConfig . newConfig holds a boolean value that alerts AACS not to start running with the stored configuration, but wait for a new configuration message. In addition, whenever the newConfig field is set to true , AACS clears all local copies of shared files and expect new file sharing intents, if necessary for the new configuration. Note : The old configuration is overwritten by the new configuration. For your application to start AACS with a new configuration, make sure your intent includes newConfig , as shown in the following example: Intent intentStartService = new Intent(); intentStartService.setComponent(new ComponentName(AACSConstants.getAACSPackageName(new WeakReference<Context>(context)), \"com.amazon.alexaautoclientservice.AlexaAutoClientService\")); intentStartService.setAction(Action.LAUNCH_SERVICE); intentStartService.putExtra(\"newConfig\", true); Omitting newConfig is the same as setting it to false , which causes AACS to use the stored configuration. Important : Sending a new configuration is allowed only once per service run. After AACS is configured and running, AACS ignores subsequent attempts to update the configuration, even if the newConfig field is true . To update an existing configuration, you must stop the service and restart it with newConfig set to true . This same rule applies to file sharing intents.","title":"Initialization Protocol"},{"location":"aacs/android/#initialization-sequence-diagram","text":"The following diagram shows an example of initializing AACS from an app used by a driver.","title":"Initialization Sequence Diagram"},{"location":"aacs/android/#default-platform-implementation","text":"Default platform implementations refer to implementations of Auto SDK platform interfaces that AACS provides to replace the normal protocol of using AASB messages. By enabling a default platform implementation in AACS, you no longer have to handle messages for a particular platform interface and can rely on AACS to provide the necessary functionality. AACS provides a default implementation for these platform interfaces: * AudioInput (audioType: VOICE, COMMS) * AudioOutput (audioType: TTS, ALARM, NOTIFICATIONS, EARCON, RINGTONE) * LocationProvider * NetworkInfoProvider * ExternalMediaAdapter for Media App Command and Control (MACC) * LocalMediaSource * PropertyManager The platform implementations for these interfaces are disabled by default; the AASB messages for these interfaces are routed to the client app to be handled . To enable the default platform implementation in AACS, you must set the aacs.defaultPlatformHandlers configuration flags. In the following example, you use aacs.defaultPlatformHandlers in the configuration file to instruct AACS to handle LocationProvider and NetworkInfoProvider , AudioInput for VOICE , and AudioOutput for TTS . Specific apps handle the other messages. \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true\", \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", \"handleAudioFocus\" : true }, } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, ... other audio types } } }","title":"Default Platform Implementation"},{"location":"aacs/android/#property-content-provider-implementation-optional","text":"AACS supports the Android ContentProvider class, which is a standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data. By extending this class, you can use a content provider, instead of AACS messages, to manage Auto SDK properties and retrieve state information. Using a content provider offers the following advantages: AACS can consistently provide the properties across multiple launches. Because properties are persistent, your application does not need to reset the properties after each AACS restart. AACS messages are asynchronous, which might cause timeouts and subsequently incorrect or error states. Using a content provider to retrieve state data makes the retrieval process synchronous, thus guaranteeing that the request for state information reaches its destination and a response is received. ContentProvider is the standard Android mechanism for performing CRUD (Create, Read, Update, Delete) operations on stored data.","title":"Property Content Provider Implementation (Optional)"},{"location":"aacs/android/#sequence-diagram-and-overview","text":"The following sequence diagram illustrates the workflow for the default property manager implementation in AACS. This implementation provides the interface, based on the Android ContentProvider , for OEM apps to get and set Auto SDK properties. aace.alexa.wakewordSupported aace.alexa.system.firmwareVersion aace.alexa.setting.locale aace.alexa.countrySupported aace.alexa.timezone aace.alexa.wakewordEnabled aace.vehicle.operatingCountry aace.core.version aace.network.networkInterface By using the native Android ContentProvider class, you can initiate query and update operations. query retrieves and returns the current String value of an Auto SDK property. update sets an Auto SDK property in the Engine and returns a boolean value based on the success of the operation. Insert and Delete operations are disabled for Auto SDK properties.","title":"Sequence Diagram and Overview"},{"location":"aacs/android/#implementation-examples","text":"Add useDefaultPropertyManager in the config.json file and set it to true , as shown in the following example: ... \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, --> \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { ... Add READ_USER_DICTIONARY permission to AndroidManifest.xml in your application, as shown in the following example: <uses-permission... <uses-permission android:name=\"android.permission.READ_USER_DICTIONARY\" /> <uses-permission... In the application implementation, set the URI for getting the ContentResolver instance as follows: private final Uri uri = Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI); Register ContentObserver for monitoring any Auto SDK property changes that are initiated by the engine. ContentObserver is a native Android class which observes changes to data and will call its onChange() method to perform callbacks when a content change occurs. It includes the changed content Uri when available. To register ContentObserver , first register your application with ContentObserver // PropertyHandler is an example class using ContentProvider API to query and update properties in your application PropertyHandler alexaPropertyHandler = new PropertyHandler(this); // PropertyContentObserver is an example implementation of the callback for property changes PropertyContentObserver propertyObserver = new PropertyContentObserver(alexaPropertyHandler, this); getContentResolver().registerContentObserver(Uri.parse(\"content://\" + AACSConstants.AACS_PROPERTY_URI), true, propertyObserver); Then implement the PropertyContentObserver class and add the desired callback behavior in method onChange() : public class PropertyContentObserver extends ContentObserver { private static Activity mActivity; public PropertyContentObserver(Handler handler, Activity activity) { super(handler); mActivity = activity; } @Override public void onChange(boolean changed) { this.onChange(changed, null); } @Override public void onChange(boolean changed, Uri uri) { // Do something when content change occurs } } Perform query() and update() operation within application using the previously set URI: query() Cursor cursor = getContentResolver().query(uri, null, propertyName, null, null); cursor.moveToFirst(); String propertyValue = cursor.getString(1); update() must be called in its own thread, not the main UI thread since update() calls setProperty and receive the result asynchronously. ExecutorService mExecutor; ContentValues cv = new ContentValues(); cv.put(propertyName, propertyValue); if (mExecutor == null ) { mExecutor = Executors.newSingleThreadExecutor(); } else { synchronized (OEMApplication.class) { if (mExecutor.isShutdown()) { // Log warning that Executor has already been shut down for update. Not updating property. } mExecutor.submit(() -> { getContentResolver().update(uri, cv, propertyName, null); }); } }","title":"Implementation Examples"},{"location":"aacs/android/#important-considerations-for-using-contentprovider","text":"AACS Property Content Provider does not support the insert and delete APIs in Property ContentProvider; You must use AACS with the AmazonLite Wake Word extension if you want to update aace.alexa.wakewordEnabled property; aace.alexa.countrySupported is a deprecated property and cannot be get/set; aace.alexa.wakewordSupported and aace.core.version are read-only properties acquired when building Auto SDK and cannot be set. Valid property value for aace.alexa.wakewordEnabled is true or false . All the other Auto SDK properties will be validated by Auto SDK. Auto SDK will provide value validation for aace.alexa.wakewordEnabled in the future.","title":"Important Considerations for Using ContentProvider"},{"location":"aacs/android/#enabling-aacs-to-synchronize-alexas-time-zone-and-locale-with-device-settings-optional","text":"AACS supports synchronizing Alexa's time zone and locale properties with the ones in device settings. To enable the functionality, refer to this README for proper configuration. Once enabled, AACS will synchronize the time zone and/or locale properties of Alexa with the device settings in the following conditions: * When Auto SDK engine is initialized, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. * When the authorization state is refreshed, AACS tries to synchronize both properties with the device settings. The property change would fail and not take effect if the system locale is not supported by Alexa. * When AACS gets android.intent.action.LOCALE_CHANGED intent as a result of device locale setting change, Alexa locale property will be updated if the locale is supported by Alexa. * When AACS gets android.intent.action.TIMEZONE_CHANGED intent as a result of device time zone setting change, Alexa time zone property will be updated. You can also disable the automatic synchronization for specific properties. This is particularly useful when your application wants to disable/enable the synchronization at runtime. For example, after the user manually selects a locale, you may want to disable the synchronization to allow the user's selection to override the system setting changes. To achieve this use case, your application can send intents with the metadata below to AACS: * Action: * Disable: com.amazon.aacs.syncSystemPropertyChange.disable * Enable: com.amazon.aacs.syncSystemPropertyChange.enable * Category: com.amazon.aacs.syncSystemPropertyChange * Extra: \"property\": <alexa_property_name> If this feature is not enabled, your application can still have the full flexibility in changing the two properties by handling AASB Property Manager messages. Additionally, you can configure AACS to update the system time zone if the user changes the Alexa's time zone for the device (e.g. the user can change the property on their Alexa mobile app). To enable the functionality, refer to this README for proper configuration. Your application with AACS needs to be a system application with android permission android.permission.SET_TIME_ZONE obtained. Note: Always provide the system permission android.permission.SET_TIME_ZONE when AACS AAR is in a system application. Refer to Privileged Permission Allowlisting in Android documentation.","title":"Enabling AACS to synchronize Alexa's Time Zone and Locale with Device Settings (Optional)"},{"location":"aacs/android/#using-custom-domain-module-with-customdomainmessagedispatcher-enabled-optional","text":"To use Custom Domain module with AACS, you need to explicitly enable it first by adding module enablement configuration. Please refer to AACS Configuration README to enable the Custom Domain module. By default, all the Custom Domain intents share the same com.amazon.aacs.aasb.customDomain intent category. If CustomDomainMessageDispatcher is enabled, the intent category will be the namespace of the custom interface prefixed with com.amazon.aacs.customDomain , which allows AACS to dispatch the Custom Domain AASB messages from the engine to the proper components in your system based on the custom namespace. Below is the intent schema of the intents sent from the dispatcher. All the intents are sent with our IPC library . You can use AACSReceiver to receive and process the AASB Custom Domain messages in the intents. Intent for handling/canceling a custom directive: Action: com.amazon.aacs.customDomain.<custom-directive-name> . Category: com.amazon.aacs.customDomain.<custom-directive-namespace> . Intent for getting the context for a custom namespace: Action: com.amazon.aacs.customDomain.GetContext Category: com.amazon.aacs.customDomain.<custom-context-namespace> . You can define intent filters in the Android Manifest of your applications to subscribe to the specific Custom Domain intents. See Specifying the Intent Targets for Handling Messages Using Android Manifest to learn more about specifying intent targets. Please refer to this README on enabling CustomDomainMessageDispatcher. Note : CustomDomainMessageDispatcher does not process any custom directives. Your application is responsible for handling any custom directives, sending custom events, and providing custom contexts following the Custom Domain AASB Documentation . If the dispatcher is not enabled, your application will be responsible for receiving all the Custom Domain AASB Messages (as intents) at one place.","title":"Using Custom Domain Module with CustomDomainMessageDispatcher Enabled (Optional)"},{"location":"aacs/android/#specifying-the-intent-targets-for-handling-messages","text":"The AASB message intent targets can be ACTIVITY , RECEIVER , or SERVICE . There are two ways to specify the intent targets for AASB message intents from AACS.","title":"Specifying the Intent Targets for Handling Messages"},{"location":"aacs/android/#using-android-manifest","text":"You can define intent filters in your application's Android Manifest. The intent filter must exactly match the intents' categories and actions. In the intent filter for an intent that wraps an AASB message, specify the category as com.amazon.aacs.aasb.<AASB_Message_Topic> and action as com.amazon.aacs.aasb.<AASB_Message_Action> . The following example shows an intent filter of all the CBL message intents for a broadcast receiver target: <intent-filter> <action android:name=\"com.amazon.aacs.aasb.CBLStateChanged\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairReceived\"/> <action android:name=\"com.amazon.aacs.aasb.CodepairExpired\"/> <action android:name=\"com.amazon.aacs.aasb.SetProfileName\"/> <action android:name=\"com.amazon.aacs.aasb.GetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.SetRefreshToken\"/> <action android:name=\"com.amazon.aacs.aasb.ClearRefreshToken\"/> <category android:name=\"com.amazon.aacs.aasb.CBL\" /> </intent-filter> To receive the message specified through the Android Manifest, the application must also have com.amazon.alexaautoclientservice permission in its Android Manifest. <uses-permission android:name=\"com.amazon.alexaautoclientservice\" /> Follow these important guidelines if the intent target is an activity: You must add <category android:name=\"android.intent.category.DEFAULT\" /> to the intent filter as explained here . Be aware that if you start applications with AACS (for example, by specifying Activity as the intent targets from AACS), the target Activity will move to the foreground or become in focus, causing distraction or confusion to the user. AACS does not request SYSTEM_ALERT_WINDOW permission to directly create windows on top of all other apps. Amazon recommends using VIS (VoiceInteractionService) to launch activities, and using Android Services or Broadcast Receivers to receive intents from AACS.","title":"Using Android Manifest"},{"location":"aacs/android/#using-aacs-configuration-file","text":"You can use the AACS configuration file to specify the app that can handle AASB messages with a specific \"topic\". This method of specifying intent targets has the highest priority, meaning it can override the ones specified through intent filters in manifests. After you use the AACS configuration to specify the app, intents with all the actions belonging to the topic go to the specified targets. Fill the optional fields in intentTargets in the AACS configuration file as needed. See the Configuration Reference documentation for information about intentTargets . The following sample configuration shows how to populate intentTargets for each topic. The field type accepts RECEIVER , ACTIVITY , and SERVICE , depending on the type of the target that handles the intents with the topic. The targets can be broadcast receiver, application activity, and service. The format for specifying AASB message intent targets for an AASB message topic is as follows: \"<topic>\" : { \"type\": [<target_1_type>, <target_2_type>, ...], \"package\": [\"<target_1_package_name>\", \"<target_2_package_name>\", ...], \"class\": [\"<target_1_class_name>\", \"<target_2_class_name>\", ...] }, The following example shows two topics, which are AASB and APL : \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\": [\"ACTIVITY\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\"com.amazon.aacstestapp.MainActivity\"] }, \"APL\" : { \"type\": [\"RECEIVER\"], \"package\": [\"com.amazon.aacstestapp\"], \"class\": [\".IntentReceiver\"] // short version of class name is also accepted. }, // In this case, the class must be in the package specified in \"package\". // ... other topics } } NOTE : If a given \"topic\" is specified both in the configuration file and the Android Manifest, the configuration file takes priority and the targets with intent filters are ignored. Amazon recommends intent filters when possible. Use the configuration approach only if you need to override the existing intent filters. AACS first searches for targets for an intent with a topic in the configuration file. If nothing is found, the package manager scans the intent filters on the device to locate a match. AACS also caches the scan results based on both topic and action. The cache is cleared every time AACS is restarted.","title":"Using AACS Configuration File"},{"location":"aacs/android/#platform-implementation-in-your-application","text":"Your applications can register for specific AASB messages and provide a platform implementation. For example, an application (\u201cLogin app\") can register for Authorization messages. For information about the Authorization module, see the Core Module README .","title":"Platform Implementation in Your Application"},{"location":"aacs/android/#initial-authentication-sequence-diagram","text":"The following sequence diagram illustrates how an application (\u201cLogin app\") exchanges messages with AACS over Android Intents to log in the user for Alexa.","title":"Initial Authentication Sequence Diagram"},{"location":"aacs/android/#wake-word-enabled-sequence-diagram","text":"The sequence diagram illustrates the sequence for the user to access Alexa if you use the default implementation of AudioInput in AACS. In this diagram, the driver is logged in and wake word is enabled. The driver initiates the action by uttering the Alexa wake word. Audio is processed locally by the wake word engine in AACS until the wake word is detected. Upon wake word detection, AACS notifies the application that the dialog state has changed to \"listening\" and initiates a Recognize event with Alexa. While in the listening state, audio data is sent to Alexa. When the end of speech is detected, Alexa sends a StopCapture directive to AACS, and the dialog state is changed to \"thinking.\" Alexa then responds with additional directives in response to the speech request. For information about other messages to provide your implementation in the client APK, please refer to the README for each Auto SDK module.","title":"Wake Word Enabled Sequence Diagram"},{"location":"aacs/android/#client-utility-library","text":"AACS also provides an optional library, AACS Common Utils . It contains useful methods to make messaging with AACS easier. You can use it as-is or as a reference to facilitate the integration of the Auto SDK with AACS. For information about the library, see AACS Common Utils README and in-code documentation in the library.","title":"Client Utility Library"},{"location":"aacs/android/#device-settings-required-for-aacs","text":"AACS requires microphone and location permissions when the default implementation is used for AudioInput and Location. If AACS runs in a system application, you can grant these permissions so that the application users do not have to set the permissions. Otherwise, be sure to instruct your users to grant the following permissions on the app info page under Settings on their device: Location: Enable android.permission.ACCESS_FINE_LOCATION to give AACS access the current location. Microphone: Enable android.permission.RECORD_AUDIO to give permission to AACS to record audio. Microphone must be enabled if you configure AudioInput to use the default implementation of AACS.","title":"Device Settings Required for AACS"},{"location":"aacs/android/#checking-aacs-connection-state","text":"Your application or service can check the status of AACS by using ping , which returns a response as long as AACS is running. The AACSPinger utility class from the IPC library enables you to use ping . To ping AACS, specify the ping permission name in your application's Android Manifest file as follows: <uses-permission android:name=\"com.amazon.alexaautoclientservice.ping\"/> The following example shows how to use AACSPinger : AACSPinger aacsPinger = new AACSPinger(getApplicationContext(), \"com.amazon.alexaautoclientservice.ping\"); Future<AACSPinger.AACSPingResponse> fut = aacsPinger.pingAACS(); AACSPinger.AACSPingResponse response = fut.get(); if (response.hasResponse) { // Ping was responded to by AACS String state = response.AACSState; ... } else { // Ping timed out without an AACS response } If AACS responds to the ping request, the AACSPingResponse.AACSState string returned by AACSPinger.pingAACS() has one of the following values: STARTED WAIT_FOR_LVC_CONFIG CONFIGURED ENGINE_INITIALIZED CONNECTED STOPPED If AACS does not respond within the default timeout of 1 second, AACSPingResponse.hasResponse is false .","title":"Checking AACS Connection State"},{"location":"aacs/android/#request-list-of-extras-from-aacs","text":"Your application can receive the list of AACS extra modules by sending an intent with the action AACSConstants.IntentAction.GET_SERVICE_METADATA and the category AACSConstants.IntentCategory.GET_SERVICE_METADATA , which returns a response by receiving an intent AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . To get the extras list from AACS- Specify the permission name in your application's Android Manifest file as follows: <uses-permission android:name= \"com.amazon.alexaautoclientservice.getservicemetadata\" /> Register a receiver in you application's Android Manifest file as follows: Following block shows an example of requesting list of extras: <receiver android:name= \".<Receiver Class>\" android:enabled= \"true\" android:exported= \"true\" /> Send a request intent to AACS. Following code snippet shows an example Intent intent = new Intent (); intent . setAction ( AACSConstants . IntentAction . GET_SERVICE_METADATA ); intent . addCategory ( AACSConstants . IntentCategory . GET_SERVICE_METADATA ); intent . putExtra ( AACSConstants . REPLY_TO_PACKAGE , getPackageName ()); intent . putExtra ( AACSConstants . REPLY_TO_CLASS , < Receiver_Class_Name > . class . getName ()); intent . putExtra ( AACSConstants . REPLY_TYPE , \"RECEIVER\" ); sendBroadcast ( intent ); Your receiver class will receive an intent with the following payload { \"metaData\" : { \"extrasModuleList\" : [] } } You can get the payload from the received intent with action AACSConstants.IntentAction.GET_SERVICE_METADATA_REPLY . Following code snippet shows the example: String payload = intent . getStringExtra ( AACSConstants . PAYLOAD );","title":"Request list of extras from AACS"},{"location":"aacs/android/#using-instrumentation","text":"You can use AACS instrumentation to log AASB messages for debugging purposes. For more information about how to use instrumentation, see the AACS Instrumentation README . Note: You can use instrumentation only if you use the debug option when building the Auto SDK with AACS.","title":"Using Instrumentation"},{"location":"aacs/android/#including-app-components-with-aacs-aar-in-your-application","text":"The Auto SDK provides packages (also called \"app components\") in the $AAC_SDK_HOME/aacs/android/app-components directory. App components could be included in your application along with AACS AAR to speed up the Alexa integration. Note: Some app components implement the handling of AASB messages for certain topics, allowing your applications to interface with AACS by using standard Android APIs. If you include such app components in your application with AACS AAR, your application does not need to handle the AASB messages for those particular AASB topics.","title":"Including App Components with AACS AAR in your application"},{"location":"aacs/android/#aacs-sample-app","text":"The Auto SDK includes an Android-based application that demonstrates how an application uses AACS. For more information about the AACS Sample App, see the AACS Sample App README .","title":"AACS Sample App"},{"location":"aacs/android/app-components/alexa-auto-apis/","text":"Alexa Auto API This Alexa Auto API package provides: * Types that are used across multiple Java packages. A Java package is a collection of related types, which is created to avoid type name collisions. * Interfaces that allow packages to communicate with each other by using standard Java, as long as the consumer and provider of the interface meet these requirements: * They are in the same Android Package (APK). * They are loaded and used in the same process. Component Registry (Service Locator) To enable a package to locate the implementation of an API, the Alexa Auto API Package defines the component registry interfaces and the mechanism to obtain the component registry (also called the service locator). Consuming Implementations from Other Packages The following list explains the component registry interfaces: * AlexaAppRootComponent is a component registry interface with an application scope. It provides interfaces that are in scope for the lifetime of the app. This interface provides access to AlexaAppScopedComponents , among other interfaces. * AlexaAppScopedComponents provides interfaces that are available for a limited scope. For example, when an app is in logged-off state, AlexaAppLoggedOutScopedComponent can be queried by using AlexaAppScopedComponents . Any library or application class can obtain AlexaAppRootComponent as long as it has the Android context. The following code example illustrates how an app obtains AlexaAppRootComponent : class MyActivity extends AppCompatActivity { public void onStart() { AlexaApp app = AlexaApp.from(this); AlexaAppRootComponent componentRegistry = app.getRootComponent(); componentRegistry.getXYZ().doSomethingUseful(); } } Publishing Implementations for Other Packages How a package publishes the implementation of an API for another package to use depends on the scope, as explained in the following list: App lifecycle implementation: If an object's lifecycle is bound to the lifecycle of an app, then the main Alexa app APK creates an instance of the object and makes it available through the implementation of AlexaAppRootComponent . Limited scoped implementations: A package can publish scoped components into the component registry to be discovered by other packages. To publish a scoped component, the package can obtain AlexaAppScopedComponentsActivator from AlexaAppRootComponent .","title":"Alexa Auto API"},{"location":"aacs/android/app-components/alexa-auto-apis/#alexa-auto-api","text":"This Alexa Auto API package provides: * Types that are used across multiple Java packages. A Java package is a collection of related types, which is created to avoid type name collisions. * Interfaces that allow packages to communicate with each other by using standard Java, as long as the consumer and provider of the interface meet these requirements: * They are in the same Android Package (APK). * They are loaded and used in the same process.","title":"Alexa Auto API"},{"location":"aacs/android/app-components/alexa-auto-apis/#component-registry-service-locator","text":"To enable a package to locate the implementation of an API, the Alexa Auto API Package defines the component registry interfaces and the mechanism to obtain the component registry (also called the service locator).","title":"Component Registry (Service Locator)"},{"location":"aacs/android/app-components/alexa-auto-apis/#consuming-implementations-from-other-packages","text":"The following list explains the component registry interfaces: * AlexaAppRootComponent is a component registry interface with an application scope. It provides interfaces that are in scope for the lifetime of the app. This interface provides access to AlexaAppScopedComponents , among other interfaces. * AlexaAppScopedComponents provides interfaces that are available for a limited scope. For example, when an app is in logged-off state, AlexaAppLoggedOutScopedComponent can be queried by using AlexaAppScopedComponents . Any library or application class can obtain AlexaAppRootComponent as long as it has the Android context. The following code example illustrates how an app obtains AlexaAppRootComponent : class MyActivity extends AppCompatActivity { public void onStart() { AlexaApp app = AlexaApp.from(this); AlexaAppRootComponent componentRegistry = app.getRootComponent(); componentRegistry.getXYZ().doSomethingUseful(); } }","title":"Consuming Implementations from Other Packages"},{"location":"aacs/android/app-components/alexa-auto-apis/#publishing-implementations-for-other-packages","text":"How a package publishes the implementation of an API for another package to use depends on the scope, as explained in the following list: App lifecycle implementation: If an object's lifecycle is bound to the lifecycle of an app, then the main Alexa app APK creates an instance of the object and makes it available through the implementation of AlexaAppRootComponent . Limited scoped implementations: A package can publish scoped components into the component registry to be discovered by other packages. To publish a scoped component, the package can obtain AlexaAppScopedComponentsActivator from AlexaAppRootComponent .","title":"Publishing Implementations for Other Packages"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/","text":"Alexa Auto APL Renderer The Alexa Auto APL Renderer library enables the AACS Sample App to render Amazon Presentation Language (APL) documents on the user's device. The library consists of the following components: APLReceiver : This class receives the APL intents. After receiving an APL RenderDocument intent, it starts adding APLFragment to VoiceActivity or sends the APLDirective event to APLFragment . APLHandler : This class handles APL intents, such as those for rendering or clearing APL documents. It also executes APL commands and implements an event interface named IAPLEventSender , which reports events to Alexa or the capability agent. APLFragment : This class initializes the APL runtime, instantiates APLPresenter , and calls the APLhandler methods to handle APL intents. This class also inflates the APL layout to render the APL document. The APLLayout object in fragment_apl.xml defines the layout. Important! The Alexa Auto APL Renderer library is for you to experiment with APL document rendering on an automotive device, it is not a preferred UX in automotive experience. Do not use the library to render APL documents in a production vehicle. Support for APL rendering in a production environment will be provided in a future Alexa Auto SDK version. Important! Certain APL templates recommend scrolling text and these will be removed for production versions of APL in a future Alexa Auto SDK version. Prerequisites for Using the Alexa Auto APL Renderer Library The APL Renderer library for the AACS Sample App depends on the capabilities provided by an Auto SDK module called APL Render module. For example, the APL Render module provides the APLPresenter class implementation. The Alexa Auto APL Renderer library initializes this class to provide the orchestration logic in the APL rendering process. For information about how to build the APL Render module, see the APL Render README . Using Alexa Auto APL Renderer Library with AACS Sample App To use the Alexa Auto APL Renderer Library with the AACS Sample App, include the appropriate build dependency and configure APL in the AACS Sample App. Including Build Dependency (AAR) The Alexa Auto APL Renderer library requires a prebuilt Android view host, which is available as an AAR on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To include the build dependency, you must place the Android view host AAR in the APL Render module libs/ folder. Configuring APL in AACS Sample App The AACS Sample App passes aacs_config.json to AACS for configuring the Auto SDK. Follow these steps to enable APL and specify the display format: Enable APL in aacs_config.json : \"aacs.modules\" : { \"aacs.apl\" : { \"APL\" : { \"enabled\" : true } } } Add the gui configuration node in aacs.alexa , as shown in the following example: { \"aacs.alexa\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 900 , \"height\" : 1200 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } } ] } } } For descriptions of the visual characteristic parameters, see the Alexa Smart Screen SDK documentation . APL viewport can be adjusted by changing the width and height pixel values in Alexa.Display.Window configuration. Building AACS Sample App with Alexa Auto APL Renderer Library To build the AACS Sample App with Alexa Auto APL Renderer library, go to ${AAC_SDK_HOME}/aacs/android/sample-app/ and enter the following command: ./gradlew assembleLocalRelease -PenabledAPL Using AACS Sample App After the gradle build command finishes building the AACS Sample App, you can test the sample app by asking, \"Alexa, tell me a joke.\" An APL document is rendered on the device. The Auto SDK 4.0 enables the ability to report the vehicle driving state to provide safer visual experiences while the vehicles is moving. To enable the driving state support, add -PenabledUXRestrictions to the build command. When you say \"Alexa, show coffee shops near me\" and view the details for a point of interest, the data displayed in the APL detail card will contain more information while the driving state is parked . Additionally, the Auto SDK 4.0 supports the ability to report the light conditions around the vehicle to support day/night mode and provide a custom theme id to alter the look and feel of the APL experience. ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions Note: The alexa-auto-ux-restrictions requires Android API level 29. Provide your own implementation for the CarUxRestrictionsController interface if your device uses API level less than 29. By default, the driving state will always be set to moving if the CarUxRestrictionsController is not implemented. Known Issues When interrupting music playback with APL utterance, APL card will be dismissed when music playback resumes, this issue could not be seen if music ducking support is enabled in AACS sample app. To do this, add audio ducking node in aacs.alexa , as shown in the following example: \"aacs.alexa\": { \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } } }","title":"Alexa Auto APL Renderer"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#alexa-auto-apl-renderer","text":"The Alexa Auto APL Renderer library enables the AACS Sample App to render Amazon Presentation Language (APL) documents on the user's device. The library consists of the following components: APLReceiver : This class receives the APL intents. After receiving an APL RenderDocument intent, it starts adding APLFragment to VoiceActivity or sends the APLDirective event to APLFragment . APLHandler : This class handles APL intents, such as those for rendering or clearing APL documents. It also executes APL commands and implements an event interface named IAPLEventSender , which reports events to Alexa or the capability agent. APLFragment : This class initializes the APL runtime, instantiates APLPresenter , and calls the APLhandler methods to handle APL intents. This class also inflates the APL layout to render the APL document. The APLLayout object in fragment_apl.xml defines the layout. Important! The Alexa Auto APL Renderer library is for you to experiment with APL document rendering on an automotive device, it is not a preferred UX in automotive experience. Do not use the library to render APL documents in a production vehicle. Support for APL rendering in a production environment will be provided in a future Alexa Auto SDK version. Important! Certain APL templates recommend scrolling text and these will be removed for production versions of APL in a future Alexa Auto SDK version.","title":"Alexa Auto APL Renderer"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#prerequisites-for-using-the-alexa-auto-apl-renderer-library","text":"The APL Renderer library for the AACS Sample App depends on the capabilities provided by an Auto SDK module called APL Render module. For example, the APL Render module provides the APLPresenter class implementation. The Alexa Auto APL Renderer library initializes this class to provide the orchestration logic in the APL rendering process. For information about how to build the APL Render module, see the APL Render README .","title":"Prerequisites for Using the Alexa Auto APL Renderer Library"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#using-alexa-auto-apl-renderer-library-with-aacs-sample-app","text":"To use the Alexa Auto APL Renderer Library with the AACS Sample App, include the appropriate build dependency and configure APL in the AACS Sample App.","title":"Using Alexa Auto APL Renderer Library with AACS Sample App"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#including-build-dependency-aar","text":"The Alexa Auto APL Renderer library requires a prebuilt Android view host, which is available as an AAR on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To include the build dependency, you must place the Android view host AAR in the APL Render module libs/ folder.","title":"Including Build Dependency (AAR)"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#configuring-apl-in-aacs-sample-app","text":"The AACS Sample App passes aacs_config.json to AACS for configuring the Auto SDK. Follow these steps to enable APL and specify the display format: Enable APL in aacs_config.json : \"aacs.modules\" : { \"aacs.apl\" : { \"APL\" : { \"enabled\" : true } } } Add the gui configuration node in aacs.alexa , as shown in the following example: { \"aacs.alexa\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 900 , \"height\" : 1200 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } } ] } } } For descriptions of the visual characteristic parameters, see the Alexa Smart Screen SDK documentation . APL viewport can be adjusted by changing the width and height pixel values in Alexa.Display.Window configuration.","title":"Configuring APL in AACS Sample App"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#building-aacs-sample-app-with-alexa-auto-apl-renderer-library","text":"To build the AACS Sample App with Alexa Auto APL Renderer library, go to ${AAC_SDK_HOME}/aacs/android/sample-app/ and enter the following command: ./gradlew assembleLocalRelease -PenabledAPL","title":"Building AACS Sample App with Alexa Auto APL Renderer Library"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#using-aacs-sample-app","text":"After the gradle build command finishes building the AACS Sample App, you can test the sample app by asking, \"Alexa, tell me a joke.\" An APL document is rendered on the device. The Auto SDK 4.0 enables the ability to report the vehicle driving state to provide safer visual experiences while the vehicles is moving. To enable the driving state support, add -PenabledUXRestrictions to the build command. When you say \"Alexa, show coffee shops near me\" and view the details for a point of interest, the data displayed in the APL detail card will contain more information while the driving state is parked . Additionally, the Auto SDK 4.0 supports the ability to report the light conditions around the vehicle to support day/night mode and provide a custom theme id to alter the look and feel of the APL experience. ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions Note: The alexa-auto-ux-restrictions requires Android API level 29. Provide your own implementation for the CarUxRestrictionsController interface if your device uses API level less than 29. By default, the driving state will always be set to moving if the CarUxRestrictionsController is not implemented.","title":"Using AACS Sample App"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/#known-issues","text":"When interrupting music playback with APL utterance, APL card will be dismissed when music playback resumes, this issue could not be seen if music ducking support is enabled in AACS sample app. To do this, add audio ducking node in aacs.alexa , as shown in the following example: \"aacs.alexa\": { \"audio\": { \"audioOutputType.music\": { \"ducking\":{ \"enabled\": true } } } }","title":"Known Issues"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/","text":"APL Render Module The APL Render module is an Android library that enables Alexa Presentation Language (APL) rendering capabilities in an Android application. For detailed information about APL, see the APL documentation . Table of Contents Overview Understanding Android View Host APL Render Module Functionality How to use the APL Render Module Defining the APL Layout Initializing the APL Runtime Implementing the Event Interface Instantiating APLPresenter Rendering an APL Document Building the APL Render Library Overriding Android View Host Options Using APLOptions.Builder APL Extensions Overview Rendering an APL document on a device requires the implementation of various components and the logic that makes the components work together. To handle APL-related directives and events, the device must support APL interfaces. It needs integration of the APL Core Library to manage the document parsing and rendering workflow. In addition, you must build a view host for the device to render the APL document on the screen, as well as provide components to download layouts, images, and other resources. If the APL document generates multimedia content, such as a video or audio file, you need a media player to play back the content. Lastly, APL rendering needs the orchestration logic to manage the lifecycle of a rendered document, which includes user events, audio focus management, time out management, visual context, command execution, and much more. The Alexa Auto SDK, with the APL Render module and a prebuilt Android view host, simplifies the process of APL rendering because it provides the aforementioned components and logic for you. Understanding Android View Host The Android view host is the component responsible for rendering APL on the screen. Amazon provides a prebuilt Android view host as an Android Archive Library (AAR) on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To use the Android Render module, you must place the Android view host AAR in the src/main/libs/ folder of the APL Render module. APL Render Module Functionality The APL Render module provides all the functionality needed for enabling APL rendering capabilities in an Android application. The APL Render module provides the following capabilities: APL runtime initialization HTTP Resource downloader Android view host integration Android audio focus management Activity tracking for timeout management Audio and media players Interfaces to easily override functionality How to use the APL Render Module To use the APL Render module without customization, follow these steps: 1) Define the APL layout. 2) Initialize the APL runtime. 3) Implement the event interface. 4) Instantiate APLPresenter . Defining the APL Layout The application must define the layout of the screen on which the APL document is rendered. the width and height of the APLLayout must fall in range with one of the three supported automotive viewport profiles : auto extra small, auto small, and auto medium. Define an com.amazon.apl.android.APLLayout object, as shown in the following example, where the object is defined under res/layout : <? xml version = \"1.0\" encoding = \"utf-8\" ?> < LinearLayout xmlns : android = \"http://schemas.android.com/apk/res/android\" android : orientation = \"vertical\" android : layout_width = \"match_parent\" xmlns : app = \"http://schemas.android.com/apk/res-auto\" android : layout_height = \"match_parent\" > < com . amazon . apl . android . APLLayout android : layout_width = \"match_parent\" android : layout_height = \"match_parent\" android : background = \"?attr/colorPrimary\" android : id = \"@+id/apl\" android : theme = \"@style/Theme.AppCompat\" app : aplTheme = \"dark\" app : isRound = \"false\" app : mode = \"auto\" /> </ LinearLayout > The app:aplTheme field corresponds to the default APL theme to be used if one is not specified in the APL document. Typical values are light or dark . The app:mode field specifies the operating mode, which is a viewport property . For information about the viewport object, see the viewport documentation . The value for this field should be auto for an Automotive device. Initializing the APL Runtime The application must invoke the APLPresenter.initialize() static method before inflating the APLLayout UI component. The following code shows how to use the onCreate method of Activity to initialize the APL runtime: import com.amazon.apl.android.render.APLPresenter ; //--------------------------------------------------------------------- // Initialize the APL Runtime. This must be called during // Activity.onCreate() or prior to APLLayout inflation. //--------------------------------------------------------------------- onCreate () { Context context = getApplicationContext (); APLPresenter . initialize ( context ); } Implementing the Event Interface The application must implement the com.amazon.apl.android.render.interfaces.IAPLEventSender interface. The IAPLEventSender interface provides the APIs to allow the APL Render module to report events to Alexa or the capability agent. You can integrate the event interface into the APL handler that implements the Auto SDK APL platform interface . The following code shows how to do the integration: import com.amazon.aace.apl.APL ; import com.amazon.apl.android.render.interfaces.IAPLEventSender ; public class APLHandler extends APL implements IAPLEventSender { //--------------------------------------------------------------------- // Override IAPLEventSender methods. // APLHandler will register with APL Render library as the event sender. //--------------------------------------------------------------------- @Override public void sendRenderDocumentResult ( String token , boolean result , String error ) { renderDocumentResult ( token , result , error ); // APL::renderDocumentResult } @Override public void sendExecuteCommandsResult ( String token , boolean result , String error ) { executeCommandsResult ( token , result , error ); // APL::executeCommandsResult } ... } Instantiating APLPresenter The application must instantiate the APLPresenter object, which provides the orchestration logic in the APL rendering process. Note: Create APLPresenter after the APL platform interface handler is registered with the Auto SDK Engine. The following code shows how to instantiate the APLPresenter object: import com.amazon.apl.android.render.APLPresenter ; public class APLHandler extends APL implements IAPLEventSender { private APLPresenter mPresenter ; public void buildAPLPresenter ( JSONArray visualCharacteristics , String defaultWindowId ) { //--------------------------------------------------------------------- // Retrieve the APLLayout view with id 'apl' defined in apl_view.xml. // This assumes that 'activity' is the application's Activity. //--------------------------------------------------------------------- aplLayout = activity . findViewById ( R . id . apl ); //--------------------------------------------------------------------- // Application needs to handle the correlation of window ids from the // visual characteristics configuration to the APLLayout instance. //--------------------------------------------------------------------- HashMap aplLayouts = new HashMap < String , APLLayout > (); aplLayouts . put ( defaultWindowId , mAplLayout ); //--------------------------------------------------------------------- // Create APLPresenter to handle APL rendering. //--------------------------------------------------------------------- mPresenter = new APLPresenter ( aplLayouts , visualCharacteristics , defaultWindowId , this ); } The following list describes the parameters to APLPresenter : The first parameter is a map of the APLLayout objects. Each APLLayout is identified by a window ID, which specifies the window where the APL document is rendered. Typically, there is one APLLayout defined for the window where all the APL documents are rendered, but you can build skills that support rendering in multiple windows. The second parameter is a JSON array` pointing to the visual characteristics defined by the device. For more information about visual characteristics, see the APL module README and the Smart Screen SDK documentation . The third parameter is the default window ID, specifying the window where APL documents are rendered if Alexa does not provide a window ID. The last parameter is the object that implements the IAPLEventSender interface. Rendering an APL Document To render an APL document, call the onRenderDocument API on the APLPresenter . The APLHandler can delegate the APL APIs to the APLPresenter , as shown in the following code: public class APLHandler extends APL implements IAPLEventSender { ... //--------------------------------------------------------------------- // Override Auto SDK APL interfaces //--------------------------------------------------------------------- @Override public void renderDocument ( String payload , String token , String windowId ) { mAplPresenter . onRenderDocument ( payload , token , windowId ); // APLRender implements these interfaces } @Override public void executeCommands ( String payload , String token ) { mPresenter . onExecuteCommands ( payload , token ); } ... } Overriding Android View Host Options Rendering an APL document requires the APL Render module to set up an APLOptions object, which is passed to the view host. The APLOptions object is configured with providers, callbacks, and listeners, as described in the following list: Providers are objects implemented outside the view host.They provide objects used during the rendering process. For example, the data retriever provider downloads APL resources, such as layouts from content delivery networks (CDNs). The media player provider plays media, such as videos. Callbacks are interfaces used by the view host to report events, such as: user events (e.g., button clicks) document lifecycle events (e.g., completion of document rendering) Listeners are interfaces for reporting the APL rendered document state or screen lock events. The APL Render module sets up all the providers, callbacks, and listeners. If the application needs to override any of them, it uses the APLOptions.Builder object. Using APLOptions.Builder To override APLOptions , extend the APLPresenter object, as shown in the following code: class MyAPLPresenter extends APLPresenter { //--------------------------------------------------------------------- // IAPLOptionsBuilderProvider override //--------------------------------------------------------------------- @Override APLOptions . Builder getAPLOptionsBuilder () { APLOptions . Builder builder = super . getAPLOptionsBuilder (); // Listen in on APL finish callback builder . onAplFinishCallback (() -> { // Do something here super . onAplFinish (); }); return builder ; } } APL Runtime Properties The IAPLContentListener exposes an interface to control some APL runtime properties that affect how APL documents are rendered. The onAPLRuntimeProperties API takes in a JSON string that contains one or more properties to update. Driving State The drivingState property supports the values moving and parked . An APL experience may differ depending on the driving state in order to provide a safer driving experience. Theme The theme property allows the APL experience to render in different color schemes. There are six supported values: light, light-gray1, light-gray2, dark, dark-black, dark-gray. The light themes can be during for day driving, while the dark themes can be used for night driving. APL Extensions Backstack This library supports the Backstack extension. The application must ensure that the APLPresenter is not destroyed and recreated when a new APL document with the same token id is received. Otherwise, the Backstack will be reinstantiated and the previous stack of documents will be lost. Local Information Data This library contains a custom APL extension that is used by the APLPresenter to expose point of interest data to the application. This data can be used to drop corresponding pins on the head unit's integrated map. Two way communication is also provided so that the application or AP runtime can notify each other when a specific data point is active or selected. There are two interfaces that the application can use to interact with Local infomation data: ILocalInfoDataConsumer and ILocalInfoDataReporter . ILocalInfoDataConsumer The IPresenter interace exposes a method to set the data consumer, which must be set by the application: /** * Saves a reference to the local info data consumer. * * @param consumer The object that consume local info data events. */ void setLocalInfoDataConsumer(ILocalInfoDataConsumer consumer); The application will be notified through the consumer method aplDataAvailable with a JSON string object represention all the points of interest. The application will be notified when a specific data point is selected on the APL document using the consume method aplDataItemSelectedById . ILocalInfoDataReporter The APLPresenter implements the ILocalInfoDataReporter interface to allow the application to notify the APL runtime when a data point is selected outside of the APL runtime. To do this notification simply call platformDataItemSelectedById on the APLPresenter instance. Building the APL Render Library Note: Before proceeding to build the APL Render library, download the Android APL resource from the developer portal according to instructions from your Solutions Architect or Partner Manager. This library can be built using the included gradle wrapper as follows ./gradlew assembleRelease","title":"APL Render Module"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-render-module","text":"The APL Render module is an Android library that enables Alexa Presentation Language (APL) rendering capabilities in an Android application. For detailed information about APL, see the APL documentation .","title":"APL Render Module"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#table-of-contents","text":"Overview Understanding Android View Host APL Render Module Functionality How to use the APL Render Module Defining the APL Layout Initializing the APL Runtime Implementing the Event Interface Instantiating APLPresenter Rendering an APL Document Building the APL Render Library Overriding Android View Host Options Using APLOptions.Builder APL Extensions","title":"Table of Contents"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#overview","text":"Rendering an APL document on a device requires the implementation of various components and the logic that makes the components work together. To handle APL-related directives and events, the device must support APL interfaces. It needs integration of the APL Core Library to manage the document parsing and rendering workflow. In addition, you must build a view host for the device to render the APL document on the screen, as well as provide components to download layouts, images, and other resources. If the APL document generates multimedia content, such as a video or audio file, you need a media player to play back the content. Lastly, APL rendering needs the orchestration logic to manage the lifecycle of a rendered document, which includes user events, audio focus management, time out management, visual context, command execution, and much more. The Alexa Auto SDK, with the APL Render module and a prebuilt Android view host, simplifies the process of APL rendering because it provides the aforementioned components and logic for you.","title":"Overview"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#understanding-android-view-host","text":"The Android view host is the component responsible for rendering APL on the screen. Amazon provides a prebuilt Android view host as an Android Archive Library (AAR) on the developer portal. To download the AAR, contact your Solutions Architect (SA) or Partner Manager. Note: To use the Android Render module, you must place the Android view host AAR in the src/main/libs/ folder of the APL Render module.","title":"Understanding Android View Host"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-render-module-functionality","text":"The APL Render module provides all the functionality needed for enabling APL rendering capabilities in an Android application. The APL Render module provides the following capabilities: APL runtime initialization HTTP Resource downloader Android view host integration Android audio focus management Activity tracking for timeout management Audio and media players Interfaces to easily override functionality","title":"APL Render Module Functionality"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#how-to-use-the-apl-render-module","text":"To use the APL Render module without customization, follow these steps: 1) Define the APL layout. 2) Initialize the APL runtime. 3) Implement the event interface. 4) Instantiate APLPresenter .","title":"How to use the APL Render Module"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#defining-the-apl-layout","text":"The application must define the layout of the screen on which the APL document is rendered. the width and height of the APLLayout must fall in range with one of the three supported automotive viewport profiles : auto extra small, auto small, and auto medium. Define an com.amazon.apl.android.APLLayout object, as shown in the following example, where the object is defined under res/layout : <? xml version = \"1.0\" encoding = \"utf-8\" ?> < LinearLayout xmlns : android = \"http://schemas.android.com/apk/res/android\" android : orientation = \"vertical\" android : layout_width = \"match_parent\" xmlns : app = \"http://schemas.android.com/apk/res-auto\" android : layout_height = \"match_parent\" > < com . amazon . apl . android . APLLayout android : layout_width = \"match_parent\" android : layout_height = \"match_parent\" android : background = \"?attr/colorPrimary\" android : id = \"@+id/apl\" android : theme = \"@style/Theme.AppCompat\" app : aplTheme = \"dark\" app : isRound = \"false\" app : mode = \"auto\" /> </ LinearLayout > The app:aplTheme field corresponds to the default APL theme to be used if one is not specified in the APL document. Typical values are light or dark . The app:mode field specifies the operating mode, which is a viewport property . For information about the viewport object, see the viewport documentation . The value for this field should be auto for an Automotive device.","title":"Defining the APL Layout"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#initializing-the-apl-runtime","text":"The application must invoke the APLPresenter.initialize() static method before inflating the APLLayout UI component. The following code shows how to use the onCreate method of Activity to initialize the APL runtime: import com.amazon.apl.android.render.APLPresenter ; //--------------------------------------------------------------------- // Initialize the APL Runtime. This must be called during // Activity.onCreate() or prior to APLLayout inflation. //--------------------------------------------------------------------- onCreate () { Context context = getApplicationContext (); APLPresenter . initialize ( context ); }","title":"Initializing the APL Runtime"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#implementing-the-event-interface","text":"The application must implement the com.amazon.apl.android.render.interfaces.IAPLEventSender interface. The IAPLEventSender interface provides the APIs to allow the APL Render module to report events to Alexa or the capability agent. You can integrate the event interface into the APL handler that implements the Auto SDK APL platform interface . The following code shows how to do the integration: import com.amazon.aace.apl.APL ; import com.amazon.apl.android.render.interfaces.IAPLEventSender ; public class APLHandler extends APL implements IAPLEventSender { //--------------------------------------------------------------------- // Override IAPLEventSender methods. // APLHandler will register with APL Render library as the event sender. //--------------------------------------------------------------------- @Override public void sendRenderDocumentResult ( String token , boolean result , String error ) { renderDocumentResult ( token , result , error ); // APL::renderDocumentResult } @Override public void sendExecuteCommandsResult ( String token , boolean result , String error ) { executeCommandsResult ( token , result , error ); // APL::executeCommandsResult } ... }","title":"Implementing the Event Interface"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#instantiating-aplpresenter","text":"The application must instantiate the APLPresenter object, which provides the orchestration logic in the APL rendering process. Note: Create APLPresenter after the APL platform interface handler is registered with the Auto SDK Engine. The following code shows how to instantiate the APLPresenter object: import com.amazon.apl.android.render.APLPresenter ; public class APLHandler extends APL implements IAPLEventSender { private APLPresenter mPresenter ; public void buildAPLPresenter ( JSONArray visualCharacteristics , String defaultWindowId ) { //--------------------------------------------------------------------- // Retrieve the APLLayout view with id 'apl' defined in apl_view.xml. // This assumes that 'activity' is the application's Activity. //--------------------------------------------------------------------- aplLayout = activity . findViewById ( R . id . apl ); //--------------------------------------------------------------------- // Application needs to handle the correlation of window ids from the // visual characteristics configuration to the APLLayout instance. //--------------------------------------------------------------------- HashMap aplLayouts = new HashMap < String , APLLayout > (); aplLayouts . put ( defaultWindowId , mAplLayout ); //--------------------------------------------------------------------- // Create APLPresenter to handle APL rendering. //--------------------------------------------------------------------- mPresenter = new APLPresenter ( aplLayouts , visualCharacteristics , defaultWindowId , this ); } The following list describes the parameters to APLPresenter : The first parameter is a map of the APLLayout objects. Each APLLayout is identified by a window ID, which specifies the window where the APL document is rendered. Typically, there is one APLLayout defined for the window where all the APL documents are rendered, but you can build skills that support rendering in multiple windows. The second parameter is a JSON array` pointing to the visual characteristics defined by the device. For more information about visual characteristics, see the APL module README and the Smart Screen SDK documentation . The third parameter is the default window ID, specifying the window where APL documents are rendered if Alexa does not provide a window ID. The last parameter is the object that implements the IAPLEventSender interface.","title":"Instantiating APLPresenter"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#rendering-an-apl-document","text":"To render an APL document, call the onRenderDocument API on the APLPresenter . The APLHandler can delegate the APL APIs to the APLPresenter , as shown in the following code: public class APLHandler extends APL implements IAPLEventSender { ... //--------------------------------------------------------------------- // Override Auto SDK APL interfaces //--------------------------------------------------------------------- @Override public void renderDocument ( String payload , String token , String windowId ) { mAplPresenter . onRenderDocument ( payload , token , windowId ); // APLRender implements these interfaces } @Override public void executeCommands ( String payload , String token ) { mPresenter . onExecuteCommands ( payload , token ); } ... }","title":"Rendering an APL Document"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#overriding-android-view-host-options","text":"Rendering an APL document requires the APL Render module to set up an APLOptions object, which is passed to the view host. The APLOptions object is configured with providers, callbacks, and listeners, as described in the following list: Providers are objects implemented outside the view host.They provide objects used during the rendering process. For example, the data retriever provider downloads APL resources, such as layouts from content delivery networks (CDNs). The media player provider plays media, such as videos. Callbacks are interfaces used by the view host to report events, such as: user events (e.g., button clicks) document lifecycle events (e.g., completion of document rendering) Listeners are interfaces for reporting the APL rendered document state or screen lock events. The APL Render module sets up all the providers, callbacks, and listeners. If the application needs to override any of them, it uses the APLOptions.Builder object.","title":"Overriding Android View Host Options"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#using-aploptionsbuilder","text":"To override APLOptions , extend the APLPresenter object, as shown in the following code: class MyAPLPresenter extends APLPresenter { //--------------------------------------------------------------------- // IAPLOptionsBuilderProvider override //--------------------------------------------------------------------- @Override APLOptions . Builder getAPLOptionsBuilder () { APLOptions . Builder builder = super . getAPLOptionsBuilder (); // Listen in on APL finish callback builder . onAplFinishCallback (() -> { // Do something here super . onAplFinish (); }); return builder ; } }","title":"Using APLOptions.Builder"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-runtime-properties","text":"The IAPLContentListener exposes an interface to control some APL runtime properties that affect how APL documents are rendered. The onAPLRuntimeProperties API takes in a JSON string that contains one or more properties to update.","title":"APL Runtime Properties"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#driving-state","text":"The drivingState property supports the values moving and parked . An APL experience may differ depending on the driving state in order to provide a safer driving experience.","title":"Driving State"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#theme","text":"The theme property allows the APL experience to render in different color schemes. There are six supported values: light, light-gray1, light-gray2, dark, dark-black, dark-gray. The light themes can be during for day driving, while the dark themes can be used for night driving.","title":"Theme"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#apl-extensions","text":"","title":"APL Extensions"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#backstack","text":"This library supports the Backstack extension. The application must ensure that the APLPresenter is not destroyed and recreated when a new APL document with the same token id is received. Otherwise, the Backstack will be reinstantiated and the previous stack of documents will be lost.","title":"Backstack"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#local-information-data","text":"This library contains a custom APL extension that is used by the APLPresenter to expose point of interest data to the application. This data can be used to drop corresponding pins on the head unit's integrated map. Two way communication is also provided so that the application or AP runtime can notify each other when a specific data point is active or selected. There are two interfaces that the application can use to interact with Local infomation data: ILocalInfoDataConsumer and ILocalInfoDataReporter .","title":"Local Information Data"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#ilocalinfodataconsumer","text":"The IPresenter interace exposes a method to set the data consumer, which must be set by the application: /** * Saves a reference to the local info data consumer. * * @param consumer The object that consume local info data events. */ void setLocalInfoDataConsumer(ILocalInfoDataConsumer consumer); The application will be notified through the consumer method aplDataAvailable with a JSON string object represention all the points of interest. The application will be notified when a specific data point is selected on the APL document using the consume method aplDataItemSelectedById .","title":"ILocalInfoDataConsumer"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#ilocalinfodatareporter","text":"The APLPresenter implements the ILocalInfoDataReporter interface to allow the application to notify the APL runtime when a data point is selected outside of the APL runtime. To do this notification simply call platformDataItemSelectedById on the APLPresenter instance.","title":"ILocalInfoDataReporter"},{"location":"aacs/android/app-components/alexa-auto-apl-renderer/modules/apl-render/#building-the-apl-render-library","text":"Note: Before proceeding to build the APL Render library, download the Android APL resource from the developer portal according to instructions from your Solutions Architect or Partner Manager. This library can be built using the included gradle wrapper as follows ./gradlew assembleRelease","title":"Building the APL Render Library"},{"location":"aacs/android/app-components/alexa-auto-apps-common-ui/","text":"Alexa Auto Apps Common UI This package provides themes, colors, fonts, styles, icons, and other common UI elements for the AACS Sample App and app components to use.","title":"Alexa Auto Apps Common UI"},{"location":"aacs/android/app-components/alexa-auto-apps-common-ui/#alexa-auto-apps-common-ui","text":"This package provides themes, colors, fonts, styles, icons, and other common UI elements for the AACS Sample App and app components to use.","title":"Alexa Auto Apps Common UI"},{"location":"aacs/android/app-components/alexa-auto-apps-common-util/","text":"Alexa Auto Apps Common Util This package provides the AACS Sample App and app components with various helper classes to simplify the implementation. The provided utilities include: * Start, Stop and share files with AACS. * Get and set the Alexa properties. * Handle the file operations. * Get the enabled Alexa Auto SDK extra modules. * Get the network connectivity status. * Check the preconditions. * Manage the ambient light sensor and Alexa Auto theme update.","title":"Alexa Auto Apps Common Util"},{"location":"aacs/android/app-components/alexa-auto-apps-common-util/#alexa-auto-apps-common-util","text":"This package provides the AACS Sample App and app components with various helper classes to simplify the implementation. The provided utilities include: * Start, Stop and share files with AACS. * Get and set the Alexa properties. * Handle the file operations. * Get the enabled Alexa Auto SDK extra modules. * Get the network connectivity status. * Check the preconditions. * Manage the ambient light sensor and Alexa Auto theme update.","title":"Alexa Auto Apps Common Util"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/","text":"AACS Car Control The AACS Car Control library is an Android library for the AACS Core Service to run car control commands in cars that are based on Android Automotive OS. A car control command is run by the AACS Core Service each time the user tries to voice-control a vehicle component. Table of Contents Overview Understanding Library Components Building the AACS Car Control Library Before Using the AACS Car Control Library Including AACS Car Control Library in a System Application Providing Permission in Android Manifest Ensuring Intent Target Specified in the Library is Used Sequence Diagrams How the AACS Car Control Library Works Overview Using the AACS Car Control Library, AACS allows user utterances to be directly applied to Android Automotive OS car control APIs and then to the Hardware Abstraction Layer to complete the car control workflow. The library translates between Auto SDK Car Control events and Android Automotive CarPropertyManager API calls, which controls various car features, such as air conditioning and fan settings. For information about CarPropertyManager , see the Android documentation on CarPropertyManager . The library works with Android Car API and CarPropertyManager API . These APIs are only available at Android API level 29 and up. The library is an optional module. You can build it into an Android archive (AAR) to be included in your application. Understanding Library Components The following list describes the purposes of the major components of the library: The AACS Car Control Broadcast Receiver: Receiving AASB AdjustControllerValue or SetControllerValue messages from the AACS Core Service. Instantiating the Car Control Handler to call specific controller operations. The exact operations supported depend on the controller type, which can be Power, Toggle, Mode, or Range. The AACS Car Control platform implementation ( CarControlHandler ): Instantiating the Android Car object to be called in the set and adjust methods for each controller type. Defining the get and set methods for each controller type. Defining the adjust methods for the Range or Power Controller. The AACS Car Control Helper/Util: Providing translation between [endpointID, controllerType, controllerID, value] in the AASB Car Control message from the Auto SDK Engine to [propertyId, areaId, value] used in the Android Automotive API call. Getting or saving the current Mode setting for the Mode Controller. Enabling you to parse an external configuration file if you want to use a customized CarControlEndpointMapping.json file. Car Control Endpoint Mapping configuration file maps [endpointID, controllerType, controllerID, value] from the Auto SDK Car Control Asset to [propertyId, areaId, value] used in the Android Automotive API call. A default CarControlEndpointMapping.json file is provided in the assets directory. Be sure to review CarControlEndpointMapping.json to verify that it contains values consistent with the ones specified in the CarControlConfig.json file in the Car Control module . For example, if you have changed an endpointId in CarControlConfig.json from \"default.light\" to \"default.roof.light\" , the CarControlEndpointMapping.json file must contain the same endpoint mapping information. Building the AACS Car Control Library You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Car Control library: ./gradlew :alexa-auto-carcontrol:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-carcontrol/aacscarcontrol/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Car Control AAR. To enable car control support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with car control enabled. ./gradlew assembleLocalRelease -PenabledCarControl For more build options, see the AACS Sample App README . Before Using the AACS Car Control Library Before using the library, follow these major steps: 1) Install your application with the AACS and Car Control AARs as a system privileged app on Android Automotive OS. 2) Provide permission in your app's Android Manifest. 3) Ensure that the intent target specified in the library is used. Including AACS Car Control Library in a System Application For AACS to enable the permission namespace android.car.permission , it must run in a system privileged app. To install your application as a system privileged app, place it in the /system/priv-app/ directory. Providing Permission in Android Manifest For security reasons, for your application to send intents to or receive intents from the AACS Car Control Library, follow these steps: 1) In privapp-permissions-com.amazon.alexaautoclientservice.xml , specify android.car.permission . The following example file shows how to specify permissions for using intents for various car control operations. <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexaautoclientservice\" > <permission name= \"android.car.permission.CONTROL_CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_DOORS\" /> <permission name= \"android.car.permission.CONTROL_CAR_CLIMATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_SEATS\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_ENVIRONMENT\" /> <permission name= \"android.car.permission.CAR_ENERGY_PORTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_MIRRORS\" /> <permission name= \"android.car.permission.READ_CAR_DISPLAY_UNITS\" /> <permission name= \"android.car.permission.CONTROL_CAR_WINDOWS\" /> <permission name= \"android.car.permission.CAR_CONTROL_AUDIO_VOLUME\" /> <permission name= \"android.car.permission.CAR_DISPLAY_IN_CLUSTER\" /> <permission name= \"android.car.permission.CAR_INSTRUMENT_CLUSTER_CONTROL\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.READ_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CAR_DYNAMICS_STATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_DISPLAY_UNITS\" /> <permission name= \"android.permission.INTERNET\" /> <permission name= \"android.permission.RECORD_AUDIO\" /> <permission name= \"android.permission.ACCESS_FINE_LOCATION\" /> <permission name= \"android.permission.ACCESS_NETWORK_STATE\" /> <permission name= \"android.permission.ACCESS_WIFI_STATE\" /> <permission name= \"android.permission.RECEIVE_BOOT_COMPLETED\" /> <permission name= \"android.permission.CONTROL_INCALL_EXPERIENCE\" /> <permission name= \"android.permission.CAPTURE_AUDIO_OUTPUT\" /> <permission name= \"android.permission.INTERACT_ACROSS_USERS\" /> </privapp-permissions> </permissions> 2) Include privapp-permissions-com.amazon.alexaautoclientservice.xml in the /etc/permissions/ directory. Ensuring Intent Target Specified in the Library is Used The AACS Car Control Broadcast Receiver listens to intents from the AACS Core Service with the CarControl topic. The intent filter in the AACS Car Control Library already defines the intent target for CarControl . For the intent filter in the library to take effect, be sure to clear the intent target defined for CarControl in the AACS configuration as follows. Otherwise, the target specification in the AACS configuration overrides the intent filter in the library. \"CarControl\" : { \"type\" : [], \"package\" : [], \"class\" : [] } Sequence Diagrams The following diagram illustrates the flow when an utterance asks Alexa to set fan speed to 3. The following diagram illustrates the flow after the set value is finished at the hardware layer. How the AACS Car Control Library Works When the user issues an utterance, the Engine receives a car control event from Alexa, which the Engine passes to AACS through an AASB message. The AASB message received by AACS has the following attributes: Action is com.amazon.aacs.aasb.AdjustControllerValue or com.amazon.aacs.aasb.SetControllerValue . Category is com.amazon.aacs.aasb.CarControl . Extras is payload . The payload object includes detailed information about the action, which is specified in the messageDescription field of the AASB message. The following list describes the payload for each action: * For SetControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"POWER\", \"endpointId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } * For AdjustControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"TOGGLE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } * For SetModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : \"{{String}}\" } * For SetRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : {{Double}} } * For AdjustModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Integer}} } * For AdjustRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Double}} } After receiving the intent, the AACS Car Control Broadcast Receiver parses the payload and calls for the Car Control Handler to perform specific car control operations.","title":"AACS Car Control"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#aacs-car-control","text":"The AACS Car Control library is an Android library for the AACS Core Service to run car control commands in cars that are based on Android Automotive OS. A car control command is run by the AACS Core Service each time the user tries to voice-control a vehicle component.","title":"AACS Car Control"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#table-of-contents","text":"Overview Understanding Library Components Building the AACS Car Control Library Before Using the AACS Car Control Library Including AACS Car Control Library in a System Application Providing Permission in Android Manifest Ensuring Intent Target Specified in the Library is Used Sequence Diagrams How the AACS Car Control Library Works","title":"Table of Contents"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#overview","text":"Using the AACS Car Control Library, AACS allows user utterances to be directly applied to Android Automotive OS car control APIs and then to the Hardware Abstraction Layer to complete the car control workflow. The library translates between Auto SDK Car Control events and Android Automotive CarPropertyManager API calls, which controls various car features, such as air conditioning and fan settings. For information about CarPropertyManager , see the Android documentation on CarPropertyManager . The library works with Android Car API and CarPropertyManager API . These APIs are only available at Android API level 29 and up. The library is an optional module. You can build it into an Android archive (AAR) to be included in your application.","title":"Overview"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#understanding-library-components","text":"The following list describes the purposes of the major components of the library: The AACS Car Control Broadcast Receiver: Receiving AASB AdjustControllerValue or SetControllerValue messages from the AACS Core Service. Instantiating the Car Control Handler to call specific controller operations. The exact operations supported depend on the controller type, which can be Power, Toggle, Mode, or Range. The AACS Car Control platform implementation ( CarControlHandler ): Instantiating the Android Car object to be called in the set and adjust methods for each controller type. Defining the get and set methods for each controller type. Defining the adjust methods for the Range or Power Controller. The AACS Car Control Helper/Util: Providing translation between [endpointID, controllerType, controllerID, value] in the AASB Car Control message from the Auto SDK Engine to [propertyId, areaId, value] used in the Android Automotive API call. Getting or saving the current Mode setting for the Mode Controller. Enabling you to parse an external configuration file if you want to use a customized CarControlEndpointMapping.json file. Car Control Endpoint Mapping configuration file maps [endpointID, controllerType, controllerID, value] from the Auto SDK Car Control Asset to [propertyId, areaId, value] used in the Android Automotive API call. A default CarControlEndpointMapping.json file is provided in the assets directory. Be sure to review CarControlEndpointMapping.json to verify that it contains values consistent with the ones specified in the CarControlConfig.json file in the Car Control module . For example, if you have changed an endpointId in CarControlConfig.json from \"default.light\" to \"default.roof.light\" , the CarControlEndpointMapping.json file must contain the same endpoint mapping information.","title":"Understanding Library Components"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#building-the-aacs-car-control-library","text":"You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Car Control library: ./gradlew :alexa-auto-carcontrol:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-carcontrol/aacscarcontrol/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Car Control AAR. To enable car control support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with car control enabled. ./gradlew assembleLocalRelease -PenabledCarControl For more build options, see the AACS Sample App README .","title":"Building the AACS Car Control Library"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#before-using-the-aacs-car-control-library","text":"Before using the library, follow these major steps: 1) Install your application with the AACS and Car Control AARs as a system privileged app on Android Automotive OS. 2) Provide permission in your app's Android Manifest. 3) Ensure that the intent target specified in the library is used.","title":"Before Using the AACS Car Control Library"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#including-aacs-car-control-library-in-a-system-application","text":"For AACS to enable the permission namespace android.car.permission , it must run in a system privileged app. To install your application as a system privileged app, place it in the /system/priv-app/ directory.","title":"Including AACS Car Control Library in a System Application"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#providing-permission-in-android-manifest","text":"For security reasons, for your application to send intents to or receive intents from the AACS Car Control Library, follow these steps: 1) In privapp-permissions-com.amazon.alexaautoclientservice.xml , specify android.car.permission . The following example file shows how to specify permissions for using intents for various car control operations. <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexaautoclientservice\" > <permission name= \"android.car.permission.CONTROL_CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_DOORS\" /> <permission name= \"android.car.permission.CONTROL_CAR_CLIMATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_SEATS\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_ENVIRONMENT\" /> <permission name= \"android.car.permission.CAR_ENERGY_PORTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_MIRRORS\" /> <permission name= \"android.car.permission.READ_CAR_DISPLAY_UNITS\" /> <permission name= \"android.car.permission.CONTROL_CAR_WINDOWS\" /> <permission name= \"android.car.permission.CAR_CONTROL_AUDIO_VOLUME\" /> <permission name= \"android.car.permission.CAR_DISPLAY_IN_CLUSTER\" /> <permission name= \"android.car.permission.CAR_INSTRUMENT_CLUSTER_CONTROL\" /> <permission name= \"android.car.permission.CAR_EXTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CONTROL_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.READ_CAR_INTERIOR_LIGHTS\" /> <permission name= \"android.car.permission.CAR_DYNAMICS_STATE\" /> <permission name= \"android.car.permission.CONTROL_CAR_DISPLAY_UNITS\" /> <permission name= \"android.permission.INTERNET\" /> <permission name= \"android.permission.RECORD_AUDIO\" /> <permission name= \"android.permission.ACCESS_FINE_LOCATION\" /> <permission name= \"android.permission.ACCESS_NETWORK_STATE\" /> <permission name= \"android.permission.ACCESS_WIFI_STATE\" /> <permission name= \"android.permission.RECEIVE_BOOT_COMPLETED\" /> <permission name= \"android.permission.CONTROL_INCALL_EXPERIENCE\" /> <permission name= \"android.permission.CAPTURE_AUDIO_OUTPUT\" /> <permission name= \"android.permission.INTERACT_ACROSS_USERS\" /> </privapp-permissions> </permissions> 2) Include privapp-permissions-com.amazon.alexaautoclientservice.xml in the /etc/permissions/ directory.","title":"Providing Permission in Android Manifest"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#ensuring-intent-target-specified-in-the-library-is-used","text":"The AACS Car Control Broadcast Receiver listens to intents from the AACS Core Service with the CarControl topic. The intent filter in the AACS Car Control Library already defines the intent target for CarControl . For the intent filter in the library to take effect, be sure to clear the intent target defined for CarControl in the AACS configuration as follows. Otherwise, the target specification in the AACS configuration overrides the intent filter in the library. \"CarControl\" : { \"type\" : [], \"package\" : [], \"class\" : [] }","title":"Ensuring Intent Target Specified in the Library is Used"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#sequence-diagrams","text":"The following diagram illustrates the flow when an utterance asks Alexa to set fan speed to 3. The following diagram illustrates the flow after the set value is finished at the hardware layer.","title":"Sequence Diagrams"},{"location":"aacs/android/app-components/alexa-auto-carcontrol/#how-the-aacs-car-control-library-works","text":"When the user issues an utterance, the Engine receives a car control event from Alexa, which the Engine passes to AACS through an AASB message. The AASB message received by AACS has the following attributes: Action is com.amazon.aacs.aasb.AdjustControllerValue or com.amazon.aacs.aasb.SetControllerValue . Category is com.amazon.aacs.aasb.CarControl . Extras is payload . The payload object includes detailed information about the action, which is specified in the messageDescription field of the AASB message. The following list describes the payload for each action: * For SetControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"POWER\", \"endpointId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } * For AdjustControllerValue , the payload has the following schema: \"payload\" : { \"controllerType\" : \"TOGGLE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"turnOn\" : {{Boolean}} } * For SetModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : \"{{String}}\" } * For SetRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"value\" : {{Double}} } * For AdjustModeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"MODE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Integer}} } * For AdjustRangeController , the payload has the following schema: \"payload\" : { \"controllerType\" : \"RANGE\", \"endpointId\" : \"{{String}}\", \"controllerId\" : \"{{String}}\", \"delta\" : {{Double}} } After receiving the intent, the AACS Car Control Broadcast Receiver parses the payload and calls for the Car Control Handler to perform specific car control operations.","title":"How the AACS Car Control Library Works"},{"location":"aacs/android/app-components/alexa-auto-comms-ui/","text":"Alexa Auto Comms UI This library serves the following purposes: It handles Bluetooth-related directives. When a Bluetooth device is connected or disconnected, the BluetoothReceiver class receives the intent with device connection status, and device MAC address and display name. It also calls the BluetoothDirectiveHandler class to update the Bluetooth device database based on the change. It handles contacts upload or removal requests to Alexa. This library starts the AACS contacts service intents to handle contacts upload or removal requests. Alexa setup screen provides options for the user to give or decline consent to contact uploads on the primary phone. The Alexa communication settings screen displays a list of connected devices with contacts upload permission status. The user can turn on or turn off the contacts upload permission for each device. If the contacts permission for the primary phone is enabled, the contacts in that device will be uploaded. If the contacts permission for a non-primary phone is enabled, the contacts in that phone will not be uploaded until the phone is selected as the primary. On the Android Automotive OS, the last connected phone is considered as the primary device. If you want to change this default behavior, implement your own system UI for users to select the primary phone and call the Android system API setUserSelectedOutgoingPhoneAccount to set the user-selected outgoing phone account. Send a com.amazon.alexa.auto.comms.primaryPhoneChanged intent to Alexa Auto Comms UI to inform the change of the primary phone. ComponentName c = new ComponentName(\"com.amazon.alexa.auto.app\", \"com.amazon.alexa.auto.comms.ui.receiver.BluetoothReceiver\"); intent.setComponent(c); intent.addCategory(\"com.amazon.alexa.auto.comms\"); intent.setAction(\"com.amazon.alexa.auto.comms.primaryPhoneChanged\"); sendBroadcast(intent); Prerequisites The following list describes the prerequisites for this library: * AACS Telephony and Contacts libraries must be built. * Your Android device must meet the prerequisites for using the AACS Telephony library .","title":"Alexa Auto Comms UI"},{"location":"aacs/android/app-components/alexa-auto-comms-ui/#alexa-auto-comms-ui","text":"This library serves the following purposes: It handles Bluetooth-related directives. When a Bluetooth device is connected or disconnected, the BluetoothReceiver class receives the intent with device connection status, and device MAC address and display name. It also calls the BluetoothDirectiveHandler class to update the Bluetooth device database based on the change. It handles contacts upload or removal requests to Alexa. This library starts the AACS contacts service intents to handle contacts upload or removal requests. Alexa setup screen provides options for the user to give or decline consent to contact uploads on the primary phone. The Alexa communication settings screen displays a list of connected devices with contacts upload permission status. The user can turn on or turn off the contacts upload permission for each device. If the contacts permission for the primary phone is enabled, the contacts in that device will be uploaded. If the contacts permission for a non-primary phone is enabled, the contacts in that phone will not be uploaded until the phone is selected as the primary. On the Android Automotive OS, the last connected phone is considered as the primary device. If you want to change this default behavior, implement your own system UI for users to select the primary phone and call the Android system API setUserSelectedOutgoingPhoneAccount to set the user-selected outgoing phone account. Send a com.amazon.alexa.auto.comms.primaryPhoneChanged intent to Alexa Auto Comms UI to inform the change of the primary phone. ComponentName c = new ComponentName(\"com.amazon.alexa.auto.app\", \"com.amazon.alexa.auto.comms.ui.receiver.BluetoothReceiver\"); intent.setComponent(c); intent.addCategory(\"com.amazon.alexa.auto.comms\"); intent.setAction(\"com.amazon.alexa.auto.comms.primaryPhoneChanged\"); sendBroadcast(intent);","title":"Alexa Auto Comms UI"},{"location":"aacs/android/app-components/alexa-auto-comms-ui/#prerequisites","text":"The following list describes the prerequisites for this library: * AACS Telephony and Contacts libraries must be built. * Your Android device must meet the prerequisites for using the AACS Telephony library .","title":"Prerequisites"},{"location":"aacs/android/app-components/alexa-auto-contacts/","text":"AACS Contacts The AACS Contacts library is an Android library used by the AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information. Table of Contents Overview Building the Library Setup for AACS Contacts Library Sequence Diagrams How the AACS Contacts Library Works with an Address Book Overview Using the Contacts Library, AACS enables your app to interact with the Auto SDK Engine easily to add or remove an address book, which contains all contact information maintained by the Android Contacts Provider. For information about Contacts Provider, see the Contact Provider documentation . Note: An address book can be of the type Contact or Navigation. The Contacts Library only works with the Contact type. For example, AACS cannot use the library to fetch data about a navigation favorite. See the Address Book Module README for more information about the AddressBookType API. The following list describes the major components of the library: The AACS Contacts Service is responsible for: Receiving AASB AddAddressBook or RemoveAddressBook messages from the AACS Core Service. Receiving defined intents from your application to upload or remove an address book The AACS Contacts Library platform implementation ( PhoneBookController ) is responsible for: Fetching the address book from the Android Contacts Provider Parsing all contact data from the address book into an AASB AddAddressBook message Sending the AASB AddAddressBook intent to the AACS Core Service to upload the address book to Alexa Sending the AASB RemoveAddressBook intent to the AACS Core Service to remove from Alexa an address book with a specific addressBookSourceId , a unique address book identifier defined in the Address Book handler (Bluetooth MAC address of connected phone) Providing the API for adding or removing an address book for your application to call The AACS Contacts Library is an optional module, which you can use as is or as a reference when you integrate the Address Book module with AACS. You can build it into an Android archive (AAR) to be included in the AACS APK (recommended) or in your application APK. Building the Library You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Contacts library: ./gradlew :alexa-auto-contacts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-contacts/aacscontacts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Contacts AAR. To enable contacts support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with contacts enabled. ./gradlew assembleLocalRelease -PenabledContacts For more build options, see the AACS Sample App README . Setup for AACS Contacts Library Before using the AACS Contacts Library, follow these major steps: 1) Provide permission in your application's Android manifest. 2) Specify targets for intents from the AACS Core Service. Providing Permission in Android Manifest For security reasons, for your application to send intents to or receive intents from the AACS Contacts Service, specify the com.amazon.aacscontacts permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacscontacts\" /> Specifying Intent Targets The AACS Contacts Service listens to intents from the AACS Core Service with the AddressBook topic. To specify AACS Contacts Service with an intent target for the AddressBook topic, follow one of these steps: Manually specify the messages in the AACS configuration file, as described in the AACS README . The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify an intent target in the AACS configuration file. In this example, the AACS Contacts Library AAR is part of the AACS APK. \"AddressBook\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexaautoclientservice\", ...], \"class\": [\"<target_1_class_name>\", \"com.amazon.aacscontacts.AACSContactsService\", ...] } Omit ANY targets for AddressBook in the AACS configuration file. As a result, the intent filter defined in the AACS Contacts Library takes effect, enabling the AACS Contacts Service to receive the intents. Sequence Diagrams The following diagram illustrates the flow when an address book is uploaded to Alexa. The following diagram illustrates the flow when an address book is removed from Alexa. How the AACS Contacts Library Works with an Address Book This section describes how the Contacts Library uploads or removes an address book. Uploading Address Book Use one of the following methods to upload an address book to Alexa: Use intent. Your application can inform the AACS Contacts Library to upload an address book to Alexa by using an intent. When the AACS Contacts Library receives the intent, the library fetches contacts from the Contacts Provider on the head unit and uploads them to Alexa. To determine whether the upload is successful, your application can subscribe to the AASB AddressBook intents. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.upload . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (Must be Bluetooth MAC address from connected phone fetched from client application) and the name of the address book (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\", \"addressBookName\": \"<Name of phone book>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.uploadContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.uploadContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.uploadContacts(addressBookSourceId, addressBookName); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts upload working properly Removing Address Book Use one of the following methods to remove an address book from Alexa: Use intent. Your application can inform the AACS Contacts Service to remove an address book from Alexa by using an intent. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.remove . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.removeContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.removeContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.removeContacts(addressBookSourceId); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts remove working properly","title":"AACS Contacts"},{"location":"aacs/android/app-components/alexa-auto-contacts/#aacs-contacts","text":"The AACS Contacts library is an Android library used by the AACS Core Service to fetch contact information from the vehicle's head unit and send it to Alexa. The AACS Core Service can also use this library to remove from Alexa the uploaded contact information.","title":"AACS Contacts"},{"location":"aacs/android/app-components/alexa-auto-contacts/#table-of-contents","text":"Overview Building the Library Setup for AACS Contacts Library Sequence Diagrams How the AACS Contacts Library Works with an Address Book","title":"Table of Contents"},{"location":"aacs/android/app-components/alexa-auto-contacts/#overview","text":"Using the Contacts Library, AACS enables your app to interact with the Auto SDK Engine easily to add or remove an address book, which contains all contact information maintained by the Android Contacts Provider. For information about Contacts Provider, see the Contact Provider documentation . Note: An address book can be of the type Contact or Navigation. The Contacts Library only works with the Contact type. For example, AACS cannot use the library to fetch data about a navigation favorite. See the Address Book Module README for more information about the AddressBookType API. The following list describes the major components of the library: The AACS Contacts Service is responsible for: Receiving AASB AddAddressBook or RemoveAddressBook messages from the AACS Core Service. Receiving defined intents from your application to upload or remove an address book The AACS Contacts Library platform implementation ( PhoneBookController ) is responsible for: Fetching the address book from the Android Contacts Provider Parsing all contact data from the address book into an AASB AddAddressBook message Sending the AASB AddAddressBook intent to the AACS Core Service to upload the address book to Alexa Sending the AASB RemoveAddressBook intent to the AACS Core Service to remove from Alexa an address book with a specific addressBookSourceId , a unique address book identifier defined in the Address Book handler (Bluetooth MAC address of connected phone) Providing the API for adding or removing an address book for your application to call The AACS Contacts Library is an optional module, which you can use as is or as a reference when you integrate the Address Book module with AACS. You can build it into an Android archive (AAR) to be included in the AACS APK (recommended) or in your application APK.","title":"Overview"},{"location":"aacs/android/app-components/alexa-auto-contacts/#building-the-library","text":"You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Contacts library: ./gradlew :alexa-auto-contacts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-contacts/aacscontacts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Contacts AAR. To enable contacts support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with contacts enabled. ./gradlew assembleLocalRelease -PenabledContacts For more build options, see the AACS Sample App README .","title":"Building the Library"},{"location":"aacs/android/app-components/alexa-auto-contacts/#setup-for-aacs-contacts-library","text":"Before using the AACS Contacts Library, follow these major steps: 1) Provide permission in your application's Android manifest. 2) Specify targets for intents from the AACS Core Service.","title":"Setup for AACS Contacts Library"},{"location":"aacs/android/app-components/alexa-auto-contacts/#providing-permission-in-android-manifest","text":"For security reasons, for your application to send intents to or receive intents from the AACS Contacts Service, specify the com.amazon.aacscontacts permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacscontacts\" />","title":"Providing Permission in Android Manifest"},{"location":"aacs/android/app-components/alexa-auto-contacts/#specifying-intent-targets","text":"The AACS Contacts Service listens to intents from the AACS Core Service with the AddressBook topic. To specify AACS Contacts Service with an intent target for the AddressBook topic, follow one of these steps: Manually specify the messages in the AACS configuration file, as described in the AACS README . The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify an intent target in the AACS configuration file. In this example, the AACS Contacts Library AAR is part of the AACS APK. \"AddressBook\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexaautoclientservice\", ...], \"class\": [\"<target_1_class_name>\", \"com.amazon.aacscontacts.AACSContactsService\", ...] } Omit ANY targets for AddressBook in the AACS configuration file. As a result, the intent filter defined in the AACS Contacts Library takes effect, enabling the AACS Contacts Service to receive the intents.","title":"Specifying Intent Targets"},{"location":"aacs/android/app-components/alexa-auto-contacts/#sequence-diagrams","text":"The following diagram illustrates the flow when an address book is uploaded to Alexa. The following diagram illustrates the flow when an address book is removed from Alexa.","title":"Sequence Diagrams"},{"location":"aacs/android/app-components/alexa-auto-contacts/#how-the-aacs-contacts-library-works-with-an-address-book","text":"This section describes how the Contacts Library uploads or removes an address book.","title":"How the AACS Contacts Library Works with an Address Book"},{"location":"aacs/android/app-components/alexa-auto-contacts/#uploading-address-book","text":"Use one of the following methods to upload an address book to Alexa: Use intent. Your application can inform the AACS Contacts Library to upload an address book to Alexa by using an intent. When the AACS Contacts Library receives the intent, the library fetches contacts from the Contacts Provider on the head unit and uploads them to Alexa. To determine whether the upload is successful, your application can subscribe to the AASB AddressBook intents. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.upload . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (Must be Bluetooth MAC address from connected phone fetched from client application) and the name of the address book (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\", \"addressBookName\": \"<Name of phone book>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.uploadContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.uploadContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.uploadContacts(addressBookSourceId, addressBookName); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts upload working properly","title":"Uploading Address Book"},{"location":"aacs/android/app-components/alexa-auto-contacts/#removing-address-book","text":"Use one of the following methods to remove an address book from Alexa: Use intent. Your application can inform the AACS Contacts Service to remove an address book from Alexa by using an intent. Define the attributes of the intent as follows: Action is com.amazon.aacscontacts.remove . Category is com.amazon.aacscontacts . Extras is addressBookSourceId (defined in the Address Book platform interface), specified as follows: { \"addressBookSourceId\": \"<addressBookSourceId>\" } Use a direct API call. This method is applicable only if you put the AACS Contacts Library in your application. The PhoneBookController.removeContacts API blocks the current thread and returns a boolean value indicating if the operation is successful. The following code shows how to use PhoneBookController.removeContacts : // Instantiate PhoneBookController PhoneBookController phoneBookController = new PhoneBookController(context); Boolean succeeded = phoneBookController.removeContacts(addressBookSourceId); Note that addressBookSourceId must be Bluetooth MAC address from connected phone fetched from client application in order to have contacts remove working properly","title":"Removing Address Book"},{"location":"aacs/android/app-components/alexa-auto-device-usage/","text":"Alexa Auto Device Usage Alexa Auto Device Usage library provides an implementation that enables the AACS Sample App to capture network usage data of Alexa Auto Client Service (AACS) using Android NetworkStatsManager . The data is logged as a metric and is sent to Amazon endpoints if AACS is built with the Device Client Metrics (DCM) extension. To obtain the pre-built AACS AAR with DCM extension, contact your Amazon Solutions Architect (SA) or Partner Manager for more information. Overview The library consists of the following components: * AASBReceiver . This Android BroadcastReceiver subsribes to AASB StartService message and AASB StopService message to get the current AACS running status, based on which the DeviceUsageHandler can start or stop the network data recording. * DeviceUsageHandler . The handler is responsible for starting and stopping the NetworkStatsManagerRunner according to the AACS running status. It starts the NetworkStatsManagerRunner in an executor thread which queries the network usage every 5 minutes and publishes the data via DeviceUsage ReportNetworkDataUsageMessage message to the Auto SDK engine. * NetworkStatsManagerRunner . This class captures the network usage data using NetworkStatsManager APIs and calls the DeviceUsageHandler to report the data. Providing Permissions for Alexa Auto Device Usage Library Using the Alexa Auto Device Usage Library requires the AACS sample app to hold certain Android permissions. If the Android version of your device is lower than 10 (Android Q): The Alexa application needs the android.permission.READ_PHONE_STATE permission to access the subscriber id (associated to the eSIM of a user), which is required to query the network consumption over the MOBILE interface. You can grant this permission to AACS sample app in \"Settings\" -> \"Apps & notifications\" -> \"Alexa\" -> \"Permissions\" -> \"Phone\". If the Android version of your device is 10 (Android Q) or higher: The Alexa application must be installed as a privileged system application and it must have the android.permission.READ_PRIVILEGED_PHONE_STATE privileged permission in order to be able to get the subscriber id . Note The Alexa Auto Device Usage Library carries all the Android permissions ( READ_PHONE_STATE , READ_PRIVILEGED_PHONE_STATE and PACKAGE_USAGE_STATS ) your application needs in order to enable the network usage data recording. To use this library, make sure your AACS sample app is built with the -PenabledDeviceUsage option, as specified in the Building AACS Sample App with Alexa Auto Device Usage Library section. If your device is on Android 10 or higher version, install AACS sample app as a system privileged app, and place the following privapp-permissions-com.amazon.alexa.auto.app.xml file under the /etc/permissions directory on your device: <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexa.auto.app\" > <permission name= \"android.permission.READ_PRIVILEGED_PHONE_STATE\" /> <permission name= \"android.permission.PACKAGE_USAGE_STATS\" /> </privapp-permissions> </permissions> Building AACS Sample App with Alexa Auto Device Usage Library To build the AACS Sample App with Alexa Auto Device Usage library, go to ${AAC_SDK_HOME}/samples/android-aacs-sample-app/ and enter the following command: // release build gradle assembleRelease -PenabledDeviceUsage // debug build gradle assembleDebug -PenabledDeviceUsage","title":"Alexa Auto Device Usage"},{"location":"aacs/android/app-components/alexa-auto-device-usage/#alexa-auto-device-usage","text":"Alexa Auto Device Usage library provides an implementation that enables the AACS Sample App to capture network usage data of Alexa Auto Client Service (AACS) using Android NetworkStatsManager . The data is logged as a metric and is sent to Amazon endpoints if AACS is built with the Device Client Metrics (DCM) extension. To obtain the pre-built AACS AAR with DCM extension, contact your Amazon Solutions Architect (SA) or Partner Manager for more information.","title":"Alexa Auto Device Usage"},{"location":"aacs/android/app-components/alexa-auto-device-usage/#overview","text":"The library consists of the following components: * AASBReceiver . This Android BroadcastReceiver subsribes to AASB StartService message and AASB StopService message to get the current AACS running status, based on which the DeviceUsageHandler can start or stop the network data recording. * DeviceUsageHandler . The handler is responsible for starting and stopping the NetworkStatsManagerRunner according to the AACS running status. It starts the NetworkStatsManagerRunner in an executor thread which queries the network usage every 5 minutes and publishes the data via DeviceUsage ReportNetworkDataUsageMessage message to the Auto SDK engine. * NetworkStatsManagerRunner . This class captures the network usage data using NetworkStatsManager APIs and calls the DeviceUsageHandler to report the data.","title":"Overview"},{"location":"aacs/android/app-components/alexa-auto-device-usage/#providing-permissions-for-alexa-auto-device-usage-library","text":"Using the Alexa Auto Device Usage Library requires the AACS sample app to hold certain Android permissions. If the Android version of your device is lower than 10 (Android Q): The Alexa application needs the android.permission.READ_PHONE_STATE permission to access the subscriber id (associated to the eSIM of a user), which is required to query the network consumption over the MOBILE interface. You can grant this permission to AACS sample app in \"Settings\" -> \"Apps & notifications\" -> \"Alexa\" -> \"Permissions\" -> \"Phone\". If the Android version of your device is 10 (Android Q) or higher: The Alexa application must be installed as a privileged system application and it must have the android.permission.READ_PRIVILEGED_PHONE_STATE privileged permission in order to be able to get the subscriber id . Note The Alexa Auto Device Usage Library carries all the Android permissions ( READ_PHONE_STATE , READ_PRIVILEGED_PHONE_STATE and PACKAGE_USAGE_STATS ) your application needs in order to enable the network usage data recording. To use this library, make sure your AACS sample app is built with the -PenabledDeviceUsage option, as specified in the Building AACS Sample App with Alexa Auto Device Usage Library section. If your device is on Android 10 or higher version, install AACS sample app as a system privileged app, and place the following privapp-permissions-com.amazon.alexa.auto.app.xml file under the /etc/permissions directory on your device: <?xml version=\"1.0\" encoding=\"utf-8\"?> <permissions> <privapp-permissions package= \"com.amazon.alexa.auto.app\" > <permission name= \"android.permission.READ_PRIVILEGED_PHONE_STATE\" /> <permission name= \"android.permission.PACKAGE_USAGE_STATS\" /> </privapp-permissions> </permissions>","title":"Providing Permissions for Alexa Auto Device Usage Library"},{"location":"aacs/android/app-components/alexa-auto-device-usage/#building-aacs-sample-app-with-alexa-auto-device-usage-library","text":"To build the AACS Sample App with Alexa Auto Device Usage library, go to ${AAC_SDK_HOME}/samples/android-aacs-sample-app/ and enter the following command: // release build gradle assembleRelease -PenabledDeviceUsage // debug build gradle assembleDebug -PenabledDeviceUsage","title":"Building AACS Sample App with Alexa Auto Device Usage Library"},{"location":"aacs/android/app-components/alexa-auto-lwa-auth/","text":"Alexa Auto Login with Amazon Authorization This package provides an implementation of AuthController defined in the alexa-auto-apis package. The AuthController implementation uses the Login with Amazon (LWA) authorization service provided by the Alexa Auto SDK and Alexa Auto Client Service (AACS). The AuthController implementation is useful for observing changes in the authentication state (indicated by the Boolean value of loggedIn ). The AuthController implementation also provides the workflow for starting authentication. After the user installs an app on an Alexa-enabled device for the first time or when the logged-off user tries to log in again, the authentication process starts. The workflow provided by AuthController supports LWA using code-based linking (CBL) as the authorization method. The CBL code obtained through the authentication workflow is displayed on the head unit device so that the user can enter the CBL code on their mobile device to authenticate the head unit device.","title":"Alexa Auto Login with Amazon Authorization"},{"location":"aacs/android/app-components/alexa-auto-lwa-auth/#alexa-auto-login-with-amazon-authorization","text":"This package provides an implementation of AuthController defined in the alexa-auto-apis package. The AuthController implementation uses the Login with Amazon (LWA) authorization service provided by the Alexa Auto SDK and Alexa Auto Client Service (AACS). The AuthController implementation is useful for observing changes in the authentication state (indicated by the Boolean value of loggedIn ). The AuthController implementation also provides the workflow for starting authentication. After the user installs an app on an Alexa-enabled device for the first time or when the logged-off user tries to log in again, the authentication process starts. The workflow provided by AuthController supports LWA using code-based linking (CBL) as the authorization method. The CBL code obtained through the authentication workflow is displayed on the head unit device so that the user can enter the CBL code on their mobile device to authenticate the head unit device.","title":"Alexa Auto Login with Amazon Authorization"},{"location":"aacs/android/app-components/alexa-auto-media-player/","text":"Alexa Auto Media Player Table of Contents Alexa Auto Media Player Include Alexa Auto Media Player in the Application Enable Media Ducking Media Resume Alexa Music After Reboot Login from Android Automotive Media UI Alexa Music Certification Alexa Auto Media Player The following list describes the purposes of this package: * It provides the audio player capability for Alexa Auto Client Service (AACS) by receiving all audio player intents and notifying AACS about the progress of media playback. * It manages the underlying media player, which is ExoPlayer. * It handles audio focus. * It implements a media session on top of the media player so that media can be controlled with standard Android Media Session APIs. This capability allows Alexa Media to integrate with the Android Automotive Media UI. Include Alexa Auto Media Player in the Application The Alexa Auto Media Player is by default enabled in the AACS Sample App. See the AACS Sample App README for build instructions. If you want to use Alexa Auto Media Player in your application, build the following app components and include all the generated AARs in your application: * alexa-auto-apis * alexa-auto-apps-common-ui * alexa-auto-apps-common-util * alexa-auto-media-player Enable Media Ducking You can enable audio ducking for the Alexa media using this configuration. By default, Alexa pauses MUSIC channel whenever Alexa TTS or ALARM channels are in the focus. Enabling ducking allows MUSIC channel to remain in the playing state when high priority channels like TTS and ALARM are active. For enabling ducking, please provide the following configuration: { \"aacs.alexa\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } } Media Resume Alexa Music After Reboot Please refer to Media Resume Last Playing Media After Platform Reboot for the details about media resume feature. This feature works out of the box on Automotive Android OS with this component. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } } Login from Android Automotive Media UI This library provides an optional feature that enables the Android Automotive Media UI to display the \"not authenticated\" message if the app is not authenticated. It then offers the option for the user to invoke the login UI workflow. To enable this feature in the app with this library, implement AlexaApp , a registry interface defined in the Alexa Auto APIs package, and resolve dependencies by using the following interfaces: * AuthController : This interface provides business logic to monitor the current authentication state (the value of loggedIn ). The interface is made available from AlexaAppRootComponent . * AlexaSetupController : This interface enables the media UI to launch the login UI activity if the authentication state indicates that the user is not logged in. Note: See the alexa-auto-apis README for more information about consuming and publishing implementations. Alexa Music Certification This version of the Alexa Auto Media Player doesn\u2019t meet all the Alexa Music Certification requirements on Android Automotive OS. It passes API validation for Amazon Music, Audible, Kindle, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, and iHeart Radio Custom. Pandora doesn\u2019t have an API validation requirement. The Media Player doesn\u2019t pass Music Service Provider (MSP) logo attribution GUI validation for Amazon Music, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, iHeart Radio Custom, and Pandora. Audible and Kindle don't have a GUI validation requirement. The Android Automotive OS doesn't have placeholder for showing MSP logo which is required for passing GUI validation. The Media Player provides text based MSP attribution. The Android Automotive OS displays album art as the background image in media player screen, which doesn't pass GUI validation of not altering album art in any way. Due to the missing media controls in TemplateRuntime RenderPlayerInfo payload, the Media Player fails to display all the required media controls, which doesn't pass media controls GUI validation. The standard certification process is required and simplified by the Alexa Auto Media Player because the above mentioned API validation has been completed. Contact your Solutions Architect (SA) or Partner Manager for information about how to obtain certification. Known Issues On low resolution screens, Music Service Provider (MSP) name may cut-off when artist string is long.","title":"Alexa Auto Media Player"},{"location":"aacs/android/app-components/alexa-auto-media-player/#alexa-auto-media-player","text":"","title":"Alexa Auto Media Player"},{"location":"aacs/android/app-components/alexa-auto-media-player/#table-of-contents","text":"Alexa Auto Media Player Include Alexa Auto Media Player in the Application Enable Media Ducking Media Resume Alexa Music After Reboot Login from Android Automotive Media UI Alexa Music Certification","title":"Table of Contents"},{"location":"aacs/android/app-components/alexa-auto-media-player/#alexa-auto-media-player_1","text":"The following list describes the purposes of this package: * It provides the audio player capability for Alexa Auto Client Service (AACS) by receiving all audio player intents and notifying AACS about the progress of media playback. * It manages the underlying media player, which is ExoPlayer. * It handles audio focus. * It implements a media session on top of the media player so that media can be controlled with standard Android Media Session APIs. This capability allows Alexa Media to integrate with the Android Automotive Media UI.","title":"Alexa Auto Media Player"},{"location":"aacs/android/app-components/alexa-auto-media-player/#include-alexa-auto-media-player-in-the-application","text":"The Alexa Auto Media Player is by default enabled in the AACS Sample App. See the AACS Sample App README for build instructions. If you want to use Alexa Auto Media Player in your application, build the following app components and include all the generated AARs in your application: * alexa-auto-apis * alexa-auto-apps-common-ui * alexa-auto-apps-common-util * alexa-auto-media-player","title":"Include Alexa Auto Media Player in the Application"},{"location":"aacs/android/app-components/alexa-auto-media-player/#enable-media-ducking","text":"You can enable audio ducking for the Alexa media using this configuration. By default, Alexa pauses MUSIC channel whenever Alexa TTS or ALARM channels are in the focus. Enabling ducking allows MUSIC channel to remain in the playing state when high priority channels like TTS and ALARM are active. For enabling ducking, please provide the following configuration: { \"aacs.alexa\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } }","title":"Enable Media Ducking"},{"location":"aacs/android/app-components/alexa-auto-media-player/#media-resume-alexa-music-after-reboot","text":"Please refer to Media Resume Last Playing Media After Platform Reboot for the details about media resume feature. This feature works out of the box on Automotive Android OS with this component. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } }","title":"Media Resume Alexa Music After Reboot"},{"location":"aacs/android/app-components/alexa-auto-media-player/#login-from-android-automotive-media-ui","text":"This library provides an optional feature that enables the Android Automotive Media UI to display the \"not authenticated\" message if the app is not authenticated. It then offers the option for the user to invoke the login UI workflow. To enable this feature in the app with this library, implement AlexaApp , a registry interface defined in the Alexa Auto APIs package, and resolve dependencies by using the following interfaces: * AuthController : This interface provides business logic to monitor the current authentication state (the value of loggedIn ). The interface is made available from AlexaAppRootComponent . * AlexaSetupController : This interface enables the media UI to launch the login UI activity if the authentication state indicates that the user is not logged in. Note: See the alexa-auto-apis README for more information about consuming and publishing implementations.","title":"Login from Android Automotive Media UI"},{"location":"aacs/android/app-components/alexa-auto-media-player/#alexa-music-certification","text":"This version of the Alexa Auto Media Player doesn\u2019t meet all the Alexa Music Certification requirements on Android Automotive OS. It passes API validation for Amazon Music, Audible, Kindle, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, and iHeart Radio Custom. Pandora doesn\u2019t have an API validation requirement. The Media Player doesn\u2019t pass Music Service Provider (MSP) logo attribution GUI validation for Amazon Music, TuneIn Radio Live, TuneIn Radio Custom, Music Skills (Deezer & SiriusXM), iHeart Radio Live, iHeart Radio Custom, and Pandora. Audible and Kindle don't have a GUI validation requirement. The Android Automotive OS doesn't have placeholder for showing MSP logo which is required for passing GUI validation. The Media Player provides text based MSP attribution. The Android Automotive OS displays album art as the background image in media player screen, which doesn't pass GUI validation of not altering album art in any way. Due to the missing media controls in TemplateRuntime RenderPlayerInfo payload, the Media Player fails to display all the required media controls, which doesn't pass media controls GUI validation. The standard certification process is required and simplified by the Alexa Auto Media Player because the above mentioned API validation has been completed. Contact your Solutions Architect (SA) or Partner Manager for information about how to obtain certification.","title":"Alexa Music Certification"},{"location":"aacs/android/app-components/alexa-auto-media-player/#known-issues","text":"On low resolution screens, Music Service Provider (MSP) name may cut-off when artist string is long.","title":"Known Issues"},{"location":"aacs/android/app-components/alexa-auto-navigation/","text":"Alexa Auto Navigation This library serves the following purposes: It handles navigation-related directives. By parsing a navigation directive and interfacing with the selected map provider, it performs the action required by the directive. The map provider used by the AACS Sample App is Google Maps. However, you can extend the library to use other map providers. This library supports navigating to a single waypoint and canceling an ongoing navigation. It handles local search template runtime directives. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directive and renders local search cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). ## Prerequisites To see local search templates your device type needs to be navigation capable.","title":"Alexa Auto Navigation"},{"location":"aacs/android/app-components/alexa-auto-navigation/#alexa-auto-navigation","text":"This library serves the following purposes: It handles navigation-related directives. By parsing a navigation directive and interfacing with the selected map provider, it performs the action required by the directive. The map provider used by the AACS Sample App is Google Maps. However, you can extend the library to use other map providers. This library supports navigating to a single waypoint and canceling an ongoing navigation. It handles local search template runtime directives. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directive and renders local search cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). ## Prerequisites To see local search templates your device type needs to be navigation capable.","title":"Alexa Auto Navigation"},{"location":"aacs/android/app-components/alexa-auto-settings/","text":"Alexa Auto Settings This package provides code containing business logic and UI components for the settings menu which is shown to the user after setup is successful. The AlexaSettingsHomeFragment houses top level settings that are available to users. Known Gaps The following features have not been developed on the settings screen yet Navigation favorites permission Push to talk Things to try Communication settings do not satisfy CX requirements. Refer to the HMI Guidelines - Communications section for guidance or work with your Amazon partner manager","title":"Alexa Auto Settings"},{"location":"aacs/android/app-components/alexa-auto-settings/#alexa-auto-settings","text":"This package provides code containing business logic and UI components for the settings menu which is shown to the user after setup is successful. The AlexaSettingsHomeFragment houses top level settings that are available to users.","title":"Alexa Auto Settings"},{"location":"aacs/android/app-components/alexa-auto-settings/#known-gaps","text":"The following features have not been developed on the settings screen yet Navigation favorites permission Push to talk Things to try Communication settings do not satisfy CX requirements. Refer to the HMI Guidelines - Communications section for guidance or work with your Amazon partner manager","title":"Known Gaps"},{"location":"aacs/android/app-components/alexa-auto-setup/","text":"Alexa Auto Setup The following list describes the contents of this package: This package provides the UI for the setup workflow which includes login and subsequent setup steps. The UI is provided as Android Fragment s along with View Model s which can be used independently for building a different flavor of the UI. At present, this package provides UI/ViewModel for CBL (Code Based Linking) and Preview mode authentication. Note: For the app to work it must either be configured as a system app or app permissions need to be manually enabled by navigating to Settings > Apps & Notifications > Show All Apps > com.amazon.alexaautoclientservice > Permissions > Enable Microphone Integration Gradle Include the project with gradle. Dependencies Please refer to alexa-auto-apis doc to find details on how to fetch/publish dependencies. CBLLoginViewModel needs access to following implementations (interfaces for them are defined in alexa-auto-apis package): * AuthController : This interface provides business logic for new authentication workflow. The interface must be made available from AlexaAppRootComponent . * LoginUIEventListener [Optional] : This interface allows UI to let the observer know when login is finished. This event can be used by observer to progress the app UI to logged-in state. The interface should be made available through AlexaAppLoggedOutScopedComponent , that should be made available through AlexaAppRootComponent#getScopedComponents() Known Gaps The setup flow in this app does satisfy CX requirements. Refer to HMI Guidelines - Setup section for guidance or work with your Amazon partner manager. Missing Steps Navigation favorites upload permission Enable Push-to-talk permission","title":"Alexa Auto Setup"},{"location":"aacs/android/app-components/alexa-auto-setup/#alexa-auto-setup","text":"The following list describes the contents of this package: This package provides the UI for the setup workflow which includes login and subsequent setup steps. The UI is provided as Android Fragment s along with View Model s which can be used independently for building a different flavor of the UI. At present, this package provides UI/ViewModel for CBL (Code Based Linking) and Preview mode authentication. Note: For the app to work it must either be configured as a system app or app permissions need to be manually enabled by navigating to Settings > Apps & Notifications > Show All Apps > com.amazon.alexaautoclientservice > Permissions > Enable Microphone","title":"Alexa Auto Setup"},{"location":"aacs/android/app-components/alexa-auto-setup/#integration","text":"","title":"Integration"},{"location":"aacs/android/app-components/alexa-auto-setup/#gradle","text":"Include the project with gradle.","title":"Gradle"},{"location":"aacs/android/app-components/alexa-auto-setup/#dependencies","text":"Please refer to alexa-auto-apis doc to find details on how to fetch/publish dependencies. CBLLoginViewModel needs access to following implementations (interfaces for them are defined in alexa-auto-apis package): * AuthController : This interface provides business logic for new authentication workflow. The interface must be made available from AlexaAppRootComponent . * LoginUIEventListener [Optional] : This interface allows UI to let the observer know when login is finished. This event can be used by observer to progress the app UI to logged-in state. The interface should be made available through AlexaAppLoggedOutScopedComponent , that should be made available through AlexaAppRootComponent#getScopedComponents()","title":"Dependencies"},{"location":"aacs/android/app-components/alexa-auto-setup/#known-gaps","text":"The setup flow in this app does satisfy CX requirements. Refer to HMI Guidelines - Setup section for guidance or work with your Amazon partner manager.","title":"Known Gaps"},{"location":"aacs/android/app-components/alexa-auto-setup/#missing-steps","text":"Navigation favorites upload permission Enable Push-to-talk permission","title":"Missing Steps"},{"location":"aacs/android/app-components/alexa-auto-telephony/","text":"AACS Telephony The AACS Telephony library is an Android library for you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. The library handles phone-related directives and events from and to the Alexa Auto SDK Engine, via the AACS Core Service. The library also works with the Dialer app on the car head unit. By including this optional library in AACS or your own application, you can easily integrate phone capabilities (e.g., dialing, redialing, and answering calls) with Alexa. Table of Contents Overview Prerequisites Building the Library Setup for AACS Telephony Library Sequence Diagram Phone Call Controlling Answer Dial Redial SendDTMF Stop Update Device Configuration (Optional) Receiving Device Connection Changes Known Issue Overview AACS Telephony Library is responsible for communicating with the AACS Core Service and initiating the corresponding actions based on the incoming directives from the Engine. The following list describes its major components that carry out these responsibilities: The AACS Telephony Service is responsible for: Receiving and processing PhoneCallController AASB message intents from the AACS Core Service. Receiving defined intents from your application for specific actions, such as providing the proper Phone Account Handler to be used to place a call. The AACS Telephony platform implementation ( PhoneCallController ) with the Android telephony framework is responsible for: Fulfilling the phone-call-related directives, which are received as intents by the AACS Telephony Service Capturing and reporting call state changes to the AACS Core Service Capturing and reporting Bluetooth connection state changes to the AACS Core Service, and broadcasting the changes to any client listeners The AACS Telephony Library is an optional module, which you can use as is or as a reference when you integrate the Phone Call Controller module with AACS. You can enable it in the AACS Sample App or in your application APK. Prerequisites Your Android system needs to support the Android Telephony framework. Your Android system needs to have a default dialer app that provides dialer and in-call UI. Your Android system needs to support Bluetooth Hands-Free Profile (HFP) and Phone Book Access Profile (PBAP). Specifically, Bluetooth profiles with ID HEADSET_CLIENT and PBAP_CLIENT are required. For example, a device running Android Automotive OS supports these profiles. Building the Library You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Telephony library: ./gradlew :alexa-auto-telephony:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-telephony/aacstelephony/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Telephony AAR. To enable telephony support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with telephony enabled. ./gradlew assembleLocalRelease -PenabledTelephony For more build options, see the AACS Sample App README . Setup for AACS Telephony Library Before using the AACS Telephony Library, follow these major steps: 1) Make the application containing the library into a system-privileged application. 2) Provide the library with appropriate system permissions. 3) Provide permission in your application's Android manifest so that the AACS Telephony Service can be started by your application. 4) Specify targets for intents from the AACS Core Service. Making Application into a System-Privileged App The AACS Telephony Library needs to control the phone calls, and monitor the Bluetooth connection states and phone call states. Therefore, the application containing the library must be a system-privileged application. If the library is included in AACS, as recommended, you must run AACS as a system-privileged application. Similarly, if you put the library in your application, your application must be system-privileged. An application acquires system privilege when you install it in /system/priv-app/ . Providing System Permissions The AACS Telephony Library requires three system-level permissions: android.permission.CONTROL_INCALL_EXPERIENCE android.permission.INTERACT_ACROSS_USERS android.permission.CAPTURE_AUDIO_OUTPUT Grant the permissions to the package containing the AACS Telephony Library. For instructions about granting permissions, see the Android documentation . To grant permissions to AACS, if it contains the library, use com.amazon.alexaautoclientservice as the package name in the XML file referenced in the Android documentation. Providing Permission in Android Manifest For security reasons, for your application to send intents to or receive intents from the AACS Telephony Service, specify the com.amazon.aacstelephony permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacstelephony\" /> Intent Targets The AACS Telephony Service listens to intents from the AACS Core Service with these topics: AASB and PhoneCallController . To specify AACS Telephony Service as the intent target, follow one of these steps: Manually specify the messages in the AACS configuration file. The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify AACS Telephony Service as an intent target for both the AASB and PhoneCallController topics. In this example, the AACS Telephony Library AAR is part of the AACS sample app APK. For more information about specifying intent targets, see the AACS README . \"AASB\" : { \"type\": [\"<target_1_type>\",\"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] }, //... other modules \"PhoneCallController\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_type>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] } //... other modules Omit ANY targets for the AASB and PhoneCallController topics in the AACS configuration file. As a result, the intent filter defined in the AACS Telephony Library takes effect, enabling the AACS Telephony Service to receive the intents. Sequence Diagram The following sequence diagram illustrates the flow when the driver initiates a call with Alexa if the AACS Telephony Library is used. Phone Call Controlling This section describes the phone call controlling actions and work flows, whether the calls are initiated by Alexa or by the user from the head unit or mobile phone. Answer When a user asks Alexa to answer a call, the AACS Telephony Library answers the call that has the matching callId in the PhoneCallController.Answer payload of the AASB message. Dial When a user asks Alexa to dial a number or call an uploaded contact, the AACS Telephony Service calls the Android API getDefaultOutgoingPhoneAccount to determine the proper PhoneAccountHandle to use for initiating the call. The specific account returned by getDefaultOutgoingPhoneAccount depends on the following priorities: * If the user-selected default PhoneAccount supports the specified scheme, it will be returned. * If there exists only one PhoneAccount that supports the specified scheme, it will be returned. In the Android Automotive OS the last connected device with HFP enabled is considered as the user-selected phone account. The OEMs can override this default behavior by implementing their own phone selection UI and calling the system API setUserSelectedOutgoingPhoneAccount to set the user selected account whenever the user makes a selection. Note: The AACS Telephony Service does not cache the phone account handle. Each time it receives the Dial message from AACS, it calls the getDefaultOutgoingPhoneAccount to determine which phone account handle to use. Redial Similar to the Dial action, each Redial action requires the AACS Telephony Service to call the getDefaultOutgoingPhoneAccount to get the proper phone account handle. The AACS Telephony phone call controller queries the Android system on the head unit by using the CallLog.Calls.getLastOutgoingCall method, to get the last dialed number. SendDTMF When AACS Telephony Service gets a sendDTMF message, it applies the specified Dual Tone Multiple-Frequency (DTMF) tones to the call that has the matching callId in the PhoneCallController.SendDTMF payload of the AASB message. Stop When AACS Telephony Service gets a PhoneCallController.Stop AASB message, it stops the current call that has the matching callId in the message payload. Update Device Configuration This section describes how to update the device configuration. Note: the Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Use one of the following methods to update the device configuration: Use intent. Your application can send messages with a particular intent to the AACS Telephony Service to update the device configuration. Specify the attributes of the intent as follows: Action is com.amazon.aacstelephony.updateDeviceConfiguration . Category is com.amazon.aacstelephony . Extras is: { \"deviceProperty\": \"<Property name>\", \"enable\": <Boolean value to enable or disable specified property> } Use a direct API call. This method is applicable only if you put the AACS Telephony Library in your application. The following code shows how to use the PhoneCallController API: // Instantiate PhoneCallController PhoneCallController phoneCallController = new PhoneCallController ( context , aacsMessageSender ); phoneCallController . updateDeviceConfiguration ( deviceProperty , enable ); Tip: All the key constants, intent actions, and categories are defined in the TelephonyConstants class in the AACS Constants Library. (Optional) Receiving Device Connection Changes The AACS Telephony Library not only detects and reports the Bluetooth connection state changes to the Engine (and subsequently Alexa), but can also broadcast the changes to your application if you find the broadcasts useful. Whenever BluetoothStateListener in the AACS Telephony Service detects a connection change with the Phone Book Access Profile (PBAP), it sends an intent with the device name and address to the listeners. The attributes of the intent with the connection information are as follows: Action is com.amazon.aacstelephony.bluetooth.connected for connected events and com.amazon.aacstelephony.bluetooth.disconnected for disconnected events. Category is com.amazon.aacstelephony . Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" } Known Issue When there is an active phone call, and if the application (either AACS or your application) containing AACS Telephony Library crashes, when it comes back, the InCallService defined in AACS Telephony Library would not automatically rebound, and therefore you cannot control the active call with Alexa. This is due to the InCallService in this library is not with the default dialer. New calls after the crash would trigger the InCallService to rebind to the system and phone call controlling would work as usual. Besides, reconnecting Bluetooth also triggers a rebinding in this case.","title":"AACS Telephony"},{"location":"aacs/android/app-components/alexa-auto-telephony/#aacs-telephony","text":"The AACS Telephony library is an Android library for you to pre-integrate Alexa Phone Call Controller functionalities with Android Telephony. The library handles phone-related directives and events from and to the Alexa Auto SDK Engine, via the AACS Core Service. The library also works with the Dialer app on the car head unit. By including this optional library in AACS or your own application, you can easily integrate phone capabilities (e.g., dialing, redialing, and answering calls) with Alexa.","title":"AACS Telephony"},{"location":"aacs/android/app-components/alexa-auto-telephony/#table-of-contents","text":"Overview Prerequisites Building the Library Setup for AACS Telephony Library Sequence Diagram Phone Call Controlling Answer Dial Redial SendDTMF Stop Update Device Configuration (Optional) Receiving Device Connection Changes Known Issue","title":"Table of Contents"},{"location":"aacs/android/app-components/alexa-auto-telephony/#overview","text":"AACS Telephony Library is responsible for communicating with the AACS Core Service and initiating the corresponding actions based on the incoming directives from the Engine. The following list describes its major components that carry out these responsibilities: The AACS Telephony Service is responsible for: Receiving and processing PhoneCallController AASB message intents from the AACS Core Service. Receiving defined intents from your application for specific actions, such as providing the proper Phone Account Handler to be used to place a call. The AACS Telephony platform implementation ( PhoneCallController ) with the Android telephony framework is responsible for: Fulfilling the phone-call-related directives, which are received as intents by the AACS Telephony Service Capturing and reporting call state changes to the AACS Core Service Capturing and reporting Bluetooth connection state changes to the AACS Core Service, and broadcasting the changes to any client listeners The AACS Telephony Library is an optional module, which you can use as is or as a reference when you integrate the Phone Call Controller module with AACS. You can enable it in the AACS Sample App or in your application APK.","title":"Overview"},{"location":"aacs/android/app-components/alexa-auto-telephony/#prerequisites","text":"Your Android system needs to support the Android Telephony framework. Your Android system needs to have a default dialer app that provides dialer and in-call UI. Your Android system needs to support Bluetooth Hands-Free Profile (HFP) and Phone Book Access Profile (PBAP). Specifically, Bluetooth profiles with ID HEADSET_CLIENT and PBAP_CLIENT are required. For example, a device running Android Automotive OS supports these profiles.","title":"Prerequisites"},{"location":"aacs/android/app-components/alexa-auto-telephony/#building-the-library","text":"You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the Telephony library: ./gradlew :alexa-auto-telephony:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-telephony/aacstelephony/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS Telephony AAR. To enable telephony support in the AACS Sample App, follow these steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to start the local build with telephony enabled. ./gradlew assembleLocalRelease -PenabledTelephony For more build options, see the AACS Sample App README .","title":"Building the Library"},{"location":"aacs/android/app-components/alexa-auto-telephony/#setup-for-aacs-telephony-library","text":"Before using the AACS Telephony Library, follow these major steps: 1) Make the application containing the library into a system-privileged application. 2) Provide the library with appropriate system permissions. 3) Provide permission in your application's Android manifest so that the AACS Telephony Service can be started by your application. 4) Specify targets for intents from the AACS Core Service.","title":"Setup for AACS Telephony Library"},{"location":"aacs/android/app-components/alexa-auto-telephony/#making-application-into-a-system-privileged-app","text":"The AACS Telephony Library needs to control the phone calls, and monitor the Bluetooth connection states and phone call states. Therefore, the application containing the library must be a system-privileged application. If the library is included in AACS, as recommended, you must run AACS as a system-privileged application. Similarly, if you put the library in your application, your application must be system-privileged. An application acquires system privilege when you install it in /system/priv-app/ .","title":"Making Application into a System-Privileged App"},{"location":"aacs/android/app-components/alexa-auto-telephony/#providing-system-permissions","text":"The AACS Telephony Library requires three system-level permissions: android.permission.CONTROL_INCALL_EXPERIENCE android.permission.INTERACT_ACROSS_USERS android.permission.CAPTURE_AUDIO_OUTPUT Grant the permissions to the package containing the AACS Telephony Library. For instructions about granting permissions, see the Android documentation . To grant permissions to AACS, if it contains the library, use com.amazon.alexaautoclientservice as the package name in the XML file referenced in the Android documentation.","title":"Providing System Permissions"},{"location":"aacs/android/app-components/alexa-auto-telephony/#providing-permission-in-android-manifest","text":"For security reasons, for your application to send intents to or receive intents from the AACS Telephony Service, specify the com.amazon.aacstelephony permission in your application's Android manifest as follows: <uses-permission android:name=\"com.amazon.aacstelephony\" />","title":"Providing Permission in Android Manifest"},{"location":"aacs/android/app-components/alexa-auto-telephony/#intent-targets","text":"The AACS Telephony Service listens to intents from the AACS Core Service with these topics: AASB and PhoneCallController . To specify AACS Telephony Service as the intent target, follow one of these steps: Manually specify the messages in the AACS configuration file. The targets in the AACS configuration file override the ones specified by intent filters. The following example shows how to specify AACS Telephony Service as an intent target for both the AASB and PhoneCallController topics. In this example, the AACS Telephony Library AAR is part of the AACS sample app APK. For more information about specifying intent targets, see the AACS README . \"AASB\" : { \"type\": [\"<target_1_type>\",\"SERVICE\", ...], \"package\": [\"<target_1_package_name>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] }, //... other modules \"PhoneCallController\" : { \"type\": [\"<target_1_type>\", \"SERVICE\", ...], \"package\": [\"<target_1_type>\", \"com.amazon.alexa.auto.app\", ...], \"class\": [\"<target_1_type>\", \"com.amazon.aacstelephony.AACSTelephonyService\", ...] } //... other modules Omit ANY targets for the AASB and PhoneCallController topics in the AACS configuration file. As a result, the intent filter defined in the AACS Telephony Library takes effect, enabling the AACS Telephony Service to receive the intents.","title":"Intent Targets"},{"location":"aacs/android/app-components/alexa-auto-telephony/#sequence-diagram","text":"The following sequence diagram illustrates the flow when the driver initiates a call with Alexa if the AACS Telephony Library is used.","title":"Sequence Diagram"},{"location":"aacs/android/app-components/alexa-auto-telephony/#phone-call-controlling","text":"This section describes the phone call controlling actions and work flows, whether the calls are initiated by Alexa or by the user from the head unit or mobile phone.","title":"Phone Call Controlling"},{"location":"aacs/android/app-components/alexa-auto-telephony/#answer","text":"When a user asks Alexa to answer a call, the AACS Telephony Library answers the call that has the matching callId in the PhoneCallController.Answer payload of the AASB message.","title":"Answer"},{"location":"aacs/android/app-components/alexa-auto-telephony/#dial","text":"When a user asks Alexa to dial a number or call an uploaded contact, the AACS Telephony Service calls the Android API getDefaultOutgoingPhoneAccount to determine the proper PhoneAccountHandle to use for initiating the call. The specific account returned by getDefaultOutgoingPhoneAccount depends on the following priorities: * If the user-selected default PhoneAccount supports the specified scheme, it will be returned. * If there exists only one PhoneAccount that supports the specified scheme, it will be returned. In the Android Automotive OS the last connected device with HFP enabled is considered as the user-selected phone account. The OEMs can override this default behavior by implementing their own phone selection UI and calling the system API setUserSelectedOutgoingPhoneAccount to set the user selected account whenever the user makes a selection. Note: The AACS Telephony Service does not cache the phone account handle. Each time it receives the Dial message from AACS, it calls the getDefaultOutgoingPhoneAccount to determine which phone account handle to use.","title":"Dial"},{"location":"aacs/android/app-components/alexa-auto-telephony/#redial","text":"Similar to the Dial action, each Redial action requires the AACS Telephony Service to call the getDefaultOutgoingPhoneAccount to get the proper phone account handle. The AACS Telephony phone call controller queries the Android system on the head unit by using the CallLog.Calls.getLastOutgoingCall method, to get the last dialed number.","title":"Redial"},{"location":"aacs/android/app-components/alexa-auto-telephony/#senddtmf","text":"When AACS Telephony Service gets a sendDTMF message, it applies the specified Dual Tone Multiple-Frequency (DTMF) tones to the call that has the matching callId in the PhoneCallController.SendDTMF payload of the AASB message.","title":"SendDTMF"},{"location":"aacs/android/app-components/alexa-auto-telephony/#stop","text":"When AACS Telephony Service gets a PhoneCallController.Stop AASB message, it stops the current call that has the matching callId in the message payload.","title":"Stop"},{"location":"aacs/android/app-components/alexa-auto-telephony/#update-device-configuration","text":"This section describes how to update the device configuration. Note: the Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Use one of the following methods to update the device configuration: Use intent. Your application can send messages with a particular intent to the AACS Telephony Service to update the device configuration. Specify the attributes of the intent as follows: Action is com.amazon.aacstelephony.updateDeviceConfiguration . Category is com.amazon.aacstelephony . Extras is: { \"deviceProperty\": \"<Property name>\", \"enable\": <Boolean value to enable or disable specified property> } Use a direct API call. This method is applicable only if you put the AACS Telephony Library in your application. The following code shows how to use the PhoneCallController API: // Instantiate PhoneCallController PhoneCallController phoneCallController = new PhoneCallController ( context , aacsMessageSender ); phoneCallController . updateDeviceConfiguration ( deviceProperty , enable ); Tip: All the key constants, intent actions, and categories are defined in the TelephonyConstants class in the AACS Constants Library.","title":"Update Device Configuration"},{"location":"aacs/android/app-components/alexa-auto-telephony/#optional-receiving-device-connection-changes","text":"The AACS Telephony Library not only detects and reports the Bluetooth connection state changes to the Engine (and subsequently Alexa), but can also broadcast the changes to your application if you find the broadcasts useful. Whenever BluetoothStateListener in the AACS Telephony Service detects a connection change with the Phone Book Access Profile (PBAP), it sends an intent with the device name and address to the listeners. The attributes of the intent with the connection information are as follows: Action is com.amazon.aacstelephony.bluetooth.connected for connected events and com.amazon.aacstelephony.bluetooth.disconnected for disconnected events. Category is com.amazon.aacstelephony . Extras is { \"deviceName\": \"<Device name>\", \"deviceAddress\": \"<Device Bluetooth MAC address>\" }","title":"(Optional) Receiving Device Connection Changes"},{"location":"aacs/android/app-components/alexa-auto-telephony/#known-issue","text":"When there is an active phone call, and if the application (either AACS or your application) containing AACS Telephony Library crashes, when it comes back, the InCallService defined in AACS Telephony Library would not automatically rebound, and therefore you cannot control the active call with Alexa. This is due to the InCallService in this library is not with the default dialer. New calls after the crash would trigger the InCallService to rebind to the system and phone call controlling would work as usual. Besides, reconnecting Bluetooth also triggers a rebinding in this case.","title":"Known Issue"},{"location":"aacs/android/app-components/alexa-auto-templateruntime-renderer/","text":"Alexa Auto Template Runtime Renderer This library houses template runtime implementations. The following template runtime directives are currently supported It handles weather template runtime directives. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directive and renders current weather and weather forecast cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). The template is automatically dismissed 8 seconds after the voice response from Alexa is completed unless the card is interacted with, in which case the card dismissal gets extended by 8 seconds from the last interaction. Known Issues The weather card comprises of 2 screens - current weather and weather forecast. The card currently scrolls continuously which is not the correct behavior. It should be paginated.","title":"Alexa Auto Template Runtime Renderer"},{"location":"aacs/android/app-components/alexa-auto-templateruntime-renderer/#alexa-auto-template-runtime-renderer","text":"This library houses template runtime implementations. The following template runtime directives are currently supported It handles weather template runtime directives. This library is one of the subscribers for the TemplateRuntime::RenderTemplate directive. It parses the incoming directive and renders current weather and weather forecast cards in the current voice session provided by the Alexa Voice Interaction Service (VIS). The template is automatically dismissed 8 seconds after the voice response from Alexa is completed unless the card is interacted with, in which case the card dismissal gets extended by 8 seconds from the last interaction.","title":"Alexa Auto Template Runtime Renderer"},{"location":"aacs/android/app-components/alexa-auto-templateruntime-renderer/#known-issues","text":"The weather card comprises of 2 screens - current weather and weather forecast. The card currently scrolls continuously which is not the correct behavior. It should be paginated.","title":"Known Issues"},{"location":"aacs/android/app-components/alexa-auto-tts/","text":"Text-to-Speech Service Text-to-Speech (TTS) Service provides an implementation on the Android platform to synthesize non-Alexa speech on demand from text. It implements the Android abstract TextToSpeechService class, which is part of Android TTS framework APIs, and in the backend uses the Text-to-Speech functionality provided by the Auto SDK. Android applications can interact with these standard Android TTS APIs to convert text to speech. Table of Contents Overview Building the Library Architecture Configuration Sample Usage Initialization Get Capabilities Synthesize Audio Known Issues Overview Text-to-Speech Service implements TextToSpeechService , which is an abstract base class for TTS engine implementations. The following list describes the responsibilities of the service and the Android TTS framework: The service is responsible for: retrieving the TTS capabilities from AACS preparing the TTS audio and vending out the stream to the Android TTS framework APIs The Android TTS framework is responsible for: handling the states of TTS requests playing out the audio saving the audio to file The Text-to-Speech Service communicates with AACS to get the available locales and fetch the synthesized audio stream. Therefore, AACS must be started, configured, and running in connected state to ensure the Text-to-Speech Service can generate the designated TTS audio correctly. Building the Library Text-to-Speech Service is built as an Android Archive (AAR) to be included in your application along with the AACS AAR. You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the TTS library: ./gradlew :alexa-auto-tts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-tts/aacstts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS TTS AAR. AACS TTS is by default enabled in the AACS Sample App. See the AACS Sample App README for build instructions. Important! The Text-to-Speech Service requires the Local Voice Control and Alexa Custom Assistant extensions to function. Architecture The following diagram shows the high-level architecture of TTS Service and AACS. The blue box in the diagram represents the Text-to-Speech Service and the white boxes in the diagram represent the other components developed by Amazon. These components are all packaged in AARs to be added along with AACS AAR into AACS Sample App or your application. The other boxes represent components that do not belong to Amazon: The yellow boxes represent the components from the Android TTS framework, and the green box represents the OEM application using Android TTS APIs. Android Application is owned by OEMs to handle the Text-to-Speech interaction with the end user by creating an instance of the TextToSpeech object and issuing Text-to-Speech requests. TextToSpeech is the Facade class that acts as a bridge between the Text-to-Speech application, which issues the TTS requests, and the underlying TextToSpeechService , which renders the response. See Android documentation for TextToSpeech here. TextToSpeechService is an abstract base class for TTS engine implementations. For more information about this class, see Android documentation for TextToSpeechService . AmazonTextToSpeechService is the actual implementation of TextToSpeechService that communicates with AACS via the IPC library to issue Text-to-Speech requests. Core Service is responsible for accepting TTS requests from AmazonTextToSpeechService and for routing those requests to the Auto SDK's TextToSpeech platform interface, which issues a request to the appropriate TTS provider. For information about TTS providers, see TextToSpeechProvider module README . Configuration To specify the intent targets for AASB message intents from AACS, follow the instructions in AACS README . The TTS Service defines a list of intent filters in its Android manifest to subscribe to specific AASB message intents. If your application uses static configuration to specify the target for AASB topics, provide the following information as part of the AACS configuration to enable the communication between TTS Service and AACS. \u200b { ... \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"AlexaClient\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"TextToSpeech\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, ... } TTS Service subscribes to the AASB messages with the AASB , AlexaClient , and TextToSpeech topics by using a broadcast receiver. Make sure that you properly populate the type, the package name, and the class name into the intentTargets JSON node for these topics, as shown in the JSON example above. Sample Usage Your application uses the Text-to-Speech Service in the same way as it would use any TTS engine. To synthesize speech, the application must create a TextToSpeech object and then set the input text. The application can also specify the speech pitch and rate. Initialization Initialize the Text-to-Speech Service in one of two ways: * If the Android application creates a TextToSpeech object without specifying the package name of the TTS engine to use, the default TTS engine is used. // Create the TextToSpeech using the default engine TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }); You can change the default engine to Text-to-Speech Service by following these steps: 1. Open the Android Settings menu and navigate \"Preferred Engine\" as follows: app \u2192 \u201cGeneral Management\u201d \u2192 \u201cLanguage and Input\u201d \u2192 \"Text-to-Speech\" \u2192 \"Preferred Engine\" 2. Choose \"Amazon Text-to-Speech Engine\" in the list. The Android application can also directly create Text-to-Speech Service by specifying the package name \"com.amazon.alexaautoclientservice\" when creating the TextToSpeech object. // Create the TextToSpeech by specifying the package name of the TextToSpeechService TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }, \"com.amazon.alexaautoclientservice\" ); You must initiate TTS Service at least once to warm up the language cache before making any synthesis requests. Get Capabilities The Android applications may query the Text-to-Speech Service to get the available voices. For information about voices, see Android Voice class . For information about languages, see Locale class . The following examples show how to get the available voices and languages from the Engine: // Query the engine about the set of available voices Set < Voice > voices = textToSpeech . getVoices (); // Query the engine about the set of available languages. Set < Locale > locales = textToSpeech . getAvailableLanguages (); // Check if the specified language as represented by the Locale is available and supported. int supported = textToSpeech . isLanguageAvailable ( Locale . US ) Synthesize Audio The Android TTS framework provides two ways of synthesizing TTS audio: Play out the audio immediately: The Android applications may call the speak API. public int speak ( CharSequence text , int queueMode , Bundle params , String utteranceId ) Save to a WAV file: The Android applications may call the synthesizeToFile API. public int synthesizeToFile ( CharSequence text , Bundle params , File file , String utteranceId ) Known Issues Conversion of MP3 to RAW Audio for TTS on the X86 platform is not yet supported.","title":"Text-to-Speech Service"},{"location":"aacs/android/app-components/alexa-auto-tts/#text-to-speech-service","text":"Text-to-Speech (TTS) Service provides an implementation on the Android platform to synthesize non-Alexa speech on demand from text. It implements the Android abstract TextToSpeechService class, which is part of Android TTS framework APIs, and in the backend uses the Text-to-Speech functionality provided by the Auto SDK. Android applications can interact with these standard Android TTS APIs to convert text to speech.","title":"Text-to-Speech Service"},{"location":"aacs/android/app-components/alexa-auto-tts/#table-of-contents","text":"Overview Building the Library Architecture Configuration Sample Usage Initialization Get Capabilities Synthesize Audio Known Issues","title":"Table of Contents"},{"location":"aacs/android/app-components/alexa-auto-tts/#overview","text":"Text-to-Speech Service implements TextToSpeechService , which is an abstract base class for TTS engine implementations. The following list describes the responsibilities of the service and the Android TTS framework: The service is responsible for: retrieving the TTS capabilities from AACS preparing the TTS audio and vending out the stream to the Android TTS framework APIs The Android TTS framework is responsible for: handling the states of TTS requests playing out the audio saving the audio to file The Text-to-Speech Service communicates with AACS to get the available locales and fetch the synthesized audio stream. Therefore, AACS must be started, configured, and running in connected state to ensure the Text-to-Speech Service can generate the designated TTS audio correctly.","title":"Overview"},{"location":"aacs/android/app-components/alexa-auto-tts/#building-the-library","text":"Text-to-Speech Service is built as an Android Archive (AAR) to be included in your application along with the AACS AAR. You can build the library locally using the following steps: 1) Enter the following command to change the directory: cd ${AAC_SDK_HOME}/aacs/android/sample-app 2) Enter the following command to build the TTS library: ./gradlew :alexa-auto-tts:assembleRelease Replace assembleRelease with assembleDebug if you want to build the debug version of the library. The generated AAR is available at alexa-auto-sdk/aacs/android/app-components/alexa-auto-tts/aacstts/build/outputs/aar . You must include the AACSIPC , AACSConstants , AACSCommonUtils , AACS and Auto SDK AARs in your application to use with the AACS TTS AAR. AACS TTS is by default enabled in the AACS Sample App. See the AACS Sample App README for build instructions. Important! The Text-to-Speech Service requires the Local Voice Control and Alexa Custom Assistant extensions to function.","title":"Building the Library"},{"location":"aacs/android/app-components/alexa-auto-tts/#architecture","text":"The following diagram shows the high-level architecture of TTS Service and AACS. The blue box in the diagram represents the Text-to-Speech Service and the white boxes in the diagram represent the other components developed by Amazon. These components are all packaged in AARs to be added along with AACS AAR into AACS Sample App or your application. The other boxes represent components that do not belong to Amazon: The yellow boxes represent the components from the Android TTS framework, and the green box represents the OEM application using Android TTS APIs. Android Application is owned by OEMs to handle the Text-to-Speech interaction with the end user by creating an instance of the TextToSpeech object and issuing Text-to-Speech requests. TextToSpeech is the Facade class that acts as a bridge between the Text-to-Speech application, which issues the TTS requests, and the underlying TextToSpeechService , which renders the response. See Android documentation for TextToSpeech here. TextToSpeechService is an abstract base class for TTS engine implementations. For more information about this class, see Android documentation for TextToSpeechService . AmazonTextToSpeechService is the actual implementation of TextToSpeechService that communicates with AACS via the IPC library to issue Text-to-Speech requests. Core Service is responsible for accepting TTS requests from AmazonTextToSpeechService and for routing those requests to the Auto SDK's TextToSpeech platform interface, which issues a request to the appropriate TTS provider. For information about TTS providers, see TextToSpeechProvider module README .","title":"Architecture"},{"location":"aacs/android/app-components/alexa-auto-tts/#configuration","text":"To specify the intent targets for AASB message intents from AACS, follow the instructions in AACS README . The TTS Service defines a list of intent filters in its Android manifest to subscribe to specific AASB message intents. If your application uses static configuration to specify the target for AASB topics, provide the following information as part of the AACS configuration to enable the communication between TTS Service and AACS. \u200b { ... \"aacs.general\" : { \"intentTargets\" : { \"AASB\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"AlexaClient\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, \"TextToSpeech\" : { \"type\" : [ \"RECEIVER\" ] , \"package\" : [ \"com.amazon.alexaautoclientservice\" ] , \"class\" : [ \"com.amazon.aacstts.TTSIntentReceiver\" ] }, ... } TTS Service subscribes to the AASB messages with the AASB , AlexaClient , and TextToSpeech topics by using a broadcast receiver. Make sure that you properly populate the type, the package name, and the class name into the intentTargets JSON node for these topics, as shown in the JSON example above.","title":"Configuration"},{"location":"aacs/android/app-components/alexa-auto-tts/#sample-usage","text":"Your application uses the Text-to-Speech Service in the same way as it would use any TTS engine. To synthesize speech, the application must create a TextToSpeech object and then set the input text. The application can also specify the speech pitch and rate.","title":"Sample Usage"},{"location":"aacs/android/app-components/alexa-auto-tts/#initialization","text":"Initialize the Text-to-Speech Service in one of two ways: * If the Android application creates a TextToSpeech object without specifying the package name of the TTS engine to use, the default TTS engine is used. // Create the TextToSpeech using the default engine TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }); You can change the default engine to Text-to-Speech Service by following these steps: 1. Open the Android Settings menu and navigate \"Preferred Engine\" as follows: app \u2192 \u201cGeneral Management\u201d \u2192 \u201cLanguage and Input\u201d \u2192 \"Text-to-Speech\" \u2192 \"Preferred Engine\" 2. Choose \"Amazon Text-to-Speech Engine\" in the list. The Android application can also directly create Text-to-Speech Service by specifying the package name \"com.amazon.alexaautoclientservice\" when creating the TextToSpeech object. // Create the TextToSpeech by specifying the package name of the TextToSpeechService TextToSpeech textToSpeech = new TextToSpeech ( getApplicationContext (), new TextToSpeech . OnInitListener () { @Override public void onInit ( int status ) { if ( status != TextToSpeech . ERROR ) { // do things upon TextToSpeechService is initialized } } }, \"com.amazon.alexaautoclientservice\" ); You must initiate TTS Service at least once to warm up the language cache before making any synthesis requests.","title":"Initialization"},{"location":"aacs/android/app-components/alexa-auto-tts/#get-capabilities","text":"The Android applications may query the Text-to-Speech Service to get the available voices. For information about voices, see Android Voice class . For information about languages, see Locale class . The following examples show how to get the available voices and languages from the Engine: // Query the engine about the set of available voices Set < Voice > voices = textToSpeech . getVoices (); // Query the engine about the set of available languages. Set < Locale > locales = textToSpeech . getAvailableLanguages (); // Check if the specified language as represented by the Locale is available and supported. int supported = textToSpeech . isLanguageAvailable ( Locale . US )","title":"Get Capabilities"},{"location":"aacs/android/app-components/alexa-auto-tts/#synthesize-audio","text":"The Android TTS framework provides two ways of synthesizing TTS audio: Play out the audio immediately: The Android applications may call the speak API. public int speak ( CharSequence text , int queueMode , Bundle params , String utteranceId ) Save to a WAV file: The Android applications may call the synthesizeToFile API. public int synthesizeToFile ( CharSequence text , Bundle params , File file , String utteranceId )","title":"Synthesize Audio"},{"location":"aacs/android/app-components/alexa-auto-tts/#known-issues","text":"Conversion of MP3 to RAW Audio for TTS on the X86 platform is not yet supported.","title":"Known Issues"},{"location":"aacs/android/app-components/alexa-auto-ux-restrictions/","text":"Alexa Auto UX Restrictions The following list describes the purposes of this library: * It provides CarUxRestrictionsModule and controls CarUxRestrictionsController life cycle. * It provides default implementation for CarUxRestrictionsController , which initializes Android CarUxRestrictionsManager , registers and unregisters OnUxRestrictionsChangedListener . To use the default implemetation, it requires Android car package exists on the device. OEM can also provide their own implementation for the car UX restrictions updates. This app component requires Android API 29. To build this component with AACS sample app, add the -PenabledUXRestrictions to your build command: ./gradlew assembleLocalRelease -PenabledUXRestrictions","title":"Alexa Auto UX Restrictions"},{"location":"aacs/android/app-components/alexa-auto-ux-restrictions/#alexa-auto-ux-restrictions","text":"The following list describes the purposes of this library: * It provides CarUxRestrictionsModule and controls CarUxRestrictionsController life cycle. * It provides default implementation for CarUxRestrictionsController , which initializes Android CarUxRestrictionsManager , registers and unregisters OnUxRestrictionsChangedListener . To use the default implemetation, it requires Android car package exists on the device. OEM can also provide their own implementation for the car UX restrictions updates. This app component requires Android API 29. To build this component with AACS sample app, add the -PenabledUXRestrictions to your build command: ./gradlew assembleLocalRelease -PenabledUXRestrictions","title":"Alexa Auto UX Restrictions"},{"location":"aacs/android/app-components/alexa-auto-voice-interaction/","text":"Alexa Auto Voice Interaction The following list describes the purposes of this library: * It provides the Alexa Voice Interaction Service (VIS), which extends the Android Voice Interaction Service API. Alexa VIS enables Alexa as a voice assistant on an Android device. To start Alexa VIS, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , and selects Alexa. > Note: After Alexa VIS is integrated with the Android Voice Interaction API, infotainment system only supports one voice agent at a time. For example, the user cannot use both Alexa and Google Voice Assistant at the same time. * It is responsible for managing the Alexa Auto Client Service (AACS) lifecycle, based on the Alexa VIS lifecycle. * When there is new voice session created, it starts an assistant activity displayed on top of other activities in the system. * It provides the Alexa Voice Assist Settings, such as Alexa Privacy Mode and Alexa Locale. To open Alexa Voice Assist Settings, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , makes sure Alexa is selected, and clicks the Settings icon beside Assist app to open the Alexa Voice Assist Settings homepage. When the user selects Alexa as the assistant, AACS is started and connected to Alexa. When the user selects another voice assistant, Alexa VIS shuts down. It also stops AACS.","title":"Alexa Auto Voice Interaction"},{"location":"aacs/android/app-components/alexa-auto-voice-interaction/#alexa-auto-voice-interaction","text":"The following list describes the purposes of this library: * It provides the Alexa Voice Interaction Service (VIS), which extends the Android Voice Interaction Service API. Alexa VIS enables Alexa as a voice assistant on an Android device. To start Alexa VIS, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , and selects Alexa. > Note: After Alexa VIS is integrated with the Android Voice Interaction API, infotainment system only supports one voice agent at a time. For example, the user cannot use both Alexa and Google Voice Assistant at the same time. * It is responsible for managing the Alexa Auto Client Service (AACS) lifecycle, based on the Alexa VIS lifecycle. * When there is new voice session created, it starts an assistant activity displayed on top of other activities in the system. * It provides the Alexa Voice Assist Settings, such as Alexa Privacy Mode and Alexa Locale. To open Alexa Voice Assist Settings, the user goes to Settings > Apps & notifications > Default apps > Assist & voice input , makes sure Alexa is selected, and clicks the Settings icon beside Assist app to open the Alexa Voice Assist Settings homepage. When the user selects Alexa as the assistant, AACS is started and connected to Alexa. When the user selects another voice assistant, Alexa VIS shuts down. It also stops AACS.","title":"Alexa Auto Voice Interaction"},{"location":"aacs/android/app-components/alexa-auto-voice-ui/","text":"Alexa Auto Voice UI The following list describes the purposes of this library: * It handles Alexa Voice Chrome UI based on the user's request. Voice Chrome requires that Alexa be selected as the device's voice assistant. * It provides the voice interaction session view and vends it out to the app components that inflate onto that view. To access the VIS component, consumers need to get the SessionViewController object via alexa-auto-apis . (See the example in alexa-auto-navigation : LocalSearchDirectiveHandler .) * It provides the voice interaction session activity and vends it out to the app components that add voice fragment onto that view. Consumers need to get the SessionActivityController object via alexa-auto-apis . (See the example in alexa-auto-apl-renderer : APLReceiver .) * It provides support for offline network error prompts. With this feature, an offline prompt is played to users when Alexa is unable to respond to utterances in case the internet is not reachable. The prompt is played in the currently active system locale and the error prompt files for the different locales are stored in res/raw/auto_error_offline_{locale}.mp3 Known Issues This only applies to Alexa Custom Assistant - If Alexa is disabled, [Brandon] is enabled and network is unavailable, the voice prompt will be played in Alexa's voice, not in [Brandon]'s.","title":"Alexa Auto Voice UI"},{"location":"aacs/android/app-components/alexa-auto-voice-ui/#alexa-auto-voice-ui","text":"The following list describes the purposes of this library: * It handles Alexa Voice Chrome UI based on the user's request. Voice Chrome requires that Alexa be selected as the device's voice assistant. * It provides the voice interaction session view and vends it out to the app components that inflate onto that view. To access the VIS component, consumers need to get the SessionViewController object via alexa-auto-apis . (See the example in alexa-auto-navigation : LocalSearchDirectiveHandler .) * It provides the voice interaction session activity and vends it out to the app components that add voice fragment onto that view. Consumers need to get the SessionActivityController object via alexa-auto-apis . (See the example in alexa-auto-apl-renderer : APLReceiver .) * It provides support for offline network error prompts. With this feature, an offline prompt is played to users when Alexa is unable to respond to utterances in case the internet is not reachable. The prompt is played in the currently active system locale and the error prompt files for the different locales are stored in res/raw/auto_error_offline_{locale}.mp3","title":"Alexa Auto Voice UI"},{"location":"aacs/android/app-components/alexa-auto-voice-ui/#known-issues","text":"This only applies to Alexa Custom Assistant - If Alexa is disabled, [Brandon] is enabled and network is unavailable, the voice prompt will be played in Alexa's voice, not in [Brandon]'s.","title":"Known Issues"},{"location":"aacs/android/common/commonutils/","text":"AACS Common Utils Overview AACS Common Utils is an optional library. You can directly use it or reference it when integrating the Auto SDK with AACS, making the messaging with AACS easier. It contains util methods, such as those for building, sending, and parsing messages. The methods enable the the client to communicate with AACS. It also provides helper functions for handling messages from AACS. See the in-code documentation for more information about each class and method. How to use To make the AACS Common Utils Library available to your project, add it to the dependencies of your project's build.gradle file. dependencies { ... implementation project(':alexa-auto-client-service:commonutils:aacscommonutils') ... }","title":"AACS Common Utils"},{"location":"aacs/android/common/commonutils/#aacs-common-utils","text":"","title":"AACS Common Utils"},{"location":"aacs/android/common/commonutils/#overview","text":"AACS Common Utils is an optional library. You can directly use it or reference it when integrating the Auto SDK with AACS, making the messaging with AACS easier. It contains util methods, such as those for building, sending, and parsing messages. The methods enable the the client to communicate with AACS. It also provides helper functions for handling messages from AACS. See the in-code documentation for more information about each class and method.","title":"Overview"},{"location":"aacs/android/common/commonutils/#how-to-use","text":"To make the AACS Common Utils Library available to your project, add it to the dependencies of your project's build.gradle file. dependencies { ... implementation project(':alexa-auto-client-service:commonutils:aacscommonutils') ... }","title":"How to use"},{"location":"aacs/android/common/ipc/","text":"Using the IPC Library with AACS Overview The IPC (inter-process communication) library implements the IPC protocol required for communications between an HMI (human-machine interface) application and AACS (Alexa Auto Client Service). The library enables AACS to send and receive arbitrary types of payloads of arbitrary sizes. The library is implemented using standard Android constructs. You can use it as-is or as a reference when implementing IPC for your app. Getting Started with the IPC Library NOTE : This section assumes that you have completed the steps for building and installing AACS. To build the IPC library, follow these steps: 1) Enter the following commands: cd $AACS_HOME/common/ipc gradle assembleDebug The aacsipc-debug.aar file is built. 1) Copy aacsipc-debug.aar to the libs folder of your app. API Usage Guide The IPC library consists of two main classes for apps to interface with: AACSSender and AACSReceiver . For an additional in-code example that illustrates how an app uses the IPC library, see an AACS Android-service project. AACSSender AACSSender enables an application to send data to another application that uses AACSReceiver . Initialization - When AACSSender initializes, it instantiates an AACSSender object as follows: // AACSSender posts callbacks to the looper specified in the constructor // argument. If none is provided, it uses the mainlooper. AACSSender mAACSSender = new AACSSender ( Looper . getMainLooper ()); Sending a message - AACSSender sends non-streaming data, such as an AASB (Alexa Auto Service Bridge) JSON message, to AACS as follows: // replace with the entire aasb json message String aasbMessage = \"...\" ; // replace with topic of the aasb message String aasbTopic = \"...\" ; // replace with action of the aasb message String aasbAction = \"...\" ; // can also be a list of multiple targets List<TargetComponent> TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); Context context = getApplicationContext (); mAACSSender . sendAASBMessageAnySize ( aasbMessage , aasbAction , aasbTopic , target ( s ), context ); Fetching data from AACS - To stream data to the application, such as audio data, AACS first sends the application a streamId (for example, the AASB message AudioOutput/Prepare ). The application then requests the stream associated with that streamId from AACS through a fetch function as follows: // streamId previously extracted from the aasb message AudioOutput/Prepare> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . StreamFetchedFromReceiverCallback fetchCallback = ( readPipe ) -> { // readPipe is a ParcelFileDescriptor // inputStream is a ParcelFileDescriptor.AutoCloseInputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseInputStream inputStream = new ParcelFileDescriptor . AutoCloseInputStream ( readPipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR (application not responding) error. // perform application logic as necessary, reading the stream // (you could read the stream here, or queue it onto a different thread, etc) // once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) inputStream . close (); }; mAACSSender . fetch ( streamId , fetchCallback , target , context ); AACS fetching data from OEM application - If the default audio input platform handler is enabled and an external audio stream source is used, when AACS receives a StartAudioInput or StopAudioInput message, it sends an IPC fetch request or an IPC cancel fetch request. This request fetches or cancels fetching the audio input stream from the application. The application must implement AACSReceiver.FetchStreamCallback , provide the write pipe associated with the audio stream in onStreamRequested(String streamId, ParcelFileDescriptor writePipe) method, and stop providing the stream in onStreamFetchCancelled(String streamId) method, as shown in the following example: AACSReceiver . FetchStreamCallback aasbFetchCallback = new AACSReceiver . FetchStreamCallback () { @Override public void onStreamRequested ( String streamId , ParcelFileDescriptor writePipe ) { // Save the streamId and create a stream using the writePipe ParcelFileDescriptor . AutoCloseOutputStream stream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // Start writing your streamed data to the ParcelFileDescriptor.AutoCloseOutputStream // Close stream and pipe as needed when streaming is done } @Override public void onStreamFetchCancelled ( String streamId ) { // Stop writing to the ParcelFileDescriptor.AutoCloseOutputStream // associated with the given streamId } } Pushing data to AACS - To receive streamed data from the application, such as microphone data, AACS first sends the application a streamId (for example, the AASB message AudioInput/StartAudioInput ). The application then sends a stream associated with AACS together with streamId to indicate which request it's fulfilling through the push function as shown in the following code: // streamId previously extracted from the aasb message AudioInput/StartAudioInput> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . PushToStreamIdCallback pushCallback = ( streamId , writePipe ) -> { // writePipe is a ParcelFileDescriptor // outputStream is a ParcelFileDescriptor.AutoCloseOutputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseOutputStream outputStream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR error. // copy microphone data to outputStream //once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) outputStream . close (); }; mAACSSender . push ( streamId , pushCallback , target , context ); Sending configuration data to AACS - The application can send configuration data to AACS as follows: String configMessage = \"{\\n\" + \" \\\"configFilepaths\\\" : [\\\"\" + path + \"\\\"],\" + \" \\\"configStrings\\\" : []\" + \"}\" ; TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); mAACSSender . sendConfigMessageAnySize ( configMessage , target , getApplicationContext ()); configMessage must include the paths to the configuration file or the config strings. AACSReceiver AACSReceiver enables an application to receive data from another application that uses AACSSender . Initialization - Most of the logic for AACSReceiver is specified in callbacks. AACSReceiver is initialized by a builder. Callbacks must be provided to the builder before the builder creates AACSReceiver . The following code shows how a builder creates AACSReceiver : AACSReceiver . Builder builder = new AACSReceiver . Builder (); AACSReceiver receiver = builder // this step is optional. If no looper is provided, // the main looper is used by default. // .receive() and .shutdown() must be called from the indicated // looper. All callbacks that AACSReceiver calls or invokes are also posted // to that looper. . withLooper ( Looper . Looper . getMainLooper ) // this callback is invoked when the receiver gets a non-streamed message, // such as an AASB message. . withAASBCallback (( message ) -> { // Perform application logic based // on the AASB message in messageString. }). build (); Receiving from the sender - AACSReceiver doesn't create any direct intent receiver, which can be a service, activity, or broadcast receiver. The AACSReceiver relies on the service, activity, or broadcast receiver in the app to forward intents to it. The following code is an example illustrating how an activity overrides onNewIntent and sends an intent to be received by AACSReceiver : @Override protected void onNewIntent ( Intent intent ) { super . onNewIntent ( intent ); setIntent ( intent ); // Intents that are sent by AACS should be received here. mAACSReceiver . receiveMessage ( intent ); }","title":"Using the IPC Library with AACS"},{"location":"aacs/android/common/ipc/#using-the-ipc-library-with-aacs","text":"","title":"Using the IPC Library with AACS"},{"location":"aacs/android/common/ipc/#overview","text":"The IPC (inter-process communication) library implements the IPC protocol required for communications between an HMI (human-machine interface) application and AACS (Alexa Auto Client Service). The library enables AACS to send and receive arbitrary types of payloads of arbitrary sizes. The library is implemented using standard Android constructs. You can use it as-is or as a reference when implementing IPC for your app.","title":"Overview"},{"location":"aacs/android/common/ipc/#getting-started-with-the-ipc-library","text":"NOTE : This section assumes that you have completed the steps for building and installing AACS. To build the IPC library, follow these steps: 1) Enter the following commands: cd $AACS_HOME/common/ipc gradle assembleDebug The aacsipc-debug.aar file is built. 1) Copy aacsipc-debug.aar to the libs folder of your app.","title":"Getting Started with the IPC Library"},{"location":"aacs/android/common/ipc/#api-usage-guide","text":"The IPC library consists of two main classes for apps to interface with: AACSSender and AACSReceiver . For an additional in-code example that illustrates how an app uses the IPC library, see an AACS Android-service project.","title":"API Usage Guide"},{"location":"aacs/android/common/ipc/#aacssender","text":"AACSSender enables an application to send data to another application that uses AACSReceiver . Initialization - When AACSSender initializes, it instantiates an AACSSender object as follows: // AACSSender posts callbacks to the looper specified in the constructor // argument. If none is provided, it uses the mainlooper. AACSSender mAACSSender = new AACSSender ( Looper . getMainLooper ()); Sending a message - AACSSender sends non-streaming data, such as an AASB (Alexa Auto Service Bridge) JSON message, to AACS as follows: // replace with the entire aasb json message String aasbMessage = \"...\" ; // replace with topic of the aasb message String aasbTopic = \"...\" ; // replace with action of the aasb message String aasbAction = \"...\" ; // can also be a list of multiple targets List<TargetComponent> TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); Context context = getApplicationContext (); mAACSSender . sendAASBMessageAnySize ( aasbMessage , aasbAction , aasbTopic , target ( s ), context ); Fetching data from AACS - To stream data to the application, such as audio data, AACS first sends the application a streamId (for example, the AASB message AudioOutput/Prepare ). The application then requests the stream associated with that streamId from AACS through a fetch function as follows: // streamId previously extracted from the aasb message AudioOutput/Prepare> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . StreamFetchedFromReceiverCallback fetchCallback = ( readPipe ) -> { // readPipe is a ParcelFileDescriptor // inputStream is a ParcelFileDescriptor.AutoCloseInputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseInputStream inputStream = new ParcelFileDescriptor . AutoCloseInputStream ( readPipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR (application not responding) error. // perform application logic as necessary, reading the stream // (you could read the stream here, or queue it onto a different thread, etc) // once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) inputStream . close (); }; mAACSSender . fetch ( streamId , fetchCallback , target , context ); AACS fetching data from OEM application - If the default audio input platform handler is enabled and an external audio stream source is used, when AACS receives a StartAudioInput or StopAudioInput message, it sends an IPC fetch request or an IPC cancel fetch request. This request fetches or cancels fetching the audio input stream from the application. The application must implement AACSReceiver.FetchStreamCallback , provide the write pipe associated with the audio stream in onStreamRequested(String streamId, ParcelFileDescriptor writePipe) method, and stop providing the stream in onStreamFetchCancelled(String streamId) method, as shown in the following example: AACSReceiver . FetchStreamCallback aasbFetchCallback = new AACSReceiver . FetchStreamCallback () { @Override public void onStreamRequested ( String streamId , ParcelFileDescriptor writePipe ) { // Save the streamId and create a stream using the writePipe ParcelFileDescriptor . AutoCloseOutputStream stream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // Start writing your streamed data to the ParcelFileDescriptor.AutoCloseOutputStream // Close stream and pipe as needed when streaming is done } @Override public void onStreamFetchCancelled ( String streamId ) { // Stop writing to the ParcelFileDescriptor.AutoCloseOutputStream // associated with the given streamId } } Pushing data to AACS - To receive streamed data from the application, such as microphone data, AACS first sends the application a streamId (for example, the AASB message AudioInput/StartAudioInput ). The application then sends a stream associated with AACS together with streamId to indicate which request it's fulfilling through the push function as shown in the following code: // streamId previously extracted from the aasb message AudioInput/StartAudioInput> String streamId = \"...\" ; Context context = getApplicationContext (); TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); AACSSender . PushToStreamIdCallback pushCallback = ( streamId , writePipe ) -> { // writePipe is a ParcelFileDescriptor // outputStream is a ParcelFileDescriptor.AutoCloseOutputStream that can be created from the given ParcelFileDescriptor ParcelFileDescriptor . AutoCloseOutputStream outputStream = new ParcelFileDescriptor . AutoCloseOutputStream ( writePipe ); // this callback gets triggered on the looper provided during construction. // If this callback is triggered on the mainlooper, it is advised // to delegate the work to a different thread to avoid // triggering an ANR error. // copy microphone data to outputStream //once finished with the stream, you must close it. // (if you queue it onto a different thread, close it there) outputStream . close (); }; mAACSSender . push ( streamId , pushCallback , target , context ); Sending configuration data to AACS - The application can send configuration data to AACS as follows: String configMessage = \"{\\n\" + \" \\\"configFilepaths\\\" : [\\\"\" + path + \"\\\"],\" + \" \\\"configStrings\\\" : []\" + \"}\" ; TargetComponent target = TargetComponent . withComponent ( new ComponentName ( \"com.amazon.alexaautoclientservice\" , \"com.amazon.alexaautoclientservice.AlexaAutoClientService\" ), TargetComponent . Type . SERVICE ); mAACSSender . sendConfigMessageAnySize ( configMessage , target , getApplicationContext ()); configMessage must include the paths to the configuration file or the config strings.","title":"AACSSender "},{"location":"aacs/android/common/ipc/#aacsreceiver","text":"AACSReceiver enables an application to receive data from another application that uses AACSSender . Initialization - Most of the logic for AACSReceiver is specified in callbacks. AACSReceiver is initialized by a builder. Callbacks must be provided to the builder before the builder creates AACSReceiver . The following code shows how a builder creates AACSReceiver : AACSReceiver . Builder builder = new AACSReceiver . Builder (); AACSReceiver receiver = builder // this step is optional. If no looper is provided, // the main looper is used by default. // .receive() and .shutdown() must be called from the indicated // looper. All callbacks that AACSReceiver calls or invokes are also posted // to that looper. . withLooper ( Looper . Looper . getMainLooper ) // this callback is invoked when the receiver gets a non-streamed message, // such as an AASB message. . withAASBCallback (( message ) -> { // Perform application logic based // on the AASB message in messageString. }). build (); Receiving from the sender - AACSReceiver doesn't create any direct intent receiver, which can be a service, activity, or broadcast receiver. The AACSReceiver relies on the service, activity, or broadcast receiver in the app to forward intents to it. The following code is an example illustrating how an activity overrides onNewIntent and sends an intent to be received by AACSReceiver : @Override protected void onNewIntent ( Intent intent ) { super . onNewIntent ( intent ); setIntent ( intent ); // Intents that are sent by AACS should be received here. mAACSReceiver . receiveMessage ( intent ); }","title":"AACSReceiver "},{"location":"aacs/android/sample-app/","text":"AACS Sample App The AACS Sample App is an Android application that runs on your vehicle's head unit. It demonstrates how an application uses Alexa Auto Client Service (AACS), an Alexa Auto SDK feature that speeds up Alexa integration for in-vehicle infotainment (IVI). The app enables the user to select Alexa as an alternative to another voice assistant and configure the way the user interacts with Alexa. The app also allows Alexa and another application to run simultaneously. This document provides conceptual information about the purpose and features of the AACS Sample App. It provides the steps for building the app and setting up Alexa. It also describes the user experience when the user interacts with Alexa when the app is running. Note: Amazon recommends that you familiarize yourself with AACS by reading the AACS README . Table of Contents AACS Sample App Architecture Prerequisites Requirements for Using AACS Sample App Requirements for Using AACS Sample App with Preview Mode Requirements for Using AACS Sample App with APL Requirements for Building AACS Sample App Requirements for Using Optional Features About App Components Building the AACS Sample App using AACS AAR Cloning the Auto SDK Repository Editing the Configuration File Including Build Dependency (AAR) Building and Signing the AACS Sample App APK Alexa Setup Language Selection Starting Alexa on the Introduction Screen Starting Authorization Alexa Configuration for Logged-in Users Using the Alexa Menu Alexa Menu for Preview Mode Users Alexa Menu for Signed-in Users Alexa Menu Options Using the AACS Sample App Selecting Alexa as the Assistant Using Alexa Custom Assistant Module Library for Animation Using the AACS Sample App for Media Player Media Resume Last Playing Media After Platform Reboot Known Issues AACS Sample App Architecture The following diagram illustrates the AACS Sample App Architecture. Prerequisites You must meet the prerequisites described in this section before you can run the AACS Sample App. Requirements for Using AACS Sample App The following list describes the requirements for the AACS Sample App: The app can only run on an Android device. The app requires AACS to be running. You can obtain the AACS AAR according to the instructions in the AACS README . The app requires the Voice Chrome extension. The app is optimized for and tested with the Android Automotive operating system. It is tested with Android API level 28. Note: The AACS Sample App requires hardware accelerated encryption on your target device. Almost all hardware-based security concepts contain this acceleration. If you see a performance issue when running the app, your device might be missing mandatory security features. Requirements for Using AACS Sample App with Preview Mode Preview Mode is an Alexa feature that gives users a restricted set of Alexa features without requiring a login to the Amazon account. To allow users to use the app with Preview Mode, obtain an app component alexa-auto-preview-mode-util from Amazon with the help of your Solutions Architect (SA) or Partner Manager. Follow the instructions included to build the app component before you proceed. Requirements for Using AACS Sample App with APL Alexa has a visual design framework called Alexa Presentation Language (APL), which allows you to build interactive voice and visual experiences across the device landscape. To allow users to use the app with APL, follow the instructions in Alexa Auto APL Renderer README to configure and build the app. Requirements for Building AACS Sample App The requirements for building the app depends on whether you use the command line interface (CLI) or Android Studio: CLI: You need Gradle to build the AACS Sample App. The tested Gradle version is 6.5. Android Studio: The Android Studio version must be 4.0 or later. Make sure that your Gradle version and Android Studio are compatible. See the Android Gradle Plugin Release Notes for information about matching Android Studio versions to Gradle versions. Requirements for Using Optional Features To use optional features delivered by Auto SDK extensions, contact your Solutions Architect or Partner Manager. The following list describes the extensions that you can use with the AACS Sample App: Alexa Custom Assistant extension gives the user the option of using a custom voice assistant when running the AACS Sample App. Mobile Authorization extension enables the user to log in to Amazon through the Alexa mobile app on the user's phone, without requiring the user to enter the CBL code. About App Components The AACS Sample App APK contains several app components, each of which consists of the compiled source code or resources used by the app to provide the UI layout, communicate with AACS, and so on. See the app components directory alexa-auto-sdk/aacs/android/app-components/ for the complete list of app components used by the AACS Sample App. See the respective README file about the purpose of each component. Building the AACS Sample App Using AACS AAR To build the AACS Sample App, follow these major steps: 1) Clone the Auto SDK repository. 2) Edit the configuration information for your device. 3) Include the build dependencies. 4) Build the AACS Sample App. Cloning the Auto SDK Repository Follow these steps to clone the Auto SDK repository: 1) Create your project directory (if you do not already have one): mkdir ~/Projects cd ~/Projects 2) Clone the alexa-auto-sdk repository into your project directory: git clone https://github.com/alexa/alexa-auto-sdk.git cd alexa-auto-sdk The Projects directory contains the Auto SDK directory structure with the android-aacs-sample-app directory and app-components directory, as shown in the following Auto SDK directory structure: . \u251c\u2500\u2500 aacs \u2502 \u2514\u2500\u2500 android \u2502 \u251c\u2500\u2500 app-components \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apis \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apl-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-carcontrol \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-comms-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-contacts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-device-usage \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-lwa-auth \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-media-player \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-navigation \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-preview-mode-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-settings \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-setup \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-telephony \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-templateruntime-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-tts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-ux-restrictions \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-voice-interaction \u2502 \u2502 \u2514\u2500\u2500 alexa-auto-voice-ui \u2502 \u251c\u2500\u2500 assets \u2502 \u251c\u2500\u2500 common \u2502 \u2502 \u251c\u2500\u2500 commonutils \u2502 \u2502 \u251c\u2500\u2500 constants \u2502 \u2502 \u2514\u2500\u2500 ipc \u2502 \u251c\u2500\u2500 sample-app \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-app \u2502 \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2514\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 service \u2502 \u251c\u2500\u2500 core-service \u2502 \u251c\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 modules Editing the Configuration File For Alexa Voice Service (AVS) to authenticate your device profile, specify the configuration information in this file: alexa-auto-sdk/aacs/android/sample-app/alexa-auto-app/src/main/assets/config/aacs_config.json The following list describes the required information for aacs.alexa.deviceInfo : For clientId , specify the Client ID that you generated when you set up your security profile for your development device. For productId , specify the Product ID that you entered when you filled in the product information for your development device. Note: clientId and productId must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . * For deviceSerialNumber , specify the serial number of your device. * For manufacturerName , specify the name of the device manufacturer. * For description , specify a description of your device. Including Build Dependency (AAR) The AACS Sample App APK requires the Auto SDK Voice Chrome extension (autovoicechrome.aar) as a dependency. Follow these steps to include the AAR: Create the following directory: alexa-auto-sdk/aacs/android/app-components/alexa-auto-voice-interaction/libs 2. Copy the AAR into the directory. After including the dependency, you can build the AACS Sample App APK either on the CLI or by using Android Studio. Building and Signing the AACS Sample App APK You can use the command line interface (CLI) or the Android Studio to build and sign the AACS Sample App APK. Using the CLI Follow these steps to build the AACS Sample App APK: 1) Enter the following command to change the directory: cd ~/Projects/alexa-auto-sdk/aacs/android/sample-app 2) Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds the Alexa Auto SDK, AACS, AACS Sample App and all the extensions present under the alexa-auto-sdk/extensions/extras directory for armv8 targets. * To enable the local debug log during the build, use assembleLocalDebug in the gradlew command. * To build AACS Sample App using the pre-built Alexa Auto SDK AARs, use assembleRemoteRelease in the gradlew command. The gradlew command creates the unsigned APK, which is located in the following directory: alexa-auto-app/build/outputs/apk/release/alexa-auto-app_release_4.0.apk The gradlew command also creates each app component's AAR, which is located in each component's build output directory. For example, the Alexa Auto Media Player AAR is in the following directory: ~/Projects/alexa-auto-sdk/aacs/android/app-components/alexa-auto-media-player/build/outputs/aar/alexa-auto-media-player_release.aar Optional Arguments The following optional arguments are supported: 1. Enable Optional Modules * To build AACS Sample App optional modules, use -Penabled<module_name> . For example, enable APL by appending -PenabledAPL to the build command. The supported module options are -PenabledAPL , -PenabledUXRestrictions , -PenabledPreviewMode , -PenabledDeviceUsage . * To enable AACS optional libraries, use -P<enabledAACSModuleName> . For example, enable AACS Telephony service by appending -PenabledTelephony to the build command. The supported module options are -PenabledTelephony , -PenabledContacts , -PenabledCarControl . See the below for the full command to enable APL, UX restrictions, telephony and contacts: ``` ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions -PenabledTelephony -PenabledContacts ``` Specify Path to Extensions By default, the builder picks up all the extensions present under the alexa-auto-sdk/extensions/extras directory. To override with your custom paths to the extensions, use -Pextensions . See the below for the full command: ./gradlew assembleLocalRelease -Pextensions=~/your/custom/path/to/extension1,~/your/custom/path/to/extension2,... Clean Cache and Rebuild To clean the AACS and AACS Sample App build cache, run ./gradlew clean first before running the build command. To rebuild only outdated dependencies, append -Pforce to the build command. This option is required when you make a change on Alexa Auto SDK. It forces the builder to re-export all the package recipes and triggers rebuild for the packages on which changes are detected. To clean all the Alexa Auto SDK cache and rebuild all the dependencies: use -PcleanDeps . Skip Dependencies To skip the step of building dependencies, use -PskipDeps . Make sure the Alexa Auto SDK dependency AARs are already present under alexa-auto-sdk/aacs/android/service/core-service/libs directory before you use this option. Specify Architecture Specify the build target by appending the option -Parch=<your_arch> , for example: -Parch=x86_64 . The supported architectures are x86 , x86_64 , armv7 , armv8 . If not specified, the builder by default builds for the armv8 target. Enable Sensitive Logs Use the option -PsensitiveLogs to enable senstive logs. Note that sensitive logs are allowed in debug builds only. Change the dependency cache location Change the location of the Alexa Auto SDK build cache by using this option: -PconanHome=your/custom/home . The default location is set to alexa-auto-sdk/builder/.builder . Automatically Accept Licenses You need to manually accept the Android SDK licenses from command line when you build the first time. Use -PacceptLicenses to automatically accept the licenses. Specify Options for Dependencies Use -PconanOptions=<recipe_name>:<option>=<custom_option> to pass any options for dependencies to the builder. AACS Sample App uses Conan to build all the Auto SDK dependencies. You can use this option to change the Conan options for any dependency recipe. Using the CLI to Sign the APK The procedure for signing the APK requires these commands: * zipalign is included in the Android SDK Build Tools. On a Mac, it is usually located in this directory: ~/Library/Android/sdk/build-tools/ /zipalign * apksigner is in Android SDK Build Tools 24.0.3 or higher. On a Mac, it is usually in the following directory: ~/Library/Android/sdk/build-tools/ /apksigner You can include the build tools in your path so that you can run the commands from any directory. The following example is for Android SDK Build Tools version 29.0.2: echo \"export PATH=\\$PATH:~/Library/Android/sdk/build-tools/29.0.2/\" ~/.bash_profile && . ~/.bash_profile To sign the APK, follow these steps: Create a custom keystore using the following command, or skip to the next step and use an existing keystore: keytool -genkey -v -keystore <keystore_name>.keystore -alias <alias> -keyalg RSA -keysize 2048 -validity 10000 Enter the following command to change to the directory where the APK is: cd alexa-auto-app/build/outputs/apk/release Enter the following command to optimize the APK files: zipalign -v -p 4 alexa-auto-app_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk Enter the following commands to sign the APK by using your keystore: apksigner sign --ks <path_to_keystore>/<keystore_name>.keystore --ks-pass pass:<passphrase> --out alexa-auto-app_signed_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk When prompted, enter the passphrase that you set when you created the keystore. Using Android Studio Note: These instructions assume that you have edited the configuration files . Launch Android Studio and select Open an existing Android Studio project. Open the folder containing the APK. For example, open the alexa-auto-app/samples/android-aacs-sample-app folder. Click the Open button. Under Build Variants , select localRelease . Add optional arguments in the alexa-auto-sdk/aacs/android/sample-app/gradle.properties file. See optional arguments for all the supported options. Remove the -P prefix when adding the option to the gradle.properties file. Note : Android Studio builds and signs the APK. Alexa Setup This section describes what the user must do to set up Alexa, which determines the user experience when the user interacts with Alexa. The information here supersedes the information in the Setup documentation . Note: The Alexa setup process is different for users of Preview Mode and users who signed in. The setup procedure includes the following steps: 1) Select Alexa's language (if the language used for IVI is not supported by Alexa). 2) Accept the use of Alexa in Preview Mode or perform a user login. 3) Configure initial Alexa settings (for logged-in users). Note: To complete Alexa setup, the user must have internet connection. Language Selection The Alexa setup starts with selecting a language to be used by Alexa. The workflow for language selection depends on the language used by the IVI: If the language used for the IVI is supported by Alexa, there is no need to select a language because the app sets Alexa's language to match the IVI language. If the user prefers to use a different language for Alexa, the user can change it at a later time through the Alexa menu. If the language used for the IVI is not supported by Alexa, a menu is displayed for language selection. After the selection, the locale is changed according to the language selected. However, the setup workflow displays text in en-US. For a list of languages supported by Alexa, see the Alexa Voice Service documentation . Starting Alexa on the Sign in Screen The Sign in screen is displayed after the user selects the language. It displays the following contents depending on whether the AACS Sample App is used with Preview Mode: With Preview Mode: The screen shows two buttons. The user can click on the TRY ALEXA button to connect to Alexa in Preview mode, or on the SIGN-IN button to sign in using their Amazon account credentials. Without Preview Mode: The screen shows the SIGN-IN button only. Starting Authorization The exact authorization workflow depends on whether the AACS Sample App is used with Preview Mode. If so, the Alexa Voice Service (AVS) access token is retrieved without a user login. Otherwise, the user uses Login With Amazon (LWA) to gain access to Alexa. The Auto SDK can use various authorization methods, such as Code-Based Linking (CBL) and Mobile Authorization, to retrieve the access token. Authorization With Preview Mode On the Sign-in screen, the user can click TRY ALEXA , which means that the user will access Alexa through Preview Mode. The Preview Mode consent screen is then displayed wherein the user can review Amazon\u2019s Conditions of Use, Alexa & Alexa Device terms and Privacy policy. After clicking on the AGREE & ENABLE ALEXA button, the Success screen is displayed providing sample utterances for the user to try. Authorization Without Preview Mode The user can log in to Amazon to access the complete set of Alexa features. How the user logs in depends on whether the Auto SDK is running with the Bluetooth extension and Mobile Authorization extension. Without the LWP feature, the user sees the Sign-in screen showing the URL and a code (in the form of a string and a QR code), which the user uses to finish the CBL authorization. After authorization, the user's Amazon account is linked to the vehicle. With the LWP feature, when the user's phone is connected to the head unit via Bluetooth, the user sees a notification on the phone. After the user accepts the notification, the user is authenticated with the Amazon account information that the Alexa mobile app uses for Amazon login. For more information about LWP, see the LWP extension README. Alexa Configuration for Logged-in Users If the user is logged in, the user is prompted to further configure Alexa. The user is shown the location consent screen wherein they have the option to either enable location sharing or skip it. Next, if a Bluetooth-connected phone is detected, the app prompts the user to give permission for Alexa to access contacts. After this configuration step, the app displays the Success screen as confirmation that the user can start using Alexa. If your device is allow-listed by Amazon for supporting device setup, the user hears a first-time conversation from Alexa, which provides the on-boarding experience. Using the Alexa Menu The AACS Sample App provides an Alexa menu through which the user can change any settings configured during the setup process. For options with an On or Off value, the menu provides a toggle button. The Alexa menu is different for users of Preview Mode and users who signed in. Note: When developing your Android app, you may add options to the Alexa menu. Add such option at the end of the Alexa menu. Alexa Menu for Preview Mode Users In Preview Mode, the Alexa menu is organized as follows: Sign in Alexa Hands-Free Location sharing Sounds Alexa's language Disable Alexa Alexa Menu for Signed-in Users For signed-in users, the Alexa menu is organized as follows: Alexa Hands-Free Do Not Disturb Location sharing Communication Device name Contacts Sounds Alexa's language Sign out Alexa Menu Options The following table describes each Alexa menu option: Option Description Possible values (Default) Sign in (For Preview Mode users only) It allows the user to sign in with CBL or LWP. Alexa Hands-Free If it is enabled, the user can say \"Alexa\" to invoke Alexa. If it is disabled, the user can still use PTT or TTT to invoke Alexa. On, Off (On) Do Not Disturb (For signed-in users only) If enabled, it disables Alexa notifications. On, Off (Off) Location sharing If it is enabled, the user can use location-based utterances like \"Alexa, show me some coffee shops near me\". If it is disabled, Alexa will not have access to the device's location and will expect the user to explicitly provide their location as a follow up voice utterance in order to respond to location-based utterances. On, Off (value specified during Alexa setup) Communication Name of the device on which the app runs (e.g., Sam's iPhone). Communication > Contacts If it is enabled, contacts are uploaded from the phone to Alexa, and the user can use Alexa to call or receive a call from a contact. On, Off (value specified during Alexa setup) Sounds Alexa sound settings. Sounds > Start/End of request sound If enabled, a sound is played with Alexa starts/stops listening. On, Off (On) Alexa's language The language used by Alexa when responding to your request. Languages supported by Alexa (language specified during Alexa setup) Sign out (For signed-in users only) Button for the user to sign out of Alexa. It displays a confirmation message before the user is signed out. Disable Alexa (For Preview Mode users only) It displays a screen with a DISABLE button, which stops Alexa from being available in the vehicle. Using the AACS Sample App This section describes the user experience after you deploy the AACS Sample App on an Android device. Selecting Alexa as the Assistant While Google Assistant is usually the default voice assistant on an Android device, when the AACS Sample App is running, the user has the option of selecting Alexa as the assistant. The app, by running Alexa Voice Interaction as an Android service, demonstrates how a user can use the Android Automotive System UI to select Alexa as the assistant as follows: 1) Go to the device's Settings. 2) Go to Apps & notifications > Default apps > Assist & voice input . Then select Alexa. Note: After selecting Alexa as the assistant, if the Auto SDK is built with the Alexa Custom Assistant extension, the user can invoke either Alexa or a custom voice assistant (e.g., Brandon). Using Alexa Custom Assistant Module Library for Animation If the Alexa Custom Assistant extension is installed, you can use the Alexa Custom Assistant Module Library to display custom animation when user is interacting with the custom assistant. For more information about how to enable custom animation, see the Alexa Custom Assistant extension README. Using the AACS Sample App for Media Player In addition to letting the user choose Alexa as the voice assistant, the AACS Sample app enables the user to start and control the media player. Alexa integrates with most music providers in cloud. After the user launches the app and selects Alexa as the assistant, the user can say, for example, \"Alexa, play the station [station call sign] on iHeartRadio.\" The app displays the user interface (UI) that comes with Android Automotive. The same UI is presented for all media providers, such as iHeartRadio and Amazon Music. However, the exact UI elements depend on the provider. For example, when the app plays music from iHeartRadio, it does not include a rewind button to go back. When the app plays music from Amazon Music, the rewind button is present. In addition, the user can say, \"Go back 30 seconds,\" to go back. The user can also use the app to listen to audio books. For example, if the user says, \"Alexa, play the start of lord of the rings book one,\" Alexa starts playing the audio book from Audible. The UI displayed by the app includes the buttons for skipping 30 seconds backward or forward. Media Resume Last Playing Media After Platform Reboot Generally, automotive infotainment platforms support media media resume after the reboot. Alexa Media Resume is a feature that helps Alexa play customers\u2019 favorite content when they restart their Alexa-enabled vehicles. Media Resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. Refer to Media Resume for more information about the feature. This feature works out of the box on Automotive Android OS. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } } Note If you are not using automotive android then it is assumed that your platform manages the sessions, enables the MediaBrowserService after reboot and sends the play command. In that case you may need to modify alexa-auto-media-player code to send the requestMediaPlayback message. Note Default implementation in the PlaybackControlMessages.java gets the elapsed boot time using Android API SystemClock.elapsedRealtime() If your platform provides the correct elapsed boot time value using any different API, please update it. Known Issues Android Emulator on macOS has poor audio quality, which would cause the Alexa Text-to-Speech (TTS) output to be unusable. In the Android Automotive Emulator, the Push-to-Talk button on the system navigation bar does not integrate with the Android Voice Interaction module properly. It is hard coded to invoke Google Assistant instead. Therefore, even if the user tries to switch from the default voice assistant to Alexa, the Push-to-Talk button on the system navigation bar still invokes the Google Assistant. Note: Please refer to the component level README files for more information/known issues that relate to the component","title":"AACS Sample App"},{"location":"aacs/android/sample-app/#aacs-sample-app","text":"The AACS Sample App is an Android application that runs on your vehicle's head unit. It demonstrates how an application uses Alexa Auto Client Service (AACS), an Alexa Auto SDK feature that speeds up Alexa integration for in-vehicle infotainment (IVI). The app enables the user to select Alexa as an alternative to another voice assistant and configure the way the user interacts with Alexa. The app also allows Alexa and another application to run simultaneously. This document provides conceptual information about the purpose and features of the AACS Sample App. It provides the steps for building the app and setting up Alexa. It also describes the user experience when the user interacts with Alexa when the app is running. Note: Amazon recommends that you familiarize yourself with AACS by reading the AACS README .","title":"AACS Sample App"},{"location":"aacs/android/sample-app/#table-of-contents","text":"AACS Sample App Architecture Prerequisites Requirements for Using AACS Sample App Requirements for Using AACS Sample App with Preview Mode Requirements for Using AACS Sample App with APL Requirements for Building AACS Sample App Requirements for Using Optional Features About App Components Building the AACS Sample App using AACS AAR Cloning the Auto SDK Repository Editing the Configuration File Including Build Dependency (AAR) Building and Signing the AACS Sample App APK Alexa Setup Language Selection Starting Alexa on the Introduction Screen Starting Authorization Alexa Configuration for Logged-in Users Using the Alexa Menu Alexa Menu for Preview Mode Users Alexa Menu for Signed-in Users Alexa Menu Options Using the AACS Sample App Selecting Alexa as the Assistant Using Alexa Custom Assistant Module Library for Animation Using the AACS Sample App for Media Player Media Resume Last Playing Media After Platform Reboot Known Issues","title":"Table of Contents"},{"location":"aacs/android/sample-app/#aacs-sample-app-architecture","text":"The following diagram illustrates the AACS Sample App Architecture.","title":"AACS Sample App Architecture"},{"location":"aacs/android/sample-app/#prerequisites","text":"You must meet the prerequisites described in this section before you can run the AACS Sample App.","title":"Prerequisites"},{"location":"aacs/android/sample-app/#requirements-for-using-aacs-sample-app","text":"The following list describes the requirements for the AACS Sample App: The app can only run on an Android device. The app requires AACS to be running. You can obtain the AACS AAR according to the instructions in the AACS README . The app requires the Voice Chrome extension. The app is optimized for and tested with the Android Automotive operating system. It is tested with Android API level 28. Note: The AACS Sample App requires hardware accelerated encryption on your target device. Almost all hardware-based security concepts contain this acceleration. If you see a performance issue when running the app, your device might be missing mandatory security features.","title":"Requirements for Using AACS Sample App"},{"location":"aacs/android/sample-app/#requirements-for-using-aacs-sample-app-with-preview-mode","text":"Preview Mode is an Alexa feature that gives users a restricted set of Alexa features without requiring a login to the Amazon account. To allow users to use the app with Preview Mode, obtain an app component alexa-auto-preview-mode-util from Amazon with the help of your Solutions Architect (SA) or Partner Manager. Follow the instructions included to build the app component before you proceed.","title":"Requirements for Using AACS Sample App with Preview Mode"},{"location":"aacs/android/sample-app/#requirements-for-using-aacs-sample-app-with-apl","text":"Alexa has a visual design framework called Alexa Presentation Language (APL), which allows you to build interactive voice and visual experiences across the device landscape. To allow users to use the app with APL, follow the instructions in Alexa Auto APL Renderer README to configure and build the app.","title":"Requirements for Using AACS Sample App with APL"},{"location":"aacs/android/sample-app/#requirements-for-building-aacs-sample-app","text":"The requirements for building the app depends on whether you use the command line interface (CLI) or Android Studio: CLI: You need Gradle to build the AACS Sample App. The tested Gradle version is 6.5. Android Studio: The Android Studio version must be 4.0 or later. Make sure that your Gradle version and Android Studio are compatible. See the Android Gradle Plugin Release Notes for information about matching Android Studio versions to Gradle versions.","title":"Requirements for Building AACS Sample App"},{"location":"aacs/android/sample-app/#requirements-for-using-optional-features","text":"To use optional features delivered by Auto SDK extensions, contact your Solutions Architect or Partner Manager. The following list describes the extensions that you can use with the AACS Sample App: Alexa Custom Assistant extension gives the user the option of using a custom voice assistant when running the AACS Sample App. Mobile Authorization extension enables the user to log in to Amazon through the Alexa mobile app on the user's phone, without requiring the user to enter the CBL code.","title":"Requirements for Using Optional Features"},{"location":"aacs/android/sample-app/#about-app-components","text":"The AACS Sample App APK contains several app components, each of which consists of the compiled source code or resources used by the app to provide the UI layout, communicate with AACS, and so on. See the app components directory alexa-auto-sdk/aacs/android/app-components/ for the complete list of app components used by the AACS Sample App. See the respective README file about the purpose of each component.","title":"About App Components"},{"location":"aacs/android/sample-app/#building-the-aacs-sample-app-using-aacs-aar","text":"To build the AACS Sample App, follow these major steps: 1) Clone the Auto SDK repository. 2) Edit the configuration information for your device. 3) Include the build dependencies. 4) Build the AACS Sample App.","title":"Building the AACS Sample App Using AACS AAR"},{"location":"aacs/android/sample-app/#cloning-the-auto-sdk-repository","text":"Follow these steps to clone the Auto SDK repository: 1) Create your project directory (if you do not already have one): mkdir ~/Projects cd ~/Projects 2) Clone the alexa-auto-sdk repository into your project directory: git clone https://github.com/alexa/alexa-auto-sdk.git cd alexa-auto-sdk The Projects directory contains the Auto SDK directory structure with the android-aacs-sample-app directory and app-components directory, as shown in the following Auto SDK directory structure: . \u251c\u2500\u2500 aacs \u2502 \u2514\u2500\u2500 android \u2502 \u251c\u2500\u2500 app-components \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apis \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apl-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-apps-common-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-carcontrol \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-comms-ui \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-contacts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-device-usage \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-lwa-auth \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-media-player \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-navigation \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-preview-mode-util \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-settings \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-setup \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-telephony \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-templateruntime-renderer \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-tts \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-ux-restrictions \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-voice-interaction \u2502 \u2502 \u2514\u2500\u2500 alexa-auto-voice-ui \u2502 \u251c\u2500\u2500 assets \u2502 \u251c\u2500\u2500 common \u2502 \u2502 \u251c\u2500\u2500 commonutils \u2502 \u2502 \u251c\u2500\u2500 constants \u2502 \u2502 \u2514\u2500\u2500 ipc \u2502 \u251c\u2500\u2500 sample-app \u2502 \u2502 \u251c\u2500\u2500 alexa-auto-app \u2502 \u2502 \u251c\u2500\u2500 build \u2502 \u2502 \u2514\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 service \u2502 \u251c\u2500\u2500 core-service \u2502 \u251c\u2500\u2500 gradle \u2502 \u2514\u2500\u2500 modules","title":"Cloning the Auto SDK Repository"},{"location":"aacs/android/sample-app/#editing-the-configuration-file","text":"For Alexa Voice Service (AVS) to authenticate your device profile, specify the configuration information in this file: alexa-auto-sdk/aacs/android/sample-app/alexa-auto-app/src/main/assets/config/aacs_config.json The following list describes the required information for aacs.alexa.deviceInfo : For clientId , specify the Client ID that you generated when you set up your security profile for your development device. For productId , specify the Product ID that you entered when you filled in the product information for your development device. Note: clientId and productId must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . * For deviceSerialNumber , specify the serial number of your device. * For manufacturerName , specify the name of the device manufacturer. * For description , specify a description of your device.","title":"Editing the Configuration File"},{"location":"aacs/android/sample-app/#including-build-dependency-aar","text":"The AACS Sample App APK requires the Auto SDK Voice Chrome extension (autovoicechrome.aar) as a dependency. Follow these steps to include the AAR: Create the following directory: alexa-auto-sdk/aacs/android/app-components/alexa-auto-voice-interaction/libs 2. Copy the AAR into the directory. After including the dependency, you can build the AACS Sample App APK either on the CLI or by using Android Studio.","title":"Including Build Dependency (AAR)"},{"location":"aacs/android/sample-app/#building-and-signing-the-aacs-sample-app-apk","text":"You can use the command line interface (CLI) or the Android Studio to build and sign the AACS Sample App APK.","title":"Building and Signing the AACS Sample App APK"},{"location":"aacs/android/sample-app/#using-the-cli","text":"Follow these steps to build the AACS Sample App APK: 1) Enter the following command to change the directory: cd ~/Projects/alexa-auto-sdk/aacs/android/sample-app 2) Enter the following command to start the local build. ./gradlew assembleLocalRelease This command builds the Alexa Auto SDK, AACS, AACS Sample App and all the extensions present under the alexa-auto-sdk/extensions/extras directory for armv8 targets. * To enable the local debug log during the build, use assembleLocalDebug in the gradlew command. * To build AACS Sample App using the pre-built Alexa Auto SDK AARs, use assembleRemoteRelease in the gradlew command. The gradlew command creates the unsigned APK, which is located in the following directory: alexa-auto-app/build/outputs/apk/release/alexa-auto-app_release_4.0.apk The gradlew command also creates each app component's AAR, which is located in each component's build output directory. For example, the Alexa Auto Media Player AAR is in the following directory: ~/Projects/alexa-auto-sdk/aacs/android/app-components/alexa-auto-media-player/build/outputs/aar/alexa-auto-media-player_release.aar","title":"Using the CLI"},{"location":"aacs/android/sample-app/#optional-arguments","text":"The following optional arguments are supported: 1. Enable Optional Modules * To build AACS Sample App optional modules, use -Penabled<module_name> . For example, enable APL by appending -PenabledAPL to the build command. The supported module options are -PenabledAPL , -PenabledUXRestrictions , -PenabledPreviewMode , -PenabledDeviceUsage . * To enable AACS optional libraries, use -P<enabledAACSModuleName> . For example, enable AACS Telephony service by appending -PenabledTelephony to the build command. The supported module options are -PenabledTelephony , -PenabledContacts , -PenabledCarControl . See the below for the full command to enable APL, UX restrictions, telephony and contacts: ``` ./gradlew assembleLocalRelease -PenabledAPL -PenabledUXRestrictions -PenabledTelephony -PenabledContacts ``` Specify Path to Extensions By default, the builder picks up all the extensions present under the alexa-auto-sdk/extensions/extras directory. To override with your custom paths to the extensions, use -Pextensions . See the below for the full command: ./gradlew assembleLocalRelease -Pextensions=~/your/custom/path/to/extension1,~/your/custom/path/to/extension2,... Clean Cache and Rebuild To clean the AACS and AACS Sample App build cache, run ./gradlew clean first before running the build command. To rebuild only outdated dependencies, append -Pforce to the build command. This option is required when you make a change on Alexa Auto SDK. It forces the builder to re-export all the package recipes and triggers rebuild for the packages on which changes are detected. To clean all the Alexa Auto SDK cache and rebuild all the dependencies: use -PcleanDeps . Skip Dependencies To skip the step of building dependencies, use -PskipDeps . Make sure the Alexa Auto SDK dependency AARs are already present under alexa-auto-sdk/aacs/android/service/core-service/libs directory before you use this option. Specify Architecture Specify the build target by appending the option -Parch=<your_arch> , for example: -Parch=x86_64 . The supported architectures are x86 , x86_64 , armv7 , armv8 . If not specified, the builder by default builds for the armv8 target. Enable Sensitive Logs Use the option -PsensitiveLogs to enable senstive logs. Note that sensitive logs are allowed in debug builds only. Change the dependency cache location Change the location of the Alexa Auto SDK build cache by using this option: -PconanHome=your/custom/home . The default location is set to alexa-auto-sdk/builder/.builder . Automatically Accept Licenses You need to manually accept the Android SDK licenses from command line when you build the first time. Use -PacceptLicenses to automatically accept the licenses. Specify Options for Dependencies Use -PconanOptions=<recipe_name>:<option>=<custom_option> to pass any options for dependencies to the builder. AACS Sample App uses Conan to build all the Auto SDK dependencies. You can use this option to change the Conan options for any dependency recipe.","title":"Optional Arguments"},{"location":"aacs/android/sample-app/#using-the-cli-to-sign-the-apk","text":"The procedure for signing the APK requires these commands: * zipalign is included in the Android SDK Build Tools. On a Mac, it is usually located in this directory: ~/Library/Android/sdk/build-tools/ /zipalign * apksigner is in Android SDK Build Tools 24.0.3 or higher. On a Mac, it is usually in the following directory: ~/Library/Android/sdk/build-tools/ /apksigner You can include the build tools in your path so that you can run the commands from any directory. The following example is for Android SDK Build Tools version 29.0.2: echo \"export PATH=\\$PATH:~/Library/Android/sdk/build-tools/29.0.2/\" ~/.bash_profile && . ~/.bash_profile To sign the APK, follow these steps: Create a custom keystore using the following command, or skip to the next step and use an existing keystore: keytool -genkey -v -keystore <keystore_name>.keystore -alias <alias> -keyalg RSA -keysize 2048 -validity 10000 Enter the following command to change to the directory where the APK is: cd alexa-auto-app/build/outputs/apk/release Enter the following command to optimize the APK files: zipalign -v -p 4 alexa-auto-app_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk Enter the following commands to sign the APK by using your keystore: apksigner sign --ks <path_to_keystore>/<keystore_name>.keystore --ks-pass pass:<passphrase> --out alexa-auto-app_signed_release_1.0.apk alexa-auto-app_unsigned_release_1.0-aligned.apk When prompted, enter the passphrase that you set when you created the keystore.","title":"Using the CLI to Sign the APK"},{"location":"aacs/android/sample-app/#using-android-studio","text":"Note: These instructions assume that you have edited the configuration files . Launch Android Studio and select Open an existing Android Studio project. Open the folder containing the APK. For example, open the alexa-auto-app/samples/android-aacs-sample-app folder. Click the Open button. Under Build Variants , select localRelease . Add optional arguments in the alexa-auto-sdk/aacs/android/sample-app/gradle.properties file. See optional arguments for all the supported options. Remove the -P prefix when adding the option to the gradle.properties file. Note : Android Studio builds and signs the APK.","title":"Using Android Studio"},{"location":"aacs/android/sample-app/#alexa-setup","text":"This section describes what the user must do to set up Alexa, which determines the user experience when the user interacts with Alexa. The information here supersedes the information in the Setup documentation . Note: The Alexa setup process is different for users of Preview Mode and users who signed in. The setup procedure includes the following steps: 1) Select Alexa's language (if the language used for IVI is not supported by Alexa). 2) Accept the use of Alexa in Preview Mode or perform a user login. 3) Configure initial Alexa settings (for logged-in users). Note: To complete Alexa setup, the user must have internet connection.","title":"Alexa Setup"},{"location":"aacs/android/sample-app/#language-selection","text":"The Alexa setup starts with selecting a language to be used by Alexa. The workflow for language selection depends on the language used by the IVI: If the language used for the IVI is supported by Alexa, there is no need to select a language because the app sets Alexa's language to match the IVI language. If the user prefers to use a different language for Alexa, the user can change it at a later time through the Alexa menu. If the language used for the IVI is not supported by Alexa, a menu is displayed for language selection. After the selection, the locale is changed according to the language selected. However, the setup workflow displays text in en-US. For a list of languages supported by Alexa, see the Alexa Voice Service documentation .","title":"Language Selection"},{"location":"aacs/android/sample-app/#starting-alexa-on-the-sign-in-screen","text":"The Sign in screen is displayed after the user selects the language. It displays the following contents depending on whether the AACS Sample App is used with Preview Mode: With Preview Mode: The screen shows two buttons. The user can click on the TRY ALEXA button to connect to Alexa in Preview mode, or on the SIGN-IN button to sign in using their Amazon account credentials. Without Preview Mode: The screen shows the SIGN-IN button only.","title":"Starting Alexa on the Sign in Screen"},{"location":"aacs/android/sample-app/#starting-authorization","text":"The exact authorization workflow depends on whether the AACS Sample App is used with Preview Mode. If so, the Alexa Voice Service (AVS) access token is retrieved without a user login. Otherwise, the user uses Login With Amazon (LWA) to gain access to Alexa. The Auto SDK can use various authorization methods, such as Code-Based Linking (CBL) and Mobile Authorization, to retrieve the access token.","title":"Starting Authorization"},{"location":"aacs/android/sample-app/#authorization-with-preview-mode","text":"On the Sign-in screen, the user can click TRY ALEXA , which means that the user will access Alexa through Preview Mode. The Preview Mode consent screen is then displayed wherein the user can review Amazon\u2019s Conditions of Use, Alexa & Alexa Device terms and Privacy policy. After clicking on the AGREE & ENABLE ALEXA button, the Success screen is displayed providing sample utterances for the user to try.","title":"Authorization With Preview Mode"},{"location":"aacs/android/sample-app/#authorization-without-preview-mode","text":"The user can log in to Amazon to access the complete set of Alexa features. How the user logs in depends on whether the Auto SDK is running with the Bluetooth extension and Mobile Authorization extension. Without the LWP feature, the user sees the Sign-in screen showing the URL and a code (in the form of a string and a QR code), which the user uses to finish the CBL authorization. After authorization, the user's Amazon account is linked to the vehicle. With the LWP feature, when the user's phone is connected to the head unit via Bluetooth, the user sees a notification on the phone. After the user accepts the notification, the user is authenticated with the Amazon account information that the Alexa mobile app uses for Amazon login. For more information about LWP, see the LWP extension README.","title":"Authorization Without Preview Mode"},{"location":"aacs/android/sample-app/#alexa-configuration-for-logged-in-users","text":"If the user is logged in, the user is prompted to further configure Alexa. The user is shown the location consent screen wherein they have the option to either enable location sharing or skip it. Next, if a Bluetooth-connected phone is detected, the app prompts the user to give permission for Alexa to access contacts. After this configuration step, the app displays the Success screen as confirmation that the user can start using Alexa. If your device is allow-listed by Amazon for supporting device setup, the user hears a first-time conversation from Alexa, which provides the on-boarding experience.","title":"Alexa Configuration for Logged-in Users"},{"location":"aacs/android/sample-app/#using-the-alexa-menu","text":"The AACS Sample App provides an Alexa menu through which the user can change any settings configured during the setup process. For options with an On or Off value, the menu provides a toggle button. The Alexa menu is different for users of Preview Mode and users who signed in. Note: When developing your Android app, you may add options to the Alexa menu. Add such option at the end of the Alexa menu.","title":"Using the Alexa Menu"},{"location":"aacs/android/sample-app/#alexa-menu-for-preview-mode-users","text":"In Preview Mode, the Alexa menu is organized as follows: Sign in Alexa Hands-Free Location sharing Sounds Alexa's language Disable Alexa","title":"Alexa Menu for Preview Mode Users"},{"location":"aacs/android/sample-app/#alexa-menu-for-signed-in-users","text":"For signed-in users, the Alexa menu is organized as follows: Alexa Hands-Free Do Not Disturb Location sharing Communication Device name Contacts Sounds Alexa's language Sign out","title":"Alexa Menu for Signed-in Users"},{"location":"aacs/android/sample-app/#alexa-menu-options","text":"The following table describes each Alexa menu option: Option Description Possible values (Default) Sign in (For Preview Mode users only) It allows the user to sign in with CBL or LWP. Alexa Hands-Free If it is enabled, the user can say \"Alexa\" to invoke Alexa. If it is disabled, the user can still use PTT or TTT to invoke Alexa. On, Off (On) Do Not Disturb (For signed-in users only) If enabled, it disables Alexa notifications. On, Off (Off) Location sharing If it is enabled, the user can use location-based utterances like \"Alexa, show me some coffee shops near me\". If it is disabled, Alexa will not have access to the device's location and will expect the user to explicitly provide their location as a follow up voice utterance in order to respond to location-based utterances. On, Off (value specified during Alexa setup) Communication Name of the device on which the app runs (e.g., Sam's iPhone). Communication > Contacts If it is enabled, contacts are uploaded from the phone to Alexa, and the user can use Alexa to call or receive a call from a contact. On, Off (value specified during Alexa setup) Sounds Alexa sound settings. Sounds > Start/End of request sound If enabled, a sound is played with Alexa starts/stops listening. On, Off (On) Alexa's language The language used by Alexa when responding to your request. Languages supported by Alexa (language specified during Alexa setup) Sign out (For signed-in users only) Button for the user to sign out of Alexa. It displays a confirmation message before the user is signed out. Disable Alexa (For Preview Mode users only) It displays a screen with a DISABLE button, which stops Alexa from being available in the vehicle.","title":"Alexa Menu Options"},{"location":"aacs/android/sample-app/#using-the-aacs-sample-app","text":"This section describes the user experience after you deploy the AACS Sample App on an Android device.","title":"Using the AACS Sample App"},{"location":"aacs/android/sample-app/#selecting-alexa-as-the-assistant","text":"While Google Assistant is usually the default voice assistant on an Android device, when the AACS Sample App is running, the user has the option of selecting Alexa as the assistant. The app, by running Alexa Voice Interaction as an Android service, demonstrates how a user can use the Android Automotive System UI to select Alexa as the assistant as follows: 1) Go to the device's Settings. 2) Go to Apps & notifications > Default apps > Assist & voice input . Then select Alexa. Note: After selecting Alexa as the assistant, if the Auto SDK is built with the Alexa Custom Assistant extension, the user can invoke either Alexa or a custom voice assistant (e.g., Brandon).","title":"Selecting Alexa as the Assistant"},{"location":"aacs/android/sample-app/#using-alexa-custom-assistant-module-library-for-animation","text":"If the Alexa Custom Assistant extension is installed, you can use the Alexa Custom Assistant Module Library to display custom animation when user is interacting with the custom assistant. For more information about how to enable custom animation, see the Alexa Custom Assistant extension README.","title":"Using Alexa Custom Assistant Module Library for Animation"},{"location":"aacs/android/sample-app/#using-the-aacs-sample-app-for-media-player","text":"In addition to letting the user choose Alexa as the voice assistant, the AACS Sample app enables the user to start and control the media player. Alexa integrates with most music providers in cloud. After the user launches the app and selects Alexa as the assistant, the user can say, for example, \"Alexa, play the station [station call sign] on iHeartRadio.\" The app displays the user interface (UI) that comes with Android Automotive. The same UI is presented for all media providers, such as iHeartRadio and Amazon Music. However, the exact UI elements depend on the provider. For example, when the app plays music from iHeartRadio, it does not include a rewind button to go back. When the app plays music from Amazon Music, the rewind button is present. In addition, the user can say, \"Go back 30 seconds,\" to go back. The user can also use the app to listen to audio books. For example, if the user says, \"Alexa, play the start of lord of the rings book one,\" Alexa starts playing the audio book from Audible. The UI displayed by the app includes the buttons for skipping 30 seconds backward or forward.","title":"Using the AACS Sample App for Media Player"},{"location":"aacs/android/sample-app/#media-resume-last-playing-media-after-platform-reboot","text":"Generally, automotive infotainment platforms support media media resume after the reboot. Alexa Media Resume is a feature that helps Alexa play customers\u2019 favorite content when they restart their Alexa-enabled vehicles. Media Resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. Refer to Media Resume for more information about the feature. This feature works out of the box on Automotive Android OS. Following configuration is required to enable and use this feature: \"aacs.alexa\" : { \"requestMediaPlayback\" : { \"mediaResumeThreshold\" : 50000 } } Note If you are not using automotive android then it is assumed that your platform manages the sessions, enables the MediaBrowserService after reboot and sends the play command. In that case you may need to modify alexa-auto-media-player code to send the requestMediaPlayback message. Note Default implementation in the PlaybackControlMessages.java gets the elapsed boot time using Android API SystemClock.elapsedRealtime() If your platform provides the correct elapsed boot time value using any different API, please update it.","title":"Media Resume Last Playing Media After Platform Reboot"},{"location":"aacs/android/sample-app/#known-issues","text":"Android Emulator on macOS has poor audio quality, which would cause the Alexa Text-to-Speech (TTS) output to be unusable. In the Android Automotive Emulator, the Push-to-Talk button on the system navigation bar does not integrate with the Android Voice Interaction module properly. It is hard coded to invoke Google Assistant instead. Therefore, even if the user tries to switch from the default voice assistant to Alexa, the Push-to-Talk button on the system navigation bar still invokes the Google Assistant. Note: Please refer to the component level README files for more information/known issues that relate to the component","title":"Known Issues"},{"location":"aacs/android/service/","text":"Configuration Reference for AACS (Alexa Auto Client Service) This document explains the various fields of the AACS configuration. The AACS configuration is similar to the Auto SDK configuration, with a few additional fields unique to AACS. Table of Contents Auto SDK Modules localMediaSource AACS Module Enablement General persistentSystemService startServiceOnBootEnabled syncSystemPropertyChange updateSystemPropertyAllowed intentTargets Default Platform Handlers useDefaultLocationProvider useDefaultNetworkInfoProvider useDefaultExternalMediaAdapter useDefaultPropertyManager useDefaultCustomDomainMessageDispatcher audioInput audioOutput useDefaultLocalMediaSource Auto SDK Modules You configure a module in AACS in a similar way as you configure a module in the Auto SDK. For example, the Auto SDK specifies a module in the configuration as aace.<module> , and AACS specifies a module in the configuration as aacs.<module> . See the Auto SDK's documentation for information about the Auto SDK configuration. The following example shows the syntax for configuring the CBL module in AACS, which is the same as the syntax in the Auto SDK: { \"aacs.cbl\" : { \"enableUserProfile\": false } } Optionally, you can also configure the timeout value of AASB synchronous messages in aacs.messageBroker , as detailed in Core Module README for configuring the MessageBroker. The default timeout duration is 500 ms. { \"aacs.messageBroker\": { ... \"defaultMessageTimeout\": 1000 } } The aacs.alexa module has a structure that is slightly different from its Auto SDK counterpart as explained in the following list: In AACS, there is no avsDeviceSDK node, because most of the configuration required for this section is done within AACS. The only required configuration from avsDeviceSDK is deviceInfo , and it is specified directly under aacs.alexa . aacs.alexa contains a node called localMediaSource , which explicitly specifies which media sources are available. The following example shows deviceInfo and localMediaSource in the configuration for aacs.alexa : { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"\", \"description\": \"\" }, \"localMediaSource\": { \"types\": [\"FM_RADIO\"] } } } localMediaSource Type: JSON Object Specifies which local media sources are available and handled in the application. If your application prefers AACS to handle the local media sources, use useDefaultLocalMediaSource instead. types Type: String Array Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT AACS Module Enablement AACS allows your application to enable/disable certain modules using AACS configuration file. To enable or disable certain modules, add certain JSON blocks to the AACS configuration inside \"aacs.modules\" block, as shown in the following examples: APL module is disabled by default. To enable APL, add the following configuration to the configuration file: \"aacs.modules\": { \"aacs.apl\": { \"APL\": { \"enabled\": true } } } - Custom Domain module is disabled by default. Similarly to APL, to enable Custom Domain, add the following configuration to aacs.modules in the configuration file: \"aacs.customDomain\": { \"CustomDomain\": { \"enabled\": true } } Note : If Custom Domain module is enabled, you must provide a valid aacs.customDomain configuration to configure the engine with your custom interfaces. Otherwise, the engine will fail to start. See Required Engine Configuration for Custom Domain module. Authorization and CBL cannot be enabled at the same time. CBL module is deprecated in version 3.1, your application should use the Authorization modules instead. To disable CBL , add the following configuration to aacs.modules in the configuration file: \"aacs.cbl\": { \"CBL\": { \"enabled\": false } } If your application uses the deprecated CBL module, disable the Authorization module in the configuration: \"aacs.authorization\": { \"Authorization\": { \"enabled\": false } } For configuring module enablement, more information can be found at Configurating the MessageBroker General aacs.general is used for most configurable values of AACS that are not required for the Auto SDK, as shown in the following example: { \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"syncSystemPropertyChange\": false, \"intentTargets\" : {...} } } version Type: String Indicates the version of AACS to be used. Releases of AACS will have current and minimum-supported versions. Versions outside this range will not be compatible and the service will not start as a result. persistentSystemService Type: Boolean When persistentSystemService is set to false (default), AACS starts as a foreground service, which has higher priority on the Android system. If you have system-level control over your device, you may set this field to true to run AACS as a truly persistent service. Doing so also hides the AACS notification that is displayed when the service is run in the foreground. startServiceOnBootEnabled Type: Boolean When startServiceOnBootEnabled is set to true , AACS automatically starts running when the device is booted up. For the service to start on boot, it must have been run at least once after it was installed. When startServiceOnBootEnabled is set to false , AACS requires the application to send an intent to start the service. syncSystemPropertyChange Type: Boolean This field is optional. When syncSystemPropertyChange is set to true , AACS handles synchronizing the time zone and locale settings of Alexa with the device settings so your application does not need to implement this feature if it is expected in your UX. When it's not present, it's default to false . updateSystemPropertyAllowed Type: Boolean This field is optional. When updateSystemPropertyAllowed is set to true , AACS updates the system settings if the corresponding Alexa's property is changed, only if AACS AAR is in a system application. For this release, only time zone property is supported. When it's not present, it's default to false . intentTargets Type: JSON Object This field is optional. Specifies a target for messages of every topic. There is a JSON object for every message topic supported in AACS, where the key is the topic name. Note: If there are any extensions that require message handling, their topic will need to be added here. package Type: String Specifies the package name of the application that receives messages for this particular module. class Type: String Specifies the class name within the application that receives messages for this particular module. Default Platform Handlers AACS provides the default platform implementation for certain services, which you can enable through the configuration in aacs.defaultPlatformHandlers . For a full explanation of default platform handlers, see the AACS README . \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } } useDefaultLocationProvider Type: Boolean Set to true to enable the default LocationProvider platform implementation in AACS. If useDefaultLocationProvider is set to false , your application must separately handle the messages for this topic. useDefaultNetworkInfoProvider Type: Boolean Set to true to enable the default NetworkInfoProvider platform implementation in AACS. If useDefaultNetworkInfoProvider is set to false , your application must separately handle the messages for this topic. useDefaultExternalMediaAdapter Type: Boolean Set to true to enable the default ExternalMediaAdapter platform implementation in AACS. If useDefaultExternalMediaAdapter is set to false , your application must separately handle the messages for this topic. useDefaultPropertyManager Type: Boolean Set to true to enable the default PropertyManager platform implementation in AACS. This enables synchronous managing of properties using AACS's ContentProvider. If useDefaultPropertyManager is set to false , your application must separately handle the messages for this topic. useDefaultCustomDomainMessageDispatcher Type: Boolean Set to true to enable the default CustomDomain message dispatcher in AACS. If CustomDomain module is enabled and useDefaultCustomDomainMessageDispatcher is set to false, your application must separately handle the messages for topic CustomDomain . audioInput Type: JSON Object Configures AudioInput in AACS based on the audio type. This JSON object consists of JSON nodes for the audio types that contain this information. Available audio types are COMMUNICATION and VOICE . useDefault Type: Boolean Set to true to enable the default AudioInput platform implementation for the given audio type. If useDefault is set to false , AudioInput for the given audio type must be handled in your application. audioSource Type: String Specifies the Android audio source for the given audio type. This assumes that the useDefault field is set to true . Available Audio sources are MediaRecorder.AudioSource.MIC , MediaRecorder.AudioSource.DEFAULT , MediaRecorder.AudioSource.VOICE_RECOGNITION , MediaRecorder.AudioSource.VOICE_COMMUNICATION and EXTERNAL . If you do not specify a value, the default audio source is MediaRecorder.AudioSource.MIC . It is recommended to set handleAudioFocus to true . This will ensure that When Alexa is in LISTENING , THINKING and EXPECTING state, AACS will request audio focus resulting in other playing media to be ducked or paused. Using EXTERNAL for audioSource means AACS fetches the audio stream from an external application, and it requires a valid externalSource object to be present in the JSON object. The following sample configuration is for an external stream: \"VOICE\": { \"useDefault\": true, \"audioSource\": \"EXTERNAL\", \"externalSource\": { \"type\": \"ACTIVITY\", \"package\": \"com.example.application\", \"class\": \".MainActivity\" } } Note : When specifying both VOICE and COMMUNICATION 's audioSource values as non- EXTERNAL , be sure that their audioSource values are the same. audioOutput Type: JSON Object Configures audioOutput in AACS based on the audio type. This JSON object consists of JSON nodes for audio types that contain this information. Available audio types are TTS , ALARM , MUSIC , NOTIFICATION , EARCON , and RINGTONE . useDefault Type: Boolean Set to true to enable the default AudioOutput platform implementation for the given audio type. If useDefault is set to false , AudioOutput for the given audio type must be handled in your application. useDefaultLocalMediaSource Type: Boolean (Followed with detailed localMediaSourceMetadata JSON array configuration if set true ) Set to true to enable the default LocalMediaSource platform implementation to configure local media sources. By default useDefaultLocalMediaSource is treated false so if not included in the config file or set to false explicitly, please define localMediaSource JSON array in the aacs.alexa node to enable AASB LocalMediaSource messages to be delivered to your application. Refer the following sample configuration for the useDefaultLocalMediaSource . \"useDefaultLocalMediaSource\" : true, \"localMediaSourceMetadata\": [ { \"sourceType\":\"BLUETOOTH\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"USB\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"FM_RADIO\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"AM_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"SATELLITE_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"LINE_IN\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"COMPACT_DISC\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"SIRIUS_XM\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"DAB\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" },{ \"sourceType\":\"DEFAULT\", \"supported\": true, \"mediaPackageName\":\"\", \"mediaServiceClass\":\"\", \"supportsSetPreset\": true } ] sourceType Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT . The DEFAULT source provides the facility to support all the media sources which are not listed in the given list. Note: This feature uses NotificationListenerService to monitor active sessions, provide BIND_NOTIFICATION_LISTENER_SERVICE permission to the application which includes AACS AAR to support the default local media source handling. If access is not provided, AACS would ignore the \"useDefaultLocalMediaSource\" : true configuration. This access is generally given by enabling the application with AACS AAR in Settings >> Apps >> Special Access >> Notification access . Note: If OEM wishes to make the application with AACS AAR as a system application, they can avoid the Notification Access step. Please add a line <uses-permission android:name=\"android.permission.MEDIA_CONTENT_CONTROL\" /> in the AACS AndroidManifest.xml file and provide all the required permissions to the system application in the Android operating system. Refer Local Media Source to know more about DEFAULT media source. supported configures the given Local Media Source. if supported is set true , that media source would be handled and controlled through AACS. If supported is set false , AACS would ignore the media source. mediaPackageName and mediaServiceClass are mandatory configuration keys. mediaPackageName represents the package name of the media source and mediaServiceClass represents the The name of the class inside of package that implements the component of the media browser service. This is a requirement of the ComponentName . Please ensure that right data is provided here. Since DEFAULT player can act on behalf of all latest the media sources except Alexa music, MACC supported players and other configured local media sources, it is not full time associated to any package name and MediaBrowserService. It always represents 0th media controller of the onActiveSessionsChanged controller list. Besides these mandatory configuration keys, following optional keys are useful for the correct mapping of metadata. metadataTitleKey By default AACS uses METADATA_KEY_TITLE to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. For example, Consider sub title as title for some reason \"metadataTitleKey\":\"android.media.metadata.DISPLAY_SUBTITLE\" metadataTrackIdKey By default AACS uses METADATA_KEY_MEDIA_ID to extract the trackId from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataTrackNumberKey By default AACS uses METADATA_KEY_TRACK_NUMBER to extract the track number from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataArtistKey By default AACS uses METADATA_KEY_ARTIST to extract the artist from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataAlbumKey By default AACS uses METADATA_KEY_ALBUM to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataDurationKey By default AACS uses METADATA_KEY_DURATION to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. supportsSetFrequency This takes a boolean value. It should be set true for AM or FM where Alexa can set the frequency in the AM or FM application. Local Media Player like FM or AM application should be able to handle this request. To support it, these app needs to implement onPrepareFromSearch and onPlayFromSearch methods. They will receive a query string containing a json in following format. { \"ContentSelector\":\"FREQUENCY\", \"payload\":\"98.7 FM HD 1\" } Note Refer Local Media Source for more information of the ContentSelector and payload. supportsSetPreset This takes a boolean value. It should be set true if media source can play media by preset number. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type PRESET as well. supportsSetChannel This takes a boolean value. It should be set true if media source like Sirius XM which can play media by channel name. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type CHANNEL as well.","title":"Configuration Reference for AACS (Alexa Auto Client Service)"},{"location":"aacs/android/service/#configuration-reference-for-aacs-alexa-auto-client-service","text":"This document explains the various fields of the AACS configuration. The AACS configuration is similar to the Auto SDK configuration, with a few additional fields unique to AACS.","title":"Configuration Reference for AACS (Alexa Auto Client Service)"},{"location":"aacs/android/service/#table-of-contents","text":"Auto SDK Modules localMediaSource AACS Module Enablement General persistentSystemService startServiceOnBootEnabled syncSystemPropertyChange updateSystemPropertyAllowed intentTargets Default Platform Handlers useDefaultLocationProvider useDefaultNetworkInfoProvider useDefaultExternalMediaAdapter useDefaultPropertyManager useDefaultCustomDomainMessageDispatcher audioInput audioOutput useDefaultLocalMediaSource","title":"Table of Contents"},{"location":"aacs/android/service/#auto-sdk-modules","text":"You configure a module in AACS in a similar way as you configure a module in the Auto SDK. For example, the Auto SDK specifies a module in the configuration as aace.<module> , and AACS specifies a module in the configuration as aacs.<module> . See the Auto SDK's documentation for information about the Auto SDK configuration. The following example shows the syntax for configuring the CBL module in AACS, which is the same as the syntax in the Auto SDK: { \"aacs.cbl\" : { \"enableUserProfile\": false } } Optionally, you can also configure the timeout value of AASB synchronous messages in aacs.messageBroker , as detailed in Core Module README for configuring the MessageBroker. The default timeout duration is 500 ms. { \"aacs.messageBroker\": { ... \"defaultMessageTimeout\": 1000 } } The aacs.alexa module has a structure that is slightly different from its Auto SDK counterpart as explained in the following list: In AACS, there is no avsDeviceSDK node, because most of the configuration required for this section is done within AACS. The only required configuration from avsDeviceSDK is deviceInfo , and it is specified directly under aacs.alexa . aacs.alexa contains a node called localMediaSource , which explicitly specifies which media sources are available. The following example shows deviceInfo and localMediaSource in the configuration for aacs.alexa : { \"aacs.alexa\": { \"deviceInfo\": { \"clientId\": \"\", \"productId\": \"\", \"deviceSerialNumber\": \"\", \"manufacturerName\": \"\", \"description\": \"\" }, \"localMediaSource\": { \"types\": [\"FM_RADIO\"] } } }","title":"Auto SDK Modules"},{"location":"aacs/android/service/#localmediasource","text":"Type: JSON Object Specifies which local media sources are available and handled in the application. If your application prefers AACS to handle the local media sources, use useDefaultLocalMediaSource instead.","title":"localMediaSource"},{"location":"aacs/android/service/#types","text":"Type: String Array Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT","title":"types"},{"location":"aacs/android/service/#aacs-module-enablement","text":"AACS allows your application to enable/disable certain modules using AACS configuration file. To enable or disable certain modules, add certain JSON blocks to the AACS configuration inside \"aacs.modules\" block, as shown in the following examples: APL module is disabled by default. To enable APL, add the following configuration to the configuration file: \"aacs.modules\": { \"aacs.apl\": { \"APL\": { \"enabled\": true } } } - Custom Domain module is disabled by default. Similarly to APL, to enable Custom Domain, add the following configuration to aacs.modules in the configuration file: \"aacs.customDomain\": { \"CustomDomain\": { \"enabled\": true } } Note : If Custom Domain module is enabled, you must provide a valid aacs.customDomain configuration to configure the engine with your custom interfaces. Otherwise, the engine will fail to start. See Required Engine Configuration for Custom Domain module. Authorization and CBL cannot be enabled at the same time. CBL module is deprecated in version 3.1, your application should use the Authorization modules instead. To disable CBL , add the following configuration to aacs.modules in the configuration file: \"aacs.cbl\": { \"CBL\": { \"enabled\": false } } If your application uses the deprecated CBL module, disable the Authorization module in the configuration: \"aacs.authorization\": { \"Authorization\": { \"enabled\": false } } For configuring module enablement, more information can be found at Configurating the MessageBroker","title":"AACS Module Enablement"},{"location":"aacs/android/service/#general","text":"aacs.general is used for most configurable values of AACS that are not required for the Auto SDK, as shown in the following example: { \"aacs.general\" : { \"version\": \"1.0\", \"persistentSystemService\": false, \"startServiceOnBootEnabled\": true, \"syncSystemPropertyChange\": false, \"intentTargets\" : {...} } }","title":"General"},{"location":"aacs/android/service/#version","text":"Type: String Indicates the version of AACS to be used. Releases of AACS will have current and minimum-supported versions. Versions outside this range will not be compatible and the service will not start as a result.","title":"version"},{"location":"aacs/android/service/#persistentsystemservice","text":"Type: Boolean When persistentSystemService is set to false (default), AACS starts as a foreground service, which has higher priority on the Android system. If you have system-level control over your device, you may set this field to true to run AACS as a truly persistent service. Doing so also hides the AACS notification that is displayed when the service is run in the foreground.","title":"persistentSystemService"},{"location":"aacs/android/service/#startserviceonbootenabled","text":"Type: Boolean When startServiceOnBootEnabled is set to true , AACS automatically starts running when the device is booted up. For the service to start on boot, it must have been run at least once after it was installed. When startServiceOnBootEnabled is set to false , AACS requires the application to send an intent to start the service.","title":"startServiceOnBootEnabled"},{"location":"aacs/android/service/#syncsystempropertychange","text":"Type: Boolean This field is optional. When syncSystemPropertyChange is set to true , AACS handles synchronizing the time zone and locale settings of Alexa with the device settings so your application does not need to implement this feature if it is expected in your UX. When it's not present, it's default to false .","title":"syncSystemPropertyChange"},{"location":"aacs/android/service/#updatesystempropertyallowed","text":"Type: Boolean This field is optional. When updateSystemPropertyAllowed is set to true , AACS updates the system settings if the corresponding Alexa's property is changed, only if AACS AAR is in a system application. For this release, only time zone property is supported. When it's not present, it's default to false .","title":"updateSystemPropertyAllowed"},{"location":"aacs/android/service/#intenttargets","text":"Type: JSON Object This field is optional. Specifies a target for messages of every topic. There is a JSON object for every message topic supported in AACS, where the key is the topic name. Note: If there are any extensions that require message handling, their topic will need to be added here.","title":"intentTargets"},{"location":"aacs/android/service/#package","text":"Type: String Specifies the package name of the application that receives messages for this particular module.","title":"package"},{"location":"aacs/android/service/#class","text":"Type: String Specifies the class name within the application that receives messages for this particular module.","title":"class"},{"location":"aacs/android/service/#default-platform-handlers","text":"AACS provides the default platform implementation for certain services, which you can enable through the configuration in aacs.defaultPlatformHandlers . For a full explanation of default platform handlers, see the AACS README . \"aacs.defaultPlatformHandlers\": { \"useDefaultLocationProvider\": true, \"useDefaultNetworkInfoProvider\": true, \"useDefaultExternalMediaAdapter\": true, \"useDefaultPropertyManager\": true, \"audioInput\": { \"audioType\": { \"VOICE\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\" }, \"COMMUNICATION\": { \"useDefault\": true, \"audioSource\": \"MediaRecorder.AudioSource.MIC\", } } }, \"audioOutput\": { \"audioType\": { \"TTS\": { \"useDefault\": true }, \"ALARM\": { \"useDefault\": true }, \"MUSIC\": { \"useDefault\": false }, \"NOTIFICATION\": { \"useDefault\": true }, \"EARCON\": { \"useDefault\": true }, \"RINGTONE\": { \"useDefault\": true }, \"COMMUNICATION\": { \"useDefault\": true } } } }","title":"Default Platform Handlers"},{"location":"aacs/android/service/#usedefaultlocationprovider","text":"Type: Boolean Set to true to enable the default LocationProvider platform implementation in AACS. If useDefaultLocationProvider is set to false , your application must separately handle the messages for this topic.","title":"useDefaultLocationProvider"},{"location":"aacs/android/service/#usedefaultnetworkinfoprovider","text":"Type: Boolean Set to true to enable the default NetworkInfoProvider platform implementation in AACS. If useDefaultNetworkInfoProvider is set to false , your application must separately handle the messages for this topic.","title":"useDefaultNetworkInfoProvider"},{"location":"aacs/android/service/#usedefaultexternalmediaadapter","text":"Type: Boolean Set to true to enable the default ExternalMediaAdapter platform implementation in AACS. If useDefaultExternalMediaAdapter is set to false , your application must separately handle the messages for this topic.","title":"useDefaultExternalMediaAdapter"},{"location":"aacs/android/service/#usedefaultpropertymanager","text":"Type: Boolean Set to true to enable the default PropertyManager platform implementation in AACS. This enables synchronous managing of properties using AACS's ContentProvider. If useDefaultPropertyManager is set to false , your application must separately handle the messages for this topic.","title":"useDefaultPropertyManager"},{"location":"aacs/android/service/#usedefaultcustomdomainmessagedispatcher","text":"Type: Boolean Set to true to enable the default CustomDomain message dispatcher in AACS. If CustomDomain module is enabled and useDefaultCustomDomainMessageDispatcher is set to false, your application must separately handle the messages for topic CustomDomain .","title":"useDefaultCustomDomainMessageDispatcher"},{"location":"aacs/android/service/#audioinput","text":"Type: JSON Object Configures AudioInput in AACS based on the audio type. This JSON object consists of JSON nodes for the audio types that contain this information. Available audio types are COMMUNICATION and VOICE .","title":"audioInput"},{"location":"aacs/android/service/#usedefault","text":"Type: Boolean Set to true to enable the default AudioInput platform implementation for the given audio type. If useDefault is set to false , AudioInput for the given audio type must be handled in your application.","title":"useDefault"},{"location":"aacs/android/service/#audiosource","text":"Type: String Specifies the Android audio source for the given audio type. This assumes that the useDefault field is set to true . Available Audio sources are MediaRecorder.AudioSource.MIC , MediaRecorder.AudioSource.DEFAULT , MediaRecorder.AudioSource.VOICE_RECOGNITION , MediaRecorder.AudioSource.VOICE_COMMUNICATION and EXTERNAL . If you do not specify a value, the default audio source is MediaRecorder.AudioSource.MIC . It is recommended to set handleAudioFocus to true . This will ensure that When Alexa is in LISTENING , THINKING and EXPECTING state, AACS will request audio focus resulting in other playing media to be ducked or paused. Using EXTERNAL for audioSource means AACS fetches the audio stream from an external application, and it requires a valid externalSource object to be present in the JSON object. The following sample configuration is for an external stream: \"VOICE\": { \"useDefault\": true, \"audioSource\": \"EXTERNAL\", \"externalSource\": { \"type\": \"ACTIVITY\", \"package\": \"com.example.application\", \"class\": \".MainActivity\" } } Note : When specifying both VOICE and COMMUNICATION 's audioSource values as non- EXTERNAL , be sure that their audioSource values are the same.","title":"audioSource"},{"location":"aacs/android/service/#audiooutput","text":"Type: JSON Object Configures audioOutput in AACS based on the audio type. This JSON object consists of JSON nodes for audio types that contain this information. Available audio types are TTS , ALARM , MUSIC , NOTIFICATION , EARCON , and RINGTONE .","title":"audioOutput"},{"location":"aacs/android/service/#usedefault_1","text":"Type: Boolean Set to true to enable the default AudioOutput platform implementation for the given audio type. If useDefault is set to false , AudioOutput for the given audio type must be handled in your application.","title":"useDefault"},{"location":"aacs/android/service/#usedefaultlocalmediasource","text":"Type: Boolean (Followed with detailed localMediaSourceMetadata JSON array configuration if set true ) Set to true to enable the default LocalMediaSource platform implementation to configure local media sources. By default useDefaultLocalMediaSource is treated false so if not included in the config file or set to false explicitly, please define localMediaSource JSON array in the aacs.alexa node to enable AASB LocalMediaSource messages to be delivered to your application. Refer the following sample configuration for the useDefaultLocalMediaSource . \"useDefaultLocalMediaSource\" : true, \"localMediaSourceMetadata\": [ { \"sourceType\":\"BLUETOOTH\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"USB\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"FM_RADIO\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"AM_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\", \"supportsSetPreset\": true, \"supportsSetFrequency\": true }, { \"sourceType\":\"SATELLITE_RADIO\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"LINE_IN\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"COMPACT_DISC\", \"supported\": true, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"SIRIUS_XM\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" }, { \"sourceType\":\"DAB\", \"supported\": false, \"mediaPackageName\":\"<Package Name>\", \"mediaServiceClass\":\"<Media Browser service class name>\" },{ \"sourceType\":\"DEFAULT\", \"supported\": true, \"mediaPackageName\":\"\", \"mediaServiceClass\":\"\", \"supportsSetPreset\": true } ] sourceType Specifies the available local media sources. Possible values are BLUETOOTH , USB , FM_RADIO , AM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT . The DEFAULT source provides the facility to support all the media sources which are not listed in the given list. Note: This feature uses NotificationListenerService to monitor active sessions, provide BIND_NOTIFICATION_LISTENER_SERVICE permission to the application which includes AACS AAR to support the default local media source handling. If access is not provided, AACS would ignore the \"useDefaultLocalMediaSource\" : true configuration. This access is generally given by enabling the application with AACS AAR in Settings >> Apps >> Special Access >> Notification access . Note: If OEM wishes to make the application with AACS AAR as a system application, they can avoid the Notification Access step. Please add a line <uses-permission android:name=\"android.permission.MEDIA_CONTENT_CONTROL\" /> in the AACS AndroidManifest.xml file and provide all the required permissions to the system application in the Android operating system. Refer Local Media Source to know more about DEFAULT media source. supported configures the given Local Media Source. if supported is set true , that media source would be handled and controlled through AACS. If supported is set false , AACS would ignore the media source. mediaPackageName and mediaServiceClass are mandatory configuration keys. mediaPackageName represents the package name of the media source and mediaServiceClass represents the The name of the class inside of package that implements the component of the media browser service. This is a requirement of the ComponentName . Please ensure that right data is provided here. Since DEFAULT player can act on behalf of all latest the media sources except Alexa music, MACC supported players and other configured local media sources, it is not full time associated to any package name and MediaBrowserService. It always represents 0th media controller of the onActiveSessionsChanged controller list. Besides these mandatory configuration keys, following optional keys are useful for the correct mapping of metadata. metadataTitleKey By default AACS uses METADATA_KEY_TITLE to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. For example, Consider sub title as title for some reason \"metadataTitleKey\":\"android.media.metadata.DISPLAY_SUBTITLE\" metadataTrackIdKey By default AACS uses METADATA_KEY_MEDIA_ID to extract the trackId from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataTrackNumberKey By default AACS uses METADATA_KEY_TRACK_NUMBER to extract the track number from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataArtistKey By default AACS uses METADATA_KEY_ARTIST to extract the artist from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataAlbumKey By default AACS uses METADATA_KEY_ALBUM to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. metadataDurationKey By default AACS uses METADATA_KEY_DURATION to extract the title data from the Local Media Source. If any of the media source provides this data through the different key, use this configuration field. supportsSetFrequency This takes a boolean value. It should be set true for AM or FM where Alexa can set the frequency in the AM or FM application. Local Media Player like FM or AM application should be able to handle this request. To support it, these app needs to implement onPrepareFromSearch and onPlayFromSearch methods. They will receive a query string containing a json in following format. { \"ContentSelector\":\"FREQUENCY\", \"payload\":\"98.7 FM HD 1\" } Note Refer Local Media Source for more information of the ContentSelector and payload. supportsSetPreset This takes a boolean value. It should be set true if media source can play media by preset number. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type PRESET as well. supportsSetChannel This takes a boolean value. It should be set true if media source like Sirius XM which can play media by channel name. Note onPrepareFromSearch and onPlayFromSearch related details given in the above section are applicable for content type CHANNEL as well.","title":"useDefaultLocalMediaSource"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/","text":"AACS Instrumentation AACS instrumentation enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. You can start or stop instrumentation at any time and customize the log file location. To use AACS instrumentation, you must use the debug option when building the Alexa Auto SDK with AACS. Table of Contents Advantages of Using Instrumentation Information Captured by Instrumentation Using Instrumentation Sample Log File Advantages of Using Instrumentation Without instrumentation, you can use the Android Log() method with the android.util.Log class to monitor the interactions between your application and AACS. To view the resultant logs, use the Android Logcat utility. The information captured in this way does not include the details of each AASB message. To view the message details, use instrumentation. For example, you can view the message payload in the instrumentation log, which Logcat does not display to prevent privacy violations. Instrumentation produces logs that are more relevant for debugging your application, as the logs provided by android.util.Log often include Android system logs. Also, instrumentation captures all the messages exchanged among the AACS core service, AASB Message Broker interface, and your application. If you use the Log() method, you would need to define the type of message to be logged, the source of the message, and so on. Using a text editor, you can view instrumentation log entries. If you want to view them in a tabular format, use a web tool, such as json2table . Information Captured by Instrumentation The following list describes the information in each instrumentation log entry: Time stamp for message arrival at AACS or message dispatch from AACS Message direction (e.g., \"FROM_ENGINE\" or \"TO_ENGINE\") Topic for the message (e.g., Navigation, CarControl) Action (e.g., EndOfSpeechDetected ) Message ID Whether the message expects a reply Payload (e.g., {\"wakeword\":\"ALEXA\"} ) If the message is a reply, whether the reply is sent within the timeout period If the message is a reply, the ID of the message that requests the reply Using Instrumentation To manage instrumentation, use the Android activity manager through the Android Debug Bridge. Enter the adb shell am command as described in the following list: To start instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To stop instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.stopinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To specify the log file location, enter the following command. In this example, the log file location is /sdcard/Log/aacs.log . adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver --es fileLocation \"/sdcard/Log/aacs.log\" By default, the location is /sdcard . Sample Log File The following is an instrumentation log file example: {\"timeStamp\":\"2021-03-04 14:30:06.989\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"SpeechRecognizer\",\"action\":\"WakewordDetected\",\"messageId\":\"4f1bcd5d-098a-43dc-9447-340d69c75f2f\",\"replyExpected\":false,\"payload\":\"{\\\"wakeword\\\":\\\"ALEXA\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:12.523\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"messageId\":\"0475aa45-050b-43a5-b943-d89254cc0261\",\"replyExpected\":true,\"payload\":\"{\\\"channel\\\":\\\"SpeechSynthesizer\\\",\\\"token\\\":\\\"d3565d16-e85a-4b4d-b18e-bcbcee2374d3\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:13.517\",\"MessageDirection\":\"TO_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"replyReceivedTimeout\":false,\"replyToId\":\"e283cecc-7a9b-42d4-b164-ef0ee63a4f91\",\"payload\":\"{\\\"position\\\":489}\"}","title":"AACS Instrumentation"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#aacs-instrumentation","text":"AACS instrumentation enables you to better understand the interactions between your application and AACS. Through instrumentation, you log Alexa Auto Service Bridge (AASB) messages to a file, which you can review for debugging purposes. You can start or stop instrumentation at any time and customize the log file location. To use AACS instrumentation, you must use the debug option when building the Alexa Auto SDK with AACS.","title":"AACS Instrumentation"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#table-of-contents","text":"Advantages of Using Instrumentation Information Captured by Instrumentation Using Instrumentation Sample Log File","title":"Table of Contents"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#advantages-of-using-instrumentation","text":"Without instrumentation, you can use the Android Log() method with the android.util.Log class to monitor the interactions between your application and AACS. To view the resultant logs, use the Android Logcat utility. The information captured in this way does not include the details of each AASB message. To view the message details, use instrumentation. For example, you can view the message payload in the instrumentation log, which Logcat does not display to prevent privacy violations. Instrumentation produces logs that are more relevant for debugging your application, as the logs provided by android.util.Log often include Android system logs. Also, instrumentation captures all the messages exchanged among the AACS core service, AASB Message Broker interface, and your application. If you use the Log() method, you would need to define the type of message to be logged, the source of the message, and so on. Using a text editor, you can view instrumentation log entries. If you want to view them in a tabular format, use a web tool, such as json2table .","title":"Advantages of Using Instrumentation"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#information-captured-by-instrumentation","text":"The following list describes the information in each instrumentation log entry: Time stamp for message arrival at AACS or message dispatch from AACS Message direction (e.g., \"FROM_ENGINE\" or \"TO_ENGINE\") Topic for the message (e.g., Navigation, CarControl) Action (e.g., EndOfSpeechDetected ) Message ID Whether the message expects a reply Payload (e.g., {\"wakeword\":\"ALEXA\"} ) If the message is a reply, whether the reply is sent within the timeout period If the message is a reply, the ID of the message that requests the reply","title":"Information Captured by Instrumentation"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#using-instrumentation","text":"To manage instrumentation, use the Android activity manager through the Android Debug Bridge. Enter the adb shell am command as described in the following list: To start instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To stop instrumentation, enter the following command: adb shell am broadcast -a com.amazon.aacs.stopinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver To specify the log file location, enter the following command. In this example, the log file location is /sdcard/Log/aacs.log . adb shell am broadcast -a com.amazon.aacs.startinstrumentation -n com.amazon.alexaautoclientservice/.receiver.InstrumentationReceiver --es fileLocation \"/sdcard/Log/aacs.log\" By default, the location is /sdcard .","title":"Using Instrumentation"},{"location":"aacs/android/service/core-service/src/debug/java/com/amazon/alexaautoclientservice/#sample-log-file","text":"The following is an instrumentation log file example: {\"timeStamp\":\"2021-03-04 14:30:06.989\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"SpeechRecognizer\",\"action\":\"WakewordDetected\",\"messageId\":\"4f1bcd5d-098a-43dc-9447-340d69c75f2f\",\"replyExpected\":false,\"payload\":\"{\\\"wakeword\\\":\\\"ALEXA\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:12.523\",\"MessageDirection\":\"FROM_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"messageId\":\"0475aa45-050b-43a5-b943-d89254cc0261\",\"replyExpected\":true,\"payload\":\"{\\\"channel\\\":\\\"SpeechSynthesizer\\\",\\\"token\\\":\\\"d3565d16-e85a-4b4d-b18e-bcbcee2374d3\\\"}\"} {\"timeStamp\":\"2021-03-04 14:30:13.517\",\"MessageDirection\":\"TO_ENGINE\",\"topic\":\"AudioOutput\",\"action\":\"GetPosition\",\"replyReceivedTimeout\":false,\"replyToId\":\"e283cecc-7a9b-42d4-b164-ef0ee63a4f91\",\"payload\":\"{\\\"position\\\":489}\"}","title":"Sample Log File"},{"location":"builder/","text":"Builder Tool Command Reference $ build.py [ -h ] { build,clean,configure,imports } ... optional arguments: -h, --help show this help message and exit commands: { build,clean,configure,imports } build builds auto sdk components ( default ) clean cleans builder cache configure builder configuration imports manages external search paths Build command $ build.py build [ -h ] [ --home PATH ] [ -v ] [ -p PLATFORM ] [ -a ARCH ] [ -g ] [ -m MODULE [ MODULE ... ]] [ -n NAME ] [ -y ] [ -f PACKAGE [ PACKAGE ... ]] [ -i PATH [ PATH ... ]] [ -o OPTION ] [ -s SETTING ] [ --with-aasb ] [ --no-aasb ] [ --with-docs ] [ --no-docs ] [ --with-unit-tests ] [ --no-unit-tests ] [ --with-sampleapp ] [ --no-sampleapp ] [ --with-sensitive-logs ] [ --no-sensitive-logs ] [ --with-latency-logs ] [ --no-latency-logs ] [ --output FILE ] [ --no-output ] [ --skip-config ] Used to build Auto SDK modules and components. optional arguments: -h, --help show this help message and exit --home PATH, --builder-home PATH override builder home path -v, --verbose enable verbose logging -p PLATFORM, --platform PLATFORM target platform - android,qnx,etc. -a ARCH, --arch ARCH target architecture -g, --debug specify debug build type -m MODULE [ MODULE ... ] , --modules MODULE [ MODULE ... ] list of modules to build -n NAME, --name NAME optional package identifier -y, --accept-licenses auto-accept licenses -f PACKAGE [ PACKAGE ... ] , --force PACKAGE [ PACKAGE ... ] force export and build package -i PATH [ PATH ... ] , --include PATH [ PATH ... ] add include path to conan configuration -o OPTION, --conan-option OPTION specify a conan build option -s SETTING, --conan-setting SETTING specify a conan build setting --with-aasb, --aasb include aasb messages ( default: True ) --no-aasb --with-docs, --docs include docs ( default: True ) --no-docs --with-unit-tests, --unit-tests include unit tests ( default: False ) --no-unit-tests --with-sampleapp, --sampleapp include sample app ( default: False ) --no-sampleapp --with-sensitive-logs, --sensitive-logs emit sensitive data in debugging logs ( default: False ) --no-sensitive-logs --with-latency-logs, --latency-logs emit latency data in debugging logs ( default: False ) --no-latency-logs --output FILE filename for output build archive --no-output don ' t create output package --skip-config skip build configuration Clean command $ build.py clean [ -h ] [ --home PATH ] [ -v ] [ --skip-conan ] [ --skip-gradle ] pattern Used to clean packages from the Builder, Conan, and Gradle caches. positional arguments: pattern pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging --skip-conan skips cleaning the conan cache --skip-gradle skips cleaning the gradle cache Configure command $ build.py configure [ -h ] [ --home PATH ] [ -v ] { init,export } ... optional arguments: -h, --help show this help message and exit commands: { init,export } init initializes the builder configuration export exports packages from the builder configuration configure init $ build.py configure init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder configuration settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging configure export $ build.py configure export [ -h ] [ --home PATH ] [ -v ] PATTERN Used to re-export packages that are configured by the builder. positional arguments: PATTERN pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging Imports command $ build.py imports [ -h ] { init,list,add,remove,enable,disable } ... optional arguments: -h, --help show this help message and exit commands: { init,list,add,remove,enable,disable } init initialize the imports configuration list lists imports managed by the configuration add adds a new import remove removes imports enable enables imports disable disables imports imports init $ build.py imports init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder imports settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports list $ build.py imports list [ -h ] [ --home PATH ] [ -v ] Used to display the imports in the Builder settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports add $ build.py imports add [ -h ] [ --home PATH ] [ -v ] NAME PATH Used create a new import in the Builder settings. positional arguments: NAME import name PATH import search path optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports remove $ build.py imports remove [ -h ] [ --home PATH ] [ -v ] PATTERN Used to remove imports from the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports enable $ build.py imports enable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to enable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging imports disable $ build.py imports disable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to disable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"Builder Tool Command Reference"},{"location":"builder/#builder-tool-command-reference","text":"$ build.py [ -h ] { build,clean,configure,imports } ... optional arguments: -h, --help show this help message and exit commands: { build,clean,configure,imports } build builds auto sdk components ( default ) clean cleans builder cache configure builder configuration imports manages external search paths","title":"Builder Tool Command Reference"},{"location":"builder/#build-command","text":"$ build.py build [ -h ] [ --home PATH ] [ -v ] [ -p PLATFORM ] [ -a ARCH ] [ -g ] [ -m MODULE [ MODULE ... ]] [ -n NAME ] [ -y ] [ -f PACKAGE [ PACKAGE ... ]] [ -i PATH [ PATH ... ]] [ -o OPTION ] [ -s SETTING ] [ --with-aasb ] [ --no-aasb ] [ --with-docs ] [ --no-docs ] [ --with-unit-tests ] [ --no-unit-tests ] [ --with-sampleapp ] [ --no-sampleapp ] [ --with-sensitive-logs ] [ --no-sensitive-logs ] [ --with-latency-logs ] [ --no-latency-logs ] [ --output FILE ] [ --no-output ] [ --skip-config ] Used to build Auto SDK modules and components. optional arguments: -h, --help show this help message and exit --home PATH, --builder-home PATH override builder home path -v, --verbose enable verbose logging -p PLATFORM, --platform PLATFORM target platform - android,qnx,etc. -a ARCH, --arch ARCH target architecture -g, --debug specify debug build type -m MODULE [ MODULE ... ] , --modules MODULE [ MODULE ... ] list of modules to build -n NAME, --name NAME optional package identifier -y, --accept-licenses auto-accept licenses -f PACKAGE [ PACKAGE ... ] , --force PACKAGE [ PACKAGE ... ] force export and build package -i PATH [ PATH ... ] , --include PATH [ PATH ... ] add include path to conan configuration -o OPTION, --conan-option OPTION specify a conan build option -s SETTING, --conan-setting SETTING specify a conan build setting --with-aasb, --aasb include aasb messages ( default: True ) --no-aasb --with-docs, --docs include docs ( default: True ) --no-docs --with-unit-tests, --unit-tests include unit tests ( default: False ) --no-unit-tests --with-sampleapp, --sampleapp include sample app ( default: False ) --no-sampleapp --with-sensitive-logs, --sensitive-logs emit sensitive data in debugging logs ( default: False ) --no-sensitive-logs --with-latency-logs, --latency-logs emit latency data in debugging logs ( default: False ) --no-latency-logs --output FILE filename for output build archive --no-output don ' t create output package --skip-config skip build configuration","title":"Build command"},{"location":"builder/#clean-command","text":"$ build.py clean [ -h ] [ --home PATH ] [ -v ] [ --skip-conan ] [ --skip-gradle ] pattern Used to clean packages from the Builder, Conan, and Gradle caches. positional arguments: pattern pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging --skip-conan skips cleaning the conan cache --skip-gradle skips cleaning the gradle cache","title":"Clean command"},{"location":"builder/#configure-command","text":"$ build.py configure [ -h ] [ --home PATH ] [ -v ] { init,export } ... optional arguments: -h, --help show this help message and exit commands: { init,export } init initializes the builder configuration export exports packages from the builder configuration","title":"Configure command"},{"location":"builder/#configure-init","text":"$ build.py configure init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder configuration settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"configure init"},{"location":"builder/#configure-export","text":"$ build.py configure export [ -h ] [ --home PATH ] [ -v ] PATTERN Used to re-export packages that are configured by the builder. positional arguments: PATTERN pattern or package name optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"configure export"},{"location":"builder/#imports-command","text":"$ build.py imports [ -h ] { init,list,add,remove,enable,disable } ... optional arguments: -h, --help show this help message and exit commands: { init,list,add,remove,enable,disable } init initialize the imports configuration list lists imports managed by the configuration add adds a new import remove removes imports enable enables imports disable disables imports","title":"Imports command"},{"location":"builder/#imports-init","text":"$ build.py imports init [ -h ] [ --home PATH ] [ -v ] Used to initialize the Builder imports settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports init"},{"location":"builder/#imports-list","text":"$ build.py imports list [ -h ] [ --home PATH ] [ -v ] Used to display the imports in the Builder settings. optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports list"},{"location":"builder/#imports-add","text":"$ build.py imports add [ -h ] [ --home PATH ] [ -v ] NAME PATH Used create a new import in the Builder settings. positional arguments: NAME import name PATH import search path optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports add"},{"location":"builder/#imports-remove","text":"$ build.py imports remove [ -h ] [ --home PATH ] [ -v ] PATTERN Used to remove imports from the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports remove"},{"location":"builder/#imports-enable","text":"$ build.py imports enable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to enable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports enable"},{"location":"builder/#imports-disable","text":"$ build.py imports disable [ -h ] [ --home PATH ] [ -v ] PATTERN Used to disable imports in the Builder settings. positional arguments: PATTERN import name or pattern optional arguments: -h, --help show this help message and exit --home PATH override builder home path -v, --verbose enable verbose logging","title":"imports disable"},{"location":"modules/aasb/aasb-docs/AASB/","text":"AASB Outgoing Messages StartService Notifies the platform that the AASB service has started. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StartService\" } } } StopService Notifies the platform that the AASB service is about to stop. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StopService\" } } }","title":"AASB Message Definition"},{"location":"modules/aasb/aasb-docs/AASB/#aasb","text":"","title":"AASB"},{"location":"modules/aasb/aasb-docs/AASB/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/aasb/aasb-docs/AASB/#startservice","text":"Notifies the platform that the AASB service has started.","title":"StartService"},{"location":"modules/aasb/aasb-docs/AASB/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StartService\" } } }","title":"JSON Structure"},{"location":"modules/aasb/aasb-docs/AASB/#stopservice","text":"Notifies the platform that the AASB service is about to stop.","title":"StopService"},{"location":"modules/aasb/aasb-docs/AASB/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AASB\", \"action\": \"StopService\" } } }","title":"JSON Structure"},{"location":"modules/address-book/","text":"Address Book Module Table of Contents Overview Managing Address Books Reducing Data Usage Configuring the Address Book Module Using the Address Book Module AASB Messages Integrating the Address Book Module Into Your Application Overview The Address Book module enables your Alexa Auto SDK client application to augment the communication and navigation capabilities of Alexa with the user's contacts and favorite addresses. By using this module in your application, the user can upload their phone contacts or navigation favorites to Alexa. This module works alongside the Phone Control module for calling contacts on a paired phone (e.g., \"Alexa, call Mom\") and the Navigation module for requesting directions to favorite destinations (e.g., \"Alexa, take me to work\"). Additionally, these features are supported offline if your application integrates with the modules of the Local Voice Control (LVC) extension. The user contacts and favorite addresses uploaded with the Address Book module are only available for use on the head unit that uploaded them and not any other Alexa devices. Note: To use the Address Book functionality, your product must be placed on the allow list by Amazon. See Requesting Additional Functionality for details. Managing Address Books Your application's Address Book module integration is responsible for managing the lifecycle of each address book (i.e., a set of contacts or navigation favorites). These responsibilities include the following: Prior to uploading any address books to the Auto SDK Engine, obtain consent from the user to allow Alexa to access their data. If the user revokes the permission for Alexa to access their data, immediately notify the Engine to remove the address book(s) so the Engine can delete the data from Alexa. Your implementation must ensure that the address books are removed successfully. If a previously uploaded address book becomes unavailable, such as when the user disconnects their phone from the head unit, notify the Engine to remove the address book. When the address book is available again, such as when the user reconnects their phone, notify the Engine to upload the address book again. Upload address books after starting the Engine if the user already granted permission. By default, the Engine deletes all address books from Alexa at Engine start to account for any cases in which deletion previously failed (e.g., network connection issues). This ensures the user's data is up-to-date across ignition cycles. However, note that there is an option to reduce the frequency of address book uploads described below. Reducing Data Usage Note: The below enhancement is not available for applications that use the LVC extension. Since uploading an address book might consume significant data, your Address Book module integration has an option to reduce the data usage of repeated uploads. You can disable automatic address book removal at Engine start by providing the configuration specified in the Configuring the Address Book Module section. If your integration disables the automatic address book deletion at Engine start, an address book might not need to be uploaded to Alexa at every start. Skip reuploading address books when all of the following conditions are true: The last successful upload was less than 24 hours ago. Note that Alexa periodically removes uploaded address books to comply with the Alexa data retention policy, so Amazon recommends reuploading the address books after 24 hours. The user connects the same phone used for the last successful upload. The phone contacts and navigation favorites on the phone are the same as the address book contents of the last successful upload. Configuring the Address Book Module To configure the Address Book module, use the \"aace.addressBook\" JSON object specified below in your Engine configuration: { \"aace.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Property Type Required Description Example aace.addressBook. cleanAllAddressBooksAtStart boolean No Whether the Engine should automatically delete all of the user's address books from Alexa at Engine start. This defaults to true if the configuration is omitted. false Note: The \"aace.addressBook\" configuration is optional since its only property is optional. Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::addressBook::config::AddressBookConfiguration::createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse AddressBookConfiguration C++ sample code #include <AACE/AddressBook/AddressBookConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto addressBookConfig = aace :: addressBook :: config :: AddressBookConfiguration :: createAddressBookConfig ( false ); configurations . push_back ( addressBookConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Android Integration To use the Address Book module Engine configuration with AACS, use \"aacs.addressBook\" instead of \"aace.addressBook\" in your AACS configuration file: { \"aacs.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory method com.amazon.aace.addressbook.config.createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. import com.amazon.aace.addressBook.config.AddressBookConfiguration ; // Configure the Engine EngineConfiguration addressBookConfiguration = AddressBookConfiguration . createAddressBookConfig ( false ); mEngine . configure ( new EngineConfiguration [] { // other config objects, addressBookConfiguration , // ... }); Using the Address Book Module AASB Messages Uploading an Address Book To upload an address book to Alexa, publish the AddAddressBook message . The Engine publishes the AddAddressBookReply message to indicate upload completion or failure. Click to expand or collapse sequence diagram: Uploading Contacts Click to expand or collapse sequence diagram: Uploading Navigation Favorites Removing an Address Book To remove an address book to Alexa, publish the RemoveAddressBook message . The Engine publishes the RemoveAddressBookReply message to indicate removal completion or failure. Click to expand or collapse sequence diagram: Removing Contacts Click to expand or collapse sequence diagram: Removing Navigation Favorites Integrating the Address Book Module Into Your Application C++ MessageBroker Integration Use the Engine's MessageBroker to publish \"AddressBook\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/AddressBook/AddressBook/ContactName.h> #include <AASB/Message/AddressBook/AddressBook/NavigationName.h> #include <AASB/Message/AddressBook/AddressBook/PhoneData.h> #include <AASB/Message/AddressBook/AddressBook/PostalAddress.h> #include <AASB/Message/AddressBook/AddressBook/AddAddressBookMessage.h> #include <AASB/Message/AddressBook/AddressBook/RemoveAddressBookMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAddressBookHandler { // Subscribe to reply messages from the Engine void MyAddressBookHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAddAddressBookReplyMessage ( message ); }, AddAddressBookMessageReply :: topic (), AddAddressBookMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRemoveAddressBookReplyMessage ( message ); }, RemoveAddressBookMessageReply :: topic (), RemoveAddressBookMessageReply :: action ()); } // Handle the AddAddressBook reply message from the Engine void MyAddressBookHandler::handleAddAddressBookReplyMessage ( const std :: string & message ) { AddAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the upload result for the message... } // Handle the RemoveAddressBook reply message from the Engine void MyAddressBookHandler::handleRemoveAddressBookReplyMessage ( const std :: string & message ) { RemoveAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the removal result for the message... } // To upload contacts to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadContacts ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: CONTACT ; msg . payload . addressBookData = populateContacts ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateContacts ( const std :: string & id ) { // Populate an AddressBook object with the contacts data from the connected phone AddressBook addressBook ; // For each contact, add a ContactName to addressBook.contactNames // and add a PhoneData to addressBook.phoneData // ... return addressBook ; } // To upload navigation favorites to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadNavigationFavorites ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: NAVIGATION ; msg . payload . addressBookData = populateNavigationFavorites ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateNavigationFavorites ( const std :: string & id ) { // Populate an AddressBook object with the navigation favorites data from the head unit AddressBook addressBook ; // For each navigation address, add a NavigationName to addressBook.navigationNames // and add a PostalAddress to addressBook.postalAddresses // ... return addressBook ; } // To remove an address book, publish a RemoveAddressBook message to the Engine bool MyAddressBookHandler::removeAddressBook ( const std :: string & id ) { RemoveAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the RemoveAddressBookReply message // Return the success status from reply message payload } }; Android Integration The Alexa Auto Client Service (AACS) provides the AACS Contacts Library to integrate the Auto SDK Address Book module on Android. See the AACS Contacts Library documentation for more information.","title":"Address Book Module"},{"location":"modules/address-book/#address-book-module","text":"Table of Contents Overview Managing Address Books Reducing Data Usage Configuring the Address Book Module Using the Address Book Module AASB Messages Integrating the Address Book Module Into Your Application","title":"Address Book Module"},{"location":"modules/address-book/#overview","text":"The Address Book module enables your Alexa Auto SDK client application to augment the communication and navigation capabilities of Alexa with the user's contacts and favorite addresses. By using this module in your application, the user can upload their phone contacts or navigation favorites to Alexa. This module works alongside the Phone Control module for calling contacts on a paired phone (e.g., \"Alexa, call Mom\") and the Navigation module for requesting directions to favorite destinations (e.g., \"Alexa, take me to work\"). Additionally, these features are supported offline if your application integrates with the modules of the Local Voice Control (LVC) extension. The user contacts and favorite addresses uploaded with the Address Book module are only available for use on the head unit that uploaded them and not any other Alexa devices. Note: To use the Address Book functionality, your product must be placed on the allow list by Amazon. See Requesting Additional Functionality for details.","title":"Overview"},{"location":"modules/address-book/#managing-address-books","text":"Your application's Address Book module integration is responsible for managing the lifecycle of each address book (i.e., a set of contacts or navigation favorites). These responsibilities include the following: Prior to uploading any address books to the Auto SDK Engine, obtain consent from the user to allow Alexa to access their data. If the user revokes the permission for Alexa to access their data, immediately notify the Engine to remove the address book(s) so the Engine can delete the data from Alexa. Your implementation must ensure that the address books are removed successfully. If a previously uploaded address book becomes unavailable, such as when the user disconnects their phone from the head unit, notify the Engine to remove the address book. When the address book is available again, such as when the user reconnects their phone, notify the Engine to upload the address book again. Upload address books after starting the Engine if the user already granted permission. By default, the Engine deletes all address books from Alexa at Engine start to account for any cases in which deletion previously failed (e.g., network connection issues). This ensures the user's data is up-to-date across ignition cycles. However, note that there is an option to reduce the frequency of address book uploads described below.","title":"Managing Address Books"},{"location":"modules/address-book/#reducing-data-usage","text":"Note: The below enhancement is not available for applications that use the LVC extension. Since uploading an address book might consume significant data, your Address Book module integration has an option to reduce the data usage of repeated uploads. You can disable automatic address book removal at Engine start by providing the configuration specified in the Configuring the Address Book Module section. If your integration disables the automatic address book deletion at Engine start, an address book might not need to be uploaded to Alexa at every start. Skip reuploading address books when all of the following conditions are true: The last successful upload was less than 24 hours ago. Note that Alexa periodically removes uploaded address books to comply with the Alexa data retention policy, so Amazon recommends reuploading the address books after 24 hours. The user connects the same phone used for the last successful upload. The phone contacts and navigation favorites on the phone are the same as the address book contents of the last successful upload.","title":"Reducing Data Usage"},{"location":"modules/address-book/#configuring-the-address-book-module","text":"To configure the Address Book module, use the \"aace.addressBook\" JSON object specified below in your Engine configuration: { \"aace.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Property Type Required Description Example aace.addressBook. cleanAllAddressBooksAtStart boolean No Whether the Engine should automatically delete all of the user's address books from Alexa at Engine start. This defaults to true if the configuration is omitted. false Note: The \"aace.addressBook\" configuration is optional since its only property is optional. Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::addressBook::config::AddressBookConfiguration::createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse AddressBookConfiguration C++ sample code #include <AACE/AddressBook/AddressBookConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto addressBookConfig = aace :: addressBook :: config :: AddressBookConfiguration :: createAddressBookConfig ( false ); configurations . push_back ( addressBookConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations );","title":"Configuring the Address Book Module"},{"location":"modules/address-book/#android-integration","text":"To use the Address Book module Engine configuration with AACS, use \"aacs.addressBook\" instead of \"aace.addressBook\" in your AACS configuration file: { \"aacs.addressBook\": { \"cleanAllAddressBooksAtStart\": {{BOOLEAN}} } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory method com.amazon.aace.addressbook.config.createAddressBookConfig to programmatically construct the EngineConfiguration in the proper format. import com.amazon.aace.addressBook.config.AddressBookConfiguration ; // Configure the Engine EngineConfiguration addressBookConfiguration = AddressBookConfiguration . createAddressBookConfig ( false ); mEngine . configure ( new EngineConfiguration [] { // other config objects, addressBookConfiguration , // ... });","title":"Android Integration "},{"location":"modules/address-book/#using-the-address-book-module-aasb-messages","text":"","title":"Using the Address Book Module AASB Messages"},{"location":"modules/address-book/#uploading-an-address-book","text":"To upload an address book to Alexa, publish the AddAddressBook message . The Engine publishes the AddAddressBookReply message to indicate upload completion or failure. Click to expand or collapse sequence diagram: Uploading Contacts Click to expand or collapse sequence diagram: Uploading Navigation Favorites","title":"Uploading an Address Book"},{"location":"modules/address-book/#removing-an-address-book","text":"To remove an address book to Alexa, publish the RemoveAddressBook message . The Engine publishes the RemoveAddressBookReply message to indicate removal completion or failure. Click to expand or collapse sequence diagram: Removing Contacts Click to expand or collapse sequence diagram: Removing Navigation Favorites","title":"Removing an Address Book"},{"location":"modules/address-book/#integrating-the-address-book-module-into-your-application","text":"","title":"Integrating the Address Book Module Into Your Application"},{"location":"modules/address-book/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to publish \"AddressBook\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/AddressBook/AddressBook/ContactName.h> #include <AASB/Message/AddressBook/AddressBook/NavigationName.h> #include <AASB/Message/AddressBook/AddressBook/PhoneData.h> #include <AASB/Message/AddressBook/AddressBook/PostalAddress.h> #include <AASB/Message/AddressBook/AddressBook/AddAddressBookMessage.h> #include <AASB/Message/AddressBook/AddressBook/RemoveAddressBookMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAddressBookHandler { // Subscribe to reply messages from the Engine void MyAddressBookHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAddAddressBookReplyMessage ( message ); }, AddAddressBookMessageReply :: topic (), AddAddressBookMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRemoveAddressBookReplyMessage ( message ); }, RemoveAddressBookMessageReply :: topic (), RemoveAddressBookMessageReply :: action ()); } // Handle the AddAddressBook reply message from the Engine void MyAddressBookHandler::handleAddAddressBookReplyMessage ( const std :: string & message ) { AddAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the upload result for the message... } // Handle the RemoveAddressBook reply message from the Engine void MyAddressBookHandler::handleRemoveAddressBookReplyMessage ( const std :: string & message ) { RemoveAddressBookMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; bool uploadWasSuccessful = msg . payload . success ; // ...Handle the removal result for the message... } // To upload contacts to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadContacts ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: CONTACT ; msg . payload . addressBookData = populateContacts ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateContacts ( const std :: string & id ) { // Populate an AddressBook object with the contacts data from the connected phone AddressBook addressBook ; // For each contact, add a ContactName to addressBook.contactNames // and add a PhoneData to addressBook.phoneData // ... return addressBook ; } // To upload navigation favorites to Alexa, publish an AddAddressBook message to the Engine bool MyAddressBookHandler::uploadNavigationFavorites ( const std :: string & id , const std :: string & name ) { AddAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; msg . payload . name = name ; msg . payload . type = AddressBookType :: NAVIGATION ; msg . payload . addressBookData = populateNavigationFavorites ( id ); m_messageBroker -> publish ( msg . toString ()); // The Engine will send the AddAddressBookReply message // Return the success status from reply message payload } AddressBook MyAddressBookHandler::populateNavigationFavorites ( const std :: string & id ) { // Populate an AddressBook object with the navigation favorites data from the head unit AddressBook addressBook ; // For each navigation address, add a NavigationName to addressBook.navigationNames // and add a PostalAddress to addressBook.postalAddresses // ... return addressBook ; } // To remove an address book, publish a RemoveAddressBook message to the Engine bool MyAddressBookHandler::removeAddressBook ( const std :: string & id ) { RemoveAddressBookMessage msg ; msg . payload . addressBookSourceId = id ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the RemoveAddressBookReply message // Return the success status from reply message payload } };","title":"C++ MessageBroker Integration"},{"location":"modules/address-book/#android-integration_1","text":"The Alexa Auto Client Service (AACS) provides the AACS Contacts Library to integrate the Auto SDK Address Book module on Android. See the AACS Contacts Library documentation for more information.","title":"Android Integration"},{"location":"modules/address-book/aasb-docs/AddressBook/","text":"AddressBook Incoming Messages AddAddressBook Notifies the engine on an availability of an address book. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}}, \"name\": {{String}}, \"type\": {{AddressBookType}}, \"addressBookData\": {{AddressBook}} } } Payload Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. name String Yes Friendly name of the address book, or an empty string if not available. type AddressBookType Yes Type of the address book AddressBookType. addressBookData AddressBook Yes A filled out AddressBook object. AddAddressBookReply Reply for AddAddressBook message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes False if address book was already added or some internal error, otherwise true on successful. RemoveAddressBook Notifies the engine on a non-availability of an already available address book. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}} } } Payload Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. Set this to empty string for engine to remove all uploaded address books. RemoveAddressBookReply Reply for RemoveAddressBook message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes False if address book is not already added or some internal error, otherwise true on successful. Type Definitions AddressBook JSON Structure { \"navigationNames\": [{{NavigationName}}], \"contactNames\": [{{ContactName}}], \"phoneData\": [{{PhoneData}}], \"postalAddresses\": [{{PostalAddress}}] } Properties Property Type Required Description Example navigationNames NavigationName [] Yes List of NavigationName. contactNames ContactName [] Yes List of ContactName. phoneData PhoneData [] Yes List of PhoneData. postalAddresses PostalAddress [] Yes List of PostalAddresses. NavigationName JSON Structure { \"entryId\": {{String}}, \"name\": {{String}}, \"phoneticName\": {{String}} } Properties Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. name String Yes Name of the entry, or an empty string if not available. If the name field contains Kanji characters, you must also provide the corresponding phoneticName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". phoneticName String No Phonetic name of the entry if available. ContactName JSON Structure { \"entryId\": {{String}}, \"firstName\": {{String}}, \"lastName\": {{String}}, \"nickname\": {{String}}, \"phoneticFirstName\": {{String}}, \"phoneticLastName\": {{String}} } Properties Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. firstName String Yes First name of the entry, or an empty string if not available. If the firstName field contains Kanji characters, you must also provide the corresponding phoneticFirstName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". lastName String Yes Last name of the entry, or an empty string if not available. If the lastName field contains Kanji characters, you must also provide the corresponding phoneticLastName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". nickname String Yes Name of the entry, or an empty string if not available. phoneticFirstName String No Phonetic first name of entry if available. phoneticLastName String No Phonetic last name of entry if available. PhoneData JSON Structure { \"entryId\": {{String}}, \"label\": {{String}}, \"number\": {{String}} } Properties Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. If multiple numbers are associated with a contact, Alexa will verbally ask the customer to confirm which number they want. If labels are assigned to the numbers and Alexa recognizes the types Alexa asks for confirmation; otherwise, Alexa says the last four digits of each number for the customer to select the one to call. number String Yes Numeric phone number, or an empty string if not available. PostalAddress JSON Structure { \"entryId\": {{String}}, \"label\": {{String}}, \"addressLine1\": {{String}}, \"addressLine2\": {{String}}, \"addressLine3\": {{String}}, \"city\": {{String}}, \"stateOrRegion\": {{String}}, \"districtOrCounty\": {{String}}, \"postalCode\": {{String}}, \"country\": {{String}}, \"latitudeInDegrees\": {{Float}}, \"longitudeInDegrees\": {{Float}}, \"accuracyInMeters\": {{Float}} } Properties Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. addressLine1 String Yes First line of the postal address, or an empty string if not available. addressLine2 String Yes Second line of the postal address, or an empty string if not available. addressLine3 String Yes addressLine3 Third line of the postal address, or an empty string if not available. city String Yes City name, or an empty string if not available. stateOrRegion String Yes State or Region name, or an empty string if not available. districtOrCounty String Yes District or County name, or an empty string if not available. postalCode String Yes Postal code or Zip code, or an empty string if not available. country String Yes Country name, or an empty string if not available. latitudeInDegrees Float Yes Geo latitude in degrees. longitudeInDegrees Float Yes Geo longitude in degrees. accuracyInMeters Float Yes Accuracy in meters, or zero if not available. Enums AddressBookType Values Value Description \"CONTACT\" Contacts. \"NAVIGATION\" Navigation Address.","title":"Address Book"},{"location":"modules/address-book/aasb-docs/AddressBook/#addressbook","text":"","title":"AddressBook"},{"location":"modules/address-book/aasb-docs/AddressBook/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/address-book/aasb-docs/AddressBook/#addaddressbook","text":"Notifies the engine on an availability of an address book.","title":"AddAddressBook"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}}, \"name\": {{String}}, \"type\": {{AddressBookType}}, \"addressBookData\": {{AddressBook}} } }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#payload","text":"Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. name String Yes Friendly name of the address book, or an empty string if not available. type AddressBookType Yes Type of the address book AddressBookType. addressBookData AddressBook Yes A filled out AddressBook object.","title":"Payload"},{"location":"modules/address-book/aasb-docs/AddressBook/#addaddressbookreply","text":"Reply for AddAddressBook message.","title":"AddAddressBookReply"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"AddAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#payload_1","text":"Property Type Required Description Example success Bool Yes False if address book was already added or some internal error, otherwise true on successful.","title":"Payload"},{"location":"modules/address-book/aasb-docs/AddressBook/#removeaddressbook","text":"Notifies the engine on a non-availability of an already available address book.","title":"RemoveAddressBook"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\" } }, \"payload\": { \"addressBookSourceId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#payload_2","text":"Property Type Required Description Example addressBookSourceId String Yes A unique identifier for an address book. Set this to empty string for engine to remove all uploaded address books.","title":"Payload"},{"location":"modules/address-book/aasb-docs/AddressBook/#removeaddressbookreply","text":"Reply for RemoveAddressBook message.","title":"RemoveAddressBookReply"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AddressBook\", \"action\": \"RemoveAddressBook\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#payload_3","text":"Property Type Required Description Example success Bool Yes False if address book is not already added or some internal error, otherwise true on successful.","title":"Payload"},{"location":"modules/address-book/aasb-docs/AddressBook/#type-definitions","text":"","title":"Type Definitions"},{"location":"modules/address-book/aasb-docs/AddressBook/#addressbook_1","text":"","title":"AddressBook"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_4","text":"{ \"navigationNames\": [{{NavigationName}}], \"contactNames\": [{{ContactName}}], \"phoneData\": [{{PhoneData}}], \"postalAddresses\": [{{PostalAddress}}] }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#properties","text":"Property Type Required Description Example navigationNames NavigationName [] Yes List of NavigationName. contactNames ContactName [] Yes List of ContactName. phoneData PhoneData [] Yes List of PhoneData. postalAddresses PostalAddress [] Yes List of PostalAddresses.","title":"Properties"},{"location":"modules/address-book/aasb-docs/AddressBook/#navigationname","text":"","title":"NavigationName"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_5","text":"{ \"entryId\": {{String}}, \"name\": {{String}}, \"phoneticName\": {{String}} }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#properties_1","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. name String Yes Name of the entry, or an empty string if not available. If the name field contains Kanji characters, you must also provide the corresponding phoneticName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". phoneticName String No Phonetic name of the entry if available.","title":"Properties"},{"location":"modules/address-book/aasb-docs/AddressBook/#contactname","text":"","title":"ContactName"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_6","text":"{ \"entryId\": {{String}}, \"firstName\": {{String}}, \"lastName\": {{String}}, \"nickname\": {{String}}, \"phoneticFirstName\": {{String}}, \"phoneticLastName\": {{String}} }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#properties_2","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. firstName String Yes First name of the entry, or an empty string if not available. If the firstName field contains Kanji characters, you must also provide the corresponding phoneticFirstName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". lastName String Yes Last name of the entry, or an empty string if not available. If the lastName field contains Kanji characters, you must also provide the corresponding phoneticLastName. Alexa uses the phonetic values for entity resolution and TTS when the device locale setting is \"ja-JP\". nickname String Yes Name of the entry, or an empty string if not available. phoneticFirstName String No Phonetic first name of entry if available. phoneticLastName String No Phonetic last name of entry if available.","title":"Properties"},{"location":"modules/address-book/aasb-docs/AddressBook/#phonedata","text":"","title":"PhoneData"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_7","text":"{ \"entryId\": {{String}}, \"label\": {{String}}, \"number\": {{String}} }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#properties_3","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. If multiple numbers are associated with a contact, Alexa will verbally ask the customer to confirm which number they want. If labels are assigned to the numbers and Alexa recognizes the types Alexa asks for confirmation; otherwise, Alexa says the last four digits of each number for the customer to select the one to call. number String Yes Numeric phone number, or an empty string if not available.","title":"Properties"},{"location":"modules/address-book/aasb-docs/AddressBook/#postaladdress","text":"","title":"PostalAddress"},{"location":"modules/address-book/aasb-docs/AddressBook/#json-structure_8","text":"{ \"entryId\": {{String}}, \"label\": {{String}}, \"addressLine1\": {{String}}, \"addressLine2\": {{String}}, \"addressLine3\": {{String}}, \"city\": {{String}}, \"stateOrRegion\": {{String}}, \"districtOrCounty\": {{String}}, \"postalCode\": {{String}}, \"country\": {{String}}, \"latitudeInDegrees\": {{Float}}, \"longitudeInDegrees\": {{Float}}, \"accuracyInMeters\": {{Float}} }","title":"JSON Structure"},{"location":"modules/address-book/aasb-docs/AddressBook/#properties_4","text":"Property Type Required Description Example entryId String Yes A unique identifier of entry in an address book. label String Yes Alphanumeric phone label (Example: HOME, MOBILE), or an empty string if not available. addressLine1 String Yes First line of the postal address, or an empty string if not available. addressLine2 String Yes Second line of the postal address, or an empty string if not available. addressLine3 String Yes addressLine3 Third line of the postal address, or an empty string if not available. city String Yes City name, or an empty string if not available. stateOrRegion String Yes State or Region name, or an empty string if not available. districtOrCounty String Yes District or County name, or an empty string if not available. postalCode String Yes Postal code or Zip code, or an empty string if not available. country String Yes Country name, or an empty string if not available. latitudeInDegrees Float Yes Geo latitude in degrees. longitudeInDegrees Float Yes Geo longitude in degrees. accuracyInMeters Float Yes Accuracy in meters, or zero if not available.","title":"Properties"},{"location":"modules/address-book/aasb-docs/AddressBook/#enums","text":"","title":"Enums"},{"location":"modules/address-book/aasb-docs/AddressBook/#addressbooktype","text":"","title":"AddressBookType"},{"location":"modules/address-book/aasb-docs/AddressBook/#values","text":"Value Description \"CONTACT\" Contacts. \"NAVIGATION\" Navigation Address.","title":"Values"},{"location":"modules/alexa/","text":"Alexa Module Table of Contents Alexa module overview Configure the Alexa module Set up Alexa for the user Authorize the device with Authorization Start the out-of-box experience with DeviceSetup Update Device Settings with PropertyManager Provide user speech input to Alexa with SpeechRecognizer Invoke Alexa with tap-and-release Invoke Alexa with press-and-hold Invoke Alexa with voice using Amazonlite wake word engine Reduce data usage with audio encoding Play Alexa speech to the user with SpeechSynthesizer Track Alexa state changes with AlexaClient Render Alexa's attention state Monitor Alexa's connection status Monitor Alexa's authorization state Display cards on screen with TemplateRuntime Stream Alexa media content Play media with AudioPlayer View media metadata on screen with TemplateRuntime Press media playback control buttons with PlaybackController Adjust equalizer settings with EqualizerController Resume media playback at startup with MediaPlaybackRequestor Enable audio ducking for Alexa media content Control local media with LocalMediaSoure Starting Playback with Content Selection by Voice Controlling Playback by Voice Reporting Playback State Example Sequence Diagrams Control external media apps with ExternalMediaAdapter Control volume with AlexaSpeaker Set a custom volume range Manage timers, alarms, and reminders with Alerts Render notification indicators with Notifications Block notifications with DoNotDisturb Alexa module overview The Alexa Auto SDK Alexa module provides interfaces for standard Alexa features. The Engine handles steps to send events and sequence directives so you can focus on using the provided AASB messages to interact with Alexa. Important! : If you are an Android developer, your application will use the Alexa Auto Client Service (AACS) as its foundation. AACS implements much of the core Auto SDK setup, abstracting it from your application and exposing only a necessary subset of the Auto SDK API in an Android-specific way. Some of the information presented in this documentation and documentation for other SDK modules might not pertain to your application exactly as written for cases in which AACS provides the implementation or further abstracts it, so keep this in mind while reading. Use the module documentation to understand the underlying layers of Auto SDK, if interested, and to reference the Engine configuration and AASB message definitions for the features you do need to build into your application yourself. Important!: Not every section of this documented is updated to reflect the Auto SDK 4.0 MessageBroker message API. Some sections still include text, code samples, or diagrams that show deprecated platform intefaces rather than their corresponding AASB message interface equivalents. Your application will use the the AASB message interfaces with MessageBroker. This document will be fully updated in the next Auto SDK version. For each interface you use, refer to its individual AASB message reference documentation. Configure the Alexa module The Alexa module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programatically with the relevant configuration factory functions. Your application must provide the aace.alexa configuration in the same format as the example specified below. Alternatively, use the AlexaConfiguration factory functions to generate individual elements of this configuration. { \"aace.alexa\": { \"avsDeviceSDK\": { \"deviceInfo\": { \"clientId\": \"${CLIENT_ID}\", \"productId\": \"${PRODUCT_ID}\", \"deviceSerialNumber\": \"${DEVICE_SERIAL_NUMBER}\", \"manufacturerName\": \"${MANUFACTURER_NAME}\", \"description\": \"${DEVICE_DESCRIPTION}\" }, \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"${CERTS_PATH}\" }, \"miscDatabase\": { \"databaseFilePath\": \"${DATA_PATH}/miscDatabase.db\" }, \"certifiedSender\": { \"databaseFilePath\": \"${DATA_PATH}/certifiedSender.db\" }, \"alertsCapabilityAgent\": { \"databaseFilePath\": \"${DATA_PATH}/alertsCapabilityAgent.db\" }, \"notifications\": { \"databaseFilePath\": \"${DATA_PATH}/notifications.db\" }, \"capabilitiesDelegate\": { \"databaseFilePath\": \"${DATA_PATH}/capabilitiesDatabase.db\" }, \"deviceSettings\": { \"databaseFilePath\": \"${DATA_PATH}/deviceSettings.db\", \"defaultLocale\":\"en-US\", \"defaultTimezone\":\"America/Vancouver\" } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 20000 } }, \"aasb.alexa\": { \"LocalMediaSource\": { \"types\": [\"FM_RADIO\", \"AM_RADIO\",\"BLUETOOTH\", \"USB\", \"SATELLITE_RADIO\", \"LINE_IN\", \"COMPACT_DISC\", \"DAB\", \"DEFAULT\"] } } } The deviceInfo field contains the details of the device. The fields libcurlUtils , miscDatabase , certifiedSender , alertsCapabilityAgent , notifications , and capabilitiesDelegate specify the respective database file paths. The deviceSettings field specifies the settings on the device. The following list describes the settings: databaseFilePath is the path to the SQLite database that stores persistent settings. The database will be created on initialization if it does not already exist. defaultLocale specifies the default locale setting, which is Alexa's locale setting until updated on the device. The default value of defaultLocale is \u201cen-US\u201d. locales specifies the list of locales supported by the device. The default value is [\"en-US\",\"en-GB\",\"de-DE\",\"en-IN\",\"en-CA\",\"ja-JP\",\"en-AU\",\"fr-FR\",\"it-IT\",\"es-ES\",\"es-MX\",\"fr-CA\",\"es-US\", \"hi-IN\", \"pt-BR\"] . localeCombinations specifies the list of locale pairs available on a device that supports multi-locale mode. Through the Dynamic Language Switching feature, Alexa can communicate with the user of such device in languages specified in the locale pairs. In each pair, the first value is the primary locale, which Alexa uses most often when interacting with the user. The second value is the secondary locale, which specifies an additional language that Alexa uses when responding to an utterance in the corresponding language. For example, if [\"en-US\", \"es-US\"] is declared in localeCombinations and the device specifies this pair as the current locale setting, Alexa primarily operates in English for the U.S. but can understand and respond to utterances in Spanish for the U.S., without requiring the device to update the locale setting. By default, localeCombinations is a list of the following combinations, which are also the supported combinations as of 2021-02-02. It is possible for the default value to be different from the list of supported combinations in the future. For updates to the supported combinations, see the Alexa Voice Service documentation . [\"en-US\", \"es-US\"] [\"es-US\", \"en-US\"] [\"en-IN\", \"hi-IN\"] [\"hi-IN\", \"en-IN\"] [\"en-CA\", \"fr-CA\"] [\"fr-CA\", \"en-CA\"] [\"en-US\", \"es-ES\"] [\"es-ES\", \"en-US\"] [\"en-US\", \"de-DE\"] [\"de-DE\", \"en-US\"] [\"en-US\", \"fr-FR\"] [\"fr-FR\", \"en-US\"] [\"en-US\", \"it-IT\"] [\"it-IT\", \"en-US\"] [\"en-US\", \"ja-JP\"] [\"ja-JP\", \"en-US\"] When a device operates in multi-locale mode, an application can select any locale pair in the list above as the locale setting if the following conditions are met: The device's primary locale setting is the first locale in the selected pair. The device also supports the secondary locale in the pair. The pair is specified in localeCombinations . Note: Dynamic Language Switching is only available in online mode. Set up Alexa for the user Authorize the device with Authorization In order to make requests to Alexa, your application requires a Login with Amazon (LWA) access token. The access token grants the device access to Alexa on behalf of the signed-in user. As part of the user sign-in experience for your application, obtain access tokens for Alexa and provide them to the Engine as outlined in the Alexa Auto SDK Authorization . Start the out-of-box experience with DeviceSetup Note: This feature requires Amazon to allowlist your device. For help, contact your Amazon Solutions Architect or partner manager . After the user signs in to your application during or after the out-of-box experience, the application starts the Engine and publishes the DeviceSetup.SetupCompleted message to notify Alexa that the setup is complete. The Engine publishes the DeviceSetup.SetupCompletedResponse to your application to indicate Alexa was notified successfully. In to the SetupCompleted event, Alexa starts an onboarding experience including a short first-time conversation with the user. Because SetupCompleted triggers an onboarding experience, do not publish the message if the signed-in user has already seen the experience. The onboarding experience is for first-time users only and might differ for returning users. Note: Do not publish the SetupCompleted message if user is in Connectivity Mode or Preview Mode or if the user has disabled handsfree listening. Publishing SetupCompleted in these conditions causes undesireable user experience. Update Device Settings with PropertyManager After starting the Engine, use the PropertyManager to update any Alexa properties that you need to keep in sync at startup. See Alexa Auto SDK Property Manager for details. Provide user speech input to Alexa with SpeechRecognizer At startup time, the SpeechRecognizer component in the Engine opens an audio input channel of type VOICE for the application to provide the user speech to Alexa. The application subscribes to the AudioInput.StartAudioInput and AudioInput.StopAudioInput messages as outlined in Alexa Auto SDK Audio Channels . When the Engine expects to receive audio from the application, it prompts the application by publishing a StartAudioInput message with audioType VOICE . The application provides the voice audio input until the Engine publishes a StopAudioInput message. The user decides when to speak to Alexa by invoking her with a tap-to-talk GUI button press, a push-to-talk physical button press, or\u2014in vehicles supporting voice-initiated listening\u2014an \"Alexa\" utterance. Invoke Alexa with tap-and-release For button press-and-release Alexa invocation, the application publishes the SpeechRecognizer.StartCapture message with initiator TAP_TO_TALK to tell the Engine that the user pressed the Alexa invocation button and wants to speak to Alexa. When requested, the application provides audio to the Engine until Alexa detects the end of the user's speech. The Engine publishes the SpeechRecognizer.EndOfSpeechDetected message to the application and requests the application to stop providing audio if no other Engine components require it. Invoke Alexa with press-and-hold For button press-and-hold Alexa invocation, the application publishes the SpeechRecognizer.StartCapture message with initiator HOLD_TO_TALK to tell the Engine that the user is holding down the Alexa invocation button and wants to speak to Alexa until releasing the button. When requested, the application provides audio to the Engine. When the user finishes speaking and releases the button, the application notifies the Engine by publishing the SpeechRecognizer.StopCapture message , and the Engine requests the application to stop providing audio if no other Engine components require it. Invoke Alexa with voice using Amazonlite wake word engine Note: To use the Amazonlite wake word engine in your application, contact your Amazon Solutions Architect or partner manager . When the application uses the Amazonlite Auto SDK module for wake word detection, the application notifies the Engine when the user has handsfree listening enabled (i.e., privacy mode is off) by publishing the PropertyManager.SetProperty message with property set to aace.alexa.wakewordEnabled and value set to true . The Engine enables Amazonlite wake word detection and requests audio input from the application. The application provides audio to the Engine for continuous wake word detection until the application disables handsfree listening by setting the aace.alexa.wakewordEnabled property to false . After disabling Amazonlite wake word detection, the Engine requests the application to stop providing audio if there no other Engine components require it. When Amazonlite detects the \"Alexa\" wake word in the continuous audio stream provided by the application, the Engine publishes the SpeechRecognizer.WakewordDetected message and starts an interaction similar to one triggered by tap-to-talk invocation. When Alexa detects the end of the user's speech, the Engine publishes the SpeechRecognizer.EndOfSpeechDetected message but keeps the audio input stream open for further wake word detection. Reduce data usage with audio encoding To save bandwidth when the Engine sends user speech to Alexa in SpeechRecognizer.Recognize events, you can configure the Engine to encode the audio with the Opus audio encoding format by adding the following object to your Engine configuration: { \"aace.alexa\": { \"speechRecognizer\": { \"encoder\": { \"name\": \"opus\" } } } } When you set this configuration in your application, the Engine still expects the application to provide audio in the Linear PCM format specified in the Alexa Auto SDK Audio Channels ; the Engine internally changes the encoding to Opus prior to including the audio attachment in the Recognize event. Click to expand or collapse details\u2014 Generate the configuration programatically with the C++ factory function If your application generates Engine configuration programmatically instead of using a JSON file, you can use the aace::alexa::config::AlexaConfiguration::createSpeechRecognizerConfig factory function to create the EngineConfiguration object. #include <AACE/Alexa/AlexaConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto speechRecognizerConfig = aace :: alexa :: config :: AlexaConfiguration :: createSpeechRecognizerConfig ( \"opus\" ); configurations . push_back ( speechRecognizerConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Click to expand or collapse details\u2014 Generate the configuration programatically with the Java factory method AACS is the recommended way to integrate Auto SDK for Android, so your application should provide the aacs.alexa configuration in the AACS configuration file. However, if your application does not use AACS, and it generates Engine configuration programmatically instead of using a JSON file, you can use the com.amazon.aace.alexa.config.AlexaConfiguration.createSpeechRecognizerConfig factory method to create the EngineConfiguration object. import com.amazon.aace.alexa.config.AlexaConfiguration ; EngineConfifguration speechRecognizerConfig = AlexaConfiguration . createSpeechRecognizerConfig ( \"opus\" ); mEngine . configure ( new EngineConfiguration [] { // ...add other EngineConfiguration objects... speechRecognizerConfig }); Play Alexa speech to the user with SpeechSynthesizer At startup time, the SpeechSynthesizer component in the Engine opens an audio output channel of type TTS for the application to play Alexa speech responses to the user. SpeechSynthesizer has no messages of its own for the application to handle because it uses the standard audio output framework specified in the Core module. When Alexa responds to a user request with speech, the Engine publishes an AudioOutput.Prepare message with audioType TTS . The application uses the payload of the message to open the audio stream and buffer the audio data. The application plays the audio to the user when the Engine publishes an AudioOutput.Play message with matching token . Track Alexa state changes with AlexaClient Render Alexa's attention state Your application can subscribe to the AlexaClient.DialogStateChanged message to be notified what state Alexa dialog is in (e.g., Alexa started listening to the user's speech or started speaking her response). This message helps your application render Alexa's attention state UI such as Voice Chrome and audio cues without having to derive these states by tracking your application's microphone and media player. The following diagram shows how you might use the dialog state changes to provide Alexa attention feedback during an interaction. Click to expand or collapse sequence diagram: Alexa invocation Monitor Alexa's connection status Your application can subscribe to the AlexaClient.ConnectionStatusChanged message to be notified when the status of the Engine's connection to Alexa has changed (e.g., the Engine lost connection to Alexa). You might use this information, for instance, to enable or disable certain functionality or display information to the user. Monitor Alexa's authorization state Your application can subscribe to the AlexaClient.AuthStateChanged message to be notified what state the Engine is in with respect to the user sign in. For example, the state is REFRESHED when the Engine has an access token. Display cards on screen with TemplateRuntime Alexa sends visual metadata (display card templates) for your device to display. When template information is received from Alexa, it is the responsibility of the platform implementation to handle the rendering of any UI with the information that is received from Alexa. There are two display card template types: The Template type provides visuals associated with a user request to accompany Alexa speech. The PlayerInfo type provides visuals associated with media playing through the AudioPlayer interface. This includes playback control buttons, which must be used with the PlaybackController interface. You can programmatically generate template runtime configuration using the aace::alexa::config::AlexaConfiguration::createTemplateRuntimeTimeoutConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"templateRuntimeCapabilityAgent\": { \"displayCardTTSFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackStoppedPausedTimeout\": <TIMEOUT_IN_MS> } } To implement a custom handler for GUI templates, extend the TemplateRuntime class: #include <AACE/Alexa/TemplateRuntime.h> class MyTemplateRuntime : public aace::alexa::TemplateRuntime { public: void renderTemplate( const std::string& payload, FocusState focusState ) override { // handle rendering the template data specified in payload } void renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) override { // handle rendering the player info data specified in payload } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyTemplateRuntime>() ); Note: In the case of lists, it is the responsibility of the platform implementation to handle pagination. Alexa sends down the entire list as a JSON response and starts reading out the first five elements of the list. At the end of the first five elements, Alexa prompts the user whether or not to read the remaining elements from the list. If the user chooses to proceed with the remaining elements, Alexa sends down the entire list as a JSON response but starts reading from the sixth element onwards. Stream Alexa media content Play media with AudioPlayer When an audio media stream is received from Alexa, it is the responsibility of the platform implementation to play the stream in a platform-specific media player. The aace::alexa::AudioPlayer class informs the platform of the changes in player state being tracked by the Engine. This can be used to update the platform GUI, for example. To implement a custom handler for audio player output, extend the AudioPlayer class: #include <AACE/Alexa/AudioPlayer.h> class MyAudioPlayer : public aace::alexa::AudioPlayer { public: void playerActivityChanged( PlayerActivity state ) override { // on state change, update playback control UI } }; ... // Register the platform interface with the Engine auto myAudioPlayer = std::make_shared<MyAudioPlayer>(); engine->registerPlatformInterface( myAudioPlayer ); View media metadata on screen with TemplateRuntime Your application subscribes to the TemplateRuntime.RenderPlayerInfo AASB message to receive metadata about the active media playback for you to display. See the TemplateRuntime AVS documentation for details about the payload. Press media playback control buttons with PlaybackController The Engine provides a platform interface aace::alexa::PlaybackController for the platform implementation to report on-device transport control button presses for media playing through Alexa. For example, if the user presses the on-screen pause button while listening to Amazon Music through Alexa's AudioPlayer interface, the platform implementation calls a PlaybackController method to report the button press to the Engine. Note: PlaybackController method calls to manage AudioPlayer 's state or playback queue proactively report button presses or the equivalent so that Alexa can react; they do not report changes to the playback state that happen locally first. The Alexa cloud manages the playback queue for AudioPlayer content, so each PlaybackController method call is a request for Alexa to act on the user's local request. The result of the request will come as one or more method invocations on the AudioOutput associated with the channel used for AudioPlayer . Note: If your implementation needs to stop AudioPlayer media in response to system events, such as audio focus transitions to audio playing outside the scope of the Auto SDK, use PlaybackController to notify the Engine of such changes. However, keep in mind that the expected usage of the interface does not change when it is used in this use case. Note: PlaybackController only controls media coming from Alexa, i.e. the AudioPlayer . PlaybackController should not be used with the expectation of controlling playback for non-media Alexa audio sources like SpeechSynthesizer or Alexa-aware external media sources integrated with ExternalMediaAdapter or LocalMediaSource . Additionally, calling a PlaybackController method while audio is playing through another Alexa-aware external media source will produce unexpected results and is not recommended. Whenever Alexa plays media through AudioPlayer , the Engine calls the platform interface method aace::alexa::TemplateRuntime::renderPlayerInfo() to provide visual metadata associated with the media that your implementation should render for the end user. The payload of this method includes descriptions of GUI controls to be displayed and the state in which to display them. When the user interacts with these on-screen controls, your implementation must use the PlaybackController interface to report the button presses to the Engine. The table below maps the controls from the renderPlayerInfo() payload to the corresponding calls in PlaybackController . RenderPlayerInfo control name PlaybackController PlaybackButton \"PLAY_PAUSE\" PLAY \"PLAY_PAUSE\" PAUSE \"NEXT\" NEXT \"PREVIOUS\" PREVIOUS \"SKIP_FORWARD\" SKIP_FORWARD \"SKIP_BACKWARD\" SKIP_BACKWARD PlaybackToggle \"SHUFFLE\" SHUFFLE \"LOOP\" LOOP \"REPEAT\" REPEAT \"THUMBS_UP\" THUMBS_UP \"THUMBS_DOWN\" THUMBS_DOWN To implement a custom handler for the playback controller, extend the PlaybackController class: #include <AACE/Alexa/PlaybackController.h> class MyPlaybackController : public aace::alexa::PlaybackController { ... void platformPlayButtonPressed() { // called by some platform event buttonPressed(PlaybackButton::PLAY); } ... void platformScrubForwardGUIButtonPressed(){ //called by the platform on an available GUI button event buttonPressed(PlaybackButton::SKIP_FORWARD); } ... void platformShuffleGUIButtonPressed(){ //called by the platform on an available GUI toggle event togglePressed(PlaybackToggle::SHUFFLE, true); //the action should send the value opposing the last playerinfo state for that toggle control } ... }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyPlaybackController>() ); Adjust equalizer settings with EqualizerController The Equalizer Controller enables Alexa voice control of the device's audio equalizer settings, which includes making gain level adjustments to any of the supported frequency bands (\"BASS\", \"MIDRANGE\", and/or \"TREBLE\") using the device's onboard audio processing. The platform implementation is responsible for the following: Determining how each supported band affects the audio Mapping Alexa's equalizer bands to the bands supported on the device, if they do not directly correspond Scaling Alexa's level values as necessary so that each step corresponds to one decibel of amplitude gain on the device Applying equalization to only selected portions of the audio output so that Alexa's speech, alarms, etc. will not be affected Persisting settings across power cycles You can programmatically generate Equalizer Controller configuration with details such as supported bands, default state, and decibel adjustment range using the aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"equalizer\": { \"bands\": { \"BASS\": true, \"MIDRANGE\": false, \"TREBLE\": true }, \"defaultState\": { \"bands\": { \"BASS\": 4, \"TREBLE\": -1 } }, \"minLevel\": -6, \"maxLevel\": 6 } } } // For example, 2 supported bands with amplitude gains ranging from -8dB to +8dB, each with a default of 0dB auto eqConfig = aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig( {EqualizerBand::BASS, EqualizerBand::TREBLE}, -8, 8, { {EqualizerBand::BASS, 0}, {EqualizerBand::TREBLE, 0} } ); engine->configure( { //other config objects..., eqConfig, ... } ); ... To implement a custom handler for Equalizer Controller, extend the EqualizerController class: #include <AACE/Alexa/EqualizerController.h> using EqualizerBand = aace::alexa::EqualizerController::EqualizerBand; using EqualizerBandLevel = aace::alexa::EqualizerController::EqualizerBandLevel; class MyEqualizerControllerHandler : public aace::alexa::EqualizerController { public: void setBandLevels( std::vector<EqualizerBandLevel> bandLevels ) override { // Handle performing audio equalization on the device // according to the provided band dB level settings // This invocation may come from \"Alexa, reset bass\", // \"Alexa, reset my equalizer\", \"Alexa, increase treble\", etc. } std::vector<EqualizerBandLevel> getBandLevels() override { // Return the current band level settings on the device return m_currentBandLevels; } }; ... // Register the platform interface with the Engine auto m_equalizerController = std::make_shared<MyEqualizerControllerHandler>(); engine->registerPlatformInterface( m_equalizerController ); ... // If levels are adjusted using local on-device controls, call inherited methods to notify the Engine: // To set a band to an absolute gain level in decibels std::vector<EqualizerBandLevel> settings{ {EqualizerBand::BASS, 4} }; // Sets bass amplitude to +4dB m_equalizerController->localSetBandLevels( settings ); // To make a relative adjustment to level settings std::vector<EqualizerBandLevel> adjustments{ {EqualizerBand::BASS, -2} }; // Decreases bass gain by 2dB m_equalizerController->localAdjustBandLevels( adjustments ); // To reset gain levels to the configured defaults (usually 0dB) std::vector<EqualizerBand> bands{EqualizerBand::BASS, EqualizerBand::TREBLE}; // Resets bass and treble bands m_equalizerController->localResetBands( bands ); Resume media playback at startup with MediaPlaybackRequestor Alexa Media-Resume is a feature that helps Alexa play customers\u2019 favorite content when they start their Alexa-enabled vehicles. Media-resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. To resume the media, Alexa auto SDK needs to send RequestMediaPlayback event with the Invocation reason AUTOMOTIVE_STARTUP . To implement a handler, extend the aace::alexa::MediaPlaybackRequestor class: #include <AACE/Alexa/MediaPlaybackRequestor.h> class MediaPlaybackRequestorHandler : public aace::alexa::MediaPlaybackRequestor { public: void mediaPlaybackResponse(MediaPlaybackRequestStatus mediaPlaybackRequestStatus) override { //Handle the status change } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MediaPlaybackRequestorHandler>()); requestMediaPlayback is the API to send the event to the cloud. This API needs InvocationReason and elapsedBootTime as input parameters. mediaPlaybackResponse callback receives the status of the requestMediaPlayback API call asynchronously. InvocationReason enum indicates the invocation reason for calling the event. AUTOMOTIVE_STARTUP represents a situation where platform automatically calls requestMediaPlayback API to automatically resume the media after infotainment system reboot. EXPLICIT_USER_ACTION represents resuming the media after explicit driver action by pressing the button or switch. Music resuming on EXPLICIT_USER_ACTION is not yet supported and this will be enabled in the future. Please check with your partner manager before using this action. MediaPlaybackRequestStatus enum indicate the status of the requestMediaPlayback API call. SUCCESS means RequestMediaPlayback event is successfully reported to the cloud. FAILED_CAN_RETRY means requestMediaPlayback API call can not be processed because Alexa Auto SDK is not in the connected state but platform implementation can retry after some time. FAILED_TIMEOUT means threshold time is crossed and media can not be resumed now. Driver can play media by making a voice request. ERROR means API could not be called successfully and media can not be resumed. This feature needs following configuration. Please contact to your partner manager for finalizing the threshold numbers. \"aace.alexa\": { \"requestMediaPlayback\": { \"mediaResumeThreshold\": 30000 } } mediaResumeThreshold is the maximum time in milliseconds to receive the requestMediaPlayback API call from the platform implementation. Platform implementation should consider their boot time, time to initialize alexa and get connected to send the RequestMediaPlayback event successfully. Platform team and partner manager should try to keep this time minimum for the better user experience. Delayed media resume can surprise driver and result in driver distraction. Note: This feature assumes that client platform maintains the media sessions and request individual media applications to resume playback if that media application was active and playing before the device shuts down. Note: requestMediaPlayback API call expects a elapsed boot time i.e. number of milliseconds elapsed from the device boot up. This feature assumes that client platform provides the correct value using their proprietary methods. The mediaResumeThreshold value and elapsedBootTime value are compared together for the guardrail condition. Enable audio ducking for Alexa media content Your application can configure the Engine to enable audio ducking for media that plays through AudioPlayer . See Alexa Auto SDK Audio Channels for details. Control local media with LocalMediaSoure The LocalMediaSource interface allows the platform to register a local media source by type ( BLUETOOTH , USB , AM_RADIO , FM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT ). Registering a local media source allows playback control of that source via Alexa (e.g. \"Alexa, play the CD player\"). It also enables playback initiation via Alexa by frequency, channel, or preset for relevant source types (e.g. \"Alexa, play 98.7 FM\"). DEFAULT media source is a generic media source that can be used for controlling any local media source on the OEM infotainment system. It is recommended to use DEFAULT media source for all local media except Alexa music, MACC-supported deep linked media players, and other registered Local Media Sources. DEFAULT media player can not be launched by name like \"Alexa, Play CD player\" but it can be used to control playback actions reported in the supportedOperations . For example, \"Alexa, play\" resumes the default player playback as long a the DEFAULT source is in focus . The following is an example of registering a CD player local media source using type Source.COMPACT_DISC : auto m_CDLocalMediaSource = std::make_shared<MyCDLocalMediaSource>( Source.COMPACT_DISC ); engine->registerPlatformInterface( m_CDLocalMediaSource ); To implement a custom handler for a CD player local media source extend the LocalMediaSource class: #include <AACE/Alexa/LocalMediaSource.h> class MyCDLocalMediaSource : public aace::alexa::LocalMediaSource { public: MyCDLocalMediaSource( LocalMediaSource::Source source ) { m_source = source; ... } ... }; ... Starting Playback with Content Selection by Voice The play() method is called when Alexa invokes play by ContentSelector type ( FREQUENCY , CHANNEL , PRESET ) for a radio local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM , DAB ). The payload is a string that depends on the ContentSelector type and local media Source type (e.g., \"1\", \"98.7 FM HD 1\"). bool play( ContentSelector type, std::string payload, const std::string& sessionId ) override { // play initiation for frequency, channel, or presets ... } The table below provides details about the supported ContentSelector types based on Source type: Source type Supported content selector(s) FM FREQUENCY, PRESET AM FREQUENCY, PRESET SXM CHANNEL, PRESET DAB CHANNEL DEFAULT PRESET The supported ranges and increments for valid frequency, preset, and channel may vary depending on the region you are in. Contact your partner manager for more detailed information. Note: The DAB channel payload is the radio station name string. If supported, then the name string must be handled by the client's DAB implementation. The play() method will not be invoked if a source cannot handle the specified ContentSelector type. The DEFAULT Local Media Source handles \"Alexa, play preset \\ \\\" utterances without requiring that users explicitly say which local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM ) actually corresponds to the preset. The meaning of the preset in the payload parameter of play(ContentSelector contentSelectorType, const std::string& payload, const std::string& sessionId) is determined by the DEFAULT platform implementation and should suit the needs of the vehicle's infotainment system, i.e. when the play() method is called, your implementation should map the preset to a preset that makes sense for the current context. Note: The GlobalPreset platform interface is deprecated. Use DEFAULT LocalMediaSource instead. Controlling Playback by Voice The playControl() method is called with a PlayControlType ( RESUME , PAUSE , STOP , NEXT , PREVIOUS , START_OVER , FAST_FORWARD , REWIND , ENABLE_REPEAT_ONE , ENABLE_REPEAT , DISABLE_REPEAT , ENABLE_SHUFFLE , DISABLE_SHUFFLE , FAVORITE , UNFAVORITE ) when Alexa invokes a playback control on the local media source. bool playControl( PlayControlType controlType ) override { // handle the control type appropriately for CD player return true; } Note: The play() method is used to initiate playback with specified content selection, whereas playControl(RESUME) is used to play or resume the source when content is not specified or not supported. E.g. FM receives play() when the user requests FM with a specific frequency (\"Alexa, play 98.7 FM radio\"), and USB receives playControl(RESUME) when the user requests playback with just the source name (\"Alexa, play USB\"). The seek() and adjustSeek() methods are invoked to seek the currently focused LocalMediaSource . These methods are only used by sources that are capable of seeking. seek() is for specifying an absolute offset, whereas adjustSeek() is for specifying a relative offset. bool seek( long offset ) override { // handle seeking CD player } ... bool adjustSeek( long offset ) override { // handle adjusting seek for CD player } The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently focused local media player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . @Override public boolean volumeChanged( float volume ) { // handle volume change } ... @Override public boolean mutedStateChanged( MutedState state ) { // handle setting mute state } ... Reporting Playback Events The LocalMediaSource interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your local source. Even though your local source manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your local source's playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your local source's state. Particular event names indicate if the source is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. playerEvent() event name Description \"PlaybackSessionStarted\" The local media source is switched from the inactive to active media state or a new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackSessionEnded\" The local media source is switched from the active to inactive media state or an active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. \"PlaybackStarted\" During an active session, the local source has started to play or resumed from a paused state. \"PlaybackStopped\" During an active session, the player stopped, either as a result of a GUI interaction or a user voice request to Alexa. playerError() event name Description \"INTERNAL_ERROR\" During an active session, an internal error caused playback to stop. Both playerEvent() and playerError() are expected to provide the appropriate sessionId. Call playerEvent(\"PlaybackSessionStarted\", sessionId) to tell the Engine that the user brought the LocalMediaSource to the foreground with a GUI interaction. The Engine considers the source to have an active playback session, although it may or may not be playing yet. If no other Alexa media source is playing, utterances such as \u201cAlexa, play\u201d target this source. You must also call playerEvent(\"PlaybackSessionStarted\", sessionId) when the source is brought into the foreground by a call to play() or playControl() as a result of a user voice request. Once the source starts playing, call playerEvent(\"PlaybackStarted\", sessionId) . Call playerEvent(\"PlaybackSessionEnded\", sessionId) to tell the Engine that the LocalMediaSource is no longer in the foreground, typically as a result of a GUI interaction from the user after the player is stopped. The Engine considers the source inactive or not in focus, and starting a new playback session for the source requires a further GUI interaction or user voice request to Alexa that targets the source by name. class MyFMRadioLocalMediaSource : public aace::alexa::LocalMediaSource { ... // public method in source handler void setAlexaFocusForFMRadio( bool isFocused ) { ... if (isFocused) { ... // FM Radio begins playback independently of Alexa playerEvent(\"PlaybackSessionStarted\", m_sessionId); } else { ... // Notify Alexa that FM Radio is no longer the active media source on the device as a result of platform driven change playerEvent(\"PlaybackSessionEnded\", m_sessionId); } ... } ... Note: Only one LocalMediaSource type can have Alexa focus at a time. Note: setFocus() and setFocus(bool) methods are deprecated for the LocalMediaSource platform interface. playerEvent() with \"PlaybackSessionStarted\" or \"PlaybackSessionEnded\" should be used instead of setFocus(true) and setFocus(false) . Please abide by following rules related to sessionId in your LocalMediaSource integration: sessionId is a universally unique identifier (UUID) generated according to the RFC 4122 specification. If a media source starts because of a call to play(contentSelector, payload, sessionId) from the Engine, note the sessionId parameter and use it in any playerEvent() calls until the session is inactive. If a media source starts for any other reason (e.g. a call to playControl(RESUME) from the Engine, or user GUI interaction on the head unit), create a new sessionId and use it in any playerEvent() calls until the session is inactive. A sessionId is always associated with one media source playback session, so USB 's sessionId should be different than COMPACT_DISC 's sessionId . An individual LocalMediaSource should maintain the sessionId for the whole cycle from playback session start to playback session end. For any \"opening\" playerEvent() call for a particular sessionId (e.g. \"PlaybackSessionStarted\" , \"PlaybackStarted\" ), you must report a corresponding closing call (e.g. \"PlaybackStopped\" , \"PlaybackSessionEnded\" ) at the appropriate time (i.e., when the source is stopped, switched, etc.) Reporting Playback State The getState() method is called to synchronize the local player's state with the cloud. This method is used to maintain correct state during startup and with every Alexa request. All relevant information should be added to the LocalMediaSourceState and returned. Many fields of the LocalMediaSourceState are not required for local media source players. You should omit these as noted below. LocalMediaSourceState getState() override { LocalMediaSourceState stateToReturn = std::make_shared<LocalMediaSourceState>(); stateToReturn.playbackState.albumName = \"mock albumName\"; // fill in all required state information (see below) return stateToReturn; } The following table describes the fields comprising a LocalMediaSourceState , which includes two sub-components: PlaybackState and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedPlaybackOperation trackOffset long No optional shuffleEnabled boolean No optional repeatEnabled boolean No optional favorites Favorites No see Favorites type String Yes must be set to \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No optional trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType No see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean No empty accessToken String No empty tokenRefreshInterval long No empty supportedContentSelectors ContentSelector[] No see ContentSelector spiVersion String Yes must be \"1.0\" supportedOperations should list the operations that the local media source supports. Below is a list of all SupportedPlaybackOperation : LocalMediaSource::SupportedPlaybackOperation::PLAY, LocalMediaSource::SupportedPlaybackOperation::PAUSE, LocalMediaSource::SupportedPlaybackOperation::STOP, LocalMediaSource::SupportedPlaybackOperation::PREVIOUS, LocalMediaSource::SupportedPlaybackOperation::NEXT, LocalMediaSource::SupportedPlaybackOperation::ENABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::DISABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT_ONE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::DISABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::SEEK, LocalMediaSource::SupportedPlaybackOperation::ADJUST_SEEK, LocalMediaSource::SupportedPlaybackOperation::FAVORITE, LocalMediaSource::SupportedPlaybackOperation::UNFAVORITE, LocalMediaSource::SupportedPlaybackOperation::FAST_FORWARD, LocalMediaSource::SupportedPlaybackOperation::REWIND, LocalMediaSource::SupportedPlaybackOperation::START_OVER Note: Currently PLAY/PAUSE/STOP are always supported for a source. Passing null allows ALL supported operations for the source. supportedContentSelectors should list the content selection types the local source can support. Below is a table of valid pairs. Source Supportable ContentSelector Values AM_RADIO PRESET , FREQUENCY FM_RADIO PRESET , FREQUENCY SIRIUS_XM PRESET , CHANNEL DEFAULT PRESET launched specifies whether the source is enabled. The player is disabled for use with Alexa when this value is false, such as when a removable source like USB is disconnected. Example Sequence Diagrams The following diagrams show examples of Local Media Source usage: 1. Starting FM by voice 2. Switching from FM to DEFAULT media source with GUI 3. Switching between different DEFAULT sources Control external media apps with ExternalMediaAdapter The External Media Player (EMP) Adapter allows you to declare and use external media application sources in your application. In order to interface with the EMP Adapter, you must use one of the following: A media connection client to interface the EMP Adapter to the external app. AACS provides an app component called the Media App Command and Control (MACC) client that provides most of the deep-linking integration specified below. The AACS Sample App supports an example using the Media App Command and Control (MACC) client to play the Android Spotify app. An embedded media app. For information about external embedded media app solutions, contact your SA or Partner Manager. Note: If the media app service requires additional customer experience details, incorporate the requirement in your implementation. For example, if the provider requires your application to show the provider's logo in a particular way, modify the implementation to meet the requirement. When advised by your SA or Partner Manager, configure the External Media Player Adapter to the device's capabilities. See aace::alexa::config::AlexaConfiguration::createExternalMediaPlayerConfig for details on configuring the supported agent, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"externalMediaPlayer\": { \"agent\": \"<agent>\" } } You must register and implement each ExternalMediaAdapter (along with its associated external client or library). After the engine establishes a connection to the Alexa service, you can run discovery to validate each external media application. You can report discovered external media players by calling reportDiscoveredPlayers() at any point during runtime. When the Alexa service recognizes the player, you will get a call to the authorize() method including the player's authorization status. Both the reportDiscoveredPlayers() method and the authorize() method can contain one or more players in their JSON payloads. Validating the application enables Alexa to exercise playback control over the registered source type. The login() and logout() methods inform AVS of login state changes, if applicable. If your application has the ability to handle cloud-based login and logout, you should also call the loginComplete() and logoutComplete() methods where appropriate. When the user makes an Alexa voice request (for example, \"Play Spotify\"), the play() method is invoked. This method contains various parameters, including the player id of the player to which the playback information should be routed. Whether through voice or GUI event, the playControl() method is called with the relevant PlayControlType . Similar to play() the control should be routed to the appropriate player. The PlayControlType is determined by player's supportedOperations , which are specified by your implementation in the return value of getState() . The ExternalMediaAdapter interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your external player. Even though your player manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your player\u2019s playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your player\u2019s state. Particular event names indicate if the player is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. The tables below describe each supported event name and what it means to the Engine. Usage of these events depends on the particular type of player controlled by the ExternalMediaAdapter instance, so contact your Solutions Architect (SA) or Partner Manager for guidance regarding supported embedded and external app solutions. playerEvent() event name Description \"PlaybackSessionStarted\" A new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackStarted\" During an active session, the player has started to play or resumed from a paused state. The Engine considers the player active and in focus. \"TrackChanged\" During an active session, one track has ended and another has started. The Engine uses this primarily for state reporting. \"PlaybackNext\" During an active session, the player skipped from one track to the next track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlaybackPrevious\" During an active session, the player skipped from one track to the previous track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlayModeChanged\" During an active session, some user setting for the track or playback session changed, such as the favorite setting or the shuffle mode. The Engine uses this primarily for state reporting. \"PlaybackStopped\" During an active session, the player has paused or stopped, either as a result of a GUI interaction or a user voice request to Alexa. The Engine considers the player active and in focus, just not currently playing. User voice requests to resume still control the player. \"PlaybackSessionEnded\" An active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. playerError() event name Description \"INTERNAL_ERROR\" Any fatal player error has occurred \"UNKNOWN_ERROR\" An unknown error occurred \"UNPLAYABLE_BY_AUTHORIZATION\" The media couldn't be played due to an unauthorized account \"UNPLAYABLE_BY_STREAM_CONCURRENCY\" The media couldn't be played due to the number of accounts currently streaming \"UNPLAYABLE_BY_ACCOUNT\" The media couldn't be played due to the account type \"UNPLAYABLE_BY_REGION\" The media couldn't be played due to the current region \"UNPLAYABLE_BY_PARENTAL_CONTROL\" The media couldn't be played due to parental settings \"UNPLAYABLE_BY_SUBSCRIPTION\" The media couldn't be played due to the subscription type \"OPERATION_REJECTED_UNINTERRUPTIBLE\" The operation could not be performed due to non interruptible media \"OPERATION_REJECTED_END_OF_QUEUE\" The operation could not be performed due to the end of media being reached \"OPERATION_UNSUPPORTED\" The operation was not supported \"OPERATION_REJECTED_SKIP_LIMIT\" The operation failed because a skip limit was reached \"PLAYER_UNKNOWN\" An unknown player was detected \"PLAYER_NOT_FOUND\" The player was not discovered \"PLAYER_CONNECTION_REJECTED\" The connection to the player failed \"PLAYER_CONNECTION_TIMEOUT\" The connection to the player timed out The seek() and adjustSeek() methods are invokable via Alexa if the currently in-focus external player supports them. seek() specifies an absolute offset, whereas adjustSeek() specifies a relative offset. The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently-focused external player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . The getState() method is called to synchronize the external player's state with the cloud. This method is used to maintain correct state during startup, and after every Alexa request. You construct the ExternalMediaAdapterState object using the data taken from the media app connection client or embedded player app (associated via localPlayerId ) and return the state information. The following table describes the fields comprising a ExternalMediaAdapterState , which includes two sub-components: PlaybackState , and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedOperation trackOffset long No optional shuffleEnabled boolean Yes report shuffle status repeatEnabled boolean Yes report repeat status favorites Favorites No see Favorites type String Yes must be set as \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No empty trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType Yes see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean Yes true if the application is in an active state accessToken String No empty tokenRefreshInterval long No empty playerCookie String No A player may declare arbitrary information for itself spiVersion String Yes must be set as \"1.0\" supportedOperations should be a list of the operations that the external media adapter supports. Below is a list of all possible supportedOperations . SupportedPlaybackOperation.PLAY, SupportedPlaybackOperation.PAUSE, SupportedPlaybackOperation.STOP, SupportedPlaybackOperation.PREVIOUS, SupportedPlaybackOperation.NEXT, SupportedPlaybackOperation.ENABLE_SHUFFLE, SupportedPlaybackOperation.DISABLE_SHUFFLE, SupportedPlaybackOperation.ENABLE_REPEAT_ONE, SupportedPlaybackOperation.ENABLE_REPEAT, SupportedPlaybackOperation.DISABLE_REPEAT, SupportedPlaybackOperation.SEEK, SupportedPlaybackOperation.ADJUST_SEEK, SupportedPlaybackOperation.FAVORITE, SupportedPlaybackOperation.UNFAVORITE, SupportedPlaybackOperation.FAST_FORWARD, SupportedPlaybackOperation.REWIND, SupportedPlaybackOperation.START_OVER Note: Currently PLAY/PAUSE/STOP will always be supported for a source. Passing null will allow ALL supported operations for the source. Control volume with AlexaSpeaker The Alexa service keeps track of two device volume types: ALEXA_VOLUME and ALERTS_VOLUME . The aace::alexa::AlexaSpeaker class should be implemented by the platform to both set the volume and mute state of these two speaker types and allow the user to set the volume and mute state of these two speaker types locally via GUI if applicable. SpeakerManager is a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\". You can programmatically generate speaker manager configuration using the aace::alexa::config::AlexaConfiguration::createSpeakerManagerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"speakerManager\": { \"enabled\": false } } } Set a custom volume range You can use a custom volume control to support an Alexa device's native input volume range. By default, Alexa supports voice utterances that specify volume values between 0 and 10, but some devices may support a different range (i.e. 0 to 100). By placing on Amazon's allow list your Alexa device's volume range for your target platform, you can specify input volume levels per your device's range. Your device's input volume range is then mapped appropriately to the Alexa volume range. Contact your Alexa Auto Solution Architect (SA) for help with allow lists. Placing a device on the allow list requires the following parameters: DeviceTypeID: Min: Max: This does not impact the range used in the directives to the device. You must continue to use the SDK 0-100 volume range used by AudioOutput and AlexaSpeaker and map these values to the correct range in your implementation. Manage timers, alarms, and reminders with Alerts When an alert is received from Alexa, it is the responsibility of the platform implementation to play the alert sounds in a platform-specific media player. See the AVS Alerts interface documentation for more information about alerts. The state of the alert is also made available for the platform to react to. The playback is handled by whichever audio channel is assigned to the ALERT type. To implement a custom handler for alerts, extend the Alerts class: #include <AACE/Alexa/Alerts.h> class MyAlerts : public aace::alexa::Alerts { public: void MyAlerts::alertStateChanged( const std::string& alertToken, AlertState state, const std::string& reason ) override { //handle the alert state change } void MyAlerts::alertCreated( const std::string& alertToken, const std::string& detailedInfo ) override { //handle the alert detailed info when alert is created (optional) /* * JSON string detailedInfo : * { * \"time\" : <String> * \"type\" : <String> * \"label\" : <String> * } */ } void MyAlerts::alertDeleted( const std::string& alertToken ) override { //handle the alert when alert is deleted (optional) } }; ... // Register the platform interface with the Engine auto myAlertsMediaPlayer = std::make_shared<MyMediaPlayer>(...); auto myAlertsSpeaker = std::make_shared<MySpeaker>(...); auto myAlerts = std::make_shared<MyAlerts>(myAudioPlayerMediaPlayer, myAudioPlayerSpeaker); engine->registerPlatformInterface( myAlerts ); Render notification indicators with Notifications It is the responsibility of the platform implementation to provide a visual indication to the user when notifications (for example, package shipment notifications, notifications from skills, etc.) are available from Alexa. See the AVS Notifications interface documentation for more information about notifications. The Engine uses the registered Notifications implementation to notify you when a notification indicator should be displayed or removed. It does not give any information about the notifications. Audio playback for the notification is handled by whichever audio channel is assigned to the NOTIFICATION type. To implement a custom handler for Notifications extend the Notifications class: #include <AACE/Alexa/Notifications.h> using IndicatorState = aace::alexa::Notifications::IndicatorState; class MyNotificationsHandler : public aace::alexa::Notifications { public: void setIndicator( IndicatorState state ) override { // set your notifications indicator! } }; ... // Register the platform interface with the Engine auto m_notificationsHandler = std::make_shared<MyNotificationsHandler>(); engine->registerPlatformInterface(m_notificationsHandler); Block notifications with DoNotDisturb The DoNotDisturb (DND) interface allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . The Engine uses the registered DND implementation to notify the client when DND has been set or unset. A user's voice request to change the DND state triggers audio playback, but no audio playback occurs when a user sets the DND state using the touch screen. To implement a custom handler for DND extend the DoNotDisturb class: #include <AACE/Alexa/DoNotDisturb> class MyDoNotDisturbHandler : public aace::alexa::DoNotDisturb { public: void setDoNotDisturb( bool doNotDisturb ) override { // set your DoNotDisturb indicator } // on user GUI setting change ... bool doNotDisturb = userSetState; doNotDisturbChanged(doNotDisturb); ... }; ... // Register the platform interface with the Engine auto m_doNotDisturbHandler = std::make_shared<MyDoNotDisturbHandler>(); engine->registerPlatformInterface(m_doNotDisturbHandler);","title":"Alexa Module <!-- omit in toc -->"},{"location":"modules/alexa/#alexa-module","text":"Table of Contents Alexa module overview Configure the Alexa module Set up Alexa for the user Authorize the device with Authorization Start the out-of-box experience with DeviceSetup Update Device Settings with PropertyManager Provide user speech input to Alexa with SpeechRecognizer Invoke Alexa with tap-and-release Invoke Alexa with press-and-hold Invoke Alexa with voice using Amazonlite wake word engine Reduce data usage with audio encoding Play Alexa speech to the user with SpeechSynthesizer Track Alexa state changes with AlexaClient Render Alexa's attention state Monitor Alexa's connection status Monitor Alexa's authorization state Display cards on screen with TemplateRuntime Stream Alexa media content Play media with AudioPlayer View media metadata on screen with TemplateRuntime Press media playback control buttons with PlaybackController Adjust equalizer settings with EqualizerController Resume media playback at startup with MediaPlaybackRequestor Enable audio ducking for Alexa media content Control local media with LocalMediaSoure Starting Playback with Content Selection by Voice Controlling Playback by Voice Reporting Playback State Example Sequence Diagrams Control external media apps with ExternalMediaAdapter Control volume with AlexaSpeaker Set a custom volume range Manage timers, alarms, and reminders with Alerts Render notification indicators with Notifications Block notifications with DoNotDisturb","title":"Alexa Module "},{"location":"modules/alexa/#alexa-module-overview","text":"The Alexa Auto SDK Alexa module provides interfaces for standard Alexa features. The Engine handles steps to send events and sequence directives so you can focus on using the provided AASB messages to interact with Alexa. Important! : If you are an Android developer, your application will use the Alexa Auto Client Service (AACS) as its foundation. AACS implements much of the core Auto SDK setup, abstracting it from your application and exposing only a necessary subset of the Auto SDK API in an Android-specific way. Some of the information presented in this documentation and documentation for other SDK modules might not pertain to your application exactly as written for cases in which AACS provides the implementation or further abstracts it, so keep this in mind while reading. Use the module documentation to understand the underlying layers of Auto SDK, if interested, and to reference the Engine configuration and AASB message definitions for the features you do need to build into your application yourself. Important!: Not every section of this documented is updated to reflect the Auto SDK 4.0 MessageBroker message API. Some sections still include text, code samples, or diagrams that show deprecated platform intefaces rather than their corresponding AASB message interface equivalents. Your application will use the the AASB message interfaces with MessageBroker. This document will be fully updated in the next Auto SDK version. For each interface you use, refer to its individual AASB message reference documentation.","title":"Alexa module overview"},{"location":"modules/alexa/#configure-the-alexa-module","text":"The Alexa module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programatically with the relevant configuration factory functions. Your application must provide the aace.alexa configuration in the same format as the example specified below. Alternatively, use the AlexaConfiguration factory functions to generate individual elements of this configuration. { \"aace.alexa\": { \"avsDeviceSDK\": { \"deviceInfo\": { \"clientId\": \"${CLIENT_ID}\", \"productId\": \"${PRODUCT_ID}\", \"deviceSerialNumber\": \"${DEVICE_SERIAL_NUMBER}\", \"manufacturerName\": \"${MANUFACTURER_NAME}\", \"description\": \"${DEVICE_DESCRIPTION}\" }, \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"${CERTS_PATH}\" }, \"miscDatabase\": { \"databaseFilePath\": \"${DATA_PATH}/miscDatabase.db\" }, \"certifiedSender\": { \"databaseFilePath\": \"${DATA_PATH}/certifiedSender.db\" }, \"alertsCapabilityAgent\": { \"databaseFilePath\": \"${DATA_PATH}/alertsCapabilityAgent.db\" }, \"notifications\": { \"databaseFilePath\": \"${DATA_PATH}/notifications.db\" }, \"capabilitiesDelegate\": { \"databaseFilePath\": \"${DATA_PATH}/capabilitiesDatabase.db\" }, \"deviceSettings\": { \"databaseFilePath\": \"${DATA_PATH}/deviceSettings.db\", \"defaultLocale\":\"en-US\", \"defaultTimezone\":\"America/Vancouver\" } }, \"requestMediaPlayback\": { \"mediaResumeThreshold\": 20000 } }, \"aasb.alexa\": { \"LocalMediaSource\": { \"types\": [\"FM_RADIO\", \"AM_RADIO\",\"BLUETOOTH\", \"USB\", \"SATELLITE_RADIO\", \"LINE_IN\", \"COMPACT_DISC\", \"DAB\", \"DEFAULT\"] } } } The deviceInfo field contains the details of the device. The fields libcurlUtils , miscDatabase , certifiedSender , alertsCapabilityAgent , notifications , and capabilitiesDelegate specify the respective database file paths. The deviceSettings field specifies the settings on the device. The following list describes the settings: databaseFilePath is the path to the SQLite database that stores persistent settings. The database will be created on initialization if it does not already exist. defaultLocale specifies the default locale setting, which is Alexa's locale setting until updated on the device. The default value of defaultLocale is \u201cen-US\u201d. locales specifies the list of locales supported by the device. The default value is [\"en-US\",\"en-GB\",\"de-DE\",\"en-IN\",\"en-CA\",\"ja-JP\",\"en-AU\",\"fr-FR\",\"it-IT\",\"es-ES\",\"es-MX\",\"fr-CA\",\"es-US\", \"hi-IN\", \"pt-BR\"] . localeCombinations specifies the list of locale pairs available on a device that supports multi-locale mode. Through the Dynamic Language Switching feature, Alexa can communicate with the user of such device in languages specified in the locale pairs. In each pair, the first value is the primary locale, which Alexa uses most often when interacting with the user. The second value is the secondary locale, which specifies an additional language that Alexa uses when responding to an utterance in the corresponding language. For example, if [\"en-US\", \"es-US\"] is declared in localeCombinations and the device specifies this pair as the current locale setting, Alexa primarily operates in English for the U.S. but can understand and respond to utterances in Spanish for the U.S., without requiring the device to update the locale setting. By default, localeCombinations is a list of the following combinations, which are also the supported combinations as of 2021-02-02. It is possible for the default value to be different from the list of supported combinations in the future. For updates to the supported combinations, see the Alexa Voice Service documentation . [\"en-US\", \"es-US\"] [\"es-US\", \"en-US\"] [\"en-IN\", \"hi-IN\"] [\"hi-IN\", \"en-IN\"] [\"en-CA\", \"fr-CA\"] [\"fr-CA\", \"en-CA\"] [\"en-US\", \"es-ES\"] [\"es-ES\", \"en-US\"] [\"en-US\", \"de-DE\"] [\"de-DE\", \"en-US\"] [\"en-US\", \"fr-FR\"] [\"fr-FR\", \"en-US\"] [\"en-US\", \"it-IT\"] [\"it-IT\", \"en-US\"] [\"en-US\", \"ja-JP\"] [\"ja-JP\", \"en-US\"] When a device operates in multi-locale mode, an application can select any locale pair in the list above as the locale setting if the following conditions are met: The device's primary locale setting is the first locale in the selected pair. The device also supports the secondary locale in the pair. The pair is specified in localeCombinations . Note: Dynamic Language Switching is only available in online mode.","title":"Configure the Alexa module"},{"location":"modules/alexa/#set-up-alexa-for-the-user","text":"","title":"Set up Alexa for the user"},{"location":"modules/alexa/#authorize-the-device-with-authorization","text":"In order to make requests to Alexa, your application requires a Login with Amazon (LWA) access token. The access token grants the device access to Alexa on behalf of the signed-in user. As part of the user sign-in experience for your application, obtain access tokens for Alexa and provide them to the Engine as outlined in the Alexa Auto SDK Authorization .","title":"Authorize the device with Authorization"},{"location":"modules/alexa/#start-the-out-of-box-experience-with-devicesetup","text":"Note: This feature requires Amazon to allowlist your device. For help, contact your Amazon Solutions Architect or partner manager . After the user signs in to your application during or after the out-of-box experience, the application starts the Engine and publishes the DeviceSetup.SetupCompleted message to notify Alexa that the setup is complete. The Engine publishes the DeviceSetup.SetupCompletedResponse to your application to indicate Alexa was notified successfully. In to the SetupCompleted event, Alexa starts an onboarding experience including a short first-time conversation with the user. Because SetupCompleted triggers an onboarding experience, do not publish the message if the signed-in user has already seen the experience. The onboarding experience is for first-time users only and might differ for returning users. Note: Do not publish the SetupCompleted message if user is in Connectivity Mode or Preview Mode or if the user has disabled handsfree listening. Publishing SetupCompleted in these conditions causes undesireable user experience.","title":"Start the out-of-box experience with DeviceSetup"},{"location":"modules/alexa/#update-device-settings-with-propertymanager","text":"After starting the Engine, use the PropertyManager to update any Alexa properties that you need to keep in sync at startup. See Alexa Auto SDK Property Manager for details.","title":"Update Device Settings with PropertyManager"},{"location":"modules/alexa/#provide-user-speech-input-to-alexa-with-speechrecognizer","text":"At startup time, the SpeechRecognizer component in the Engine opens an audio input channel of type VOICE for the application to provide the user speech to Alexa. The application subscribes to the AudioInput.StartAudioInput and AudioInput.StopAudioInput messages as outlined in Alexa Auto SDK Audio Channels . When the Engine expects to receive audio from the application, it prompts the application by publishing a StartAudioInput message with audioType VOICE . The application provides the voice audio input until the Engine publishes a StopAudioInput message. The user decides when to speak to Alexa by invoking her with a tap-to-talk GUI button press, a push-to-talk physical button press, or\u2014in vehicles supporting voice-initiated listening\u2014an \"Alexa\" utterance.","title":"Provide user speech input to Alexa with SpeechRecognizer "},{"location":"modules/alexa/#invoke-alexa-with-tap-and-release","text":"For button press-and-release Alexa invocation, the application publishes the SpeechRecognizer.StartCapture message with initiator TAP_TO_TALK to tell the Engine that the user pressed the Alexa invocation button and wants to speak to Alexa. When requested, the application provides audio to the Engine until Alexa detects the end of the user's speech. The Engine publishes the SpeechRecognizer.EndOfSpeechDetected message to the application and requests the application to stop providing audio if no other Engine components require it.","title":"Invoke Alexa with tap-and-release"},{"location":"modules/alexa/#invoke-alexa-with-press-and-hold","text":"For button press-and-hold Alexa invocation, the application publishes the SpeechRecognizer.StartCapture message with initiator HOLD_TO_TALK to tell the Engine that the user is holding down the Alexa invocation button and wants to speak to Alexa until releasing the button. When requested, the application provides audio to the Engine. When the user finishes speaking and releases the button, the application notifies the Engine by publishing the SpeechRecognizer.StopCapture message , and the Engine requests the application to stop providing audio if no other Engine components require it.","title":"Invoke Alexa with press-and-hold"},{"location":"modules/alexa/#invoke-alexa-with-voice-using-amazonlite-wake-word-engine","text":"Note: To use the Amazonlite wake word engine in your application, contact your Amazon Solutions Architect or partner manager . When the application uses the Amazonlite Auto SDK module for wake word detection, the application notifies the Engine when the user has handsfree listening enabled (i.e., privacy mode is off) by publishing the PropertyManager.SetProperty message with property set to aace.alexa.wakewordEnabled and value set to true . The Engine enables Amazonlite wake word detection and requests audio input from the application. The application provides audio to the Engine for continuous wake word detection until the application disables handsfree listening by setting the aace.alexa.wakewordEnabled property to false . After disabling Amazonlite wake word detection, the Engine requests the application to stop providing audio if there no other Engine components require it. When Amazonlite detects the \"Alexa\" wake word in the continuous audio stream provided by the application, the Engine publishes the SpeechRecognizer.WakewordDetected message and starts an interaction similar to one triggered by tap-to-talk invocation. When Alexa detects the end of the user's speech, the Engine publishes the SpeechRecognizer.EndOfSpeechDetected message but keeps the audio input stream open for further wake word detection.","title":"Invoke Alexa with voice using Amazonlite wake word engine"},{"location":"modules/alexa/#reduce-data-usage-with-audio-encoding","text":"To save bandwidth when the Engine sends user speech to Alexa in SpeechRecognizer.Recognize events, you can configure the Engine to encode the audio with the Opus audio encoding format by adding the following object to your Engine configuration: { \"aace.alexa\": { \"speechRecognizer\": { \"encoder\": { \"name\": \"opus\" } } } } When you set this configuration in your application, the Engine still expects the application to provide audio in the Linear PCM format specified in the Alexa Auto SDK Audio Channels ; the Engine internally changes the encoding to Opus prior to including the audio attachment in the Recognize event. Click to expand or collapse details\u2014 Generate the configuration programatically with the C++ factory function If your application generates Engine configuration programmatically instead of using a JSON file, you can use the aace::alexa::config::AlexaConfiguration::createSpeechRecognizerConfig factory function to create the EngineConfiguration object. #include <AACE/Alexa/AlexaConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto speechRecognizerConfig = aace :: alexa :: config :: AlexaConfiguration :: createSpeechRecognizerConfig ( \"opus\" ); configurations . push_back ( speechRecognizerConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Click to expand or collapse details\u2014 Generate the configuration programatically with the Java factory method AACS is the recommended way to integrate Auto SDK for Android, so your application should provide the aacs.alexa configuration in the AACS configuration file. However, if your application does not use AACS, and it generates Engine configuration programmatically instead of using a JSON file, you can use the com.amazon.aace.alexa.config.AlexaConfiguration.createSpeechRecognizerConfig factory method to create the EngineConfiguration object. import com.amazon.aace.alexa.config.AlexaConfiguration ; EngineConfifguration speechRecognizerConfig = AlexaConfiguration . createSpeechRecognizerConfig ( \"opus\" ); mEngine . configure ( new EngineConfiguration [] { // ...add other EngineConfiguration objects... speechRecognizerConfig });","title":"Reduce data usage with audio encoding"},{"location":"modules/alexa/#play-alexa-speech-to-the-user-with-speechsynthesizer","text":"At startup time, the SpeechSynthesizer component in the Engine opens an audio output channel of type TTS for the application to play Alexa speech responses to the user. SpeechSynthesizer has no messages of its own for the application to handle because it uses the standard audio output framework specified in the Core module. When Alexa responds to a user request with speech, the Engine publishes an AudioOutput.Prepare message with audioType TTS . The application uses the payload of the message to open the audio stream and buffer the audio data. The application plays the audio to the user when the Engine publishes an AudioOutput.Play message with matching token .","title":"Play Alexa speech to the user with SpeechSynthesizer"},{"location":"modules/alexa/#track-alexa-state-changes-with-alexaclient","text":"","title":"Track Alexa state changes with AlexaClient"},{"location":"modules/alexa/#render-alexas-attention-state","text":"Your application can subscribe to the AlexaClient.DialogStateChanged message to be notified what state Alexa dialog is in (e.g., Alexa started listening to the user's speech or started speaking her response). This message helps your application render Alexa's attention state UI such as Voice Chrome and audio cues without having to derive these states by tracking your application's microphone and media player. The following diagram shows how you might use the dialog state changes to provide Alexa attention feedback during an interaction. Click to expand or collapse sequence diagram: Alexa invocation","title":"Render Alexa's attention state"},{"location":"modules/alexa/#monitor-alexas-connection-status","text":"Your application can subscribe to the AlexaClient.ConnectionStatusChanged message to be notified when the status of the Engine's connection to Alexa has changed (e.g., the Engine lost connection to Alexa). You might use this information, for instance, to enable or disable certain functionality or display information to the user.","title":"Monitor Alexa's connection status"},{"location":"modules/alexa/#monitor-alexas-authorization-state","text":"Your application can subscribe to the AlexaClient.AuthStateChanged message to be notified what state the Engine is in with respect to the user sign in. For example, the state is REFRESHED when the Engine has an access token.","title":"Monitor Alexa's authorization state"},{"location":"modules/alexa/#display-cards-on-screen-with-templateruntime","text":"Alexa sends visual metadata (display card templates) for your device to display. When template information is received from Alexa, it is the responsibility of the platform implementation to handle the rendering of any UI with the information that is received from Alexa. There are two display card template types: The Template type provides visuals associated with a user request to accompany Alexa speech. The PlayerInfo type provides visuals associated with media playing through the AudioPlayer interface. This includes playback control buttons, which must be used with the PlaybackController interface. You can programmatically generate template runtime configuration using the aace::alexa::config::AlexaConfiguration::createTemplateRuntimeTimeoutConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"templateRuntimeCapabilityAgent\": { \"displayCardTTSFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackFinishedTimeout\": <TIMEOUT_IN_MS>, \"displayCardAudioPlaybackStoppedPausedTimeout\": <TIMEOUT_IN_MS> } } To implement a custom handler for GUI templates, extend the TemplateRuntime class: #include <AACE/Alexa/TemplateRuntime.h> class MyTemplateRuntime : public aace::alexa::TemplateRuntime { public: void renderTemplate( const std::string& payload, FocusState focusState ) override { // handle rendering the template data specified in payload } void renderPlayerInfo( const std::string& payload, PlayerActivity audioPlayerState, std::chrono::milliseconds offset, FocusState focusState ) override { // handle rendering the player info data specified in payload } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyTemplateRuntime>() ); Note: In the case of lists, it is the responsibility of the platform implementation to handle pagination. Alexa sends down the entire list as a JSON response and starts reading out the first five elements of the list. At the end of the first five elements, Alexa prompts the user whether or not to read the remaining elements from the list. If the user chooses to proceed with the remaining elements, Alexa sends down the entire list as a JSON response but starts reading from the sixth element onwards.","title":"Display cards on screen with TemplateRuntime"},{"location":"modules/alexa/#stream-alexa-media-content","text":"","title":"Stream Alexa media content"},{"location":"modules/alexa/#play-media-with-audioplayer","text":"When an audio media stream is received from Alexa, it is the responsibility of the platform implementation to play the stream in a platform-specific media player. The aace::alexa::AudioPlayer class informs the platform of the changes in player state being tracked by the Engine. This can be used to update the platform GUI, for example. To implement a custom handler for audio player output, extend the AudioPlayer class: #include <AACE/Alexa/AudioPlayer.h> class MyAudioPlayer : public aace::alexa::AudioPlayer { public: void playerActivityChanged( PlayerActivity state ) override { // on state change, update playback control UI } }; ... // Register the platform interface with the Engine auto myAudioPlayer = std::make_shared<MyAudioPlayer>(); engine->registerPlatformInterface( myAudioPlayer );","title":"Play media with AudioPlayer"},{"location":"modules/alexa/#view-media-metadata-on-screen-with-templateruntime","text":"Your application subscribes to the TemplateRuntime.RenderPlayerInfo AASB message to receive metadata about the active media playback for you to display. See the TemplateRuntime AVS documentation for details about the payload.","title":"View media metadata on screen with TemplateRuntime"},{"location":"modules/alexa/#press-media-playback-control-buttons-with-playbackcontroller","text":"The Engine provides a platform interface aace::alexa::PlaybackController for the platform implementation to report on-device transport control button presses for media playing through Alexa. For example, if the user presses the on-screen pause button while listening to Amazon Music through Alexa's AudioPlayer interface, the platform implementation calls a PlaybackController method to report the button press to the Engine. Note: PlaybackController method calls to manage AudioPlayer 's state or playback queue proactively report button presses or the equivalent so that Alexa can react; they do not report changes to the playback state that happen locally first. The Alexa cloud manages the playback queue for AudioPlayer content, so each PlaybackController method call is a request for Alexa to act on the user's local request. The result of the request will come as one or more method invocations on the AudioOutput associated with the channel used for AudioPlayer . Note: If your implementation needs to stop AudioPlayer media in response to system events, such as audio focus transitions to audio playing outside the scope of the Auto SDK, use PlaybackController to notify the Engine of such changes. However, keep in mind that the expected usage of the interface does not change when it is used in this use case. Note: PlaybackController only controls media coming from Alexa, i.e. the AudioPlayer . PlaybackController should not be used with the expectation of controlling playback for non-media Alexa audio sources like SpeechSynthesizer or Alexa-aware external media sources integrated with ExternalMediaAdapter or LocalMediaSource . Additionally, calling a PlaybackController method while audio is playing through another Alexa-aware external media source will produce unexpected results and is not recommended. Whenever Alexa plays media through AudioPlayer , the Engine calls the platform interface method aace::alexa::TemplateRuntime::renderPlayerInfo() to provide visual metadata associated with the media that your implementation should render for the end user. The payload of this method includes descriptions of GUI controls to be displayed and the state in which to display them. When the user interacts with these on-screen controls, your implementation must use the PlaybackController interface to report the button presses to the Engine. The table below maps the controls from the renderPlayerInfo() payload to the corresponding calls in PlaybackController . RenderPlayerInfo control name PlaybackController PlaybackButton \"PLAY_PAUSE\" PLAY \"PLAY_PAUSE\" PAUSE \"NEXT\" NEXT \"PREVIOUS\" PREVIOUS \"SKIP_FORWARD\" SKIP_FORWARD \"SKIP_BACKWARD\" SKIP_BACKWARD PlaybackToggle \"SHUFFLE\" SHUFFLE \"LOOP\" LOOP \"REPEAT\" REPEAT \"THUMBS_UP\" THUMBS_UP \"THUMBS_DOWN\" THUMBS_DOWN To implement a custom handler for the playback controller, extend the PlaybackController class: #include <AACE/Alexa/PlaybackController.h> class MyPlaybackController : public aace::alexa::PlaybackController { ... void platformPlayButtonPressed() { // called by some platform event buttonPressed(PlaybackButton::PLAY); } ... void platformScrubForwardGUIButtonPressed(){ //called by the platform on an available GUI button event buttonPressed(PlaybackButton::SKIP_FORWARD); } ... void platformShuffleGUIButtonPressed(){ //called by the platform on an available GUI toggle event togglePressed(PlaybackToggle::SHUFFLE, true); //the action should send the value opposing the last playerinfo state for that toggle control } ... }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MyPlaybackController>() );","title":"Press media playback control buttons with PlaybackController"},{"location":"modules/alexa/#adjust-equalizer-settings-with-equalizercontroller","text":"The Equalizer Controller enables Alexa voice control of the device's audio equalizer settings, which includes making gain level adjustments to any of the supported frequency bands (\"BASS\", \"MIDRANGE\", and/or \"TREBLE\") using the device's onboard audio processing. The platform implementation is responsible for the following: Determining how each supported band affects the audio Mapping Alexa's equalizer bands to the bands supported on the device, if they do not directly correspond Scaling Alexa's level values as necessary so that each step corresponds to one decibel of amplitude gain on the device Applying equalization to only selected portions of the audio output so that Alexa's speech, alarms, etc. will not be affected Persisting settings across power cycles You can programmatically generate Equalizer Controller configuration with details such as supported bands, default state, and decibel adjustment range using the aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\" { \"equalizer\": { \"bands\": { \"BASS\": true, \"MIDRANGE\": false, \"TREBLE\": true }, \"defaultState\": { \"bands\": { \"BASS\": 4, \"TREBLE\": -1 } }, \"minLevel\": -6, \"maxLevel\": 6 } } } // For example, 2 supported bands with amplitude gains ranging from -8dB to +8dB, each with a default of 0dB auto eqConfig = aace::alexa::config::AlexaConfiguration::createEqualizerControllerConfig( {EqualizerBand::BASS, EqualizerBand::TREBLE}, -8, 8, { {EqualizerBand::BASS, 0}, {EqualizerBand::TREBLE, 0} } ); engine->configure( { //other config objects..., eqConfig, ... } ); ... To implement a custom handler for Equalizer Controller, extend the EqualizerController class: #include <AACE/Alexa/EqualizerController.h> using EqualizerBand = aace::alexa::EqualizerController::EqualizerBand; using EqualizerBandLevel = aace::alexa::EqualizerController::EqualizerBandLevel; class MyEqualizerControllerHandler : public aace::alexa::EqualizerController { public: void setBandLevels( std::vector<EqualizerBandLevel> bandLevels ) override { // Handle performing audio equalization on the device // according to the provided band dB level settings // This invocation may come from \"Alexa, reset bass\", // \"Alexa, reset my equalizer\", \"Alexa, increase treble\", etc. } std::vector<EqualizerBandLevel> getBandLevels() override { // Return the current band level settings on the device return m_currentBandLevels; } }; ... // Register the platform interface with the Engine auto m_equalizerController = std::make_shared<MyEqualizerControllerHandler>(); engine->registerPlatformInterface( m_equalizerController ); ... // If levels are adjusted using local on-device controls, call inherited methods to notify the Engine: // To set a band to an absolute gain level in decibels std::vector<EqualizerBandLevel> settings{ {EqualizerBand::BASS, 4} }; // Sets bass amplitude to +4dB m_equalizerController->localSetBandLevels( settings ); // To make a relative adjustment to level settings std::vector<EqualizerBandLevel> adjustments{ {EqualizerBand::BASS, -2} }; // Decreases bass gain by 2dB m_equalizerController->localAdjustBandLevels( adjustments ); // To reset gain levels to the configured defaults (usually 0dB) std::vector<EqualizerBand> bands{EqualizerBand::BASS, EqualizerBand::TREBLE}; // Resets bass and treble bands m_equalizerController->localResetBands( bands );","title":"Adjust equalizer settings with EqualizerController"},{"location":"modules/alexa/#resume-media-playback-at-startup-with-mediaplaybackrequestor","text":"Alexa Media-Resume is a feature that helps Alexa play customers\u2019 favorite content when they start their Alexa-enabled vehicles. Media-resume simplifies the content selection and playing process for customers, removing the need for them to use dash touch buttons or to ask Alexa. To resume the media, Alexa auto SDK needs to send RequestMediaPlayback event with the Invocation reason AUTOMOTIVE_STARTUP . To implement a handler, extend the aace::alexa::MediaPlaybackRequestor class: #include <AACE/Alexa/MediaPlaybackRequestor.h> class MediaPlaybackRequestorHandler : public aace::alexa::MediaPlaybackRequestor { public: void mediaPlaybackResponse(MediaPlaybackRequestStatus mediaPlaybackRequestStatus) override { //Handle the status change } }; ... // Register the platform interface with the Engine engine->registerPlatformInterface( std::make_shared<MediaPlaybackRequestorHandler>()); requestMediaPlayback is the API to send the event to the cloud. This API needs InvocationReason and elapsedBootTime as input parameters. mediaPlaybackResponse callback receives the status of the requestMediaPlayback API call asynchronously. InvocationReason enum indicates the invocation reason for calling the event. AUTOMOTIVE_STARTUP represents a situation where platform automatically calls requestMediaPlayback API to automatically resume the media after infotainment system reboot. EXPLICIT_USER_ACTION represents resuming the media after explicit driver action by pressing the button or switch. Music resuming on EXPLICIT_USER_ACTION is not yet supported and this will be enabled in the future. Please check with your partner manager before using this action. MediaPlaybackRequestStatus enum indicate the status of the requestMediaPlayback API call. SUCCESS means RequestMediaPlayback event is successfully reported to the cloud. FAILED_CAN_RETRY means requestMediaPlayback API call can not be processed because Alexa Auto SDK is not in the connected state but platform implementation can retry after some time. FAILED_TIMEOUT means threshold time is crossed and media can not be resumed now. Driver can play media by making a voice request. ERROR means API could not be called successfully and media can not be resumed. This feature needs following configuration. Please contact to your partner manager for finalizing the threshold numbers. \"aace.alexa\": { \"requestMediaPlayback\": { \"mediaResumeThreshold\": 30000 } } mediaResumeThreshold is the maximum time in milliseconds to receive the requestMediaPlayback API call from the platform implementation. Platform implementation should consider their boot time, time to initialize alexa and get connected to send the RequestMediaPlayback event successfully. Platform team and partner manager should try to keep this time minimum for the better user experience. Delayed media resume can surprise driver and result in driver distraction. Note: This feature assumes that client platform maintains the media sessions and request individual media applications to resume playback if that media application was active and playing before the device shuts down. Note: requestMediaPlayback API call expects a elapsed boot time i.e. number of milliseconds elapsed from the device boot up. This feature assumes that client platform provides the correct value using their proprietary methods. The mediaResumeThreshold value and elapsedBootTime value are compared together for the guardrail condition.","title":"Resume media playback at startup with MediaPlaybackRequestor"},{"location":"modules/alexa/#enable-audio-ducking-for-alexa-media-content","text":"Your application can configure the Engine to enable audio ducking for media that plays through AudioPlayer . See Alexa Auto SDK Audio Channels for details.","title":"Enable audio ducking for Alexa media content"},{"location":"modules/alexa/#control-local-media-with-localmediasoure","text":"The LocalMediaSource interface allows the platform to register a local media source by type ( BLUETOOTH , USB , AM_RADIO , FM_RADIO , SATELLITE_RADIO , LINE_IN , COMPACT_DISC , SIRIUS_XM , DAB , and DEFAULT ). Registering a local media source allows playback control of that source via Alexa (e.g. \"Alexa, play the CD player\"). It also enables playback initiation via Alexa by frequency, channel, or preset for relevant source types (e.g. \"Alexa, play 98.7 FM\"). DEFAULT media source is a generic media source that can be used for controlling any local media source on the OEM infotainment system. It is recommended to use DEFAULT media source for all local media except Alexa music, MACC-supported deep linked media players, and other registered Local Media Sources. DEFAULT media player can not be launched by name like \"Alexa, Play CD player\" but it can be used to control playback actions reported in the supportedOperations . For example, \"Alexa, play\" resumes the default player playback as long a the DEFAULT source is in focus . The following is an example of registering a CD player local media source using type Source.COMPACT_DISC : auto m_CDLocalMediaSource = std::make_shared<MyCDLocalMediaSource>( Source.COMPACT_DISC ); engine->registerPlatformInterface( m_CDLocalMediaSource ); To implement a custom handler for a CD player local media source extend the LocalMediaSource class: #include <AACE/Alexa/LocalMediaSource.h> class MyCDLocalMediaSource : public aace::alexa::LocalMediaSource { public: MyCDLocalMediaSource( LocalMediaSource::Source source ) { m_source = source; ... } ... }; ...","title":"Control local media with LocalMediaSoure"},{"location":"modules/alexa/#starting-playback-with-content-selection-by-voice","text":"The play() method is called when Alexa invokes play by ContentSelector type ( FREQUENCY , CHANNEL , PRESET ) for a radio local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM , DAB ). The payload is a string that depends on the ContentSelector type and local media Source type (e.g., \"1\", \"98.7 FM HD 1\"). bool play( ContentSelector type, std::string payload, const std::string& sessionId ) override { // play initiation for frequency, channel, or presets ... } The table below provides details about the supported ContentSelector types based on Source type: Source type Supported content selector(s) FM FREQUENCY, PRESET AM FREQUENCY, PRESET SXM CHANNEL, PRESET DAB CHANNEL DEFAULT PRESET The supported ranges and increments for valid frequency, preset, and channel may vary depending on the region you are in. Contact your partner manager for more detailed information. Note: The DAB channel payload is the radio station name string. If supported, then the name string must be handled by the client's DAB implementation. The play() method will not be invoked if a source cannot handle the specified ContentSelector type. The DEFAULT Local Media Source handles \"Alexa, play preset \\ \\\" utterances without requiring that users explicitly say which local media source ( AM_RADIO , FM_RADIO , SIRIUS_XM ) actually corresponds to the preset. The meaning of the preset in the payload parameter of play(ContentSelector contentSelectorType, const std::string& payload, const std::string& sessionId) is determined by the DEFAULT platform implementation and should suit the needs of the vehicle's infotainment system, i.e. when the play() method is called, your implementation should map the preset to a preset that makes sense for the current context. Note: The GlobalPreset platform interface is deprecated. Use DEFAULT LocalMediaSource instead.","title":"Starting Playback with Content Selection by Voice"},{"location":"modules/alexa/#controlling-playback-by-voice","text":"The playControl() method is called with a PlayControlType ( RESUME , PAUSE , STOP , NEXT , PREVIOUS , START_OVER , FAST_FORWARD , REWIND , ENABLE_REPEAT_ONE , ENABLE_REPEAT , DISABLE_REPEAT , ENABLE_SHUFFLE , DISABLE_SHUFFLE , FAVORITE , UNFAVORITE ) when Alexa invokes a playback control on the local media source. bool playControl( PlayControlType controlType ) override { // handle the control type appropriately for CD player return true; } Note: The play() method is used to initiate playback with specified content selection, whereas playControl(RESUME) is used to play or resume the source when content is not specified or not supported. E.g. FM receives play() when the user requests FM with a specific frequency (\"Alexa, play 98.7 FM radio\"), and USB receives playControl(RESUME) when the user requests playback with just the source name (\"Alexa, play USB\"). The seek() and adjustSeek() methods are invoked to seek the currently focused LocalMediaSource . These methods are only used by sources that are capable of seeking. seek() is for specifying an absolute offset, whereas adjustSeek() is for specifying a relative offset. bool seek( long offset ) override { // handle seeking CD player } ... bool adjustSeek( long offset ) override { // handle adjusting seek for CD player } The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently focused local media player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . @Override public boolean volumeChanged( float volume ) { // handle volume change } ... @Override public boolean mutedStateChanged( MutedState state ) { // handle setting mute state } ...","title":"Controlling Playback by Voice"},{"location":"modules/alexa/#reporting-playback-events","text":"The LocalMediaSource interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your local source. Even though your local source manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your local source's playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your local source's state. Particular event names indicate if the source is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. playerEvent() event name Description \"PlaybackSessionStarted\" The local media source is switched from the inactive to active media state or a new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackSessionEnded\" The local media source is switched from the active to inactive media state or an active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. \"PlaybackStarted\" During an active session, the local source has started to play or resumed from a paused state. \"PlaybackStopped\" During an active session, the player stopped, either as a result of a GUI interaction or a user voice request to Alexa. playerError() event name Description \"INTERNAL_ERROR\" During an active session, an internal error caused playback to stop. Both playerEvent() and playerError() are expected to provide the appropriate sessionId. Call playerEvent(\"PlaybackSessionStarted\", sessionId) to tell the Engine that the user brought the LocalMediaSource to the foreground with a GUI interaction. The Engine considers the source to have an active playback session, although it may or may not be playing yet. If no other Alexa media source is playing, utterances such as \u201cAlexa, play\u201d target this source. You must also call playerEvent(\"PlaybackSessionStarted\", sessionId) when the source is brought into the foreground by a call to play() or playControl() as a result of a user voice request. Once the source starts playing, call playerEvent(\"PlaybackStarted\", sessionId) . Call playerEvent(\"PlaybackSessionEnded\", sessionId) to tell the Engine that the LocalMediaSource is no longer in the foreground, typically as a result of a GUI interaction from the user after the player is stopped. The Engine considers the source inactive or not in focus, and starting a new playback session for the source requires a further GUI interaction or user voice request to Alexa that targets the source by name. class MyFMRadioLocalMediaSource : public aace::alexa::LocalMediaSource { ... // public method in source handler void setAlexaFocusForFMRadio( bool isFocused ) { ... if (isFocused) { ... // FM Radio begins playback independently of Alexa playerEvent(\"PlaybackSessionStarted\", m_sessionId); } else { ... // Notify Alexa that FM Radio is no longer the active media source on the device as a result of platform driven change playerEvent(\"PlaybackSessionEnded\", m_sessionId); } ... } ... Note: Only one LocalMediaSource type can have Alexa focus at a time. Note: setFocus() and setFocus(bool) methods are deprecated for the LocalMediaSource platform interface. playerEvent() with \"PlaybackSessionStarted\" or \"PlaybackSessionEnded\" should be used instead of setFocus(true) and setFocus(false) . Please abide by following rules related to sessionId in your LocalMediaSource integration: sessionId is a universally unique identifier (UUID) generated according to the RFC 4122 specification. If a media source starts because of a call to play(contentSelector, payload, sessionId) from the Engine, note the sessionId parameter and use it in any playerEvent() calls until the session is inactive. If a media source starts for any other reason (e.g. a call to playControl(RESUME) from the Engine, or user GUI interaction on the head unit), create a new sessionId and use it in any playerEvent() calls until the session is inactive. A sessionId is always associated with one media source playback session, so USB 's sessionId should be different than COMPACT_DISC 's sessionId . An individual LocalMediaSource should maintain the sessionId for the whole cycle from playback session start to playback session end. For any \"opening\" playerEvent() call for a particular sessionId (e.g. \"PlaybackSessionStarted\" , \"PlaybackStarted\" ), you must report a corresponding closing call (e.g. \"PlaybackStopped\" , \"PlaybackSessionEnded\" ) at the appropriate time (i.e., when the source is stopped, switched, etc.)","title":"Reporting Playback Events"},{"location":"modules/alexa/#reporting-playback-state","text":"The getState() method is called to synchronize the local player's state with the cloud. This method is used to maintain correct state during startup and with every Alexa request. All relevant information should be added to the LocalMediaSourceState and returned. Many fields of the LocalMediaSourceState are not required for local media source players. You should omit these as noted below. LocalMediaSourceState getState() override { LocalMediaSourceState stateToReturn = std::make_shared<LocalMediaSourceState>(); stateToReturn.playbackState.albumName = \"mock albumName\"; // fill in all required state information (see below) return stateToReturn; } The following table describes the fields comprising a LocalMediaSourceState , which includes two sub-components: PlaybackState and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedPlaybackOperation trackOffset long No optional shuffleEnabled boolean No optional repeatEnabled boolean No optional favorites Favorites No see Favorites type String Yes must be set to \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No optional trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType No see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean No empty accessToken String No empty tokenRefreshInterval long No empty supportedContentSelectors ContentSelector[] No see ContentSelector spiVersion String Yes must be \"1.0\" supportedOperations should list the operations that the local media source supports. Below is a list of all SupportedPlaybackOperation : LocalMediaSource::SupportedPlaybackOperation::PLAY, LocalMediaSource::SupportedPlaybackOperation::PAUSE, LocalMediaSource::SupportedPlaybackOperation::STOP, LocalMediaSource::SupportedPlaybackOperation::PREVIOUS, LocalMediaSource::SupportedPlaybackOperation::NEXT, LocalMediaSource::SupportedPlaybackOperation::ENABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::DISABLE_SHUFFLE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT_ONE, LocalMediaSource::SupportedPlaybackOperation::ENABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::DISABLE_REPEAT, LocalMediaSource::SupportedPlaybackOperation::SEEK, LocalMediaSource::SupportedPlaybackOperation::ADJUST_SEEK, LocalMediaSource::SupportedPlaybackOperation::FAVORITE, LocalMediaSource::SupportedPlaybackOperation::UNFAVORITE, LocalMediaSource::SupportedPlaybackOperation::FAST_FORWARD, LocalMediaSource::SupportedPlaybackOperation::REWIND, LocalMediaSource::SupportedPlaybackOperation::START_OVER Note: Currently PLAY/PAUSE/STOP are always supported for a source. Passing null allows ALL supported operations for the source. supportedContentSelectors should list the content selection types the local source can support. Below is a table of valid pairs. Source Supportable ContentSelector Values AM_RADIO PRESET , FREQUENCY FM_RADIO PRESET , FREQUENCY SIRIUS_XM PRESET , CHANNEL DEFAULT PRESET launched specifies whether the source is enabled. The player is disabled for use with Alexa when this value is false, such as when a removable source like USB is disconnected.","title":"Reporting Playback State"},{"location":"modules/alexa/#example-sequence-diagrams","text":"The following diagrams show examples of Local Media Source usage: 1. Starting FM by voice 2. Switching from FM to DEFAULT media source with GUI 3. Switching between different DEFAULT sources","title":"Example Sequence Diagrams"},{"location":"modules/alexa/#control-external-media-apps-with-externalmediaadapter","text":"The External Media Player (EMP) Adapter allows you to declare and use external media application sources in your application. In order to interface with the EMP Adapter, you must use one of the following: A media connection client to interface the EMP Adapter to the external app. AACS provides an app component called the Media App Command and Control (MACC) client that provides most of the deep-linking integration specified below. The AACS Sample App supports an example using the Media App Command and Control (MACC) client to play the Android Spotify app. An embedded media app. For information about external embedded media app solutions, contact your SA or Partner Manager. Note: If the media app service requires additional customer experience details, incorporate the requirement in your implementation. For example, if the provider requires your application to show the provider's logo in a particular way, modify the implementation to meet the requirement. When advised by your SA or Partner Manager, configure the External Media Player Adapter to the device's capabilities. See aace::alexa::config::AlexaConfiguration::createExternalMediaPlayerConfig for details on configuring the supported agent, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"externalMediaPlayer\": { \"agent\": \"<agent>\" } } You must register and implement each ExternalMediaAdapter (along with its associated external client or library). After the engine establishes a connection to the Alexa service, you can run discovery to validate each external media application. You can report discovered external media players by calling reportDiscoveredPlayers() at any point during runtime. When the Alexa service recognizes the player, you will get a call to the authorize() method including the player's authorization status. Both the reportDiscoveredPlayers() method and the authorize() method can contain one or more players in their JSON payloads. Validating the application enables Alexa to exercise playback control over the registered source type. The login() and logout() methods inform AVS of login state changes, if applicable. If your application has the ability to handle cloud-based login and logout, you should also call the loginComplete() and logoutComplete() methods where appropriate. When the user makes an Alexa voice request (for example, \"Play Spotify\"), the play() method is invoked. This method contains various parameters, including the player id of the player to which the playback information should be routed. Whether through voice or GUI event, the playControl() method is called with the relevant PlayControlType . Similar to play() the control should be routed to the appropriate player. The PlayControlType is determined by player's supportedOperations , which are specified by your implementation in the return value of getState() . The ExternalMediaAdapter interface provides methods playerEvent() and playerError() for your implementation to report events regarding the state of the playback session managed by your external player. Even though your player manages its own playback, including reacting to on-device transport control button presses from the user and reacting appropriately to other non-Alexa audio events on the system, the playerEvent() and playerError() calls provide important information to the Engine: The Engine may use calls to these methods to synchronize the state of your player\u2019s playback session with Alexa. The Engine may react to these calls according to the event name specified to update its internal view of your player\u2019s state. Particular event names indicate if the player is focused on the system (meaning it has an active playback session) or if it is un-focused (meaning it is not in use and is brought into use only by further on-device interaction by the user or a user voice request to Alexa). The Engine uses this information to sync its internal focus management. The tables below describe each supported event name and what it means to the Engine. Usage of these events depends on the particular type of player controlled by the ExternalMediaAdapter instance, so contact your Solutions Architect (SA) or Partner Manager for guidance regarding supported embedded and external app solutions. playerEvent() event name Description \"PlaybackSessionStarted\" A new playback session has started, either from a GUI interaction or as a result of a user voice request to Alexa. The Engine considers the player active and in focus (although it may or may not yet be playing). \"PlaybackStarted\" During an active session, the player has started to play or resumed from a paused state. The Engine considers the player active and in focus. \"TrackChanged\" During an active session, one track has ended and another has started. The Engine uses this primarily for state reporting. \"PlaybackNext\" During an active session, the player skipped from one track to the next track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlaybackPrevious\" During an active session, the player skipped from one track to the previous track, either as a result of a GUI interaction or a user voice request to Alexa. The Engine uses this primarily for state reporting. \"PlayModeChanged\" During an active session, some user setting for the track or playback session changed, such as the favorite setting or the shuffle mode. The Engine uses this primarily for state reporting. \"PlaybackStopped\" During an active session, the player has paused or stopped, either as a result of a GUI interaction or a user voice request to Alexa. The Engine considers the player active and in focus, just not currently playing. User voice requests to resume still control the player. \"PlaybackSessionEnded\" An active playback session has ended. The player should no longer be playing or playable until a new session is started by GUI interaction or user voice request to Alexa. The Engine considers the player inactive and no longer in focus. playerError() event name Description \"INTERNAL_ERROR\" Any fatal player error has occurred \"UNKNOWN_ERROR\" An unknown error occurred \"UNPLAYABLE_BY_AUTHORIZATION\" The media couldn't be played due to an unauthorized account \"UNPLAYABLE_BY_STREAM_CONCURRENCY\" The media couldn't be played due to the number of accounts currently streaming \"UNPLAYABLE_BY_ACCOUNT\" The media couldn't be played due to the account type \"UNPLAYABLE_BY_REGION\" The media couldn't be played due to the current region \"UNPLAYABLE_BY_PARENTAL_CONTROL\" The media couldn't be played due to parental settings \"UNPLAYABLE_BY_SUBSCRIPTION\" The media couldn't be played due to the subscription type \"OPERATION_REJECTED_UNINTERRUPTIBLE\" The operation could not be performed due to non interruptible media \"OPERATION_REJECTED_END_OF_QUEUE\" The operation could not be performed due to the end of media being reached \"OPERATION_UNSUPPORTED\" The operation was not supported \"OPERATION_REJECTED_SKIP_LIMIT\" The operation failed because a skip limit was reached \"PLAYER_UNKNOWN\" An unknown player was detected \"PLAYER_NOT_FOUND\" The player was not discovered \"PLAYER_CONNECTION_REJECTED\" The connection to the player failed \"PLAYER_CONNECTION_TIMEOUT\" The connection to the player timed out The seek() and adjustSeek() methods are invokable via Alexa if the currently in-focus external player supports them. seek() specifies an absolute offset, whereas adjustSeek() specifies a relative offset. The volumeChanged() and mutedStateChanged() methods are invoked to change the volume and mute state of the currently-focused external player. volumeChanged() specifies the new volume. mutedStateChanged() specifies the new MutedState . The getState() method is called to synchronize the external player's state with the cloud. This method is used to maintain correct state during startup, and after every Alexa request. You construct the ExternalMediaAdapterState object using the data taken from the media app connection client or embedded player app (associated via localPlayerId ) and return the state information. The following table describes the fields comprising a ExternalMediaAdapterState , which includes two sub-components: PlaybackState , and SessionState . State Type Required Notes PlaybackState state String Yes \"IDLE\"/\"STOPPED\"/\"PLAYING\" supportedOperations SupportedPlaybackOperation[] Yes see SupportedOperation trackOffset long No optional shuffleEnabled boolean Yes report shuffle status repeatEnabled boolean Yes report repeat status favorites Favorites No see Favorites type String Yes must be set as \"ExternalMediaPlayerMusicItem\" playbackSource String No If available else use local player name playbackSourceId String No empty trackName String No If available else use local player name trackId String No empty trackNumber String No optional artistName String No optional artistId String No empty albumName String No optional albumId String No empty tinyURL String No optional smallURL String No optional mediumURL String No optional largeURL String No optional coverId String No empty mediaProvider String No optional mediaType MediaType Yes see MediaType duration long No optional SessionsState endpointId String No empty loggedIn boolean No empty userName String No empty isGuest boolean No empty launched boolean Yes true if the source is enabled, false otherwise active boolean Yes true if the application is in an active state accessToken String No empty tokenRefreshInterval long No empty playerCookie String No A player may declare arbitrary information for itself spiVersion String Yes must be set as \"1.0\" supportedOperations should be a list of the operations that the external media adapter supports. Below is a list of all possible supportedOperations . SupportedPlaybackOperation.PLAY, SupportedPlaybackOperation.PAUSE, SupportedPlaybackOperation.STOP, SupportedPlaybackOperation.PREVIOUS, SupportedPlaybackOperation.NEXT, SupportedPlaybackOperation.ENABLE_SHUFFLE, SupportedPlaybackOperation.DISABLE_SHUFFLE, SupportedPlaybackOperation.ENABLE_REPEAT_ONE, SupportedPlaybackOperation.ENABLE_REPEAT, SupportedPlaybackOperation.DISABLE_REPEAT, SupportedPlaybackOperation.SEEK, SupportedPlaybackOperation.ADJUST_SEEK, SupportedPlaybackOperation.FAVORITE, SupportedPlaybackOperation.UNFAVORITE, SupportedPlaybackOperation.FAST_FORWARD, SupportedPlaybackOperation.REWIND, SupportedPlaybackOperation.START_OVER Note: Currently PLAY/PAUSE/STOP will always be supported for a source. Passing null will allow ALL supported operations for the source.","title":"Control external media apps with ExternalMediaAdapter "},{"location":"modules/alexa/#control-volume-with-alexaspeaker","text":"The Alexa service keeps track of two device volume types: ALEXA_VOLUME and ALERTS_VOLUME . The aace::alexa::AlexaSpeaker class should be implemented by the platform to both set the volume and mute state of these two speaker types and allow the user to set the volume and mute state of these two speaker types locally via GUI if applicable. SpeakerManager is a configurable option, enabled by default. When not enabled, user requests to change the volume or mute now have an appropriate Alexa response, e.g. \"Sorry, I can't control the volume on your device\". You can programmatically generate speaker manager configuration using the aace::alexa::config::AlexaConfiguration::createSpeakerManagerConfig() factory method, or provide the equivalent JSON values in a configuration file. { \"aace.alexa\": { \"speakerManager\": { \"enabled\": false } } }","title":"Control volume with AlexaSpeaker"},{"location":"modules/alexa/#set-a-custom-volume-range","text":"You can use a custom volume control to support an Alexa device's native input volume range. By default, Alexa supports voice utterances that specify volume values between 0 and 10, but some devices may support a different range (i.e. 0 to 100). By placing on Amazon's allow list your Alexa device's volume range for your target platform, you can specify input volume levels per your device's range. Your device's input volume range is then mapped appropriately to the Alexa volume range. Contact your Alexa Auto Solution Architect (SA) for help with allow lists. Placing a device on the allow list requires the following parameters: DeviceTypeID: Min: Max: This does not impact the range used in the directives to the device. You must continue to use the SDK 0-100 volume range used by AudioOutput and AlexaSpeaker and map these values to the correct range in your implementation.","title":"Set a custom volume range"},{"location":"modules/alexa/#manage-timers-alarms-and-reminders-with-alerts","text":"When an alert is received from Alexa, it is the responsibility of the platform implementation to play the alert sounds in a platform-specific media player. See the AVS Alerts interface documentation for more information about alerts. The state of the alert is also made available for the platform to react to. The playback is handled by whichever audio channel is assigned to the ALERT type. To implement a custom handler for alerts, extend the Alerts class: #include <AACE/Alexa/Alerts.h> class MyAlerts : public aace::alexa::Alerts { public: void MyAlerts::alertStateChanged( const std::string& alertToken, AlertState state, const std::string& reason ) override { //handle the alert state change } void MyAlerts::alertCreated( const std::string& alertToken, const std::string& detailedInfo ) override { //handle the alert detailed info when alert is created (optional) /* * JSON string detailedInfo : * { * \"time\" : <String> * \"type\" : <String> * \"label\" : <String> * } */ } void MyAlerts::alertDeleted( const std::string& alertToken ) override { //handle the alert when alert is deleted (optional) } }; ... // Register the platform interface with the Engine auto myAlertsMediaPlayer = std::make_shared<MyMediaPlayer>(...); auto myAlertsSpeaker = std::make_shared<MySpeaker>(...); auto myAlerts = std::make_shared<MyAlerts>(myAudioPlayerMediaPlayer, myAudioPlayerSpeaker); engine->registerPlatformInterface( myAlerts );","title":"Manage timers, alarms, and reminders with Alerts"},{"location":"modules/alexa/#render-notification-indicators-with-notifications","text":"It is the responsibility of the platform implementation to provide a visual indication to the user when notifications (for example, package shipment notifications, notifications from skills, etc.) are available from Alexa. See the AVS Notifications interface documentation for more information about notifications. The Engine uses the registered Notifications implementation to notify you when a notification indicator should be displayed or removed. It does not give any information about the notifications. Audio playback for the notification is handled by whichever audio channel is assigned to the NOTIFICATION type. To implement a custom handler for Notifications extend the Notifications class: #include <AACE/Alexa/Notifications.h> using IndicatorState = aace::alexa::Notifications::IndicatorState; class MyNotificationsHandler : public aace::alexa::Notifications { public: void setIndicator( IndicatorState state ) override { // set your notifications indicator! } }; ... // Register the platform interface with the Engine auto m_notificationsHandler = std::make_shared<MyNotificationsHandler>(); engine->registerPlatformInterface(m_notificationsHandler);","title":"Render notification indicators with Notifications"},{"location":"modules/alexa/#block-notifications-with-donotdisturb","text":"The DoNotDisturb (DND) interface allows users to block all incoming notifications, announcements, and calls to their devices, and to set daily recurring schedules that turn DND off and on. For details, see the DND Interface documentation . The Engine uses the registered DND implementation to notify the client when DND has been set or unset. A user's voice request to change the DND state triggers audio playback, but no audio playback occurs when a user sets the DND state using the touch screen. To implement a custom handler for DND extend the DoNotDisturb class: #include <AACE/Alexa/DoNotDisturb> class MyDoNotDisturbHandler : public aace::alexa::DoNotDisturb { public: void setDoNotDisturb( bool doNotDisturb ) override { // set your DoNotDisturb indicator } // on user GUI setting change ... bool doNotDisturb = userSetState; doNotDisturbChanged(doNotDisturb); ... }; ... // Register the platform interface with the Engine auto m_doNotDisturbHandler = std::make_shared<MyDoNotDisturbHandler>(); engine->registerPlatformInterface(m_doNotDisturbHandler);","title":"Block notifications with DoNotDisturb"},{"location":"modules/alexa/aasb-docs/Alerts/","text":"Alerts Outgoing Messages AlertCreated Notifies the platform implementation of an alert created, with detailed alert info. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertCreated\" } }, \"payload\": { \"alertToken\": {{String}}, \"detailedInfo\": {{String}} } } Payload Property Type Required Description Example alertToken String Yes The AVS token of the alert. detailedInfo String Yes The alert info payload. AlertDeleted Notifies the platform implementation of an alert deleted, with the alertToken. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertDeleted\" } }, \"payload\": { \"alertToken\": {{String}} } } Payload Property Type Required Description Example alertToken String Yes The AVS token of the alert. AlertStateChanged Notifies the platform implementation of an alert state change. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertStateChanged\" } }, \"payload\": { \"alertToken\": {{String}}, \"state\": {{AlertState}}, \"reason\": {{String}} } } Payload Property Type Required Description Example alertToken String Yes The opaque token that uniquely identifies the alert. state AlertState Yes The new alert state. reason String Yes The reason for the state change. Incoming Messages RemoveAllAlerts Notifies the Engine of a platform request to clear the user's pending alerts from storage. This may be useful for a scenario in which a user's pending alerts should not go off after he logs out of the application. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"RemoveAllAlerts\" } } } LocalStop Notifies the Engine of a platform request to stop any active alert, such as when a user presses a physical 'stop' button. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"LocalStop\" } } } Enums AlertState Values Value Description \"READY\" The alert is ready to activate and is waiting for channel focus. \"STARTED\" The alert is activated, and rendering is perceivable by the user. \"STOPPED\" The alert has stopped due to user or system intervention. \"SNOOZED\" The alert is active but has been snoozed. \"COMPLETED\" The alert has completed on its own, without user interaction. \"PAST_DUE\" The alert has expired and will not be rendered. \"FOCUS_ENTERED_FOREGROUND\" The alert has entered the foreground. \"FOCUS_ENTERED_BACKGROUND\" The alert has entered the background. \"ERROR\" The alert has encountered an error. \"DELETED\" The alert has been deleted. \"SCHEDULED_FOR_LATER\" The alert has been scheduled to trigger at a future time.","title":"Alerts"},{"location":"modules/alexa/aasb-docs/Alerts/#alerts","text":"","title":"Alerts"},{"location":"modules/alexa/aasb-docs/Alerts/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/Alerts/#alertcreated","text":"Notifies the platform implementation of an alert created, with detailed alert info.","title":"AlertCreated"},{"location":"modules/alexa/aasb-docs/Alerts/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertCreated\" } }, \"payload\": { \"alertToken\": {{String}}, \"detailedInfo\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Alerts/#payload","text":"Property Type Required Description Example alertToken String Yes The AVS token of the alert. detailedInfo String Yes The alert info payload.","title":"Payload"},{"location":"modules/alexa/aasb-docs/Alerts/#alertdeleted","text":"Notifies the platform implementation of an alert deleted, with the alertToken.","title":"AlertDeleted"},{"location":"modules/alexa/aasb-docs/Alerts/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertDeleted\" } }, \"payload\": { \"alertToken\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Alerts/#payload_1","text":"Property Type Required Description Example alertToken String Yes The AVS token of the alert.","title":"Payload"},{"location":"modules/alexa/aasb-docs/Alerts/#alertstatechanged","text":"Notifies the platform implementation of an alert state change.","title":"AlertStateChanged"},{"location":"modules/alexa/aasb-docs/Alerts/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"AlertStateChanged\" } }, \"payload\": { \"alertToken\": {{String}}, \"state\": {{AlertState}}, \"reason\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Alerts/#payload_2","text":"Property Type Required Description Example alertToken String Yes The opaque token that uniquely identifies the alert. state AlertState Yes The new alert state. reason String Yes The reason for the state change.","title":"Payload"},{"location":"modules/alexa/aasb-docs/Alerts/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/Alerts/#removeallalerts","text":"Notifies the Engine of a platform request to clear the user's pending alerts from storage. This may be useful for a scenario in which a user's pending alerts should not go off after he logs out of the application.","title":"RemoveAllAlerts"},{"location":"modules/alexa/aasb-docs/Alerts/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"RemoveAllAlerts\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Alerts/#localstop","text":"Notifies the Engine of a platform request to stop any active alert, such as when a user presses a physical 'stop' button.","title":"LocalStop"},{"location":"modules/alexa/aasb-docs/Alerts/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Alerts\", \"action\": \"LocalStop\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Alerts/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/Alerts/#alertstate","text":"","title":"AlertState"},{"location":"modules/alexa/aasb-docs/Alerts/#values","text":"Value Description \"READY\" The alert is ready to activate and is waiting for channel focus. \"STARTED\" The alert is activated, and rendering is perceivable by the user. \"STOPPED\" The alert has stopped due to user or system intervention. \"SNOOZED\" The alert is active but has been snoozed. \"COMPLETED\" The alert has completed on its own, without user interaction. \"PAST_DUE\" The alert has expired and will not be rendered. \"FOCUS_ENTERED_FOREGROUND\" The alert has entered the foreground. \"FOCUS_ENTERED_BACKGROUND\" The alert has entered the background. \"ERROR\" The alert has encountered an error. \"DELETED\" The alert has been deleted. \"SCHEDULED_FOR_LATER\" The alert has been scheduled to trigger at a future time.","title":"Values"},{"location":"modules/alexa/aasb-docs/AlexaClient/","text":"AlexaClient Outgoing Messages ConnectionStatusChanged Notifies the platform implementation of an AVS connection status change. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"ConnectionStatusChanged\" } }, \"payload\": { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}} } } Payload Property Type Required Description Example status ConnectionStatus Yes The new AVS connection status. reason ConnectionChangedReason Yes The reason for the status change. DialogStateChanged Notifies the platform implementation of an Alexa dialog state change. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"DialogStateChanged\" } }, \"payload\": { \"state\": {{DialogState}} } } Payload Property Type Required Description Example state DialogState Yes The new Alexa dialog state. AuthStateChanged Notifies the platform implementation of an AVS authorization state change. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"state\": {{AuthState}}, \"error\": {{AuthError}} } } Payload Property Type Required Description Example state AuthState Yes The new authorization state. error AuthError Yes The error state of the authorization attempt. Incoming Messages StopForegroundActivity Notifies the Engine to stop foreground activity. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"StopForegroundActivity\" } } } Enums DialogState Values Value Description \"IDLE\" Alexa is idle and ready for an interaction. \"LISTENING\" Alexa is currently listening. \"EXPECTING\" Alexa is currently expecting a response from the user. \"THINKING\" A user request has completed, and no more user input is being accepted. Alexa is waiting for a response from AVS. \"SPEAKING\" Alexa is responding to a request with speech. ConnectionStatus Values Value Description \"DISCONNECTED\" Not connected to AVS. \"PENDING\" Attempting to establish a connection to AVS. \"CONNECTED\" Connected to AVS. ConnectionChangedReason Values Value Description \"NONE\" No reason specified. \"SUCCESS\" The connection status changed due to a successful operation. \"UNRECOVERABLE_ERROR\" The connection status changed due to an error from which there is no recovery. \"ACL_CLIENT_REQUEST\" The connection status changed due to a client request. \"ACL_DISABLED\" The connection attempt failed because connection was disabled. \"DNS_TIMEDOUT\" The connection attempt failed due to a DNS resolution timeout. \"CONNECTION_TIMEDOUT\" The connection attempt failed due to a connection timeout. \"CONNECTION_THROTTLED\" The connection attempt failed due to excessive load on the server. \"INVALID_AUTH\" The provided access credentials were invalid. \"PING_TIMEDOUT\" There was a timeout sending a ping request. \"WRITE_TIMEDOUT\" There was a timeout writing to AVS. \"READ_TIMEDOUT\" There was a timeout reading from AVS. \"FAILURE_PROTOCOL_ERROR\" There was an underlying protocol error. \"INTERNAL_ERROR\" There was an internal error. \"SERVER_INTERNAL_ERROR\" There was an internal error on the server. \"SERVER_SIDE_DISCONNECT\" The server asked the client to reconnect. \"SERVER_ENDPOINT_CHANGED\" The server endpoint has changed.","title":"AlexaClient"},{"location":"modules/alexa/aasb-docs/AlexaClient/#alexaclient","text":"","title":"AlexaClient"},{"location":"modules/alexa/aasb-docs/AlexaClient/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/AlexaClient/#connectionstatuschanged","text":"Notifies the platform implementation of an AVS connection status change.","title":"ConnectionStatusChanged"},{"location":"modules/alexa/aasb-docs/AlexaClient/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"ConnectionStatusChanged\" } }, \"payload\": { \"status\": {{ConnectionStatus}}, \"reason\": {{ConnectionChangedReason}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaClient/#payload","text":"Property Type Required Description Example status ConnectionStatus Yes The new AVS connection status. reason ConnectionChangedReason Yes The reason for the status change.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaClient/#dialogstatechanged","text":"Notifies the platform implementation of an Alexa dialog state change.","title":"DialogStateChanged"},{"location":"modules/alexa/aasb-docs/AlexaClient/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"DialogStateChanged\" } }, \"payload\": { \"state\": {{DialogState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaClient/#payload_1","text":"Property Type Required Description Example state DialogState Yes The new Alexa dialog state.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaClient/#authstatechanged","text":"Notifies the platform implementation of an AVS authorization state change.","title":"AuthStateChanged"},{"location":"modules/alexa/aasb-docs/AlexaClient/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"state\": {{AuthState}}, \"error\": {{AuthError}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaClient/#payload_2","text":"Property Type Required Description Example state AuthState Yes The new authorization state. error AuthError Yes The error state of the authorization attempt.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaClient/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/AlexaClient/#stopforegroundactivity","text":"Notifies the Engine to stop foreground activity.","title":"StopForegroundActivity"},{"location":"modules/alexa/aasb-docs/AlexaClient/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaClient\", \"action\": \"StopForegroundActivity\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaClient/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/AlexaClient/#dialogstate","text":"","title":"DialogState"},{"location":"modules/alexa/aasb-docs/AlexaClient/#values","text":"Value Description \"IDLE\" Alexa is idle and ready for an interaction. \"LISTENING\" Alexa is currently listening. \"EXPECTING\" Alexa is currently expecting a response from the user. \"THINKING\" A user request has completed, and no more user input is being accepted. Alexa is waiting for a response from AVS. \"SPEAKING\" Alexa is responding to a request with speech.","title":"Values"},{"location":"modules/alexa/aasb-docs/AlexaClient/#connectionstatus","text":"","title":"ConnectionStatus"},{"location":"modules/alexa/aasb-docs/AlexaClient/#values_1","text":"Value Description \"DISCONNECTED\" Not connected to AVS. \"PENDING\" Attempting to establish a connection to AVS. \"CONNECTED\" Connected to AVS.","title":"Values"},{"location":"modules/alexa/aasb-docs/AlexaClient/#connectionchangedreason","text":"","title":"ConnectionChangedReason"},{"location":"modules/alexa/aasb-docs/AlexaClient/#values_2","text":"Value Description \"NONE\" No reason specified. \"SUCCESS\" The connection status changed due to a successful operation. \"UNRECOVERABLE_ERROR\" The connection status changed due to an error from which there is no recovery. \"ACL_CLIENT_REQUEST\" The connection status changed due to a client request. \"ACL_DISABLED\" The connection attempt failed because connection was disabled. \"DNS_TIMEDOUT\" The connection attempt failed due to a DNS resolution timeout. \"CONNECTION_TIMEDOUT\" The connection attempt failed due to a connection timeout. \"CONNECTION_THROTTLED\" The connection attempt failed due to excessive load on the server. \"INVALID_AUTH\" The provided access credentials were invalid. \"PING_TIMEDOUT\" There was a timeout sending a ping request. \"WRITE_TIMEDOUT\" There was a timeout writing to AVS. \"READ_TIMEDOUT\" There was a timeout reading from AVS. \"FAILURE_PROTOCOL_ERROR\" There was an underlying protocol error. \"INTERNAL_ERROR\" There was an internal error. \"SERVER_INTERNAL_ERROR\" There was an internal error on the server. \"SERVER_SIDE_DISCONNECT\" The server asked the client to reconnect. \"SERVER_ENDPOINT_CHANGED\" The server endpoint has changed.","title":"Values"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/","text":"AlexaSpeaker Outgoing Messages SpeakerSettingsChanged Notifies the platform implementation that the speaker settings have changed for a specific speaker type. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"SpeakerSettingsChanged\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"local\": {{Bool}}, \"volume\": {{Int}}, \"mute\": {{Bool}} } } Payload Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. local Bool Yes True if the change originated from calling localSetVolume(). volume Int Yes he new volume setting of the Speaker. mute Bool Yes The mute setting of the Speaker. Incoming Messages LocalAdjustVolume Notifies the Engine of a relative adjustment to the volume setting of the Speaker, originating on the platform. The delta value is relative to the current volume setting and is positive to increase volume or negative to reduce volume. The volume delta value should be scaled to fit the needs of the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalAdjustVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"delta\": {{Int}} } } Payload Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. delta Int Yes The volume adjustment to apply to the Speaker. LocalSetVolume Notifies the Engine of a volume change event originating on the platform, such as a user pressing a \"volume up\" or \"volume down\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setVolume() on each AVS-synced Speaker. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"volume\": {{Int}} } } Payload Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. volume Int Yes The new volume setting of the Speaker. LocalSetMute Notifies the Engine of a mute setting change event originating on the platform, such as a user pressing a \"mute\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setMute() on each AVS-synced Speaker. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetMute\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"mute\": {{Bool}} } } Payload Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. mute Bool Yes The new mute setting of the Speaker. Enums SpeakerType Values Value Description \"ALEXA_VOLUME\" The Speaker type that is controlled by AVS. \"ALERTS_VOLUME\" The Speaker type that is controlled locally by the platform.","title":"AlexaSpeaker"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#alexaspeaker","text":"","title":"AlexaSpeaker"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#speakersettingschanged","text":"Notifies the platform implementation that the speaker settings have changed for a specific speaker type.","title":"SpeakerSettingsChanged"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"SpeakerSettingsChanged\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"local\": {{Bool}}, \"volume\": {{Int}}, \"mute\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#payload","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. local Bool Yes True if the change originated from calling localSetVolume(). volume Int Yes he new volume setting of the Speaker. mute Bool Yes The mute setting of the Speaker.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#localadjustvolume","text":"Notifies the Engine of a relative adjustment to the volume setting of the Speaker, originating on the platform. The delta value is relative to the current volume setting and is positive to increase volume or negative to reduce volume. The volume delta value should be scaled to fit the needs of the platform.","title":"LocalAdjustVolume"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalAdjustVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"delta\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#payload_1","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. delta Int Yes The volume adjustment to apply to the Speaker.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#localsetvolume","text":"Notifies the Engine of a volume change event originating on the platform, such as a user pressing a \"volume up\" or \"volume down\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setVolume() on each AVS-synced Speaker.","title":"LocalSetVolume"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetVolume\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"volume\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#payload_2","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. volume Int Yes The new volume setting of the Speaker.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#localsetmute","text":"Notifies the Engine of a mute setting change event originating on the platform, such as a user pressing a \"mute\" button. If the Speaker is AVS_SPEAKER_VOLUME, the Engine will respond with a call to setMute() on each AVS-synced Speaker.","title":"LocalSetMute"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaSpeaker\", \"action\": \"LocalSetMute\" } }, \"payload\": { \"type\": {{SpeakerType}}, \"mute\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#payload_3","text":"Property Type Required Description Example type SpeakerType Yes The type of Alexa speaker being set. mute Bool Yes The new mute setting of the Speaker.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#speakertype","text":"","title":"SpeakerType"},{"location":"modules/alexa/aasb-docs/AlexaSpeaker/#values","text":"Value Description \"ALEXA_VOLUME\" The Speaker type that is controlled by AVS. \"ALERTS_VOLUME\" The Speaker type that is controlled locally by the platform.","title":"Values"},{"location":"modules/alexa/aasb-docs/AudioPlayer/","text":"AudioPlayer Outgoing Messages PlayerActivityChanged Notifies the platform implementation of a change in audio playback state. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"PlayerActivityChanged\" } }, \"payload\": { \"state\": {{PlayerActivity}} } } Payload Property Type Required Description Example state PlayerActivity Yes The new playback state. Incoming Messages GetPlayerPosition Returns the current playback position of the audio player. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\" } } } GetPlayerPositionReply Reply for GetPlayerPosition message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackPosition\": {{Int}} } } Payload Property Type Required Description Example playbackPosition Int Yes The audio player's playback position in milliseconds. GetPlayerDuration Returns the playback duration of the audio player. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\" } } } GetPlayerDurationReply Reply for GetPlayerDuration message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackDuration\": {{Int}} } } Payload Property Type Required Description Example playbackDuration Int Yes The audio player's playback duration in milliseconds. Enums PlayerActivity Values Value Description \"IDLE\" Audio playback has not yet begun. \"PLAYING\" Audio is currently playing. \"STOPPED\" Audio playback is stopped, either from a stop directive or playback error. \"PAUSED\" Audio playback is paused. \"BUFFER_UNDERRUN\" Audio playback is stalled because a buffer underrun has occurred. \"FINISHED\" Audio playback is finished.","title":"AudioPlayer"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#audioplayer","text":"","title":"AudioPlayer"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#playeractivitychanged","text":"Notifies the platform implementation of a change in audio playback state.","title":"PlayerActivityChanged"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"PlayerActivityChanged\" } }, \"payload\": { \"state\": {{PlayerActivity}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#payload","text":"Property Type Required Description Example state PlayerActivity Yes The new playback state.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#getplayerposition","text":"Returns the current playback position of the audio player.","title":"GetPlayerPosition"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#getplayerpositionreply","text":"Reply for GetPlayerPosition message.","title":"GetPlayerPositionReply"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackPosition\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#payload_1","text":"Property Type Required Description Example playbackPosition Int Yes The audio player's playback position in milliseconds.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#getplayerduration","text":"Returns the playback duration of the audio player.","title":"GetPlayerDuration"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#getplayerdurationreply","text":"Reply for GetPlayerDuration message.","title":"GetPlayerDurationReply"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioPlayer\", \"action\": \"GetPlayerDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"playbackDuration\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#payload_2","text":"Property Type Required Description Example playbackDuration Int Yes The audio player's playback duration in milliseconds.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#playeractivity","text":"","title":"PlayerActivity"},{"location":"modules/alexa/aasb-docs/AudioPlayer/#values","text":"Value Description \"IDLE\" Audio playback has not yet begun. \"PLAYING\" Audio is currently playing. \"STOPPED\" Audio playback is stopped, either from a stop directive or playback error. \"PAUSED\" Audio playback is paused. \"BUFFER_UNDERRUN\" Audio playback is stalled because a buffer underrun has occurred. \"FINISHED\" Audio playback is finished.","title":"Values"},{"location":"modules/alexa/aasb-docs/AuthProvider/","text":"AuthProvider Outgoing Messages GetAuthToken Returns the token used by the platform implementation for authorization with AVS. The platform implementation should retrieve an auth token if it does not have one. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\" } } } GetAuthTokenReply Reply for GetAuthToken message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\", \"replyToId\": {{String}} } }, \"payload\": { \"authToken\": {{String}} } } Payload Property Type Required Description Example authToken String Yes The token used to authorize with AVS. GetAuthState Returns the AVS authorization state of the platform implementation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\" } } } GetAuthStateReply Reply for GetAuthState message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{AuthState}} } } Payload Property Type Required Description Example state AuthState Yes The AVS authorization state. Incoming Messages AuthStateChanged Notifies the Engine of a change in AVS authorization state in the platform implementation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"authState\": {{AuthState}}, \"authError\": {{AuthError}} } } Payload Property Type Required Description Example authState AuthState Yes The new authorization state. authError AuthError Yes The error state of the authorization attempt. Enums AuthError Values Value Description \"NO_ERROR\" No error encountered. \"UNKNOWN_ERROR\" An error was encountered, but no error description can be determined. \"AUTHORIZATION_FAILED\" The client authorization failed. \"UNAUTHORIZED_CLIENT\" The client is not authorized to use authorization codes. \"SERVER_ERROR\" The server encountered a runtime error. \"INVALID_REQUEST\" The request is missing a required parameter, has an invalid value, or is otherwise malformed. \"INVALID_VALUE\" One of the values in the request was invalid. \"AUTHORIZATION_EXPIRED\" The authorization code is invalid, expired, revoked, or was issued to a different client. \"UNSUPPORTED_GRANT_TYPE\" The client specified the wrong token type. \"INVALID_CODE_PAIR\" Invalid code pair provided in Code-based linking token request. \"AUTHORIZATION_PENDING\" Waiting for user to authorize the specified code pair. \"SLOW_DOWN\" Client should slow down in the rate of requests polling for an access token. \"INTERNAL_ERROR\" Internal error in client code. \"INVALID_CBL_CLIENT_ID\" Client ID not valid for use with code based linking. AuthState Values Value Description \"UNINITIALIZED\" Authorization has not yet been acquired. \"REFRESHED\" Authorization has been refreshed. \"EXPIRED\" Authorization has expired. \"UNRECOVERABLE_ERROR\" Authorization has failed in a manner that cannot be corrected by retrying.","title":"AuthProvider"},{"location":"modules/alexa/aasb-docs/AuthProvider/#authprovider","text":"","title":"AuthProvider"},{"location":"modules/alexa/aasb-docs/AuthProvider/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/AuthProvider/#getauthtoken","text":"Returns the token used by the platform implementation for authorization with AVS. The platform implementation should retrieve an auth token if it does not have one.","title":"GetAuthToken"},{"location":"modules/alexa/aasb-docs/AuthProvider/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AuthProvider/#getauthtokenreply","text":"Reply for GetAuthToken message.","title":"GetAuthTokenReply"},{"location":"modules/alexa/aasb-docs/AuthProvider/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthToken\", \"replyToId\": {{String}} } }, \"payload\": { \"authToken\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AuthProvider/#payload","text":"Property Type Required Description Example authToken String Yes The token used to authorize with AVS.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AuthProvider/#getauthstate","text":"Returns the AVS authorization state of the platform implementation.","title":"GetAuthState"},{"location":"modules/alexa/aasb-docs/AuthProvider/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AuthProvider/#getauthstatereply","text":"Reply for GetAuthState message.","title":"GetAuthStateReply"},{"location":"modules/alexa/aasb-docs/AuthProvider/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"GetAuthState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{AuthState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AuthProvider/#payload_1","text":"Property Type Required Description Example state AuthState Yes The AVS authorization state.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AuthProvider/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/AuthProvider/#authstatechanged","text":"Notifies the Engine of a change in AVS authorization state in the platform implementation.","title":"AuthStateChanged"},{"location":"modules/alexa/aasb-docs/AuthProvider/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AuthProvider\", \"action\": \"AuthStateChanged\" } }, \"payload\": { \"authState\": {{AuthState}}, \"authError\": {{AuthError}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/AuthProvider/#payload_2","text":"Property Type Required Description Example authState AuthState Yes The new authorization state. authError AuthError Yes The error state of the authorization attempt.","title":"Payload"},{"location":"modules/alexa/aasb-docs/AuthProvider/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/AuthProvider/#autherror","text":"","title":"AuthError"},{"location":"modules/alexa/aasb-docs/AuthProvider/#values","text":"Value Description \"NO_ERROR\" No error encountered. \"UNKNOWN_ERROR\" An error was encountered, but no error description can be determined. \"AUTHORIZATION_FAILED\" The client authorization failed. \"UNAUTHORIZED_CLIENT\" The client is not authorized to use authorization codes. \"SERVER_ERROR\" The server encountered a runtime error. \"INVALID_REQUEST\" The request is missing a required parameter, has an invalid value, or is otherwise malformed. \"INVALID_VALUE\" One of the values in the request was invalid. \"AUTHORIZATION_EXPIRED\" The authorization code is invalid, expired, revoked, or was issued to a different client. \"UNSUPPORTED_GRANT_TYPE\" The client specified the wrong token type. \"INVALID_CODE_PAIR\" Invalid code pair provided in Code-based linking token request. \"AUTHORIZATION_PENDING\" Waiting for user to authorize the specified code pair. \"SLOW_DOWN\" Client should slow down in the rate of requests polling for an access token. \"INTERNAL_ERROR\" Internal error in client code. \"INVALID_CBL_CLIENT_ID\" Client ID not valid for use with code based linking.","title":"Values"},{"location":"modules/alexa/aasb-docs/AuthProvider/#authstate","text":"","title":"AuthState"},{"location":"modules/alexa/aasb-docs/AuthProvider/#values_1","text":"Value Description \"UNINITIALIZED\" Authorization has not yet been acquired. \"REFRESHED\" Authorization has been refreshed. \"EXPIRED\" Authorization has expired. \"UNRECOVERABLE_ERROR\" Authorization has failed in a manner that cannot be corrected by retrying.","title":"Values"},{"location":"modules/alexa/aasb-docs/DeviceSetup/","text":"DeviceSetup Outgoing Messages SetupCompletedResponse SetupCompletedResponse description JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompletedResponse\" } }, \"payload\": { \"statusCode\": {{StatusCode}} } } Payload Property Type Required Description Example statusCode StatusCode Yes Status description. Incoming Messages SetupCompleted SetupCompleted description. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompleted\" } } } Enums StatusCode Values Value Description \"SUCCESS\" Successful description. \"FAIL\" Failure description.","title":"DeviceSetup"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#devicesetup","text":"","title":"DeviceSetup"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#setupcompletedresponse","text":"SetupCompletedResponse description","title":"SetupCompletedResponse"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompletedResponse\" } }, \"payload\": { \"statusCode\": {{StatusCode}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#payload","text":"Property Type Required Description Example statusCode StatusCode Yes Status description.","title":"Payload"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#setupcompleted","text":"SetupCompleted description.","title":"SetupCompleted"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceSetup\", \"action\": \"SetupCompleted\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#statuscode","text":"","title":"StatusCode"},{"location":"modules/alexa/aasb-docs/DeviceSetup/#values","text":"Value Description \"SUCCESS\" Successful description. \"FAIL\" Failure description.","title":"Values"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/","text":"DoNotDisturb Outgoing Messages SetDoNotDisturb Handle setting of DND directive. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"SetDoNotDisturb\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } } Payload Property Type Required Description Example doNotDisturb Bool Yes setting state. Incoming Messages DoNotDisturbChanged Notifies the Engine of a platform request to set the DND State. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"DoNotDisturbChanged\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } } Payload Property Type Required Description Example doNotDisturb Bool Yes setting state.","title":"DoNotDisturb"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#donotdisturb","text":"","title":"DoNotDisturb"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#setdonotdisturb","text":"Handle setting of DND directive.","title":"SetDoNotDisturb"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"SetDoNotDisturb\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#payload","text":"Property Type Required Description Example doNotDisturb Bool Yes setting state.","title":"Payload"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#donotdisturbchanged","text":"Notifies the Engine of a platform request to set the DND State.","title":"DoNotDisturbChanged"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DoNotDisturb\", \"action\": \"DoNotDisturbChanged\" } }, \"payload\": { \"doNotDisturb\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/DoNotDisturb/#payload_1","text":"Property Type Required Description Example doNotDisturb Bool Yes setting state.","title":"Payload"},{"location":"modules/alexa/aasb-docs/EqualizerController/","text":"EqualizerController Outgoing Messages GetBandLevels Retrieves the current equalizer gain settings on the device for each supported band. If unsupported band levels are provided, the Engine will truncate levels to the configured range. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\" } } } GetBandLevelsReply Reply for GetBandLevels message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\", \"replyToId\": {{String}} } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } } Payload Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The supported equalizer bands and their current gain settings as integer dB values. SetBandLevels Notifies the platform implementation to apply the provided gain settings to the corresponding equalizer bands. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"SetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } } Payload Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands and their gain settings to apply as integer dB values. Incoming Messages LocalResetBands Notifies the Engine that the gain levels for the equalizer bands are being reset to their defaults. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalResetBands\" } }, \"payload\": { \"bands\": [{{EqualizerBand}}] } } Payload Property Type Required Description Example bands EqualizerBand [] No The equalizer bands to reset. Empty @a bands resets all supported equalizer bands. LocalSetBandLevels Notifies the Engine that gain levels for one or more equalizer bands are being set directly on the device. If unsupported levels are provided, the Engine will truncate the settings to the configured range. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalSetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } } Payload Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands to change and their gain settings as integer dB values. LocalAdjustBandLevels Notifies the Engine that relative adjustments to equalizer band gain levels are being made directly on the device. If adjustments put the band level settings beyond the configured dB range, the Engine will truncate the settings to the configured range. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalAdjustBandLevels\" } }, \"payload\": { \"bandAdjustments\": [{{EqualizerBandLevel}}] } } Payload Property Type Required Description Example bandAdjustments EqualizerBandLevel [] Yes he equalizer bands to adjust and their relative gain adjustments as integer dB values. Type Definitions EqualizerBandLevel JSON Structure { \"band\": {{EqualizerBand}}, \"level\": {{Int}} } Properties Property Type Required Description Example band EqualizerBand Yes Describes the equalizer bands supported by Alexa. The platform implementation may support a subset of these. level Int Yes Describes the level of gain of a particular equalizer band as an integer dB value. Enums EqualizerBand Values Value Description \"BASS\" Bass equalizer band. \"MIDRANGE\" Mid-range equalizer band. \"TREBLE\" Treble equalizer band.","title":"EqualizerController"},{"location":"modules/alexa/aasb-docs/EqualizerController/#equalizercontroller","text":"","title":"EqualizerController"},{"location":"modules/alexa/aasb-docs/EqualizerController/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/EqualizerController/#getbandlevels","text":"Retrieves the current equalizer gain settings on the device for each supported band. If unsupported band levels are provided, the Engine will truncate levels to the configured range.","title":"GetBandLevels"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#getbandlevelsreply","text":"Reply for GetBandLevels message.","title":"GetBandLevelsReply"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"GetBandLevels\", \"replyToId\": {{String}} } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#payload","text":"Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The supported equalizer bands and their current gain settings as integer dB values.","title":"Payload"},{"location":"modules/alexa/aasb-docs/EqualizerController/#setbandlevels","text":"Notifies the platform implementation to apply the provided gain settings to the corresponding equalizer bands.","title":"SetBandLevels"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"SetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#payload_1","text":"Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands and their gain settings to apply as integer dB values.","title":"Payload"},{"location":"modules/alexa/aasb-docs/EqualizerController/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/EqualizerController/#localresetbands","text":"Notifies the Engine that the gain levels for the equalizer bands are being reset to their defaults.","title":"LocalResetBands"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalResetBands\" } }, \"payload\": { \"bands\": [{{EqualizerBand}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#payload_2","text":"Property Type Required Description Example bands EqualizerBand [] No The equalizer bands to reset. Empty @a bands resets all supported equalizer bands.","title":"Payload"},{"location":"modules/alexa/aasb-docs/EqualizerController/#localsetbandlevels","text":"Notifies the Engine that gain levels for one or more equalizer bands are being set directly on the device. If unsupported levels are provided, the Engine will truncate the settings to the configured range.","title":"LocalSetBandLevels"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalSetBandLevels\" } }, \"payload\": { \"bandLevels\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#payload_3","text":"Property Type Required Description Example bandLevels EqualizerBandLevel [] Yes The equalizer bands to change and their gain settings as integer dB values.","title":"Payload"},{"location":"modules/alexa/aasb-docs/EqualizerController/#localadjustbandlevels","text":"Notifies the Engine that relative adjustments to equalizer band gain levels are being made directly on the device. If adjustments put the band level settings beyond the configured dB range, the Engine will truncate the settings to the configured range.","title":"LocalAdjustBandLevels"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"EqualizerController\", \"action\": \"LocalAdjustBandLevels\" } }, \"payload\": { \"bandAdjustments\": [{{EqualizerBandLevel}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#payload_4","text":"Property Type Required Description Example bandAdjustments EqualizerBandLevel [] Yes he equalizer bands to adjust and their relative gain adjustments as integer dB values.","title":"Payload"},{"location":"modules/alexa/aasb-docs/EqualizerController/#type-definitions","text":"","title":"Type Definitions"},{"location":"modules/alexa/aasb-docs/EqualizerController/#equalizerbandlevel","text":"","title":"EqualizerBandLevel"},{"location":"modules/alexa/aasb-docs/EqualizerController/#json-structure_6","text":"{ \"band\": {{EqualizerBand}}, \"level\": {{Int}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/EqualizerController/#properties","text":"Property Type Required Description Example band EqualizerBand Yes Describes the equalizer bands supported by Alexa. The platform implementation may support a subset of these. level Int Yes Describes the level of gain of a particular equalizer band as an integer dB value.","title":"Properties"},{"location":"modules/alexa/aasb-docs/EqualizerController/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/EqualizerController/#equalizerband","text":"","title":"EqualizerBand"},{"location":"modules/alexa/aasb-docs/EqualizerController/#values","text":"Value Description \"BASS\" Bass equalizer band. \"MIDRANGE\" Mid-range equalizer band. \"TREBLE\" Treble equalizer band.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/","text":"ExternalMediaAdapter Outgoing Messages PlayControl Occurs during playback control via voice interaction or PlaybackController interface. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayControl\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"controlType\": {{PlayControlType}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. controlType PlayControlType Yes Playback control type being invoked. Seek Called when the user invokes media seek via speech. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Seek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"offset\": {{Int}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. offset Int Yes Offset position within media item, in milliseconds. Logout Directive called after a discovered player initiates the logoutComplete event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Logout\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. Play Called when the user first calls play for the external media via voice control. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Play\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"playContextToken\": {{String}}, \"index\": {{Int}}, \"offset\": {{Int}}, \"preload\": {{Bool}}, \"navigation\": {{Navigation}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. playContextToken String Yes Track/playlist/album/artist/station/podcast context identifier. index Int Yes If the playback context is an indexable container like a playlist, the index of the media item in the container. offset Int Yes Offset position within media item, in milliseconds. preload Bool Yes Whether the media item should preload or not. navigation Navigation Yes The app transition behavior. GetState Must provide the local external media player apps @PlaybackStateExternal, and @SessionStateExternal information to maintain cloud sync. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"GetState\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"state\": {{ExternalMediaAdapterState}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. state ExternalMediaAdapterState Yes The ExternalMediaAdapterState to be initialized by the platform. Login Directive called after a discovered player initiates the loginComplete event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Login\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"accessToken\": {{String}}, \"userName\": {{String}}, \"forceLogin\": {{Bool}}, \"tokenRefreshInterval\": {{Int}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. accessToken String Yes The handshake token between AVS, and the external media player app session. userName String Yes The username provided by the external media player app, if available. forceLogin Bool Yes True if no handshake is needed, and login is simply assumed. tokenRefreshInterval Int Yes refresh interval of the accessToken, if available. AdjustSeek Called when the user invokes media seek adjustment via speech. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"deltaOffset\": {{Int}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. deltaOffset Int Yes Change in offset position within media item, in milliseconds. MutedStateChanged Notifies the platform implementation to apply a mute state change to the output channel. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"state\": {{MutedState}} } } Payload Property Type Required Description Example state MutedState Yes The muted state to apply to the output channel. MUTED when the output channel be muted, UNMUTED when unmuted. VolumeChanged Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"volume\": {{Float}} } } Payload Property Type Required Description Example volume Float Yes The volume to set on the output channel. volume is in the range [0,1]. Authorize Called after discovered media players have been reported. Returns a list of reported players and whether they have been authorized for use with Alexa. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Authorize\" } }, \"payload\": { \"authorizedPlayers\": [{{AuthorizedPlayerInfo}}] } } Payload Property Type Required Description Example authorizedPlayers AuthorizedPlayerInfo [] Yes A list of discovered players with their status of authorization for use with Alexa. Incoming Messages PlayerEvent Should be called on a local external media player event. This will sync the context with AVS. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"eventName\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. eventName String Yes Canonical event name. LogoutComplete Should be called on a local external media player logout. This will unset authorization of the app with AVS. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LogoutComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. LoginComplete Should be called on a local external media player login. This will set authorization of the app with AVS. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LoginComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes Should be called on a local external media player login. This will set authorization of the app with AVS. SetFocus Should be called on local external media player events. This will switch the media focus to that context. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"SetFocus\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. ReportDiscoveredPlayers Should be called on startup in order to notify AVS of the local external media players. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"ReportDiscoveredPlayers\" } }, \"payload\": { \"discoveredPlayers\": [{{DiscoveredPlayerInfo}}] } } Payload Property Type Required Description Example discoveredPlayers DiscoveredPlayerInfo [] Yes The List of discovered players. RemoveDiscoveredPlayer RemoveDiscoveredPlayer description. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RemoveDiscoveredPlayer\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes localPlayerId description. RequestToken The device is responsible for requesting an access token when needed. This is typically done immediately upon connection to AVS. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RequestToken\" } }, \"payload\": { \"localPlayerId\": {{String}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. PlayerError Should be called on a player error. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerError\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}} } } Payload Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. Type Definitions ExternalMediaAdapterState JSON Structure { \"sessionState\": {{SessionStateExternal}}, \"playbackState\": {{PlaybackStateExternal}} } Properties Property Type Required Description Example sessionState SessionStateExternal Yes Variable to hold the session state. playbackState PlaybackStateExternal Yes Variable to hold the playback state. SessionStateExternal JSON Structure { \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"playerCookie\": {{String}}, \"spiVersion\": {{String}} } Properties Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. playerCookie String Yes A player may declare arbitrary information for itself. spiVersion String Yes The only spiVersion that currently exists is \"1.0\". PlaybackStateExternal JSON Structure { \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} } Properties Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PLAYING. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled or not. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled or not. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource. smallURL String Yes The URL for small cover art image resource. mediumURL String Yes The URL for medium cover art image resource. largeURL String Yes The URL for large cover art image resource. coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds. AuthorizedPlayerInfo JSON Structure { \"localPlayerId\": {{String}}, \"authorized\": {{Bool}} } Properties Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. authorized Bool Yes Authorization status. ValidationData JSON Structure { \"certificate\": {{String}} } Properties Property Type Required Description Example certificate String Yes Validation data. DiscoveredPlayerInfo JSON Structure { \"localPlayerId\": {{String}}, \"spiVersion\": {{String}}, \"validationMethod\": {{ValidationMethod}}, \"validationData\": [{{ValidationData}}] } Properties Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. spiVersion String Yes The only spiVersion that currently exists is '1.0'. validationMethod ValidationMethod Yes Validation methods. validationData ValidationData [] Yes Validation data: 1. Device platform issued app signing certificate. A List of certificates may be attached. 2. In some cases validation is performed locally. The certificate is trasmitted as validationData during discovery to announce the activated app's identity in order to allow app activation to be revoked. 3. empty. Enums SupportedPlaybackOperation Values Value Description \"PLAY\" Play is supported (voice only). \"PAUSE\" Pause is supported. \"STOP\" Stop is supported. \"NEXT\" Next is supported. \"PREVIOUS\" Previous is supported. \"START_OVER\" Start Over is supported. \"FAST_FORWARD\" Fast Forward is supported. \"REWIND\" Rewind is supported. \"ENABLE_REPEAT\" Enable Repeat is supported. \"ENABLE_REPEAT_ONE\" Enable Repeat One is supported. \"DISABLE_REPEAT\" Disbale Repeat is supported. \"ENABLE_SHUFFLE\" Enable Shuffle is supported. \"DISABLE_SHUFFLE\" Disable Shuffle is supported. \"FAVORITE\" Favorite is supported. \"UNFAVORITE\" Unfavorite is supported. \"SEEK\" Seek is supported. \"ADJUST_SEEK\" Adjust Seek is supported. PlayControlType Values Value Description \"PAUSE\" pause playback. \"RESUME\" resume playback. \"STOP\" stop playback. \"NEXT\" next song. \"PREVIOUS\" previous playback. \"START_OVER\" start playback over. \"FAST_FORWARD\" fast forward external media described time. \"REWIND\" rewind external media described time. \"ENABLE_REPEAT_ONE\" enable repeat current song. \"ENABLE_REPEAT\" enable playlist looping. \"DISABLE_REPEAT\" disable playlist looping. \"ENABLE_SHUFFLE\" enable playlist shuffling. \"DISABLE_SHUFFLE\" disable playlist shuffling. \"FAVORITE\" favorite song. \"UNFAVORITE\" unfavorite song. ValidationMethod Values Value Description \"SIGNING_CERTIFICATE\" description for SIGNING_CERTIFICATE. \"GENERATED_CERTIFICATE\" description for GENERATED_CERTIFICATE. \"NONE\" description for NONE. Favorites Values Value Description \"FAVORITED\" song is favorited. \"UNFAVORITED\" song is unfavorited. \"NOT_RATED\" song is not rated. MutedState Values Value Description \"MUTED\" The audio channel state id muted. \"UNMUTED\" The audio channel state id unmuted. Navigation Values Value Description \"DEFAULT\" Source dependant behavior. \"NONE\" No navigation should occur. \"FOREGROUND\" External app should take foreground. MediaType Values Value Description \"TRACK\" A single song source. \"PODCAST\" A podcast source. \"STATION\" A station source. \"AD\" An advertisement source. \"SAMPLE\" A sample source. \"OTHER\" A miscellaneous source.","title":"ExternalMediaAdapter"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#externalmediaadapter","text":"","title":"ExternalMediaAdapter"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#playcontrol","text":"Occurs during playback control via voice interaction or PlaybackController interface.","title":"PlayControl"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayControl\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"controlType\": {{PlayControlType}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. controlType PlayControlType Yes Playback control type being invoked.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#seek","text":"Called when the user invokes media seek via speech.","title":"Seek"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Seek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"offset\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_1","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. offset Int Yes Offset position within media item, in milliseconds.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#logout","text":"Directive called after a discovered player initiates the logoutComplete event.","title":"Logout"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Logout\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_2","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#play","text":"Called when the user first calls play for the external media via voice control.","title":"Play"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Play\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"playContextToken\": {{String}}, \"index\": {{Int}}, \"offset\": {{Int}}, \"preload\": {{Bool}}, \"navigation\": {{Navigation}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_3","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. playContextToken String Yes Track/playlist/album/artist/station/podcast context identifier. index Int Yes If the playback context is an indexable container like a playlist, the index of the media item in the container. offset Int Yes Offset position within media item, in milliseconds. preload Bool Yes Whether the media item should preload or not. navigation Navigation Yes The app transition behavior.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#getstate","text":"Must provide the local external media player apps @PlaybackStateExternal, and @SessionStateExternal information to maintain cloud sync.","title":"GetState"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"GetState\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"state\": {{ExternalMediaAdapterState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_4","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. state ExternalMediaAdapterState Yes The ExternalMediaAdapterState to be initialized by the platform.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#login","text":"Directive called after a discovered player initiates the loginComplete event.","title":"Login"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Login\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"accessToken\": {{String}}, \"userName\": {{String}}, \"forceLogin\": {{Bool}}, \"tokenRefreshInterval\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_5","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. accessToken String Yes The handshake token between AVS, and the external media player app session. userName String Yes The username provided by the external media player app, if available. forceLogin Bool Yes True if no handshake is needed, and login is simply assumed. tokenRefreshInterval Int Yes refresh interval of the accessToken, if available.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#adjustseek","text":"Called when the user invokes media seek adjustment via speech.","title":"AdjustSeek"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"deltaOffset\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_6","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. deltaOffset Int Yes Change in offset position within media item, in milliseconds.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#mutedstatechanged","text":"Notifies the platform implementation to apply a mute state change to the output channel.","title":"MutedStateChanged"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"state\": {{MutedState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_7","text":"Property Type Required Description Example state MutedState Yes The muted state to apply to the output channel. MUTED when the output channel be muted, UNMUTED when unmuted.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#volumechanged","text":"Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform.","title":"VolumeChanged"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"volume\": {{Float}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_8","text":"Property Type Required Description Example volume Float Yes The volume to set on the output channel. volume is in the range [0,1].","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#authorize","text":"Called after discovered media players have been reported. Returns a list of reported players and whether they have been authorized for use with Alexa.","title":"Authorize"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"Authorize\" } }, \"payload\": { \"authorizedPlayers\": [{{AuthorizedPlayerInfo}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_9","text":"Property Type Required Description Example authorizedPlayers AuthorizedPlayerInfo [] Yes A list of discovered players with their status of authorization for use with Alexa.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#playerevent","text":"Should be called on a local external media player event. This will sync the context with AVS.","title":"PlayerEvent"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"eventName\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_10","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. eventName String Yes Canonical event name.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#logoutcomplete","text":"Should be called on a local external media player logout. This will unset authorization of the app with AVS.","title":"LogoutComplete"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LogoutComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_11","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#logincomplete","text":"Should be called on a local external media player login. This will set authorization of the app with AVS.","title":"LoginComplete"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"LoginComplete\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_12","text":"Property Type Required Description Example localPlayerId String Yes Should be called on a local external media player login. This will set authorization of the app with AVS.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#setfocus","text":"Should be called on local external media player events. This will switch the media focus to that context.","title":"SetFocus"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"SetFocus\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_13","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#reportdiscoveredplayers","text":"Should be called on startup in order to notify AVS of the local external media players.","title":"ReportDiscoveredPlayers"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_14","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"ReportDiscoveredPlayers\" } }, \"payload\": { \"discoveredPlayers\": [{{DiscoveredPlayerInfo}}] } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_14","text":"Property Type Required Description Example discoveredPlayers DiscoveredPlayerInfo [] Yes The List of discovered players.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#removediscoveredplayer","text":"RemoveDiscoveredPlayer description.","title":"RemoveDiscoveredPlayer"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_15","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RemoveDiscoveredPlayer\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_15","text":"Property Type Required Description Example localPlayerId String Yes localPlayerId description.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#requesttoken","text":"The device is responsible for requesting an access token when needed. This is typically done immediately upon connection to AVS.","title":"RequestToken"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_16","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"RequestToken\" } }, \"payload\": { \"localPlayerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_16","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#playererror","text":"Should be called on a player error.","title":"PlayerError"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_17","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"ExternalMediaAdapter\", \"action\": \"PlayerError\" } }, \"payload\": { \"localPlayerId\": {{String}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#payload_17","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal.","title":"Payload"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#type-definitions","text":"","title":"Type Definitions"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#externalmediaadapterstate","text":"","title":"ExternalMediaAdapterState"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_18","text":"{ \"sessionState\": {{SessionStateExternal}}, \"playbackState\": {{PlaybackStateExternal}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#properties","text":"Property Type Required Description Example sessionState SessionStateExternal Yes Variable to hold the session state. playbackState PlaybackStateExternal Yes Variable to hold the playback state.","title":"Properties"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#sessionstateexternal","text":"","title":"SessionStateExternal"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_19","text":"{ \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"playerCookie\": {{String}}, \"spiVersion\": {{String}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#properties_1","text":"Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. playerCookie String Yes A player may declare arbitrary information for itself. spiVersion String Yes The only spiVersion that currently exists is \"1.0\".","title":"Properties"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#playbackstateexternal","text":"","title":"PlaybackStateExternal"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_20","text":"{ \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#properties_2","text":"Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PLAYING. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled or not. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled or not. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource. smallURL String Yes The URL for small cover art image resource. mediumURL String Yes The URL for medium cover art image resource. largeURL String Yes The URL for large cover art image resource. coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds.","title":"Properties"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#authorizedplayerinfo","text":"","title":"AuthorizedPlayerInfo"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_21","text":"{ \"localPlayerId\": {{String}}, \"authorized\": {{Bool}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#properties_3","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. authorized Bool Yes Authorization status.","title":"Properties"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#validationdata","text":"","title":"ValidationData"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_22","text":"{ \"certificate\": {{String}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#properties_4","text":"Property Type Required Description Example certificate String Yes Validation data.","title":"Properties"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#discoveredplayerinfo","text":"","title":"DiscoveredPlayerInfo"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#json-structure_23","text":"{ \"localPlayerId\": {{String}}, \"spiVersion\": {{String}}, \"validationMethod\": {{ValidationMethod}}, \"validationData\": [{{ValidationData}}] }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#properties_5","text":"Property Type Required Description Example localPlayerId String Yes The opaque token that uniquely identifies the local external player app. spiVersion String Yes The only spiVersion that currently exists is '1.0'. validationMethod ValidationMethod Yes Validation methods. validationData ValidationData [] Yes Validation data: 1. Device platform issued app signing certificate. A List of certificates may be attached. 2. In some cases validation is performed locally. The certificate is trasmitted as validationData during discovery to announce the activated app's identity in order to allow app activation to be revoked. 3. empty.","title":"Properties"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#supportedplaybackoperation","text":"","title":"SupportedPlaybackOperation"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values","text":"Value Description \"PLAY\" Play is supported (voice only). \"PAUSE\" Pause is supported. \"STOP\" Stop is supported. \"NEXT\" Next is supported. \"PREVIOUS\" Previous is supported. \"START_OVER\" Start Over is supported. \"FAST_FORWARD\" Fast Forward is supported. \"REWIND\" Rewind is supported. \"ENABLE_REPEAT\" Enable Repeat is supported. \"ENABLE_REPEAT_ONE\" Enable Repeat One is supported. \"DISABLE_REPEAT\" Disbale Repeat is supported. \"ENABLE_SHUFFLE\" Enable Shuffle is supported. \"DISABLE_SHUFFLE\" Disable Shuffle is supported. \"FAVORITE\" Favorite is supported. \"UNFAVORITE\" Unfavorite is supported. \"SEEK\" Seek is supported. \"ADJUST_SEEK\" Adjust Seek is supported.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#playcontroltype","text":"","title":"PlayControlType"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values_1","text":"Value Description \"PAUSE\" pause playback. \"RESUME\" resume playback. \"STOP\" stop playback. \"NEXT\" next song. \"PREVIOUS\" previous playback. \"START_OVER\" start playback over. \"FAST_FORWARD\" fast forward external media described time. \"REWIND\" rewind external media described time. \"ENABLE_REPEAT_ONE\" enable repeat current song. \"ENABLE_REPEAT\" enable playlist looping. \"DISABLE_REPEAT\" disable playlist looping. \"ENABLE_SHUFFLE\" enable playlist shuffling. \"DISABLE_SHUFFLE\" disable playlist shuffling. \"FAVORITE\" favorite song. \"UNFAVORITE\" unfavorite song.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#validationmethod","text":"","title":"ValidationMethod"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values_2","text":"Value Description \"SIGNING_CERTIFICATE\" description for SIGNING_CERTIFICATE. \"GENERATED_CERTIFICATE\" description for GENERATED_CERTIFICATE. \"NONE\" description for NONE.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#favorites","text":"","title":"Favorites"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values_3","text":"Value Description \"FAVORITED\" song is favorited. \"UNFAVORITED\" song is unfavorited. \"NOT_RATED\" song is not rated.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#mutedstate","text":"","title":"MutedState"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values_4","text":"Value Description \"MUTED\" The audio channel state id muted. \"UNMUTED\" The audio channel state id unmuted.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#navigation","text":"","title":"Navigation"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values_5","text":"Value Description \"DEFAULT\" Source dependant behavior. \"NONE\" No navigation should occur. \"FOREGROUND\" External app should take foreground.","title":"Values"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#mediatype","text":"","title":"MediaType"},{"location":"modules/alexa/aasb-docs/ExternalMediaAdapter/#values_6","text":"Value Description \"TRACK\" A single song source. \"PODCAST\" A podcast source. \"STATION\" A station source. \"AD\" An advertisement source. \"SAMPLE\" A sample source. \"OTHER\" A miscellaneous source.","title":"Values"},{"location":"modules/alexa/aasb-docs/GlobalPreset/","text":"GlobalPreset Outgoing Messages SetGlobalPreset Called after receiving a global preset play directive. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"GlobalPreset\", \"action\": \"SetGlobalPreset\" } }, \"payload\": { \"preset\": {{Int}} } } Payload Property Type Required Description Example preset Int Yes The preset integer from the playbackContextToken.","title":"GlobalPreset"},{"location":"modules/alexa/aasb-docs/GlobalPreset/#globalpreset","text":"","title":"GlobalPreset"},{"location":"modules/alexa/aasb-docs/GlobalPreset/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/GlobalPreset/#setglobalpreset","text":"Called after receiving a global preset play directive.","title":"SetGlobalPreset"},{"location":"modules/alexa/aasb-docs/GlobalPreset/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"GlobalPreset\", \"action\": \"SetGlobalPreset\" } }, \"payload\": { \"preset\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/GlobalPreset/#payload","text":"Property Type Required Description Example preset Int Yes The preset integer from the playbackContextToken.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/","text":"LocalMediaSource Outgoing Messages PlayControl Occurs during playback control via voice interaction or PlaybackController interface. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayControl\" } }, \"payload\": { \"source\": {{Source}}, \"controlType\": {{PlayControlType}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. controlType PlayControlType Yes Playback control type being invoked. Seek Called when the user invokes media seek via speech. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Seek\" } }, \"payload\": { \"source\": {{Source}}, \"offset\": {{Int}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. offset Int Yes Offset position within media item, in milliseconds. Play Called when the user calls play with a content selection type. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Play\" } }, \"payload\": { \"source\": {{Source}}, \"contentSelectorType\": {{ContentSelector}}, \"payload\": {{String}}, \"sessionId\": {{String}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. contentSelectorType ContentSelector Yes Content selection type. payload String Yes Content selector payload. sessionId String Yes Universally unique identifier (UUID) generated according to the RFC 4122 specification. Since Alexa is starting the session here, use this session Id for further events and errors. GetState Must provide the local media source @PlaybackStateLocal, and @SessionStateLocal information to maintain cloud sync. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\" } }, \"payload\": { \"source\": {{Source}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. GetStateReply Reply for GetState message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{LocalMediaSourceState}} } } Payload Property Type Required Description Example state LocalMediaSourceState Yes state description. AdjustSeek Called when the user invokes media seek adjustment via speech. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"source\": {{Source}}, \"deltaOffset\": {{Int}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. deltaOffset Int Yes Change in offset position within media item, in milliseconds. MutedStateChanged Notifies the platform implementation to apply a muted state has changed for the output channel. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"source\": {{Source}}, \"state\": {{MutedState}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. state MutedState Yes The muted state to apply to the output channel. VolumeChanged Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"source\": {{Source}}, \"volume\": {{Float}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. volume Float Yes The volume to set on the output channel. Incoming Messages PlayerEvent Should be called on a local media source player event. This will sync the context with AVS. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"source\": {{Source}}, \"eventName\": {{String}}, \"sessionId\": {{String}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. eventName String Yes Canonical event name. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended. SetFocus Should be called on local media source player events. This will switch the media focus to that context. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"SetFocus\" } }, \"payload\": { \"source\": {{Source}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. PlayerError Should be called on a local media source player error. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerError\" } }, \"payload\": { \"source\": {{Source}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}}, \"sessionId\": {{String}} } } Payload Property Type Required Description Example source Source Yes LocalMediaSource source type. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended. Type Definitions LocalMediaSourceState JSON Structure { \"sessionState\": {{SessionState}}, \"playbackState\": {{PlaybackState}} } Properties Property Type Required Description Example sessionState SessionState Yes Variable to hold the session state. playbackState PlaybackState Yes Variable to hold the playback state. PlaybackState JSON Structure { \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} } Properties Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PAUSED/PLAYING/FINISHED/FAST_FORWARDING/REWINDING/BUFFER_UNDERRUN. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource} . smallURL String Yes The URL for small cover art image resource} . mediumURL String Yes The URL for medium cover art image resource} . largeURL String Yes The URL for large cover art image resource} . coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds. SessionState JSON Structure { \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"supportedContentSelectors\": [{{ContentSelector}}], \"spiVersion\": {{String}} } Properties Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. supportedContentSelectors ContentSelector [] Yes Array of content selector types supported by the player. spiVersion String Yes The only spiVersion that currently exists is '1.0'. Enums Source Values Value Description \"BLUETOOTH\" bluetooth source. \"USB\" USB source. \"FM_RADIO\" FM radio source. \"AM_RADIO\" AM radio source. \"SATELLITE_RADIO\" satellite radio source. \"LINE_IN\" audio line source. \"COMPACT_DISC\" CD player source. \"SIRIUS_XM\" SIRIUS XM source. \"DAB\" DAB source. \"DEFAULT\" DEFAULT source. ContentSelector Values Value Description \"FREQUENCY\" radio station selection. \"CHANNEL\" radio channel selection. \"PRESET\" preset selection.","title":"LocalMediaSource"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#localmediasource","text":"","title":"LocalMediaSource"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#playcontrol","text":"Occurs during playback control via voice interaction or PlaybackController interface.","title":"PlayControl"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayControl\" } }, \"payload\": { \"source\": {{Source}}, \"controlType\": {{PlayControlType}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. controlType PlayControlType Yes Playback control type being invoked.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#seek","text":"Called when the user invokes media seek via speech.","title":"Seek"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Seek\" } }, \"payload\": { \"source\": {{Source}}, \"offset\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_1","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. offset Int Yes Offset position within media item, in milliseconds.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#play","text":"Called when the user calls play with a content selection type.","title":"Play"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"Play\" } }, \"payload\": { \"source\": {{Source}}, \"contentSelectorType\": {{ContentSelector}}, \"payload\": {{String}}, \"sessionId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_2","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. contentSelectorType ContentSelector Yes Content selection type. payload String Yes Content selector payload. sessionId String Yes Universally unique identifier (UUID) generated according to the RFC 4122 specification. Since Alexa is starting the session here, use this session Id for further events and errors.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#getstate","text":"Must provide the local media source @PlaybackStateLocal, and @SessionStateLocal information to maintain cloud sync.","title":"GetState"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\" } }, \"payload\": { \"source\": {{Source}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_3","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#getstatereply","text":"Reply for GetState message.","title":"GetStateReply"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"GetState\", \"replyToId\": {{String}} } }, \"payload\": { \"state\": {{LocalMediaSourceState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_4","text":"Property Type Required Description Example state LocalMediaSourceState Yes state description.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#adjustseek","text":"Called when the user invokes media seek adjustment via speech.","title":"AdjustSeek"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"AdjustSeek\" } }, \"payload\": { \"source\": {{Source}}, \"deltaOffset\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_5","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. deltaOffset Int Yes Change in offset position within media item, in milliseconds.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#mutedstatechanged","text":"Notifies the platform implementation to apply a muted state has changed for the output channel.","title":"MutedStateChanged"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"source\": {{Source}}, \"state\": {{MutedState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_6","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. state MutedState Yes The muted state to apply to the output channel.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#volumechanged","text":"Notifies the platform implementation to set the volume of the output channel. The volume value should be scaled to fit the needs of the platform.","title":"VolumeChanged"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"source\": {{Source}}, \"volume\": {{Float}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_7","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. volume Float Yes The volume to set on the output channel.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#playerevent","text":"Should be called on a local media source player event. This will sync the context with AVS.","title":"PlayerEvent"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerEvent\" } }, \"payload\": { \"source\": {{Source}}, \"eventName\": {{String}}, \"sessionId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_8","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. eventName String Yes Canonical event name. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#setfocus","text":"Should be called on local media source player events. This will switch the media focus to that context.","title":"SetFocus"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"SetFocus\" } }, \"payload\": { \"source\": {{Source}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_9","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#playererror","text":"Should be called on a local media source player error.","title":"PlayerError"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocalMediaSource\", \"action\": \"PlayerError\" } }, \"payload\": { \"source\": {{Source}}, \"errorName\": {{String}}, \"code\": {{Int}}, \"description\": {{String}}, \"fatal\": {{Bool}}, \"sessionId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#payload_10","text":"Property Type Required Description Example source Source Yes LocalMediaSource source type. errorName String Yes The name of the error. code Int Yes The error code. description String Yes The detailed error description. fatal Bool Yes true if the error is fatal. sessionId String No Universally unique identifier (UUID) generated according to the RFC 4122 specification. If playback session is started because of 'Play', use the same session Id. If the session is started due to any other reason, generate unique UUID and use it as a session ID until session is not ended.","title":"Payload"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#type-definitions","text":"","title":"Type Definitions"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#localmediasourcestate","text":"","title":"LocalMediaSourceState"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_11","text":"{ \"sessionState\": {{SessionState}}, \"playbackState\": {{PlaybackState}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#properties","text":"Property Type Required Description Example sessionState SessionState Yes Variable to hold the session state. playbackState PlaybackState Yes Variable to hold the playback state.","title":"Properties"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#playbackstate","text":"","title":"PlaybackState"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_12","text":"{ \"state\": {{String}}, \"supportedOperations\": [{{SupportedPlaybackOperation}}], \"trackOffset\": {{Int}}, \"shuffleEnabled\": {{Bool}}, \"repeatEnabled\": {{Bool}}, \"favorites\": {{Favorites}}, \"type\": {{String}}, \"playbackSource\": {{String}}, \"playbackSourceId\": {{String}}, \"trackName\": {{String}}, \"trackId\": {{String}}, \"trackNumber\": {{String}}, \"artistName\": {{String}}, \"artistId\": {{String}}, \"albumName\": {{String}}, \"albumId\": {{String}}, \"tinyURL\": {{String}}, \"smallURL\": {{String}}, \"mediumURL\": {{String}}, \"largeURL\": {{String}}, \"coverId\": {{String}}, \"mediaProvider\": {{String}}, \"mediaType\": {{MediaType}}, \"duration\": {{Int}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#properties_1","text":"Property Type Required Description Example state String Yes The state of the default player - IDLE/STOPPED/PAUSED/PLAYING/FINISHED/FAST_FORWARDING/REWINDING/BUFFER_UNDERRUN. supportedOperations SupportedPlaybackOperation [] Yes The set of states the default player can move into from its current state. trackOffset Int Yes The offset of the track in milliseconds. shuffleEnabled Bool Yes Bool to identify if shuffling is enabled. repeatEnabled Bool Yes Bool to identify if looping of songs is enabled. favorites Favorites Yes The favorite status {\"FAVORITED\"/\"UNFAVORITED\"/\"NOT_RATED\"}. type String Yes The type of the media item. For now hard-coded to ExternalMediaAdapterMusicItem. playbackSource String Yes The display name for current playback context, e.g. playlist name. playbackSourceId String Yes An arbitrary identifier for current playback context as per the music provider, e.g. a URI that can be saved as a preset or queried to Music Service Provider services for additional info. trackName String Yes The display name for the currently playing trackname of the track. trackId String Yes The arbitrary identifier for currently playing trackid of the track as per the music provider. trackNumber String Yes The display value for the number or abstract position of the currently playing track in the album or context trackNumber of the track. artistName String Yes The display name for the currently playing artist. artistId String Yes An arbitrary identifier for currently playing artist as per the music provider, e.g. a URI that can be queried to MSP services for additional info. albumName String Yes The display name of the currently playing album. albumId String Yes Arbitrary identifier for currently playing album specific to the music provider, e.g. a URI that can be queried to MSP services for additional info. tinyURL String Yes The URL for tiny cover art image resource} . smallURL String Yes The URL for small cover art image resource} . mediumURL String Yes The URL for medium cover art image resource} . largeURL String Yes The URL for large cover art image resource} . coverId String Yes The Arbitrary identifier for cover art image resource specific to the music provider, for retrieval from an MSP API. mediaProvider String Yes Music Service Provider name for the currently playing media item; distinct from the application identity although the two may be the same. mediaType MediaType Yes The Media type enum value from {TRACK, PODCAST, STATION, AD, SAMPLE, OTHER} type of the media. duration Int Yes Media item duration in milliseconds.","title":"Properties"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#sessionstate","text":"","title":"SessionState"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#json-structure_13","text":"{ \"endpointId\": {{String}}, \"loggedIn\": {{Bool}}, \"userName\": {{String}}, \"isGuest\": {{Bool}}, \"launched\": {{Bool}}, \"active\": {{Bool}}, \"accessToken\": {{String}}, \"tokenRefreshInterval\": {{int64}}, \"supportedContentSelectors\": [{{ContentSelector}}], \"spiVersion\": {{String}} }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#properties_2","text":"Property Type Required Description Example endpointId String Yes The unique device endpoint. loggedIn Bool Yes Flag that identifies if a user is currently logged in or not. userName String Yes The userName of the user currently logged in via a Login directive from the AVS. isGuest Bool Yes Flag that identifies if the user currently logged in is a guest or not. launched Bool Yes Flag that identifies if an application has been launched or not. active Bool Yes Flag that identifies if the application is currently active or not. This could mean different things for different applications. accessToken String Yes The accessToken used to login a user. The access token may also be used as a bearer token if the adapter makes an authenticated Web API to the music provider. tokenRefreshInterval int64 Yes The validity period of the token in milliseconds. supportedContentSelectors ContentSelector [] Yes Array of content selector types supported by the player. spiVersion String Yes The only spiVersion that currently exists is '1.0'.","title":"Properties"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#source","text":"","title":"Source"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#values","text":"Value Description \"BLUETOOTH\" bluetooth source. \"USB\" USB source. \"FM_RADIO\" FM radio source. \"AM_RADIO\" AM radio source. \"SATELLITE_RADIO\" satellite radio source. \"LINE_IN\" audio line source. \"COMPACT_DISC\" CD player source. \"SIRIUS_XM\" SIRIUS XM source. \"DAB\" DAB source. \"DEFAULT\" DEFAULT source.","title":"Values"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#contentselector","text":"","title":"ContentSelector"},{"location":"modules/alexa/aasb-docs/LocalMediaSource/#values_1","text":"Value Description \"FREQUENCY\" radio station selection. \"CHANNEL\" radio channel selection. \"PRESET\" preset selection.","title":"Values"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/","text":"MediaPlaybackRequestor Outgoing Messages MediaPlaybackResponse Result of the RequestMediaPlayback request. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"MediaPlaybackResponse\" } }, \"payload\": { \"mediaPlaybackRequestStatus\": {{MediaPlaybackRequestStatus}} } } Payload Property Type Required Description Example mediaPlaybackRequestStatus MediaPlaybackRequestStatus Yes Enum value representing the response of the RequestMediaPlaybackMessage request. Incoming Messages RequestMediaPlayback OEM Developers are expected to call this method whenever Alexa is the right candidate for the media resume. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"RequestMediaPlayback\" } }, \"payload\": { \"invocationReason\": {{InvocationReason}}, \"elapsedBootTime\": {{int64}} } } Payload Property Type Required Description Example invocationReason InvocationReason Yes Reason for calling this API. elapsedBootTime int64 Yes Provide the elapsed boot time in mili seconds if your platform does not provide a right value using https://developer.android.com/reference/android/os/SystemClock#elapsedRealtime() or https://man7.org/linux/man-pages/man2/sysinfo.2.html uptime. Enums MediaPlaybackRequestStatus Values Value Description \"SUCCESS\" Successful description. \"FAILED_CAN_RETRY\" Failure description. \"FAILED_TIMEOUT\" Too late to send RequestMediaPlaybackMessage, Failed to deliver. \"ERROR\" Event call is failed because of an error. InvocationReason Values Value Description \"AUTOMOTIVE_STARTUP\" System call for the automatic media resume. \"EXPLICIT_USER_ACTION\" Driver action for the media resume.","title":"MediaPlaybackRequestor"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#mediaplaybackrequestor","text":"","title":"MediaPlaybackRequestor"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#mediaplaybackresponse","text":"Result of the RequestMediaPlayback request.","title":"MediaPlaybackResponse"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"MediaPlaybackResponse\" } }, \"payload\": { \"mediaPlaybackRequestStatus\": {{MediaPlaybackRequestStatus}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#payload","text":"Property Type Required Description Example mediaPlaybackRequestStatus MediaPlaybackRequestStatus Yes Enum value representing the response of the RequestMediaPlaybackMessage request.","title":"Payload"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#requestmediaplayback","text":"OEM Developers are expected to call this method whenever Alexa is the right candidate for the media resume.","title":"RequestMediaPlayback"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"MediaPlaybackRequestor\", \"action\": \"RequestMediaPlayback\" } }, \"payload\": { \"invocationReason\": {{InvocationReason}}, \"elapsedBootTime\": {{int64}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#payload_1","text":"Property Type Required Description Example invocationReason InvocationReason Yes Reason for calling this API. elapsedBootTime int64 Yes Provide the elapsed boot time in mili seconds if your platform does not provide a right value using https://developer.android.com/reference/android/os/SystemClock#elapsedRealtime() or https://man7.org/linux/man-pages/man2/sysinfo.2.html uptime.","title":"Payload"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#mediaplaybackrequeststatus","text":"","title":"MediaPlaybackRequestStatus"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#values","text":"Value Description \"SUCCESS\" Successful description. \"FAILED_CAN_RETRY\" Failure description. \"FAILED_TIMEOUT\" Too late to send RequestMediaPlaybackMessage, Failed to deliver. \"ERROR\" Event call is failed because of an error.","title":"Values"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#invocationreason","text":"","title":"InvocationReason"},{"location":"modules/alexa/aasb-docs/MediaPlaybackRequestor/#values_1","text":"Value Description \"AUTOMOTIVE_STARTUP\" System call for the automatic media resume. \"EXPLICIT_USER_ACTION\" Driver action for the media resume.","title":"Values"},{"location":"modules/alexa/aasb-docs/Notifications/","text":"Notifications Outgoing Messages SetIndicator Notifies the platform implementation of whether a notification indicator should be rendered. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"SetIndicator\" } }, \"payload\": { \"state\": {{IndicatorState}} } } Payload Property Type Required Description Example state IndicatorState Yes The new notification indicator state. OnNotificationReceived Notifies the platform implementation of notification received. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"OnNotificationReceived\" } } } Enums IndicatorState Values Value Description \"OFF\" The notification indicator should be turned off. \"ON\" The notification indicator should be turned on. \"UNKNOWN\" The notification indicator state is unknown.","title":"Notifications"},{"location":"modules/alexa/aasb-docs/Notifications/#notifications","text":"","title":"Notifications"},{"location":"modules/alexa/aasb-docs/Notifications/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/Notifications/#setindicator","text":"Notifies the platform implementation of whether a notification indicator should be rendered.","title":"SetIndicator"},{"location":"modules/alexa/aasb-docs/Notifications/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"SetIndicator\" } }, \"payload\": { \"state\": {{IndicatorState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Notifications/#payload","text":"Property Type Required Description Example state IndicatorState Yes The new notification indicator state.","title":"Payload"},{"location":"modules/alexa/aasb-docs/Notifications/#onnotificationreceived","text":"Notifies the platform implementation of notification received.","title":"OnNotificationReceived"},{"location":"modules/alexa/aasb-docs/Notifications/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Notifications\", \"action\": \"OnNotificationReceived\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/Notifications/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/Notifications/#indicatorstate","text":"","title":"IndicatorState"},{"location":"modules/alexa/aasb-docs/Notifications/#values","text":"Value Description \"OFF\" The notification indicator should be turned off. \"ON\" The notification indicator should be turned on. \"UNKNOWN\" The notification indicator state is unknown.","title":"Values"},{"location":"modules/alexa/aasb-docs/PlaybackController/","text":"PlaybackController Incoming Messages ButtonPressed Notifies the Engine of a platform button request (i.e. Play/Pause/Next/Previous/Skip Forward/Skip Backward) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer to control playback on the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"ButtonPressed\" } }, \"payload\": { \"button\": {{PlaybackButton}} } } Payload Property Type Required Description Example button PlaybackButton Yes The playback button type. TogglePressed Notifies the Engine of a platform toggle request (i.e. Shuffle/Loop/Repeat/Thumbs Up/Thumbs Down) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"TogglePressed\" } }, \"payload\": { \"toggle\": {{PlaybackToggle}}, \"action\": {{Bool}} } } Payload Property Type Required Description Example toggle PlaybackToggle Yes The playback toggle type. action Bool Yes The toggle action. Enums PlaybackButton Values Value Description \"PLAY\" Play button. \"PAUSE\" Pause button. \"NEXT\" Next button. \"PREVIOUS\" Previous button. \"SKIP_FORWARD\" Skip Forward button. \"SKIP_BACKWARD\" Skip Backward button. PlaybackToggle Values Value Description \"SHUFFLE\" Shuffle toggle. \"LOOP\" Loop toggle. \"REPEAT\" Repeat toggle. \"THUMBS_UP\" Thumbs Up toggle. \"THUMBS_DOWN\" Thumbs Down toggle.","title":"PlaybackController"},{"location":"modules/alexa/aasb-docs/PlaybackController/#playbackcontroller","text":"","title":"PlaybackController"},{"location":"modules/alexa/aasb-docs/PlaybackController/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/PlaybackController/#buttonpressed","text":"Notifies the Engine of a platform button request (i.e. Play/Pause/Next/Previous/Skip Forward/Skip Backward) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer to control playback on the platform.","title":"ButtonPressed"},{"location":"modules/alexa/aasb-docs/PlaybackController/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"ButtonPressed\" } }, \"payload\": { \"button\": {{PlaybackButton}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/PlaybackController/#payload","text":"Property Type Required Description Example button PlaybackButton Yes The playback button type.","title":"Payload"},{"location":"modules/alexa/aasb-docs/PlaybackController/#togglepressed","text":"Notifies the Engine of a platform toggle request (i.e. Shuffle/Loop/Repeat/Thumbs Up/Thumbs Down) For certain playback types, the Engine will issue playback directives to the AudioPlayer MediaPlayer.","title":"TogglePressed"},{"location":"modules/alexa/aasb-docs/PlaybackController/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PlaybackController\", \"action\": \"TogglePressed\" } }, \"payload\": { \"toggle\": {{PlaybackToggle}}, \"action\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/PlaybackController/#payload_1","text":"Property Type Required Description Example toggle PlaybackToggle Yes The playback toggle type. action Bool Yes The toggle action.","title":"Payload"},{"location":"modules/alexa/aasb-docs/PlaybackController/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/PlaybackController/#playbackbutton","text":"","title":"PlaybackButton"},{"location":"modules/alexa/aasb-docs/PlaybackController/#values","text":"Value Description \"PLAY\" Play button. \"PAUSE\" Pause button. \"NEXT\" Next button. \"PREVIOUS\" Previous button. \"SKIP_FORWARD\" Skip Forward button. \"SKIP_BACKWARD\" Skip Backward button.","title":"Values"},{"location":"modules/alexa/aasb-docs/PlaybackController/#playbacktoggle","text":"","title":"PlaybackToggle"},{"location":"modules/alexa/aasb-docs/PlaybackController/#values_1","text":"Value Description \"SHUFFLE\" Shuffle toggle. \"LOOP\" Loop toggle. \"REPEAT\" Repeat toggle. \"THUMBS_UP\" Thumbs Up toggle. \"THUMBS_DOWN\" Thumbs Down toggle.","title":"Values"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/","text":"SpeechRecognizer Outgoing Messages WakewordDetected Notifies the platform implementation when a wake word is detected. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"WakewordDetected\" } }, \"payload\": { \"wakeword\": {{String}} } } Payload Property Type Required Description Example wakeword String Yes The wake word that was detected. EndOfSpeechDetected Notifies the platform implementation when end of speech is detected for the current recognize event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"EndOfSpeechDetected\" } } } Incoming Messages StopCapture Notifies the Engine to terminate the current recognize event. The Engine will call stopAudioInput() to notify the platform implementation when to stop writing audio samples. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StopCapture\" } } } StartCapture Notifies the Engine of a speech recognition event. The Engine will call startAudioInput() to notify the platform implementation when to start writing audio samples. If the initator type is HOLD_TO_TALK, then the platform implementation should call stopCapture() to terminate speech recognition on release of the press-and-hold action. Otherwise, the Engine will terminate the recognize event when end of speech is detected. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StartCapture\" } }, \"payload\": { \"initiator\": {{Initiator}}, \"keywordBegin\": {{Int}}, \"keywordEnd\": {{Int}}, \"keyword\": {{String}} } } Payload Property Type Required Description Example initiator Initiator Yes Initiator type for the speech recognition event. keywordBegin Int No (default: -1 ) The sample index where the keyword begins. Must be provided when initiator type is WAKEWORD. keywordEnd Int No (default: -1 ) The sample index where the keyword ends. Must be provided when initiator type is WAKEWORD. keyword String No The keyword being recognized, e.g. alexa. Must be provided when initiator type is WAKEWORD. Enums Initiator Values Value Description \"HOLD_TO_TALK\" Hold-to-talk speech initiator type. \"TAP_TO_TALK\" Tap-to-talk speech initiator type. \"WAKEWORD\" Wakeword speech initiator type.","title":"SpeechRecognizer"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#speechrecognizer","text":"","title":"SpeechRecognizer"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#wakeworddetected","text":"Notifies the platform implementation when a wake word is detected.","title":"WakewordDetected"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"WakewordDetected\" } }, \"payload\": { \"wakeword\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#payload","text":"Property Type Required Description Example wakeword String Yes The wake word that was detected.","title":"Payload"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#endofspeechdetected","text":"Notifies the platform implementation when end of speech is detected for the current recognize event.","title":"EndOfSpeechDetected"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"EndOfSpeechDetected\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#stopcapture","text":"Notifies the Engine to terminate the current recognize event. The Engine will call stopAudioInput() to notify the platform implementation when to stop writing audio samples.","title":"StopCapture"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StopCapture\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#startcapture","text":"Notifies the Engine of a speech recognition event. The Engine will call startAudioInput() to notify the platform implementation when to start writing audio samples. If the initator type is HOLD_TO_TALK, then the platform implementation should call stopCapture() to terminate speech recognition on release of the press-and-hold action. Otherwise, the Engine will terminate the recognize event when end of speech is detected.","title":"StartCapture"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"SpeechRecognizer\", \"action\": \"StartCapture\" } }, \"payload\": { \"initiator\": {{Initiator}}, \"keywordBegin\": {{Int}}, \"keywordEnd\": {{Int}}, \"keyword\": {{String}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#payload_1","text":"Property Type Required Description Example initiator Initiator Yes Initiator type for the speech recognition event. keywordBegin Int No (default: -1 ) The sample index where the keyword begins. Must be provided when initiator type is WAKEWORD. keywordEnd Int No (default: -1 ) The sample index where the keyword ends. Must be provided when initiator type is WAKEWORD. keyword String No The keyword being recognized, e.g. alexa. Must be provided when initiator type is WAKEWORD.","title":"Payload"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#initiator","text":"","title":"Initiator"},{"location":"modules/alexa/aasb-docs/SpeechRecognizer/#values","text":"Value Description \"HOLD_TO_TALK\" Hold-to-talk speech initiator type. \"TAP_TO_TALK\" Tap-to-talk speech initiator type. \"WAKEWORD\" Wakeword speech initiator type.","title":"Values"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/","text":"TemplateRuntime Outgoing Messages RenderTemplate Provides visual metadata associated with a user request to Alexa. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderTemplate\" } }, \"payload\": { \"payload\": {{String}}, \"focusState\": {{FocusState}} } } Payload Property Type Required Description Example payload String Yes Renderable template metadata in structured JSON format. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface. ClearPlayerInfo Notifies the platform implementation to dismiss the player info display card. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearPlayerInfo\" } } } ClearTemplate Notifies the platform implementation to dismiss the template display card. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearTemplate\" } } } RenderPlayerInfo Provides visual metadata associated with a user request to Alexa for audio playback. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderPlayerInfo\" } }, \"payload\": { \"payload\": {{String}}, \"audioPlayerState\": {{PlayerActivity}}, \"offset\": {{Int}}, \"focusState\": {{FocusState}} } } Payload Property Type Required Description Example payload String Yes Renderable player info metadata in structured JSON format. audioPlayerState PlayerActivity Yes The state of the AudioPlayer. offset Int Yes The offset in millisecond of the media that AudioPlayer is handling. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface. Incoming Messages DisplayCardCleared Notifies the Engine that a display card has been cleared from the screen. Upon getting this notification, the TemplateRuntime will release the visual channel. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"DisplayCardCleared\" } } } Enums FocusState Values Value Description \"FOREGROUND\" Represents the highest focus a Channel can have. \"BACKGROUND\" Represents the intermediate level focus a Channel can have. \"NONE\" This focus is used to represent when a Channel is not being used.","title":"TemplateRuntime"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#templateruntime","text":"","title":"TemplateRuntime"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#rendertemplate","text":"Provides visual metadata associated with a user request to Alexa.","title":"RenderTemplate"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderTemplate\" } }, \"payload\": { \"payload\": {{String}}, \"focusState\": {{FocusState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#payload","text":"Property Type Required Description Example payload String Yes Renderable template metadata in structured JSON format. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface.","title":"Payload"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#clearplayerinfo","text":"Notifies the platform implementation to dismiss the player info display card.","title":"ClearPlayerInfo"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearPlayerInfo\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#cleartemplate","text":"Notifies the platform implementation to dismiss the template display card.","title":"ClearTemplate"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"ClearTemplate\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#renderplayerinfo","text":"Provides visual metadata associated with a user request to Alexa for audio playback.","title":"RenderPlayerInfo"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"RenderPlayerInfo\" } }, \"payload\": { \"payload\": {{String}}, \"audioPlayerState\": {{PlayerActivity}}, \"offset\": {{Int}}, \"focusState\": {{FocusState}} } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#payload_1","text":"Property Type Required Description Example payload String Yes Renderable player info metadata in structured JSON format. audioPlayerState PlayerActivity Yes The state of the AudioPlayer. offset Int Yes The offset in millisecond of the media that AudioPlayer is handling. focusState FocusState Yes FocusState of the channel used by TemplateRuntime interface.","title":"Payload"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#displaycardcleared","text":"Notifies the Engine that a display card has been cleared from the screen. Upon getting this notification, the TemplateRuntime will release the visual channel.","title":"DisplayCardCleared"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TemplateRuntime\", \"action\": \"DisplayCardCleared\" } } }","title":"JSON Structure"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#enums","text":"","title":"Enums"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#focusstate","text":"","title":"FocusState"},{"location":"modules/alexa/aasb-docs/TemplateRuntime/#values","text":"Value Description \"FOREGROUND\" Represents the highest focus a Channel can have. \"BACKGROUND\" Represents the intermediate level focus a Channel can have. \"NONE\" This focus is used to represent when a Channel is not being used.","title":"Values"},{"location":"modules/apl/","text":"Alexa Presentation Language (APL) Module Table of Contents Overview Automotive Viewport Profiles Vehicle Driving State Day and Night Mode Automotive Themes Supported APL Experiences APL Viewhost Template Runtime Configuring the APL Module Using the APL AASB Messages Integrating the APL Module Into Your Application Registering an APL Handler Android Integration Visual Characteristics Overview The Alexa Presentation Language (APL) module enables your Alexa Auto SDK client application to use visual capabilities of Alexa. By using this module in your application, you enable your device to receive visual experiences from certified Alexa Skills that support APL. Additionally, this modules provides messages for reporting the driving state of the vehicle, the day/night mode, and theme id. All of those properties affect how APL is rendered in the vehicle. Support for three new Alexa Automotive viewport profiles is now available. APL directives from the Alexa Voice Service (AVS) contain metadata needed to render Alexa's visual responses for devices with a graphical user interface (GUI). The lifecycle of an APL document includes sending events, providing document and window state, and more. For more information about APL, see the APL documentation . Note: The APL module doesn't render APL documents; it provides the conduit to render APL documents and process user events from the GUI or voice user interface (VUI). APL rendering is available separately for Android platforms. Automotive Viewport Profiles APL supports various types of viewport profiles for different types of devices and screen sizes. There are three new viewport profiles specifically added for vehicles: auto extra small, auto small and auto medium. Please refer to the viewport profile documentation for specific sizes and configuration information. Vehicle Driving State The vehicle driving state describes the motion state of the vehicle. The two supported values are moving and parked . Setting the appropriate driving state helps make visual experiences safer in the vehicle. When the vehicle is parked , APL experiences may contain more visual elements. When the vehicle is moving , some visual elements may be hidden to reduce cognitive load on the driver and make the experience safer. Video will automatically be disabled when the vehicle is moving . Day and Night Mode Day and night mode provide a way to render APL experiences in different contrasts based on the ambient light conditions of the vehicle. During the day when more light is available, the APL experience will typically be rendered with a light background and dark font. During the night or when travelling through a tunnel, the APL experience will be rendered with a dark background and light font. Automotive Themes Automotive themes allow the OEM to customize some aspects of the APL experience such as background and font color. Themes have predefined color values and affect supported Alexa Responsive Templates . This can help make the APL experience match more closely to the look and feel of the native UI in the head unit. There are a total of six available themes that include three for day mode and three for night mode. Day mode includes a default theme, and two additional themes with values gray1 and gray2 . Night mode includes a default theme, and two additional themes with values black and gray . The OEM application must ensure that a valid theme is set for day and night modes. The theme is optional, and in the case that it is not provided then the default theme is used. Supported APL Experiences Only APL experiences that have been certified for Automotive devices will be allowed to send APL directives. We are working to provide a process for skill developers to support automotive devices. More information will be provided in the online documentation . Contact your Amazon Solutions Architect (SA) or Partner Manager for more information about what Alexa domains and skills support APL in the vehicle. APL Viewhost The viewhost is a software component responsible for rendering the APL payload on screen. The Auto SDK provides a native Android viewhost solution. Contact your Amazon Solutions Architect (SA) or Partner Manager for more information. Template Runtime APL and Template Runtime both provide visual experiences. The Auto SDK supports both capabilities on the vehicle. Alexa skills typically give APL preference if both capabilities are reported, and will return APL directives. The new Auto SDK audio ducking feature is necessary for Template Runtime render player info cards and APL cards to be active at the same time. Configuring the APL Module The APL module can be optionally configured with the following Engine setting: { \"alexaPresentationCapabilityAgent\": { \"displayDocumentInteractionIdleTimeout\": <TIMEOUT_IN_MS> } } Note: The default value for the configuration timeout is 30 seconds. Using the APL AASB Messages General APL Message When a user interacts with an APL enabled Alexa skill, the Engine publishes the RenderDocument message . It is the responsibility of the application to integrate a viewhost capable of rendering APL documents. During the APL lifecyle, there will be context information (such as document and window state) as well as user events generated by interaction with the rendered APL document. The skill can send additional directives, which must be forwarded to the viewhost. This diagram illustrates the sequence of interacting with an APL enabled Alexa skill. Click to expand or collapse sequence diagram: General APL Directive Flow Set Platform Property Message This diagram illustrates the sequence of setting platform properties for APL. Click to expand or collapse sequence diagram: Setting platform properties Integrating the APL Module Into Your Application The Auto SDK provides out of the box support for APL through the Alexa Auto Client Service (AACS). However, you can use the Engine's MessageBroker to subscribe to and publish \"APL\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/APL/APL/ActivityEvent.h> #include <AASB/Message/APL/APL/ClearAllExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ClearCardMessage.h> #include <AASB/Message/APL/APL/ClearDocumentMessage.h> #include <AASB/Message/APL/APL/DataSourceUpdateMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsResultMessage.h> #include <AASB/Message/APL/APL/InterruptCommandSequenceMessage.h> #include <AASB/Message/APL/APL/ProcessActivityEventMessage.h> #include <AASB/Message/APL/APL/RenderDocumentMessage.h> #include <AASB/Message/APL/APL/RenderDocumentResultMessage.h> #include <AASB/Message/APL/APL/SendDataSourceFetchRequestEventMessage.h> #include <AASB/Message/APL/APL/SendDeviceWindowStateMessage.h> #include <AASB/Message/APL/APL/SendRuntimeErrorEventMessage.h> #include <AASB/Message/APL/APL/SendUserEventMessage.h> #include <AASB/Message/APL/APL/SendDocumentStateMessage.h> #include <AASB/Message/APL/APL/SetAPLMaxVersionMessage.h> #include <AASB/Message/APL/APL/SetDocumentIdleTimeoutMessage.h> #include <AASB/Message/APL/APL/SetPlatformPropertyMessage.h> #include <AASB/Message/APL/APL/UpdateAPLRuntimePropertiesMessage.h> #include <nlohmann/json.hpp> using json = nlohmann::json; class MyAPLHandler { // Subscribe to messages from the Engine void MyAPLHandler::subscribeToAASBMessages() { m_messageBroker->subscribe( [=](const std::string& message) { handleRenderDocumentMessage(message); }, RenderDocumentMessage::topic(), RenderDocumentMessage::action()); ... // Handle the RenderDocument message from the Engine void MyAPLHandler::handleRenderDocumentMessage(const std::string& message) { RenderDocumentMessage msg = json::parse(message); std::string payload = msg.payload.payload; std::string token = msg.payload.token; // ...Pass data to viewhost for rendering... } Registering an APL Handler To implement a custom handler for APL, extend the aace::apl::APL class as follows: class APLHandler : public aace::apl::APL { public: APLHandler(); void renderDocument(const std::string& jsonPayload, const std::string& token, const std::string& windowId) override; void clearDocument(const std::string& token) override; void executeCommands(const std::string& jsonPayload, const std::string& token) override; void interruptCommandSequence(const std::string& token) override; void dataSourceUpdate(const std::string& sourceType, const std::string& jsonPayload, const std::string& token) override; }; Android Integration The Alexa Auto Client Service (AACS) provides the AACS APL Renderer component to integrate the Auto SDK APL module on Android. See the AACS APL Renderer documentation for more information. Visual Characteristics The APL module requires that the platform implementation define the visual characteristics of the device. Visual characteristics are passed directly to the Smart Screen SDK, and therefore have the format described in the Alexa Smart Screen SDK documentation . Include the visualCharacteristics configuration in the JSON object aace.alexa/avsDeviceSDK/gui as shown in the following example. You can pass the configuration to the Engine using a StreamConfiguration or ConfigurationFile object. { \"aace.alexa\" : { \"avsDeviceSDK\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 1280 , \"height\" : 720 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display\" , \"version\" : \"1.0\" , \"configurations\" : { \"display\" : { \"type\" : \"PIXEL\" , \"touch\" : [ \"UNSUPPORTED\" ], \"shape\" : \"RECTANGLE\" , \"dimensions\" : { \"resolution\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } }, \"physicalSize\" : { \"unit\" : \"INCHES\" , \"value\" : { \"width\" : 8.9 , \"height\" : 6.05 } }, \"pixelDensity\" : { \"unit\" : \"DPI\" , \"value\" : 288 }, \"densityIndependentResolution\" : { \"unit\" : \"DP\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } } } } } } ] } } } }","title":"Alexa Presentation Language (APL) Module"},{"location":"modules/apl/#alexa-presentation-language-apl-module","text":"","title":"Alexa Presentation Language (APL) Module"},{"location":"modules/apl/#table-of-contents","text":"Overview Automotive Viewport Profiles Vehicle Driving State Day and Night Mode Automotive Themes Supported APL Experiences APL Viewhost Template Runtime Configuring the APL Module Using the APL AASB Messages Integrating the APL Module Into Your Application Registering an APL Handler Android Integration Visual Characteristics","title":"Table of Contents"},{"location":"modules/apl/#overview","text":"The Alexa Presentation Language (APL) module enables your Alexa Auto SDK client application to use visual capabilities of Alexa. By using this module in your application, you enable your device to receive visual experiences from certified Alexa Skills that support APL. Additionally, this modules provides messages for reporting the driving state of the vehicle, the day/night mode, and theme id. All of those properties affect how APL is rendered in the vehicle. Support for three new Alexa Automotive viewport profiles is now available. APL directives from the Alexa Voice Service (AVS) contain metadata needed to render Alexa's visual responses for devices with a graphical user interface (GUI). The lifecycle of an APL document includes sending events, providing document and window state, and more. For more information about APL, see the APL documentation . Note: The APL module doesn't render APL documents; it provides the conduit to render APL documents and process user events from the GUI or voice user interface (VUI). APL rendering is available separately for Android platforms.","title":"Overview "},{"location":"modules/apl/#automotive-viewport-profiles","text":"APL supports various types of viewport profiles for different types of devices and screen sizes. There are three new viewport profiles specifically added for vehicles: auto extra small, auto small and auto medium. Please refer to the viewport profile documentation for specific sizes and configuration information.","title":"Automotive Viewport Profiles "},{"location":"modules/apl/#vehicle-driving-state","text":"The vehicle driving state describes the motion state of the vehicle. The two supported values are moving and parked . Setting the appropriate driving state helps make visual experiences safer in the vehicle. When the vehicle is parked , APL experiences may contain more visual elements. When the vehicle is moving , some visual elements may be hidden to reduce cognitive load on the driver and make the experience safer. Video will automatically be disabled when the vehicle is moving .","title":"Vehicle Driving State "},{"location":"modules/apl/#day-and-night-mode","text":"Day and night mode provide a way to render APL experiences in different contrasts based on the ambient light conditions of the vehicle. During the day when more light is available, the APL experience will typically be rendered with a light background and dark font. During the night or when travelling through a tunnel, the APL experience will be rendered with a dark background and light font.","title":"Day and Night Mode "},{"location":"modules/apl/#automotive-themes","text":"Automotive themes allow the OEM to customize some aspects of the APL experience such as background and font color. Themes have predefined color values and affect supported Alexa Responsive Templates . This can help make the APL experience match more closely to the look and feel of the native UI in the head unit. There are a total of six available themes that include three for day mode and three for night mode. Day mode includes a default theme, and two additional themes with values gray1 and gray2 . Night mode includes a default theme, and two additional themes with values black and gray . The OEM application must ensure that a valid theme is set for day and night modes. The theme is optional, and in the case that it is not provided then the default theme is used.","title":"Automotive Themes "},{"location":"modules/apl/#supported-apl-experiences","text":"Only APL experiences that have been certified for Automotive devices will be allowed to send APL directives. We are working to provide a process for skill developers to support automotive devices. More information will be provided in the online documentation . Contact your Amazon Solutions Architect (SA) or Partner Manager for more information about what Alexa domains and skills support APL in the vehicle.","title":"Supported APL Experiences "},{"location":"modules/apl/#apl-viewhost","text":"The viewhost is a software component responsible for rendering the APL payload on screen. The Auto SDK provides a native Android viewhost solution. Contact your Amazon Solutions Architect (SA) or Partner Manager for more information.","title":"APL Viewhost "},{"location":"modules/apl/#template-runtime","text":"APL and Template Runtime both provide visual experiences. The Auto SDK supports both capabilities on the vehicle. Alexa skills typically give APL preference if both capabilities are reported, and will return APL directives. The new Auto SDK audio ducking feature is necessary for Template Runtime render player info cards and APL cards to be active at the same time.","title":"Template Runtime "},{"location":"modules/apl/#configuring-the-apl-module","text":"The APL module can be optionally configured with the following Engine setting: { \"alexaPresentationCapabilityAgent\": { \"displayDocumentInteractionIdleTimeout\": <TIMEOUT_IN_MS> } } Note: The default value for the configuration timeout is 30 seconds.","title":"Configuring the APL Module "},{"location":"modules/apl/#using-the-apl-aasb-messages","text":"","title":"Using the APL AASB Messages "},{"location":"modules/apl/#general-apl-message","text":"When a user interacts with an APL enabled Alexa skill, the Engine publishes the RenderDocument message . It is the responsibility of the application to integrate a viewhost capable of rendering APL documents. During the APL lifecyle, there will be context information (such as document and window state) as well as user events generated by interaction with the rendered APL document. The skill can send additional directives, which must be forwarded to the viewhost. This diagram illustrates the sequence of interacting with an APL enabled Alexa skill. Click to expand or collapse sequence diagram: General APL Directive Flow","title":"General APL Message"},{"location":"modules/apl/#set-platform-property-message","text":"This diagram illustrates the sequence of setting platform properties for APL. Click to expand or collapse sequence diagram: Setting platform properties","title":"Set Platform Property Message"},{"location":"modules/apl/#integrating-the-apl-module-into-your-application","text":"The Auto SDK provides out of the box support for APL through the Alexa Auto Client Service (AACS). However, you can use the Engine's MessageBroker to subscribe to and publish \"APL\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/APL/APL/ActivityEvent.h> #include <AASB/Message/APL/APL/ClearAllExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ClearCardMessage.h> #include <AASB/Message/APL/APL/ClearDocumentMessage.h> #include <AASB/Message/APL/APL/DataSourceUpdateMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsMessage.h> #include <AASB/Message/APL/APL/ExecuteCommandsResultMessage.h> #include <AASB/Message/APL/APL/InterruptCommandSequenceMessage.h> #include <AASB/Message/APL/APL/ProcessActivityEventMessage.h> #include <AASB/Message/APL/APL/RenderDocumentMessage.h> #include <AASB/Message/APL/APL/RenderDocumentResultMessage.h> #include <AASB/Message/APL/APL/SendDataSourceFetchRequestEventMessage.h> #include <AASB/Message/APL/APL/SendDeviceWindowStateMessage.h> #include <AASB/Message/APL/APL/SendRuntimeErrorEventMessage.h> #include <AASB/Message/APL/APL/SendUserEventMessage.h> #include <AASB/Message/APL/APL/SendDocumentStateMessage.h> #include <AASB/Message/APL/APL/SetAPLMaxVersionMessage.h> #include <AASB/Message/APL/APL/SetDocumentIdleTimeoutMessage.h> #include <AASB/Message/APL/APL/SetPlatformPropertyMessage.h> #include <AASB/Message/APL/APL/UpdateAPLRuntimePropertiesMessage.h> #include <nlohmann/json.hpp> using json = nlohmann::json; class MyAPLHandler { // Subscribe to messages from the Engine void MyAPLHandler::subscribeToAASBMessages() { m_messageBroker->subscribe( [=](const std::string& message) { handleRenderDocumentMessage(message); }, RenderDocumentMessage::topic(), RenderDocumentMessage::action()); ... // Handle the RenderDocument message from the Engine void MyAPLHandler::handleRenderDocumentMessage(const std::string& message) { RenderDocumentMessage msg = json::parse(message); std::string payload = msg.payload.payload; std::string token = msg.payload.token; // ...Pass data to viewhost for rendering... }","title":"Integrating the APL Module Into Your Application "},{"location":"modules/apl/#registering-an-apl-handler","text":"To implement a custom handler for APL, extend the aace::apl::APL class as follows: class APLHandler : public aace::apl::APL { public: APLHandler(); void renderDocument(const std::string& jsonPayload, const std::string& token, const std::string& windowId) override; void clearDocument(const std::string& token) override; void executeCommands(const std::string& jsonPayload, const std::string& token) override; void interruptCommandSequence(const std::string& token) override; void dataSourceUpdate(const std::string& sourceType, const std::string& jsonPayload, const std::string& token) override; };","title":"Registering an APL Handler "},{"location":"modules/apl/#android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS APL Renderer component to integrate the Auto SDK APL module on Android. See the AACS APL Renderer documentation for more information.","title":"Android Integration "},{"location":"modules/apl/#visual-characteristics","text":"The APL module requires that the platform implementation define the visual characteristics of the device. Visual characteristics are passed directly to the Smart Screen SDK, and therefore have the format described in the Alexa Smart Screen SDK documentation . Include the visualCharacteristics configuration in the JSON object aace.alexa/avsDeviceSDK/gui as shown in the following example. You can pass the configuration to the Engine using a StreamConfiguration or ConfigurationFile object. { \"aace.alexa\" : { \"avsDeviceSDK\" : { \"gui\" : { \"visualCharacteristics\" : [ { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.InteractionMode\" , \"version\" : \"1.1\" , \"configurations\" : { \"interactionModes\" : [ { \"id\" : \"apl-interaction-id\" , \"uiMode\" : \"AUTO\" , \"interactionDistance\" : { \"unit\" : \"INCHES\" , \"value\" : 24 }, \"touch\" : \"SUPPORTED\" , \"keyboard\" : \"SUPPORTED\" , \"video\" : \"SUPPORTED\" , \"dialog\" : \"SUPPORTED\" } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Presentation.APL.Video\" , \"version\" : \"1.0\" , \"configurations\" : { \"video\" : { \"codecs\" : [ \"H_264_42\" , \"H_264_41\" ] } } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display.Window\" , \"version\" : \"1.0\" , \"configurations\" : { \"templates\" : [ { \"id\" : \"apl-window-id\" , \"type\" : \"STANDARD\" , \"configuration\" : { \"sizes\" : [ { \"type\" : \"DISCRETE\" , \"id\" : \"window-size-id\" , \"value\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 1280 , \"height\" : 720 } } } ], \"interactionModes\" : [ \"apl-interaction-id\" ] } } ] } }, { \"type\" : \"AlexaInterface\" , \"interface\" : \"Alexa.Display\" , \"version\" : \"1.0\" , \"configurations\" : { \"display\" : { \"type\" : \"PIXEL\" , \"touch\" : [ \"UNSUPPORTED\" ], \"shape\" : \"RECTANGLE\" , \"dimensions\" : { \"resolution\" : { \"unit\" : \"PIXEL\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } }, \"physicalSize\" : { \"unit\" : \"INCHES\" , \"value\" : { \"width\" : 8.9 , \"height\" : 6.05 } }, \"pixelDensity\" : { \"unit\" : \"DPI\" , \"value\" : 288 }, \"densityIndependentResolution\" : { \"unit\" : \"DP\" , \"value\" : { \"width\" : 2048 , \"height\" : 1536 } } } } } } ] } } } }","title":"Visual Characteristics "},{"location":"modules/apl/aasb-docs/APL/","text":"APL Outgoing Messages DataSourceUpdate Notifies the platform implementation of a dynamic data source update. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"DataSourceUpdate\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example type String Yes The type of data source update received. payload String Yes The data source update payload in JSON format. token String Yes The presentation token associated with the APL document. InterruptCommandSequence Notifies the platform implementation to clear the APL document rendering. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"InterruptCommandSequence\" } }, \"payload\": { \"token\": {{String}} } } Payload Property Type Required Description Example token String Yes The presentation token associated with the APL document. UpdateAPLRuntimeProperties Notifies the platform implementation of APL runtime properties to be used during rendering. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"UpdateAPLRuntimeProperties\" } }, \"payload\": { \"properties\": {{String}} } } Payload Property Type Required Description Example properties String Yes String in JSON format containing updated APL runtime properties. RenderDocument Notifies the platform implementation that an APL document needs rendering. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocument\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}}, \"windowId\": {{String}} } } Payload Property Type Required Description Example payload String Yes The APL document to be rendered represented as a JSON string. token String Yes The presentation token associated with the APL document. windowId String Yes The window ID where the APL document will be rendered or empty string for default window. ExecuteCommands Notifies the platform implementation that an APL document needs rendering. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommands\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example payload String Yes The APL commands to be executed represented as a JSON string. token String Yes The presentation token associated with the APL document. ClearDocument Notifies the platform implementation to clear the APL document rendering. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearDocument\" } }, \"payload\": { \"token\": {{String}} } } Payload Property Type Required Description Example token String Yes The presentation token associated with the APL document. Incoming Messages ProcessActivityEvent Notifies the Engine of an activity event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ProcessActivityEvent\" } }, \"payload\": { \"source\": {{String}}, \"event\": {{ActivityEvent}} } } Payload Property Type Required Description Example source String Yes The source value for the activity event. event ActivityEvent Yes The activity event type. SetAPLMaxVersion Notifies the Engine of the maximum APL version supported. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetAPLMaxVersion\" } }, \"payload\": { \"version\": {{String}} } } Payload Property Type Required Description Example version String Yes The maximum APL version supported. SendUserEvent Notifies the Engine that user generated an event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendUserEvent\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes The APL user event represented as a JSON string. SendDataSourceFetchRequestEvent Notifies the Engine of a data source fetch request. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDataSourceFetchRequestEvent\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}} } } Payload Property Type Required Description Example type String Yes The type of data source fetch request. payload String Yes The APL user event represented as a JSON string. SendDeviceWindowState Notifies the Engine of the current window state. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDeviceWindowState\" } }, \"payload\": { \"state\": {{String}} } } Payload Property Type Required Description Example state String Yes JSON string representing the payload of the window state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/display-window.html#windowstate-context-object. SendDocumentState Notifies the Engine that APL runtime generated visual document state. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDocumentState\" } }, \"payload\": { \"state\": {{String}} } } Payload Property Type Required Description Example state String Yes JSON string representing the payload of the rendered document state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/presentation-apl.html#rendereddocumentstate. SendRuntimeErrorEvent Notifies the Engine that an APL runtime error occurred. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendRuntimeErrorEvent\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes The APL runtime error event represented as a JSON string. ClearAllExecuteCommands Notifies the Engine that APL render finished clearing all commands. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearAllExecuteCommands\" } } } SetPlatformProperty Notifies the Engine of properties such as vehicle driving state, day/night mode, and custom theme id. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetPlatformProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } } Payload Property Type Required Description Example name String Yes The name of the property to be set. value String Yes The value that the property will be set to. ExecuteCommandsResult Notifies the Engine of the command execution result. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommandsResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } } Payload Property Type Required Description Example token String Yes The token associated with the commands. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty. SetDocumentIdleTimeout Notifies the Engine of the idle timeout value. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetDocumentIdleTimeout\" } }, \"payload\": { \"timeout\": {{int64}} } } Payload Property Type Required Description Example timeout int64 Yes Idle timeout value in milliseconds. RenderDocumentResult Notifies the Engine of command execution result. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocumentResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } } Payload Property Type Required Description Example token String Yes The token associated with the APL document. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty. ClearCard Notifies the Engine that APL render finished clearing document. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearCard\" } } } Enums ActivityEvent Values Value Description \"ACTIVATED\" GUI switched to active state. \"DEACTIVATED\" GUI become inactive. \"ONE_TIME\" GUI processed one-time event (touch/scroll/etc). \"INTERRUPT\" Interrupt event (touch). \"UNKNOWN\" Guard option for unknown received state.","title":"APL"},{"location":"modules/apl/aasb-docs/APL/#apl","text":"","title":"APL"},{"location":"modules/apl/aasb-docs/APL/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/apl/aasb-docs/APL/#datasourceupdate","text":"Notifies the platform implementation of a dynamic data source update.","title":"DataSourceUpdate"},{"location":"modules/apl/aasb-docs/APL/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"DataSourceUpdate\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload","text":"Property Type Required Description Example type String Yes The type of data source update received. payload String Yes The data source update payload in JSON format. token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#interruptcommandsequence","text":"Notifies the platform implementation to clear the APL document rendering.","title":"InterruptCommandSequence"},{"location":"modules/apl/aasb-docs/APL/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"InterruptCommandSequence\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_1","text":"Property Type Required Description Example token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#updateaplruntimeproperties","text":"Notifies the platform implementation of APL runtime properties to be used during rendering.","title":"UpdateAPLRuntimeProperties"},{"location":"modules/apl/aasb-docs/APL/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"UpdateAPLRuntimeProperties\" } }, \"payload\": { \"properties\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_2","text":"Property Type Required Description Example properties String Yes String in JSON format containing updated APL runtime properties.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#renderdocument","text":"Notifies the platform implementation that an APL document needs rendering.","title":"RenderDocument"},{"location":"modules/apl/aasb-docs/APL/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocument\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}}, \"windowId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_3","text":"Property Type Required Description Example payload String Yes The APL document to be rendered represented as a JSON string. token String Yes The presentation token associated with the APL document. windowId String Yes The window ID where the APL document will be rendered or empty string for default window.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#executecommands","text":"Notifies the platform implementation that an APL document needs rendering.","title":"ExecuteCommands"},{"location":"modules/apl/aasb-docs/APL/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommands\" } }, \"payload\": { \"payload\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_4","text":"Property Type Required Description Example payload String Yes The APL commands to be executed represented as a JSON string. token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#cleardocument","text":"Notifies the platform implementation to clear the APL document rendering.","title":"ClearDocument"},{"location":"modules/apl/aasb-docs/APL/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearDocument\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_5","text":"Property Type Required Description Example token String Yes The presentation token associated with the APL document.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/apl/aasb-docs/APL/#processactivityevent","text":"Notifies the Engine of an activity event.","title":"ProcessActivityEvent"},{"location":"modules/apl/aasb-docs/APL/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ProcessActivityEvent\" } }, \"payload\": { \"source\": {{String}}, \"event\": {{ActivityEvent}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_6","text":"Property Type Required Description Example source String Yes The source value for the activity event. event ActivityEvent Yes The activity event type.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#setaplmaxversion","text":"Notifies the Engine of the maximum APL version supported.","title":"SetAPLMaxVersion"},{"location":"modules/apl/aasb-docs/APL/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetAPLMaxVersion\" } }, \"payload\": { \"version\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_7","text":"Property Type Required Description Example version String Yes The maximum APL version supported.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#senduserevent","text":"Notifies the Engine that user generated an event.","title":"SendUserEvent"},{"location":"modules/apl/aasb-docs/APL/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendUserEvent\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_8","text":"Property Type Required Description Example payload String Yes The APL user event represented as a JSON string.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#senddatasourcefetchrequestevent","text":"Notifies the Engine of a data source fetch request.","title":"SendDataSourceFetchRequestEvent"},{"location":"modules/apl/aasb-docs/APL/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDataSourceFetchRequestEvent\" } }, \"payload\": { \"type\": {{String}}, \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_9","text":"Property Type Required Description Example type String Yes The type of data source fetch request. payload String Yes The APL user event represented as a JSON string.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#senddevicewindowstate","text":"Notifies the Engine of the current window state.","title":"SendDeviceWindowState"},{"location":"modules/apl/aasb-docs/APL/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDeviceWindowState\" } }, \"payload\": { \"state\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_10","text":"Property Type Required Description Example state String Yes JSON string representing the payload of the window state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/display-window.html#windowstate-context-object.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#senddocumentstate","text":"Notifies the Engine that APL runtime generated visual document state.","title":"SendDocumentState"},{"location":"modules/apl/aasb-docs/APL/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendDocumentState\" } }, \"payload\": { \"state\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_11","text":"Property Type Required Description Example state String Yes JSON string representing the payload of the rendered document state https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/presentation-apl.html#rendereddocumentstate.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#sendruntimeerrorevent","text":"Notifies the Engine that an APL runtime error occurred.","title":"SendRuntimeErrorEvent"},{"location":"modules/apl/aasb-docs/APL/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SendRuntimeErrorEvent\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_12","text":"Property Type Required Description Example payload String Yes The APL runtime error event represented as a JSON string.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#clearallexecutecommands","text":"Notifies the Engine that APL render finished clearing all commands.","title":"ClearAllExecuteCommands"},{"location":"modules/apl/aasb-docs/APL/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearAllExecuteCommands\" } } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#setplatformproperty","text":"Notifies the Engine of properties such as vehicle driving state, day/night mode, and custom theme id.","title":"SetPlatformProperty"},{"location":"modules/apl/aasb-docs/APL/#json-structure_14","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetPlatformProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_13","text":"Property Type Required Description Example name String Yes The name of the property to be set. value String Yes The value that the property will be set to.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#executecommandsresult","text":"Notifies the Engine of the command execution result.","title":"ExecuteCommandsResult"},{"location":"modules/apl/aasb-docs/APL/#json-structure_15","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ExecuteCommandsResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_14","text":"Property Type Required Description Example token String Yes The token associated with the commands. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#setdocumentidletimeout","text":"Notifies the Engine of the idle timeout value.","title":"SetDocumentIdleTimeout"},{"location":"modules/apl/aasb-docs/APL/#json-structure_16","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"SetDocumentIdleTimeout\" } }, \"payload\": { \"timeout\": {{int64}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_15","text":"Property Type Required Description Example timeout int64 Yes Idle timeout value in milliseconds.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#renderdocumentresult","text":"Notifies the Engine of command execution result.","title":"RenderDocumentResult"},{"location":"modules/apl/aasb-docs/APL/#json-structure_17","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"RenderDocumentResult\" } }, \"payload\": { \"token\": {{String}}, \"result\": {{Bool}}, \"error\": {{String}} } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#payload_16","text":"Property Type Required Description Example token String Yes The token associated with the APL document. result Bool Yes True if rendering was successful, otherwise false. error String Yes Error message if rendering failed, otherwise empty.","title":"Payload"},{"location":"modules/apl/aasb-docs/APL/#clearcard","text":"Notifies the Engine that APL render finished clearing document.","title":"ClearCard"},{"location":"modules/apl/aasb-docs/APL/#json-structure_18","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"APL\", \"action\": \"ClearCard\" } } }","title":"JSON Structure"},{"location":"modules/apl/aasb-docs/APL/#enums","text":"","title":"Enums"},{"location":"modules/apl/aasb-docs/APL/#activityevent","text":"","title":"ActivityEvent"},{"location":"modules/apl/aasb-docs/APL/#values","text":"Value Description \"ACTIVATED\" GUI switched to active state. \"DEACTIVATED\" GUI become inactive. \"ONE_TIME\" GUI processed one-time event (touch/scroll/etc). \"INTERRUPT\" Interrupt event (touch). \"UNKNOWN\" Guard option for unknown received state.","title":"Values"},{"location":"modules/bluetooth/","text":"Bluetooth Extension The Bluetooth extension allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features, such as Alexa Mobile Accessory (AMA) or Login with Phone, to users of Android or iOS smartphones. Table of Contents Requirements for Bluetooth Classic or BLE Bluetooth Classic BLE Choosing a Transport Protocol Supporting Bluetooth Classic Supporting BLE Registering the BluetoothProvider Platform Interface Sequence Diagrams Bluetooth Classic Connection BLE Connection Examples of Implementation Implementation for BluetoothProviderHandler Implementation for Bluetooth Classic Implementation for BLE Requirement for Accepting Connections from Another Device Requirements for Bluetooth Classic or BLE The variant of the Bluetooth standard determines the tasks required to support the client. Bluetooth Classic Complete the following tasks to support different clients: For Android phones, create a RFCOMM socket with the corresponding Service Discovery Protocol (SDP) record. (RFCOMM is a Bluetooth transport protocol.) For iOS phones, create an iOS Accessory Protocol 2 (iAP2) communication channel. For information about these tasks, see Supporting Bluetooth Classic . BLE Add a new Generic Attribute Profile (GATT) service and advertise the service. For information about this task, see Supporting BLE . Choosing a Transport Protocol Consider the following factors when choosing the protocol to use with Bluetooth: Capabilities and limitations of remote devices (e.g., Android or iOS phones) Capabilities of the Bluetooth software stack, which includes the system service, driver, and firmware (e.g., whether the software supports RFCOMM or iAP2) Capabilities of the Bluetooth chipset used on the head unit (e.g., single-mode or dual-mode) The following table shows the transport protocol to use based on the head unit chipset and the type of smartphone. Note: To use Bluetooth for Login With Phone, you must use RFCOMM as the transport protocol. Single-mode chipset Dual-mode chipset iOS phone iAP2 iAP2 or GATT Android phone RFCOMM RFCOMM or GATT Supporting Bluetooth Classic Follow one of these steps, depending on the transport protocol, to create a communication channel between the head unit and the phone: For RFCOMM communication, assign an unused RFCOMM channel to the head unit to listen on. The implementation must register an SDP record with the local SDP server, which is part of the Bluetooth software stack. The server contains the specified UUID, service name, and auto-assigned channel. Remote Bluetooth devices can use the same UUID to query the SDP server and discover the channel to connect to. The SDP record is removed when the socket is closed or if the application closes unexpectedly. Android clients discover the head unit by using the method that is described in BluetoothDevice.getUuids . For iAP2, allocate a communication channel with the specified protocol identifier. For information about iAP2, see the Accessory Interface Specification for Apple Devices. Supporting BLE In your implementation, create a new GATT service according to the JSON configuration specified in the GATTServer.start call. The following JSON shows a sample configuration: { \"characteristics\" : [ { \"id\" : \"A49921F7-9E7D-46F6-8832-9F44658892AC\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic TX\" , \"permissions\" : [ \"write\" ], \"properties\" : [ \"write\" ] }, { \"descriptors\" : [ { \"id\" : \"00002902-0000-1000-8000-00805f9b34fb\" , \"name\" : \"Configuration\" , \"permissions\" : [ \"read\" , \"write\" ] } ], \"id\" : \"34D7A574-5298-4C35-8109-1EAA2E9476E8\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic RX\" , \"permissions\" : [ \"read\" ], \"properties\" : [ \"notify\" , \"read\" ] } ] } Registering the BluetoothProvider Platform Interface For Linux and QNX, register the following C++ platform interface with the Auto SDK: class BluetoothProvider : public aace :: core :: PlatformInterface { /** * Create a GATT Server. * * @return the created GATT server. nullptr if GATT is not supported. */ virtual std :: shared_ptr < GATTServer > createGATTServer (); /** * Create an RFCOMM server socket and register the corresponding SDP record. * * @param name service name for SDP record * @param uuid uuid for SDP record * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingRfcomm ( const std :: string & name , const std :: string & uuid ); /** * Create an iAP2 server socket with specified protocol. * * @param protocol the protocol to use when communicating with the device * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingiAP2 ( const std :: string & protocol ); }; For Android, register the following Java platform interface with the Auto SDK: public abstract class BluetoothProvider extends PlatformInterface { public GATTServer createGATTServer () {...} public BluetoothServerSocket listenUsingRfcomm ( String name , String uuid ) {...} public BluetoothServerSocket listenUsingiAP2 ( String protocol ) {...} } Sequence Diagrams The sequence diagrams illustrate the flow for a Bluetooth Classic connection and the flow for a BLE connection. Bluetooth Classic Connection BLE Connection Examples of Implementation This section provides examples of implementation to support Bluetooth Classic and BLE on Android. Note: Amazon does not provide reference implementation for Linux and QNX. Implementation for BluetoothProviderHandler The following example shows the implementation for BluetoothProviderHandler , which is needed for either Bluetooth Classic or BLE connections: public class BluetoothProviderHandler extends BluetoothProvider { private final Activity mActivity ; private final LoggerHandler mLogger ; public BluetoothProviderHandler ( Activity activity , LoggerHandler logger ) { mActivity = activity ; mLogger = logger ; } @Override public GATTServer createGATTServer () { return new GATTServerHandler ( mActivity , mLogger ); } @Override public BluetoothServerSocket listenUsingRfcomm ( String name , String uuid ) { return new BluetoothServerSocketHandler ( mActivity , name , uuid ); } } Implementation for Bluetooth Classic The code samples in this section illustrate how to use BluetoothServerSocketHandler and BluetoothSocketHandler for Bluetooth Classic connections: public class BluetoothServerSocketHandler extends com . amazon . aace . bluetooth . BluetoothServerSocket { private static final String TAG = \"BluetoothSSHandler\" ; private BluetoothServerSocket mServerSocket ; BluetoothServerSocketHandler ( Context context , String name , String uuid ) throws IOException { BluetoothManager bluetoothManager = ( BluetoothManager ) context . getSystemService ( Context . BLUETOOTH_SERVICE ); BluetoothAdapter bluetoothAdapter = bluetoothManager . getAdapter (); mServerSocket = bluetoothAdapter . listenUsingRfcommWithServiceRecord ( name , UUID . fromString ( uuid )); } @Override public com . amazon . aace . bluetooth . BluetoothSocket accept () { try { return new BluetoothSocketHandler ( mServerSocket . accept ()); } catch ( IOException e ) { Log . e ( TAG , \"failed to accept incoming connection\" , e ); } return null ; } } Note: To create a listening, secure RFCOMM Bluetooth socket with an SDP record of a specified UUID, use listenUsingRfcommWithServiceRecord as described in the BluetoothAdapter documentation . The remote device connecting to this socket should be paired with the head unit first. public class BluetoothSocketHandler extends com . amazon . aace . bluetooth . BluetoothSocket { private static final String TAG = \"BluetoothSocketHandler\" ; BluetoothSocket mSocket ; BluetoothSocketHandler ( BluetoothSocket socket ) { mSocket = socket ; } @Override public int read ( byte [] data , int off , int len ) { try { return mSocket . getInputStream (). read ( data , off , len ); } catch ( IOException e ) { Log . e ( TAG , \"failed to read\" , e ); } return - 1 ; } @Override public void write ( byte [] data , int off , int len ) { try { mSocket . getOutputStream (). write ( data , off , len ); } catch ( IOException e ) { Log . e ( TAG , \"failed to write\" , e ); } } @Override public void close () { try { mSocket . close (); } catch ( IOException e ) { Log . e ( TAG , \"failed to close\" , e ); } } } Implementation for BLE The following example supports BLE connections: public class GATTServerHandler extends GATTServer { private static final String TAG = GATTServerHandler . class . getSimpleName (); private final Activity mActivity ; private final LoggerHandler mLogger ; private BluetoothManager mBluetoothManager ; private BluetoothGattServer mGattServer ; private BluetoothLeAdvertiser mAdvertiser ; private BluetoothDevice mBluetoothDevice ; public GATTServerHandler ( Activity activity , LoggerHandler logger ) { mActivity = activity ; mLogger = logger ; mBluetoothManager = ( BluetoothManager ) activity . getSystemService ( Context . BLUETOOTH_SERVICE ); } @Override public boolean start ( String configuration ) { // Open the GATT server mGattServer = mBluetoothManager . openGattServer ( mActivity , mGattServerCallback ); // Parse the json services specified in the config // ... // Add the services mGattServer . addService ( gattService ); // Start advertising the service mAdvertiser = BluetoothAdapter . getDefaultAdapter (). getBluetoothLeAdvertiser (); mAdvertiser . startAdvertising ( advertiseSettings . build (), advertiseData . build (), mAdvertisingCallback ); return true ; } @Override public boolean setCharacteristicValue ( String serviceId , String characteristicId , byte [] data ) { BluetoothGattCharacteristic characteristic = mGattServer . getService ( UUID . fromString ( serviceId )) . getCharacteristic ( UUID . fromString ( characteristicId )); characteristic . setValue ( data ); mGattServer . notifyCharacteristicChanged ( mBluetoothDevice , characteristic , false ); } @Override public boolean stop () {...} private final BluetoothGattServerCallback mGattServerCallback = new BluetoothGattServerCallback () { @Override public void onConnectionStateChange ( BluetoothDevice device , int status , int newState ) { switch ( newState ) { case BluetoothProfile . STATE_CONNECTED : mBluetoothDevice = device ; connectionStateChanged ( device . getAddress (), ConnectionState . CONNECTED ); break ; case BluetoothProfile . STATE_DISCONNECTED : mBluetoothDevice = null ; connectionStateChanged ( device . getAddress (), ConnectionState . DISCONNECTED ); break ; } } @Override public void onCharacteristicReadRequest ( BluetoothDevice device , int requestId , int offset , BluetoothGattCharacteristic characteristic ) { mGattServer . sendResponse ( device , requestId , BluetoothGatt . GATT_SUCCESS , offset , characteristic . getValue ()); } @Override public void onCharacteristicWriteRequest ( BluetoothDevice device , int requestId , BluetoothGattCharacteristic characteristic , boolean preparedWrite , boolean responseNeeded , int offset , byte [] value ) { // let the engine impl handle the request requestCharacteristic ( device . getAddress (), requestId , service . getUuid (). toString (), characteristic . getUuid (). toString (), value ); } } } You can determine the BLE advertising power level and frequency. The following values are recommended: AdvertiseSettings.ADVERTISE_MODE_BALANCED AdvertiseSettings.ADVERTISE_TX_POWER_MEDIUM Requirement for Accepting Connections from Another Device The Alexa app hosting either the GATT service or RFCOMM server socket must run in the background to accept connections from another device.","title":"Bluetooth Extension"},{"location":"modules/bluetooth/#bluetooth-extension","text":"The Bluetooth extension allows the Alexa Auto SDK to connect to devices through the Bluetooth Classic or Bluetooth Low Energy (BLE) protocol. Using these protocols, the Auto SDK can offer Bluetooth-based features, such as Alexa Mobile Accessory (AMA) or Login with Phone, to users of Android or iOS smartphones.","title":"Bluetooth Extension"},{"location":"modules/bluetooth/#table-of-contents","text":"Requirements for Bluetooth Classic or BLE Bluetooth Classic BLE Choosing a Transport Protocol Supporting Bluetooth Classic Supporting BLE Registering the BluetoothProvider Platform Interface Sequence Diagrams Bluetooth Classic Connection BLE Connection Examples of Implementation Implementation for BluetoothProviderHandler Implementation for Bluetooth Classic Implementation for BLE Requirement for Accepting Connections from Another Device","title":"Table of Contents"},{"location":"modules/bluetooth/#requirements-for-bluetooth-classic-or-ble","text":"The variant of the Bluetooth standard determines the tasks required to support the client.","title":"Requirements for Bluetooth Classic or BLE"},{"location":"modules/bluetooth/#bluetooth-classic","text":"Complete the following tasks to support different clients: For Android phones, create a RFCOMM socket with the corresponding Service Discovery Protocol (SDP) record. (RFCOMM is a Bluetooth transport protocol.) For iOS phones, create an iOS Accessory Protocol 2 (iAP2) communication channel. For information about these tasks, see Supporting Bluetooth Classic .","title":"Bluetooth Classic"},{"location":"modules/bluetooth/#ble","text":"Add a new Generic Attribute Profile (GATT) service and advertise the service. For information about this task, see Supporting BLE .","title":"BLE"},{"location":"modules/bluetooth/#choosing-a-transport-protocol","text":"Consider the following factors when choosing the protocol to use with Bluetooth: Capabilities and limitations of remote devices (e.g., Android or iOS phones) Capabilities of the Bluetooth software stack, which includes the system service, driver, and firmware (e.g., whether the software supports RFCOMM or iAP2) Capabilities of the Bluetooth chipset used on the head unit (e.g., single-mode or dual-mode) The following table shows the transport protocol to use based on the head unit chipset and the type of smartphone. Note: To use Bluetooth for Login With Phone, you must use RFCOMM as the transport protocol. Single-mode chipset Dual-mode chipset iOS phone iAP2 iAP2 or GATT Android phone RFCOMM RFCOMM or GATT","title":"Choosing a Transport Protocol"},{"location":"modules/bluetooth/#supporting-bluetooth-classic","text":"Follow one of these steps, depending on the transport protocol, to create a communication channel between the head unit and the phone: For RFCOMM communication, assign an unused RFCOMM channel to the head unit to listen on. The implementation must register an SDP record with the local SDP server, which is part of the Bluetooth software stack. The server contains the specified UUID, service name, and auto-assigned channel. Remote Bluetooth devices can use the same UUID to query the SDP server and discover the channel to connect to. The SDP record is removed when the socket is closed or if the application closes unexpectedly. Android clients discover the head unit by using the method that is described in BluetoothDevice.getUuids . For iAP2, allocate a communication channel with the specified protocol identifier. For information about iAP2, see the Accessory Interface Specification for Apple Devices.","title":"Supporting Bluetooth Classic"},{"location":"modules/bluetooth/#supporting-ble","text":"In your implementation, create a new GATT service according to the JSON configuration specified in the GATTServer.start call. The following JSON shows a sample configuration: { \"characteristics\" : [ { \"id\" : \"A49921F7-9E7D-46F6-8832-9F44658892AC\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic TX\" , \"permissions\" : [ \"write\" ], \"properties\" : [ \"write\" ] }, { \"descriptors\" : [ { \"id\" : \"00002902-0000-1000-8000-00805f9b34fb\" , \"name\" : \"Configuration\" , \"permissions\" : [ \"read\" , \"write\" ] } ], \"id\" : \"34D7A574-5298-4C35-8109-1EAA2E9476E8\" , \"mtu\" : 104 , \"name\" : \"Alexa Characteristic RX\" , \"permissions\" : [ \"read\" ], \"properties\" : [ \"notify\" , \"read\" ] } ] }","title":"Supporting BLE"},{"location":"modules/bluetooth/#registering-the-bluetoothprovider-platform-interface","text":"For Linux and QNX, register the following C++ platform interface with the Auto SDK: class BluetoothProvider : public aace :: core :: PlatformInterface { /** * Create a GATT Server. * * @return the created GATT server. nullptr if GATT is not supported. */ virtual std :: shared_ptr < GATTServer > createGATTServer (); /** * Create an RFCOMM server socket and register the corresponding SDP record. * * @param name service name for SDP record * @param uuid uuid for SDP record * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingRfcomm ( const std :: string & name , const std :: string & uuid ); /** * Create an iAP2 server socket with specified protocol. * * @param protocol the protocol to use when communicating with the device * @return the created server socket. nullptr if any error occurs. */ virtual std :: shared_ptr < BluetoothServerSocket > listenUsingiAP2 ( const std :: string & protocol ); }; For Android, register the following Java platform interface with the Auto SDK: public abstract class BluetoothProvider extends PlatformInterface { public GATTServer createGATTServer () {...} public BluetoothServerSocket listenUsingRfcomm ( String name , String uuid ) {...} public BluetoothServerSocket listenUsingiAP2 ( String protocol ) {...} }","title":"Registering the BluetoothProvider Platform Interface"},{"location":"modules/bluetooth/#sequence-diagrams","text":"The sequence diagrams illustrate the flow for a Bluetooth Classic connection and the flow for a BLE connection.","title":"Sequence Diagrams"},{"location":"modules/bluetooth/#bluetooth-classic-connection","text":"","title":"Bluetooth Classic Connection"},{"location":"modules/bluetooth/#ble-connection","text":"","title":"BLE Connection"},{"location":"modules/bluetooth/#examples-of-implementation","text":"This section provides examples of implementation to support Bluetooth Classic and BLE on Android. Note: Amazon does not provide reference implementation for Linux and QNX.","title":"Examples of Implementation"},{"location":"modules/bluetooth/#implementation-for-bluetoothproviderhandler","text":"The following example shows the implementation for BluetoothProviderHandler , which is needed for either Bluetooth Classic or BLE connections: public class BluetoothProviderHandler extends BluetoothProvider { private final Activity mActivity ; private final LoggerHandler mLogger ; public BluetoothProviderHandler ( Activity activity , LoggerHandler logger ) { mActivity = activity ; mLogger = logger ; } @Override public GATTServer createGATTServer () { return new GATTServerHandler ( mActivity , mLogger ); } @Override public BluetoothServerSocket listenUsingRfcomm ( String name , String uuid ) { return new BluetoothServerSocketHandler ( mActivity , name , uuid ); } }","title":"Implementation for BluetoothProviderHandler"},{"location":"modules/bluetooth/#implementation-for-bluetooth-classic","text":"The code samples in this section illustrate how to use BluetoothServerSocketHandler and BluetoothSocketHandler for Bluetooth Classic connections: public class BluetoothServerSocketHandler extends com . amazon . aace . bluetooth . BluetoothServerSocket { private static final String TAG = \"BluetoothSSHandler\" ; private BluetoothServerSocket mServerSocket ; BluetoothServerSocketHandler ( Context context , String name , String uuid ) throws IOException { BluetoothManager bluetoothManager = ( BluetoothManager ) context . getSystemService ( Context . BLUETOOTH_SERVICE ); BluetoothAdapter bluetoothAdapter = bluetoothManager . getAdapter (); mServerSocket = bluetoothAdapter . listenUsingRfcommWithServiceRecord ( name , UUID . fromString ( uuid )); } @Override public com . amazon . aace . bluetooth . BluetoothSocket accept () { try { return new BluetoothSocketHandler ( mServerSocket . accept ()); } catch ( IOException e ) { Log . e ( TAG , \"failed to accept incoming connection\" , e ); } return null ; } } Note: To create a listening, secure RFCOMM Bluetooth socket with an SDP record of a specified UUID, use listenUsingRfcommWithServiceRecord as described in the BluetoothAdapter documentation . The remote device connecting to this socket should be paired with the head unit first. public class BluetoothSocketHandler extends com . amazon . aace . bluetooth . BluetoothSocket { private static final String TAG = \"BluetoothSocketHandler\" ; BluetoothSocket mSocket ; BluetoothSocketHandler ( BluetoothSocket socket ) { mSocket = socket ; } @Override public int read ( byte [] data , int off , int len ) { try { return mSocket . getInputStream (). read ( data , off , len ); } catch ( IOException e ) { Log . e ( TAG , \"failed to read\" , e ); } return - 1 ; } @Override public void write ( byte [] data , int off , int len ) { try { mSocket . getOutputStream (). write ( data , off , len ); } catch ( IOException e ) { Log . e ( TAG , \"failed to write\" , e ); } } @Override public void close () { try { mSocket . close (); } catch ( IOException e ) { Log . e ( TAG , \"failed to close\" , e ); } } }","title":"Implementation for Bluetooth Classic"},{"location":"modules/bluetooth/#implementation-for-ble","text":"The following example supports BLE connections: public class GATTServerHandler extends GATTServer { private static final String TAG = GATTServerHandler . class . getSimpleName (); private final Activity mActivity ; private final LoggerHandler mLogger ; private BluetoothManager mBluetoothManager ; private BluetoothGattServer mGattServer ; private BluetoothLeAdvertiser mAdvertiser ; private BluetoothDevice mBluetoothDevice ; public GATTServerHandler ( Activity activity , LoggerHandler logger ) { mActivity = activity ; mLogger = logger ; mBluetoothManager = ( BluetoothManager ) activity . getSystemService ( Context . BLUETOOTH_SERVICE ); } @Override public boolean start ( String configuration ) { // Open the GATT server mGattServer = mBluetoothManager . openGattServer ( mActivity , mGattServerCallback ); // Parse the json services specified in the config // ... // Add the services mGattServer . addService ( gattService ); // Start advertising the service mAdvertiser = BluetoothAdapter . getDefaultAdapter (). getBluetoothLeAdvertiser (); mAdvertiser . startAdvertising ( advertiseSettings . build (), advertiseData . build (), mAdvertisingCallback ); return true ; } @Override public boolean setCharacteristicValue ( String serviceId , String characteristicId , byte [] data ) { BluetoothGattCharacteristic characteristic = mGattServer . getService ( UUID . fromString ( serviceId )) . getCharacteristic ( UUID . fromString ( characteristicId )); characteristic . setValue ( data ); mGattServer . notifyCharacteristicChanged ( mBluetoothDevice , characteristic , false ); } @Override public boolean stop () {...} private final BluetoothGattServerCallback mGattServerCallback = new BluetoothGattServerCallback () { @Override public void onConnectionStateChange ( BluetoothDevice device , int status , int newState ) { switch ( newState ) { case BluetoothProfile . STATE_CONNECTED : mBluetoothDevice = device ; connectionStateChanged ( device . getAddress (), ConnectionState . CONNECTED ); break ; case BluetoothProfile . STATE_DISCONNECTED : mBluetoothDevice = null ; connectionStateChanged ( device . getAddress (), ConnectionState . DISCONNECTED ); break ; } } @Override public void onCharacteristicReadRequest ( BluetoothDevice device , int requestId , int offset , BluetoothGattCharacteristic characteristic ) { mGattServer . sendResponse ( device , requestId , BluetoothGatt . GATT_SUCCESS , offset , characteristic . getValue ()); } @Override public void onCharacteristicWriteRequest ( BluetoothDevice device , int requestId , BluetoothGattCharacteristic characteristic , boolean preparedWrite , boolean responseNeeded , int offset , byte [] value ) { // let the engine impl handle the request requestCharacteristic ( device . getAddress (), requestId , service . getUuid (). toString (), characteristic . getUuid (). toString (), value ); } } } You can determine the BLE advertising power level and frequency. The following values are recommended: AdvertiseSettings.ADVERTISE_MODE_BALANCED AdvertiseSettings.ADVERTISE_TX_POWER_MEDIUM","title":"Implementation for BLE"},{"location":"modules/bluetooth/#requirement-for-accepting-connections-from-another-device","text":"The Alexa app hosting either the GATT service or RFCOMM server socket must run in the background to accept connections from another device.","title":"Requirement for Accepting Connections from Another Device"},{"location":"modules/car-control/","text":"Car Control Module Table of Contents Overview Endpoints Capabilities Zones Assets Configuring the Car Control Module Configuration Schema Overview Power Controller Capability Configuration Toggle Controller Capability Configuration Mode Controller Capability Configuration Range Controller Capability Configuration Additional Notes about Assets Sample Configuration Using the Car Control Module AASB Messages Changing the power state of an endpoint Toggling an endpoint property Changing the mode of an endpoint property Changing the numeric setting of an endpoint property Integrating the Car Control Module Into Your Application Overview The Alexa Auto SDK Car Control module enables you to build a custom experience that allows users to use Alexa to voice-control vehicle features. The following concepts comprise the Car Control module APIs: Endpoints The head unit device acting as an Alexa Auto SDK client is an \"endpoint\" that connects to the Alexa service. Other Auto SDK modules, such as Alexa , configure capabilities on this \"root\" or \"default\" endpoint because the capabilities pertain to the head unit itself. The Car Control module enables the default Auto SDK client endpoint to act as a proxy to receive events and directives on behalf of connected endpoints. You can configure a separate endpoint for every vehicle component that the head unit can control through device-level connections. This enables the user to target individual vehicle components directly with utterances like \"Alexa, turn on the AC\" or \"Alexa, set the temperature to 65.\" Capabilities In the utterance \"Alexa, turn on the AC\", \"turn on\" corresponds to a specific capability configured for the \"AC\" endpoint. Defining an endpoint declares a vehicle feature to be controllable, and defining capabilities on the endpoint declares how the endpoint can be controlled. Car Control supports four capability interfaces that can be declared alone or in combination for a particular endpoint to model its individual control experience: Power Controller controls the overall power state of an endpoint. For example, configuring an \"AC\" endpoint with a Power Controller capability enables utterances such as \"Alexa, turn on the AC\" and \"Alexa, power off the AC\". Toggle Controller controls a particular named property of an endpoint that can be turned on and off. For example, configuring a \"windshield\" endpoint with a \"defroster\" Toggle Controller capability instance enables utterances such as \"Alexa, turn on the windshield defroster.\" Mode Controller controls a particular named property of an endpoint that can be set to a discrete value from a defined set of values. For example, if an ambient light endpoint has red and green color settings, configuring an \"ambient light\" endpoint with a \"color\" Mode Controller capability instance enables utterances such as \"Alexa, set the ambient light color to red\" and \"Alexa, change the ambient light to green.\" Range Controller controls a particular named property of an endpoint that can be set to a numeric value within a range. For example, if a fan endpoint has a speed property with settings 1 through 3, configuring a \"fan\" endpoint with a \"speed\" Range Controller capability instance enables utterances such as \"Alexa, set the fan speed to 2.\" You can configure names, such as \"medium\", for a range value to enable additional utterances such as \"Alexa, set the fan to medium\" to set the fan speed setting to 2. Capability Primitives and Semantic Annotations Toggle Controller, Mode Controller, and Range Controller are known as \"capability primitives.\" You can use multiple instances of the same capability primitive interface on an endpoint under different instance names. For example, a heater endpoint might have intensity and position properties that are both best modeled as modes. You can declare an \"intensity\" Mode Controller instance and a \"position\" Mode Controller instance on the same \"heater\" endpoint so the user can target each property separately. To provide intuitive experiences for users, capability primitives offer \"semantic annotations\" for the devices to map specific utterances to the behaviors of capability instances. For example, if the vehicle uses a Range Controller to control a window, a user would prefer to say \"Alexa, open the window\" over the default utterances of the Range Controller such as \"Alexa, set the window height to 0\". For any endpoint to which the \"open\", \"close\", \"raise\", or \"lower\" concepts apply, you can configure the capability primitive instances of the endpoint with a \"semantics\" object that maps user utterances for these actions to the appropriate capability directives. Each action (e.g., \"open\") is allowed only once per endpoint since the action expresses intent to control the endpoint as a whole. The actions specified in configuration are action IDs rather than literal strings, which ensures Alexa recognizes all synonyms and translations for the action in the user utterance. The supported actions are \"Alexa.Actions.Open\", \"Alexa.Actions.Close\", \"Alexa.Actions.Raise\", and \"Alexa.Actions.Lower.\" Zones Each endpoint can belong to zero, one, or many \"zones.\" Zones, configured with member endpoints, define named regions of the vehicle and allow users to target endpoints by location. Zones are essential for unambiguous targeting of endpoints that have friendly names that overlap with other endpoints. For example, defining \"driver\" and \"passenger\" zones and assigning distinct \"seat\" endpoints to each allows proper control of the \"driver seat\" and the \"passenger seat\" independently. Assigning one zone in particular as the \"default\" enables endpoints in this zone to take precedence over endpoints sharing the same friendly name but not in the default zone when the user does not specify a zone in the utterance. This is useful for distinguishing \"zoneless\" endpoints from \"zoned\" endpoints with the same name when it is most likely that the user intends to target the \"zoneless\" one. For example, consider a vehicle with zone IDs \"zone.all\", \"zone.rear\", and \"zone.left\" with a distinct fan endpoint in each zone. If the user says \"Alexa, turn on the fan\", it is most likely that he wants to turn on the fan that refers to the vehicle as a whole because there is no natural way to specify its location. You can ensure that Alexa will resolve this utterance to the fan in the \"all\" zone by assigning \"zone.all\" as the default zone. Additionally, the default zone is useful for cases in which you have zoned endpoints with overlapping names, but one of the endpoints is a clear \"default\" to the user. For example, consider a vehicle with zones \"zone.all\" (assigned as default), \"zone.driver\", and \"zone.passenger\". The vehicle has a \"driver window\" in \"zone.driver\" and a \"passenger window\" in \"zone.passenger\", but Alexa cannot resolve which endpoint is the intended target of the user utterance \"Alexa, open the window.\" However, the user probably means \"Alexa, open the driver window\". You can ensure that Alexa considers the \"driver window\" as the \"default\" window by assigning it to \"zone.all\" as well. Assets The definitions of endpoints, capabilities, and zones include \"assets.\" Assets, identified by unique IDs, group a voice-accessible friendly name like \"air conditioner\" into a named group of synonyms and translations for all supported languages. For example, using the asset with ID \"Alexa.Automotive.DeviceName.AirConditioner\" in your car control module configuration for an AC endpoint not only enables the user to target the air conditioner with the default phrase \"air conditioner\", but also with phrases like \"air con\" and \"AC\" in English as well as synonyms in other supported locales. Using assets allows decoupling the many ways of identifying components from the core configuration of the components and enables de-duplication across different components that have overlapping ways to be identified. The Alexa Auto SDK provides a list of IDs for the \"default assets,\" which form an automotive-specific catalog. The catalog contains asset definitions for supported car control features, including endpoint names, zone names, and capability settings. Each default asset ID is prefixed with \"Alexa.Automotive.\" You can use these asset IDs in your Car Control module configuration without the corresponding definitions of friendly names, synonyms, and translations, because the definitions are specified in the Alexa cloud. Configuring the Car Control Module Car Control module configuration is vehicle-specific and tells the Auto SDK Engine which vehicle features to advertise to Alexa for control by the user. You must configure the Auto SDK Engine with an EngineConfiguration object that describes the vehicle. Like all Auto SDK Engine configuration, you can either define the JSON in a file and construct an EngineConfiguration from that file, or you can use the provided CarControlConfiguration class to programmatically construct the EngineConfiguration in the proper format. The following subsections describe the JSON schema. See the CarControlConfiguration class for details on how to build configuration programmatically. Configuration Schema Overview The Engine configuration for the Car Control module includes definitions of endpoints with their capabilities, zones with their member endpoints, and an optional path to a JSON file defining additional assets. Sample JSON Object { \"aace.carControl\": { \"endpoints\": [ { \"endpointId\": \"{{STRING}}\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"capabilities\": [ // list of capability definitions for this endpoint ] } ], \"zones\": [ { \"zoneID\": \"{{STRING}}\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] }, \"members\": [ { \"endpointId\": \"{{STRING}}\" } ] } ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Object Parameters Property Type Required Description aace.carControl. endpoints list Yes The list of connected endpoints for which the device implements capabilities. Each endpoint describes one controllable vehicle component. aace.carControl. endpoints[i]. endpointId string Yes The identifier for the endpoint, unique amongst all endpoints in the vehicle. The same endpointId is used to identify the endpoint targeted in an AASB message sent by the Engine. Note: Do not use this format for the endpointId : \\<clientId>::\\<productId>::\\<serialNumber>::[-\\<extEndpoint>] The Engine internally prepends the 3-part device prefix to your specified endpointId before sending the configuration to Alexa. Configuring the full ID directly results in duplication and excess characters. aace.carControl. endpoints[i]. endpointResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this endpoint. Note: Only \u201casset\u201d type labels are supported. aace.carControl. endpoints[i]. endpointResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to the endpoint. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. endpoints[i]. capabilities list Yes A list of capability definitions, representing capabilities implemented by the device on behalf of the endpoint, that define how the endpoint can be controlled by the user. Each object in this list must be a valid definition for one of the capabilities supported by the Car Control module: Alexa.PowerController , Alexa.ToggleController , Alexa.ModeController , and Alexa.RangeController aace.carControl. zones list No, but recommended A list of zone definitions for the named regions in the vehicle. aace.carControl. zones[i]. zoneId string Yes The identifier for the zone, unique amongst all zones in the vehicle. aace.carControl. zones[i]. zoneResources. friendlyNames list Yes A list of label objects that describe the possible ways to refer to this zone. Note: Only \u201casset\u201d type labels are supported. aace.carControl. zones[i]. zoneResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of strings used to refer to the zone in all supported locales. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. zones[i]. members list Yes A list of endpoints that belong to this zone. aace.carControl. zones[i]. members[j]. endpointId string Yes The endpointId for an endpoint that belongs to this zone. aace.carControl. defaultZoneId string No, but recommended The zoneId of the default zone. Endpoints in this zone take precedence when a user utterance does not specify a zone. It is recommended to use a zone that describes the whole vehicle as the default rather than a zone describing a specific region. aace.carControl. assets.customAssetsPath string (file path) No Specifies the path to a JSON file defining additional assets. Power Controller Capability Configuration Click to expand or collapse description See [\"Alexa.PowerController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-powercontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.PowerController\", \"version\": \"3\", \"properties\": { \"supported\": [ { \"name\": \"powerState\" } ], \"proactivelyReported\": false, \"retrievable\": false } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"powerState\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"powerState\") can be retrieved by Alexa. **Accepted values:** `false` | Toggle Controller Capability Configuration Click to expand or collapse description See [\"Alexa.ToggleController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-togglecontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ToggleController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"proactivelyReported\": false, \"retrievable\": false, \"supported\": [ { \"name\": \"toggleState\" } ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {} } }, ... ] } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | instance | string | Yes | The identifier of this instance of Alexa.ToggleController on this endpoint. | | capabilityResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. **Note:** Only `\u201casset\u201d` type labels are supported. | | capabilityResources. friendlyNames[i]. assetId | string | Yes | The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at `aace.carControl.assets.customAssetsPath`. See the [\"Additional Notes about Assets\" section](#additional-notes-about-assets) for more details. | | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"toggleState\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"toggleState\") can be retrieved by Alexa. **Accepted values:** `false` | | semantics | object | No | Semantic annotations that enable mapping user utterances with directives targeting this capability instance. **Note:** `semantics.stateMappings` is not supported. | | semantics. actionMappings[i]. actions[j] | string | Yes, if `semantics` is present | The identifiers of the utterances that should trigger the specified directive. **Accepted values:** `\"Alexa.Actions.Open\"`: \"open {endpoint}\" `\"Alexa.Actions.Close\"`: \"close {endpoint}\" `\"Alexa.Actions.Raise\"`: \"raise {endpoint}\" `\"Alexa.Actions.Lower\"`: \"lower {endpoint}\" | | semantics. actionMappings[i]. directive. name | string | Yes, if `semantics` is present | **Accepted values:** `\"TurnOn\"`: The specified `actions` will trigger the \"TurnOn\" directive. The Engine will publish the `SetToggleControllerValue` message, with the `turnOn` attribute set to `true`. `\"TurnOff\"`: The specified `actions` will trigger the \"TurnOff\" directive. The Engine will publish the `SetToggleControllerValue` message, with the `turnOn` attribute set to `false`. | Mode Controller Capability Configuration Click to expand or collapse description See [\"Alexa.ModeController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-modecontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ModeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"mode\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"ordered\": {{BOOLEAN}}, \"supportedModes\": [ { \"value\": \"{{STRING}}\", \"modeResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] } }, ... ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | instance | string | Yes | The identifier of this instance of Alexa.ModeController on this endpoint. | | capabilityResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. **Note:** Only `\u201casset\u201d` type labels are supported. | | capabilityResources. friendlyNames[i]. assetId | string | Yes | The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at `aace.carControl.assets.customAssetsPath`. See the [\"Additional Notes about Assets\" section](#additional-notes-about-assets) for more details. | | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"mode\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"mode\") can be retrieved by Alexa. **Accepted values:** `false` | | configuration. ordered | boolean | Yes | Whether the modes of this capability instance are ordered, enabling iteration through them using the \"AdjustMode\" directive. | | configuration. supportedModes | list | Yes | A list of objects describing the available modes of this capability instance. If `ordered` is true, the order of the objects in this list implies the ordering of the modes. | | configuration. supportedModes[i]. value | string | Yes | The identifier of this mode on this capability instance. | | configuration. supportedModes[i]. modeResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this mode. **Note:** Only `\u201casset\u201d` type labels are supported. | | semantics | object | No | Semantic annotations that enable mapping user utterances with directives targeting this capability instance. **Note:** `semantics.stateMappings` is not supported. | | semantics. actionMappings[i]. actions[j] | string | Yes, if `semantics` is present | The identifiers of the utterances that should trigger the specified directive. **Accepted values:** `\"Alexa.Actions.Open\"`: \"open {endpoint}\" `\"Alexa.Actions.Close\"`: \"close {endpoint}\" `\"Alexa.Actions.Raise\"`: \"raise {endpoint}\" `\"Alexa.Actions.Lower\"`: \"lower {endpoint}\" | | semantics. actionMappings[i]. directive. name | string | Yes, if `semantics` is present | **Accepted values:** `\"SetMode\"`: The specified actions will trigger the \"SetMode\" directive with the specified `payload`. The Engine will publish the `SetModeControllerValue` message. `\"AdjustMode\"`: The specified actions will trigger the \"AdjustMode\" directive with the specified `payload`. The Engine will publish the `AdjustModeControllerValue` message. \"AdjustMode\" is accepted only if this capability instance is `ordered`. | | semantics. actionMappings[i]. directive. payload | object | Yes, if `semantics` is present | If `name` is \u201cSetMode\u201d, this is the \u201cSetMode\u201d directive payload object that contains the \u201cmode\u201d property and the corresponding value from `configuration.supportedModes[].value`. If `name` is \u201cAdjustMode\u201d, this is the \u201cAdjustMode\u201d directive payload object that contains the \u201cmodeDelta\u201d field and the corresponding number of modes to advance. | Range Controller Capability Configuration Click to expand or collapse description See [\"Alexa.RangeController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-rangecontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.RangeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"rangeValue\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"supportedRange\": { \"minimumValue\": {{LONG}}, \"maximumValue\": {{LONG}}, \"precision\": {{LONG}} }, \"unitOfMeasure\": \"{{STRING}}\", \"presets\": [ { \"rangeValue\": {{LONG}}, \"presetResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] } }, ... ], \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | instance | string | Yes | The identifier of this instance of Alexa.RangeController on this endpoint. | | capabilityResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. **Note:** Only `\u201casset\u201d` type labels are supported. | | capabilityResources. friendlyNames[i]. assetId | string | Yes | The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at `aace.carControl.assets.customAssetsPath`. See the [\"Additional Notes about Assets\" section](#additional-notes-about-assets) for more details. | | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be retrieved by Alexa. **Accepted values:** `false` | | configuration. supportedRange. minimumValue | long | Yes | The minimum value of the range this capability instance supports. | | configuration. supportedRange. maximumValue | long | Yes | The maximum value of the range this capability instance supports. | | configuration. supportedRange. precision | long | Yes | The amount by which the set value changes when iterating through the range. For example, if a user asks Alexa to increase the value but doesn't specify by how much, this value will be used. | | configuration. unitOfMeasure | string | No | The unit of measure for the range. | | configuration. presets | list | Yes | A list of objects describing values that can be invoked by name. For example, a `rangeValue` of 10 might be configured as the \"high\" preset. | | configuration. presets[i]. rangeValue | long | Yes | The value within the `supportedRange` that has an associated named preset. | | configuration. presets[i]. presetResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this preset. **Note:** Only `\u201casset\u201d` type labels are supported. | | semantics | object | No | Semantic annotations that enable mapping user utterances with directives targeting this capability instance. **Note:** `semantics.stateMappings` is not supported. | | semantics. actionMappings[i]. actions[j] | string | Yes, if `semantics` is present | The identifiers of the utterances that should trigger the specified directive. **Accepted values:** `\"Alexa.Actions.Open\"`: \"open {endpoint}\" `\"Alexa.Actions.Close\"`: \"close {endpoint}\" `\"Alexa.Actions.Raise\"`: \"raise {endpoint}\" `\"Alexa.Actions.Lower\"`: \"lower {endpoint}\" | | semantics. actionMappings[i]. directive. name | string | Yes, if `semantics` is present | **Accepted values:** `\"SetRangeValue\"`: The specified actions will trigger the \"SetRangeValue\" directive with the specified `payload`. The Engine will publish the `SetRangeControllerValue` message. `\"AdjustRangeValue\"`: The specified actions will trigger the \"AdjustRangeValue\" directive with the specified `payload`. The Engine will publish the `AdjustRangeControllerValue` message. | | semantics. actionMappings[i]. directive. payload | object | Yes, if `semantics` is present | If `name` is \u201cSetRangeValue\u201d, this is the \u201cSetRangeValue\u201d directive payload object that contains the \"rangeValue\" property and the corresponding value between `configuration.supportedRange.minumumValue` and `configuration.supportedRange.maximumValue`. If `name` is \u201cAdjustRangeValue\u201d, this is the \u201cAdjustRangeValue\u201d directive payload object that contains the \u201crangeValueDelta\u201d field. | Additional Notes about Assets The Car Control module provides the full list of asset IDs available in the default automotive catalog of assets in the CarControlAssets.h header file, which defines string constants for these asset IDs to be used when constructing configuration programmatically. The values of the constants are the same asset IDs that you should use if you construct your configuration in a JSON file. This module also provides a reference JSON file with sample definitions of the assets in the automotive catalog. Your implementation does not need to duplicate these asset definitions or specify the path to this file because the definitions also exist in the Alexa cloud. This copy of the file is a reference for you to see the synonyms and translations for the available assets. Note: Because the actual asset definitions are defined in the Alexa cloud, this reference file may be outdated or missing translations. The automotive catalog of assets defines assets for every feature officially supported by car control. The majority of your configuration will use these asset IDs. Amazon recommends that you not create new, custom assets for features that already exist in the default catalog. However, if your vehicle has a feature that cannot be described using the default assets (e.g., an endpoint with a proprietary name), create an additional JSON file defining a complementary set of assets to use alongside the default catalog. The format of this file must follow the same schema as the reference default assets JSON , and the definitions must include entries for each of the locales supported in the default catalog. Prefix every assetId in this file with \"My.\" , and specify the path to the file in the optional aace.carControl.assets.customAssetsPath field of configuration. Note for LVC: When using Local Voice Control and car control custom assets, there are two distinct configurations \u2014 the Auto SDK Engine and the LVC app \u2014 that require the path to the custom assets definition file. See the below subsections for details for this configuration on Linux or Android. (Local Voice Control) Custom Assets for Linux Integration The default LVC app configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the aace.carControl.assets.customAssetsPath field in the Car Control module configuration. (Local Voice Control) Custom Assets for Android Integration Local Voice Control Android integrations using the LVC APK implement the ILVCClient interface to configure Local Voice Control in the LVC APK (See the LVC extension documentation for more details). The \"CarControl.CustomAssetsFilePath\" field of the ILVCClient.getConfiguration() configuration schema specifies a path to the custom assets definition file, which must be accessible to the processes running the LVC APK services. When you integrate with AACS, you do not need to provide the CarControl.CustomAssetsFilePath field in any AACS configuration message; instead, your application should directly share permissions to the custom assets definition file using the AACS file sharing protocol. AACS will create a local copy of the file and use the path to its local copy to configure the LVC APK. Sample Configuration The Car Control module provides a sample JSON file to configure the Auto SDK Engine with a vehicle fully equipped for every use case officially supported for car control. This file models each supported endpoint with a configuration of capabilities and zones that ensures all supported utterances for that endpoint work as expected. It is recommended that you construct the configuration for your application by selecting the parts of this sample that describe features supported by your vehicle. Make adjustments to the endpoints, such as modifying modes and range settings, as needed. Configuration for Linux Integration If your implementation constructs the Car Control module EngineConfiguration programmatically rather than with a JSON file, see the following example usage of the aace::carControl::config::CarControlConfiguration builder class that produces the same fully-equipped vehicle as the sample file: Click to expand or collapse CarControlConfiguration C++ sample code #include <AACE/CarControl/CarControlAssets.h> using namespace aace :: carControl :: config ; using namespace aace :: carControl :: assets ; // Auto SDK Engine configuration std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configuration ; auto config = aace :: carControl :: config :: CarControlConfiguration :: create (); config -> createZone ( \"zone.default\" ) . addAssetId ( alexa :: location :: ALL ) . addMembers ({ \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }) . createZone ( \"zone.driver\" ) . addAssetId ( alexa :: location :: DRIVER ) . addAssetId ( alexa :: location :: FRONT_LEFT ) . addMembers ({ \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }) . createZone ( \"zone.passenger\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addAssetId ( alexa :: location :: FRONT_RIGHT ) . addMembers ({ \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }) . createZone ( \"zone.front\" ) . addAssetId ( alexa :: location :: FRONT ) . addMembers ({ \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }) . createZone ( \"zone.rear\" ) . addAssetId ( alexa :: location :: REAR ) . addMembers ({ \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }) . createZone ( \"zone.left\" ) . addAssetId ( alexa :: location :: LEFT ) . addMembers ({ \"left.heater\" , \"driver.seat\" , \"driver.vent\" }) . createZone ( \"zone.right\" ) . addAssetId ( alexa :: location :: RIGHT ) . addMembers ({ \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }) . createZone ( \"zone.rear.driver\" ) . addAssetId ( alexa :: location :: REAR_DRIVER ) . addAssetId ( alexa :: location :: REAR_LEFT ) . addMembers ({ \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }) . createZone ( \"zone.rear.passenger\" ) . addAssetId ( alexa :: location :: REAR_PASSENGER ) . addAssetId ( alexa :: location :: REAR_RIGHT ) . addMembers ({ \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }) . createZone ( \"zone.secondRow\" ) . addAssetId ( alexa :: location :: SECOND_ROW ) . addMembers ({ \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }) . createZone ( \"zone.thirdRow\" ) . addAssetId ( alexa :: location :: THIRD_ROW ) . addMembers ({ \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }) . setDefaultZone ( \"zone.default\" ) // \"Car\" . createEndpoint ( \"car\" ) . addAssetId ( alexa :: device :: CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( alexa :: value :: INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( alexa :: value :: OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( alexa :: setting :: CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( alexa :: setting :: DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( alexa :: value :: COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( alexa :: value :: SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( alexa :: value :: SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( alexa :: setting :: TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( alexa :: setting :: HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( alexa :: setting :: WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( alexa :: setting :: AUTO_BRAKE_HOLD ) // Ambient Light . createEndpoint ( \"ambient.light\" ) . addAssetId ( alexa :: device :: AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( alexa :: setting :: COLOR ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"RED\" ) . addAssetId ( alexa :: color :: RED ) . addValue ( \"BLUE\" ) . addAssetId ( alexa :: color :: BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( alexa :: color :: GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( alexa :: color :: WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( alexa :: color :: ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( alexa :: color :: YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( alexa :: color :: INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( alexa :: color :: VIOLET ) // Air Conditioner . createEndpoint ( \"default.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Air Conditioner . createEndpoint ( \"front.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Air Conditioner . createEndpoint ( \"rear.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Fan . createEndpoint ( \"default.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Fan . createEndpoint ( \"driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Fan . createEndpoint ( \"passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Fan . createEndpoint ( \"front.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Fan . createEndpoint ( \"rear.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Driver Fan . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Passenger Fan . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Fan . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Fan . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Vent . createEndpoint ( \"default.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Driver Vent . createEndpoint ( \"driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Passenger Vent . createEndpoint ( \"passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Front Vent . createEndpoint ( \"front.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Vent . createEndpoint ( \"rear.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Driver Vent . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Passenger Vent . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Second Row Vent . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Third Row Vent . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Climate Control . createEndpoint ( \"climatecontrol\" ) . addAssetId ( alexa :: device :: CLIMATE_CONTROL ) . addAssetId ( alexa :: setting :: AUTO ) . addPowerController ( false ) // Heater . createEndpoint ( \"default.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Heater . createEndpoint ( \"driver.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Heater . createEndpoint ( \"passenger.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Left Heater . createEndpoint ( \"left.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Right Heater . createEndpoint ( \"right.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Heater . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Heater . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Light . createEndpoint ( \"default.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Driver Light . createEndpoint ( \"driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Passenger Light . createEndpoint ( \"passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Front Light . createEndpoint ( \"front.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Light . createEndpoint ( \"rear.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Driver Light . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Passenger Light . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Second Row Light . createEndpoint ( \"secondRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Third Row Light . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Reading Light . createEndpoint ( \"default.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Reading Light . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Passenger Reading Light . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Front Reading Light . createEndpoint ( \"front.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Reading Light . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Driver Reading Light . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Passenger Reading Light . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Second Row Reading Light . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Third Row Reading Light . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Cupholder . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Passenger Cupholder . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Front Cupholder . createEndpoint ( \"front.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Cupholder . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Driver Cupholder . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Passenger Cupholder . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Second Row Cupholder . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Third Row Cupholder . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Driver Armrest . createEndpoint ( \"driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Passenger Armrest . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Front Armrest . createEndpoint ( \"front.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Armrest . createEndpoint ( \"rear.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Driver Armrest . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Passenger Armrest . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Second Row Armrest . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Third Row Armrest . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Driver Seat . createEndpoint ( \"driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Passenger Seat . createEndpoint ( \"passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Seat . createEndpoint ( \"front.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Seat . createEndpoint ( \"rear.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Driver Seat . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Passenger Seat . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Second Row Seat . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Third Row Seat . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Window . createEndpoint ( \"front.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Window . createEndpoint ( \"rear.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Driver Window . createEndpoint ( \"driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Passenger Window . createEndpoint ( \"passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Driver Window . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Passenger Window . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Second Row Window . createEndpoint ( \"secondRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Third Row Window . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Front Windshield . createEndpoint ( \"front.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Rear Windshield . createEndpoint ( \"rear.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Front Foglight . createEndpoint ( \"front.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Rear Foglight . createEndpoint ( \"rear.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Hazard Light . createEndpoint ( \"hazardlight\" ) . addAssetId ( alexa :: device :: HAZARD_LIGHTS ) . addAssetId ( alexa :: device :: PARKING_LIGHTS ) . addPowerController ( false ) // Front Wipers . createEndpoint ( \"front.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Wipers . createEndpoint ( \"rear.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Sunroof . createEndpoint ( \"sunroof\" ) . addAssetId ( alexa :: device :: SUNROOF ) . addAssetId ( alexa :: device :: MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // Sunshade . createEndpoint ( \"sunshade\" ) . addAssetId ( alexa :: device :: SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // HUD . createEndpoint ( \"hud\" ) . addAssetId ( alexa :: device :: HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: HUD ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // IVI . createEndpoint ( \"ivi\" ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( alexa :: value :: OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Dynamics Coordinator Page . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Performance Page . createEndpoint ( \"performancePage\" ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Home Page . createEndpoint ( \"homepage\" ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Bluetooth Page . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Radio Page . createEndpoint ( \"radioPage\" ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Settings Page . createEndpoint ( \"settingsPage\" ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Controls Page . createEndpoint ( \"controlsPage\" ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Navigation Page . createEndpoint ( \"navigationPage\" ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // GPS Page . createEndpoint ( \"gpsPage\" ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Service Page . createEndpoint ( \"servicePage\" ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Satellite Radio Page . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Information Page . createEndpoint ( \"informationPage\" ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Vehicle Status Page . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Multimedia Page . createEndpoint ( \"multimediaPage\" ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addAssetId ( alexa :: value :: MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Telephone Page . createEndpoint ( \"telephonePage\" ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Contacts Page . createEndpoint ( \"contactsPage\" ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Alerts Page . createEndpoint ( \"alertsPage\" ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Notifications Page . createEndpoint ( \"notificationsPage\" ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // 360 Camera . createEndpoint ( \"360Camera\" ) . addAssetId ( alexa :: device :: CAMERA_360 ) . addAssetId ( alexa :: device :: AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( alexa :: setting :: DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( alexa :: location :: FRONT ) . addValue ( \"REAR\" ) . addAssetId ( alexa :: location :: REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( alexa :: location :: DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Steering Wheel . createEndpoint ( \"steeringWheel\" ) . addAssetId ( alexa :: device :: STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Hood . createEndpoint ( \"hood\" ) . addAssetId ( alexa :: device :: HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Trunk . createEndpoint ( \"trunk\" ) . addAssetId ( alexa :: device :: TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Charge Door . createEndpoint ( \"chargedoor\" ) . addAssetId ( alexa :: device :: CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Gas Door . createEndpoint ( \"gasdoor\" ) . addAssetId ( alexa :: device :: GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ); configuration . push_back ( config ); Configuration for Android Integration To use the Car Control module Engine configuration with AACS, use \"aacs.carControl\" instead of \"aace.carControl\" in your AACS configuration file: { \"aacs.carControl\": { \"endpoints\": [ // list of endpoint definitions ], \"zones\": [ // list of zone definitions ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory class [com.amazon.aace.carControl.CarControlConfiguration](https://gitlab.automotive.alexa.a2z.com/alexa-auto-hut/aac-sdk/-/blob/3.3/platforms/android/modules/car-control/src/main/java/com/amazon/aace/carControl/CarControlConfiguration.java) to programmatically construct the `EngineConfiguration` in the proper format, as shown in the example below. ###### CarControlConfiguration Java sample code import com.amazon.aace.carControl.CarControlAssets ; import com.amazon.aace.carControl.CarControlConfiguration ; import com.amazon.aace.core.config.EngineConfiguration ; // Auto SDK Engine configuration List < EngineConfiguration > configuration = new ArrayList <> (); CarControlConfiguration config = CarControlConfiguration . create (); config . createZone ( \"zone.default\" ) . addAssetId ( CarControlAssets . Location . ALL ) . addMembers ( new String [] { \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }); config . createZone ( \"zone.driver\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addAssetId ( CarControlAssets . Location . FRONT_LEFT ) . addMembers ( new String [] { \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }); config . createZone ( \"zone.passenger\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addAssetId ( CarControlAssets . Location . FRONT_RIGHT ) . addMembers ( new String [] { \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }); config . createZone ( \"zone.front\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addMembers ( new String [] { \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }); config . createZone ( \"zone.rear\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addMembers ( new String [] { \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }); config . createZone ( \"zone.left\" ) . addAssetId ( CarControlAssets . Location . LEFT ) . addMembers ( new String [] { \"left.heater\" , \"driver.seat\" , \"driver.vent\" }); config . createZone ( \"zone.right\" ) . addAssetId ( CarControlAssets . Location . RIGHT ) . addMembers ( new String [] { \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }); config . createZone ( \"zone.rear.driver\" ) . addAssetId ( CarControlAssets . Location . REAR_DRIVER ) . addAssetId ( CarControlAssets . Location . REAR_LEFT ) . addMembers ( new String [] { \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }); config . createZone ( \"zone.rear.passenger\" ) . addAssetId ( CarControlAssets . Location . REAR_PASSENGER ) . addAssetId ( CarControlAssets . Location . REAR_RIGHT ) . addMembers ( new String [] { \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }); config . createZone ( \"zone.secondRow\" ) . addAssetId ( CarControlAssets . Location . SECOND_ROW ) . addMembers ( new String [] { \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }); config . createZone ( \"zone.thirdRow\" ) . addAssetId ( CarControlAssets . Location . THIRD_ROW ) . addMembers ( new String [] { \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }); config . setDefaultZone ( \"zone.default\" ); // \"Car\" config . createEndpoint ( \"car\" ) . addAssetId ( CarControlAssets . Device . CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( CarControlAssets . Value . INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( CarControlAssets . Value . OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( CarControlAssets . Setting . CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( CarControlAssets . Setting . DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( CarControlAssets . Value . COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( CarControlAssets . Value . SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( CarControlAssets . Value . SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( CarControlAssets . Setting . TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( CarControlAssets . Setting . HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( CarControlAssets . Setting . WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( CarControlAssets . Setting . AUTO_BRAKE_HOLD ); // Ambient Light config . createEndpoint ( \"ambient.light\" ) . addAssetId ( CarControlAssets . Device . AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( CarControlAssets . Setting . COLOR ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"RED\" ) . addAssetId ( CarControlAssets . Color . RED ) . addValue ( \"BLUE\" ) . addAssetId ( CarControlAssets . Color . BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( CarControlAssets . Color . GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( CarControlAssets . Color . WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( CarControlAssets . Color . ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( CarControlAssets . Color . YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( CarControlAssets . Color . INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( CarControlAssets . Color . VIOLET ); // Air Conditioner config . createEndpoint ( \"default.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Air Conditioner config . createEndpoint ( \"front.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Air Conditioner config . createEndpoint ( \"rear.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Fan config . createEndpoint ( \"default.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Fan config . createEndpoint ( \"driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Fan config . createEndpoint ( \"passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Fan config . createEndpoint ( \"front.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Fan config . createEndpoint ( \"rear.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Driver Fan config . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Passenger Fan config . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Fan config . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Fan config . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Vent config . createEndpoint ( \"default.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Driver Vent config . createEndpoint ( \"driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Passenger Vent config . createEndpoint ( \"passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Front Vent config . createEndpoint ( \"front.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Vent config . createEndpoint ( \"rear.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Driver Vent config . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Passenger Vent config . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Second Row Vent config . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Third Row Vent config . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Climate Control config . createEndpoint ( \"climatecontrol\" ) . addAssetId ( CarControlAssets . Device . CLIMATE_CONTROL ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addPowerController ( false ); // Heater config . createEndpoint ( \"default.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Heater config . createEndpoint ( \"driver.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Heater config . createEndpoint ( \"passenger.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Left Heater config . createEndpoint ( \"left.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Right Heater config . createEndpoint ( \"right.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Heater config . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Heater config . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Light config . createEndpoint ( \"default.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Driver Light config . createEndpoint ( \"driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Passenger Light config . createEndpoint ( \"passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Front Light config . createEndpoint ( \"front.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Light config . createEndpoint ( \"rear.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Driver Light config . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Passenger Light config . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Second Row Light config . createEndpoint ( \"secondRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Third Row Light config . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Reading Light config . createEndpoint ( \"default.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Reading Light config . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Passenger Reading Light config . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Front Reading Light config . createEndpoint ( \"front.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Reading Light config . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Driver Reading Light config . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Passenger Reading Light config . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Second Row Reading Light config . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Third Row Reading Light config . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Cupholder config . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Passenger Cupholder config . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Front Cupholder config . createEndpoint ( \"front.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Cupholder config . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Driver Cupholder config . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Passenger Cupholder config . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Second Row Cupholder config . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Third Row Cupholder config . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Driver Armrest config . createEndpoint ( \"driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Passenger Armrest config . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Front Armrest config . createEndpoint ( \"front.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Armrest config . createEndpoint ( \"rear.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Driver Armrest config . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Passenger Armrest config . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Second Row Armrest config . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Third Row Armrest config . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Driver Seat config . createEndpoint ( \"driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Passenger Seat config . createEndpoint ( \"passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Seat config . createEndpoint ( \"front.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Seat config . createEndpoint ( \"rear.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Driver Seat config . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Passenger Seat config . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Second Row Seat config . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Third Row Seat config . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Window config . createEndpoint ( \"front.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Window config . createEndpoint ( \"rear.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Driver Window config . createEndpoint ( \"driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Passenger Window config . createEndpoint ( \"passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Driver Window config . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Passenger Window config . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Second Row Window config . createEndpoint ( \"secondRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Third Row Window config . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Front Windshield config . createEndpoint ( \"front.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Rear Windshield config . createEndpoint ( \"rear.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Front Foglight config . createEndpoint ( \"front.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Rear Foglight config . createEndpoint ( \"rear.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Hazard Light config . createEndpoint ( \"hazardlight\" ) . addAssetId ( CarControlAssets . Device . HAZARD_LIGHTS ) . addAssetId ( CarControlAssets . Device . PARKING_LIGHTS ) . addPowerController ( false ); // Front Wipers config . createEndpoint ( \"front.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Wipers config . createEndpoint ( \"rear.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Sunroof config . createEndpoint ( \"sunroof\" ) . addAssetId ( CarControlAssets . Device . SUNROOF ) . addAssetId ( CarControlAssets . Device . MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // Sunshade config . createEndpoint ( \"sunshade\" ) . addAssetId ( CarControlAssets . Device . SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // HUD config . createEndpoint ( \"hud\" ) . addAssetId ( CarControlAssets . Device . HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . HUD ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // IVI config . createEndpoint ( \"ivi\" ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( CarControlAssets . Value . OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Dynamics Coordinator Page config . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Performance Page config . createEndpoint ( \"performancePage\" ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Home Page config . createEndpoint ( \"homepage\" ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Bluetooth Page config . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Radio Page config . createEndpoint ( \"radioPage\" ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Settings Page config . createEndpoint ( \"settingsPage\" ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Controls Page config . createEndpoint ( \"controlsPage\" ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Navigation Page config . createEndpoint ( \"navigationPage\" ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // GPS Page config . createEndpoint ( \"gpsPage\" ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Service Page config . createEndpoint ( \"servicePage\" ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Satellite Radio Page config . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Information Page config . createEndpoint ( \"informationPage\" ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Vehicle Status Page config . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Multimedia Page config . createEndpoint ( \"multimediaPage\" ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addAssetId ( CarControlAssets . Value . MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Telephone Page config . createEndpoint ( \"telephonePage\" ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Contacts Page config . createEndpoint ( \"contactsPage\" ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Alerts Page config . createEndpoint ( \"alertsPage\" ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Notifications Page config . createEndpoint ( \"notificationsPage\" ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // 360 Camera config . createEndpoint ( \"360Camera\" ) . addAssetId ( CarControlAssets . Device . CAMERA_360 ) . addAssetId ( CarControlAssets . Device . AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( CarControlAssets . Setting . DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addValue ( \"REAR\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Steering Wheel config . createEndpoint ( \"steeringWheel\" ) . addAssetId ( CarControlAssets . Device . STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Hood config . createEndpoint ( \"hood\" ) . addAssetId ( CarControlAssets . Device . HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Trunk config . createEndpoint ( \"trunk\" ) . addAssetId ( CarControlAssets . Device . TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Charge Door config . createEndpoint ( \"chargedoor\" ) . addAssetId ( CarControlAssets . Device . CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Gas Door config . createEndpoint ( \"gasdoor\" ) . addAssetId ( CarControlAssets . Device . GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); configuration . add ( config ); Using the Car Control Module AASB Messages The Auto SDK Engine provides an AASB message interface with topic CarControl for you to handle the car control directives from Alexa. The messages include an endpointId to identify the connected endpoint that Alexa identified to match the user's intent. For directives targeting primitive capability instances, the message includes the instanceId as well. The endpointId and instanceId match the configured IDs from aace.carControl.endpoints[i].endpointId and aace.carControl.endpoints[i].capabilities[j].instance , respectively. Changing the power state of an endpoint When the user requests Alexa to turn an endpoint on or off, the Engine publishes a SetControllerValue message for power state . Your application must power on or off the endpoint and publish SetControllerReply message in response. Click to expand or collapse sequence diagram: Turning on AC Click to expand or collapse sequence diagram: Turning off AC Toggling an endpoint property When the user requests Alexa to turn on or off a named property of an endpoint, the Engine publishes a SetControllerValue message for toggle of the setting . Your application must turn on or off the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Turning on the rear windshield defroster Click to expand or collapse sequence diagram: Turning off the rear windshield defroster Changing the mode of an endpoint property When the user requests Alexa to set the mode of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for mode of the setting . Your application must set the mode of the property and publish SetControllerValueReply` message in response. Click to expand or collapse sequence diagram: Setting the AC intensity to minimum When the user requests Alexa to increase or decrease the mode of a named property of an endpoint, the Engine publishes an AdjustControllerValue message for mode of the setting . Your application must adjust the mode of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the AC intensity Changing the numeric setting of an endpoint property When the user requests Alexa to set the numeric setting of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for the range setting . Your application must set the value of the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Setting the temperature to 70 When the user requests Alexa to adjust (increment or decrement) the numeric setting of a named property of an endpoint by a delta value, the Engine publishes a AdjustControllerValue message for the range setting . Your application must adjust the value of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the temperature by 4 Integrating the Car Control Module Into Your Application C++ MessageBroker Integration Use the Engine's MessageBroker to subscribe to \"CarControl\" AASB messages and publish replies. Click to expand or collapse C++ sample code #include <AACE/CarControl/CarControlConfiguration.h> #include <AACE/Core/MessageBroker.h> #include <AASB/Message/CarControl/CarControl/AdjustControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetPowerControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetToggleControllerValueMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyCarControlHandler { static const std :: string AASB_TOPIC_CAR_CONTROL ( \"CarControl\" ); static const std :: string AASB_ACTION_SET_CONTROLLER_VALUE ( \"SetControllerValue\" ); static const std :: string AASB_ACTION_ADJUST_CONTROLLER_VALUE ( \"AdjustControllerValue\" ); // Subscribe to \"CarControl\" messages from the Engine void MyCarControlHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_SET_CONTROLLER_VALUE ); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAdjustControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_ADJUST_CONTROLLER_VALUE ); } // Handle the messages from the Engine for \"SetControllerValue\" action void MyCarControlHandler::handleSetControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"POWER\" ) == 0 ) { SetPowerControllerValueMessage msg = json :: parse ( message ); setPowerControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"TOGGLE\" ) == 0 ) { SetToggleControllerValueMessage msg = json :: parse ( message ); setToggleControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { SetRangeControllerValueMessage msg = json :: parse ( message ); setRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { SetModeControllerValueMessage msg = json :: parse ( message ); setModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::setPowerControllerValue ( const std :: string & messageId , const std :: string & endpointId , bool turnOn ) { if ( turnOn ) { // Power on the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Power off the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setToggleControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , bool turnOn ) { if ( turnOn ) { // Turn on the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Turn off the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double value ) { // Set the numeric setting of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::setModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , const std :: string & value ) { // Set the mode of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendSetControllerValueMessageReply ( const std :: string & messageId , bool successful ) { SetControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); } // Handle the messages from the Engine for \"AdjustControllerValue\" action void MyCarControlHandler::handleAdjustControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { AdjustRangeControllerValueMessage msg = json :: parse ( message ); adjustRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { AdjustModeControllerValueMessage msg = json :: parse ( message ); adjustModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::adjustRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the numeric setting of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::adjustModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the mode of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendAdjustControllerValueMessageReply ( const std :: string & messageId , bool successful ) { AdjustControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); } AACS Android integration The Alexa Auto Client Service (AACS) provides the AACS Car Control Library to integrate the Auto SDK Car Control module on Android. See the AACS Car Control Library documentation for more information.","title":"Car Control Module"},{"location":"modules/car-control/#car-control-module","text":"Table of Contents Overview Endpoints Capabilities Zones Assets Configuring the Car Control Module Configuration Schema Overview Power Controller Capability Configuration Toggle Controller Capability Configuration Mode Controller Capability Configuration Range Controller Capability Configuration Additional Notes about Assets Sample Configuration Using the Car Control Module AASB Messages Changing the power state of an endpoint Toggling an endpoint property Changing the mode of an endpoint property Changing the numeric setting of an endpoint property Integrating the Car Control Module Into Your Application","title":"Car Control Module"},{"location":"modules/car-control/#overview","text":"The Alexa Auto SDK Car Control module enables you to build a custom experience that allows users to use Alexa to voice-control vehicle features. The following concepts comprise the Car Control module APIs:","title":"Overview "},{"location":"modules/car-control/#endpoints","text":"The head unit device acting as an Alexa Auto SDK client is an \"endpoint\" that connects to the Alexa service. Other Auto SDK modules, such as Alexa , configure capabilities on this \"root\" or \"default\" endpoint because the capabilities pertain to the head unit itself. The Car Control module enables the default Auto SDK client endpoint to act as a proxy to receive events and directives on behalf of connected endpoints. You can configure a separate endpoint for every vehicle component that the head unit can control through device-level connections. This enables the user to target individual vehicle components directly with utterances like \"Alexa, turn on the AC\" or \"Alexa, set the temperature to 65.\"","title":"Endpoints "},{"location":"modules/car-control/#capabilities","text":"In the utterance \"Alexa, turn on the AC\", \"turn on\" corresponds to a specific capability configured for the \"AC\" endpoint. Defining an endpoint declares a vehicle feature to be controllable, and defining capabilities on the endpoint declares how the endpoint can be controlled. Car Control supports four capability interfaces that can be declared alone or in combination for a particular endpoint to model its individual control experience: Power Controller controls the overall power state of an endpoint. For example, configuring an \"AC\" endpoint with a Power Controller capability enables utterances such as \"Alexa, turn on the AC\" and \"Alexa, power off the AC\". Toggle Controller controls a particular named property of an endpoint that can be turned on and off. For example, configuring a \"windshield\" endpoint with a \"defroster\" Toggle Controller capability instance enables utterances such as \"Alexa, turn on the windshield defroster.\" Mode Controller controls a particular named property of an endpoint that can be set to a discrete value from a defined set of values. For example, if an ambient light endpoint has red and green color settings, configuring an \"ambient light\" endpoint with a \"color\" Mode Controller capability instance enables utterances such as \"Alexa, set the ambient light color to red\" and \"Alexa, change the ambient light to green.\" Range Controller controls a particular named property of an endpoint that can be set to a numeric value within a range. For example, if a fan endpoint has a speed property with settings 1 through 3, configuring a \"fan\" endpoint with a \"speed\" Range Controller capability instance enables utterances such as \"Alexa, set the fan speed to 2.\" You can configure names, such as \"medium\", for a range value to enable additional utterances such as \"Alexa, set the fan to medium\" to set the fan speed setting to 2.","title":"Capabilities "},{"location":"modules/car-control/#capability-primitives-and-semantic-annotations","text":"Toggle Controller, Mode Controller, and Range Controller are known as \"capability primitives.\" You can use multiple instances of the same capability primitive interface on an endpoint under different instance names. For example, a heater endpoint might have intensity and position properties that are both best modeled as modes. You can declare an \"intensity\" Mode Controller instance and a \"position\" Mode Controller instance on the same \"heater\" endpoint so the user can target each property separately. To provide intuitive experiences for users, capability primitives offer \"semantic annotations\" for the devices to map specific utterances to the behaviors of capability instances. For example, if the vehicle uses a Range Controller to control a window, a user would prefer to say \"Alexa, open the window\" over the default utterances of the Range Controller such as \"Alexa, set the window height to 0\". For any endpoint to which the \"open\", \"close\", \"raise\", or \"lower\" concepts apply, you can configure the capability primitive instances of the endpoint with a \"semantics\" object that maps user utterances for these actions to the appropriate capability directives. Each action (e.g., \"open\") is allowed only once per endpoint since the action expresses intent to control the endpoint as a whole. The actions specified in configuration are action IDs rather than literal strings, which ensures Alexa recognizes all synonyms and translations for the action in the user utterance. The supported actions are \"Alexa.Actions.Open\", \"Alexa.Actions.Close\", \"Alexa.Actions.Raise\", and \"Alexa.Actions.Lower.\"","title":"Capability Primitives and Semantic Annotations "},{"location":"modules/car-control/#zones","text":"Each endpoint can belong to zero, one, or many \"zones.\" Zones, configured with member endpoints, define named regions of the vehicle and allow users to target endpoints by location. Zones are essential for unambiguous targeting of endpoints that have friendly names that overlap with other endpoints. For example, defining \"driver\" and \"passenger\" zones and assigning distinct \"seat\" endpoints to each allows proper control of the \"driver seat\" and the \"passenger seat\" independently. Assigning one zone in particular as the \"default\" enables endpoints in this zone to take precedence over endpoints sharing the same friendly name but not in the default zone when the user does not specify a zone in the utterance. This is useful for distinguishing \"zoneless\" endpoints from \"zoned\" endpoints with the same name when it is most likely that the user intends to target the \"zoneless\" one. For example, consider a vehicle with zone IDs \"zone.all\", \"zone.rear\", and \"zone.left\" with a distinct fan endpoint in each zone. If the user says \"Alexa, turn on the fan\", it is most likely that he wants to turn on the fan that refers to the vehicle as a whole because there is no natural way to specify its location. You can ensure that Alexa will resolve this utterance to the fan in the \"all\" zone by assigning \"zone.all\" as the default zone. Additionally, the default zone is useful for cases in which you have zoned endpoints with overlapping names, but one of the endpoints is a clear \"default\" to the user. For example, consider a vehicle with zones \"zone.all\" (assigned as default), \"zone.driver\", and \"zone.passenger\". The vehicle has a \"driver window\" in \"zone.driver\" and a \"passenger window\" in \"zone.passenger\", but Alexa cannot resolve which endpoint is the intended target of the user utterance \"Alexa, open the window.\" However, the user probably means \"Alexa, open the driver window\". You can ensure that Alexa considers the \"driver window\" as the \"default\" window by assigning it to \"zone.all\" as well.","title":"Zones "},{"location":"modules/car-control/#assets","text":"The definitions of endpoints, capabilities, and zones include \"assets.\" Assets, identified by unique IDs, group a voice-accessible friendly name like \"air conditioner\" into a named group of synonyms and translations for all supported languages. For example, using the asset with ID \"Alexa.Automotive.DeviceName.AirConditioner\" in your car control module configuration for an AC endpoint not only enables the user to target the air conditioner with the default phrase \"air conditioner\", but also with phrases like \"air con\" and \"AC\" in English as well as synonyms in other supported locales. Using assets allows decoupling the many ways of identifying components from the core configuration of the components and enables de-duplication across different components that have overlapping ways to be identified. The Alexa Auto SDK provides a list of IDs for the \"default assets,\" which form an automotive-specific catalog. The catalog contains asset definitions for supported car control features, including endpoint names, zone names, and capability settings. Each default asset ID is prefixed with \"Alexa.Automotive.\" You can use these asset IDs in your Car Control module configuration without the corresponding definitions of friendly names, synonyms, and translations, because the definitions are specified in the Alexa cloud.","title":"Assets "},{"location":"modules/car-control/#configuring-the-car-control-module","text":"Car Control module configuration is vehicle-specific and tells the Auto SDK Engine which vehicle features to advertise to Alexa for control by the user. You must configure the Auto SDK Engine with an EngineConfiguration object that describes the vehicle. Like all Auto SDK Engine configuration, you can either define the JSON in a file and construct an EngineConfiguration from that file, or you can use the provided CarControlConfiguration class to programmatically construct the EngineConfiguration in the proper format. The following subsections describe the JSON schema. See the CarControlConfiguration class for details on how to build configuration programmatically.","title":"Configuring the Car Control Module "},{"location":"modules/car-control/#configuration-schema-overview","text":"The Engine configuration for the Car Control module includes definitions of endpoints with their capabilities, zones with their member endpoints, and an optional path to a JSON file defining additional assets. Sample JSON Object { \"aace.carControl\": { \"endpoints\": [ { \"endpointId\": \"{{STRING}}\", \"endpointResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"capabilities\": [ // list of capability definitions for this endpoint ] } ], \"zones\": [ { \"zoneID\": \"{{STRING}}\", \"zoneResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] }, \"members\": [ { \"endpointId\": \"{{STRING}}\" } ] } ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Object Parameters Property Type Required Description aace.carControl. endpoints list Yes The list of connected endpoints for which the device implements capabilities. Each endpoint describes one controllable vehicle component. aace.carControl. endpoints[i]. endpointId string Yes The identifier for the endpoint, unique amongst all endpoints in the vehicle. The same endpointId is used to identify the endpoint targeted in an AASB message sent by the Engine. Note: Do not use this format for the endpointId : \\<clientId>::\\<productId>::\\<serialNumber>::[-\\<extEndpoint>] The Engine internally prepends the 3-part device prefix to your specified endpointId before sending the configuration to Alexa. Configuring the full ID directly results in duplication and excess characters. aace.carControl. endpoints[i]. endpointResources. friendlyNames list Yes A list of label objects that describe the possible friendly names for this endpoint. Note: Only \u201casset\u201d type labels are supported. aace.carControl. endpoints[i]. endpointResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of localized strings used to refer to the endpoint. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. endpoints[i]. capabilities list Yes A list of capability definitions, representing capabilities implemented by the device on behalf of the endpoint, that define how the endpoint can be controlled by the user. Each object in this list must be a valid definition for one of the capabilities supported by the Car Control module: Alexa.PowerController , Alexa.ToggleController , Alexa.ModeController , and Alexa.RangeController aace.carControl. zones list No, but recommended A list of zone definitions for the named regions in the vehicle. aace.carControl. zones[i]. zoneId string Yes The identifier for the zone, unique amongst all zones in the vehicle. aace.carControl. zones[i]. zoneResources. friendlyNames list Yes A list of label objects that describe the possible ways to refer to this zone. Note: Only \u201casset\u201d type labels are supported. aace.carControl. zones[i]. zoneResources. friendlyNames[j]. assetId string Yes The ID of an asset definition that includes the list of strings used to refer to the zone in all supported locales. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at aace.carControl.assets.customAssetsPath . See the \"Additional Notes about Assets\" section for more details. aace.carControl. zones[i]. members list Yes A list of endpoints that belong to this zone. aace.carControl. zones[i]. members[j]. endpointId string Yes The endpointId for an endpoint that belongs to this zone. aace.carControl. defaultZoneId string No, but recommended The zoneId of the default zone. Endpoints in this zone take precedence when a user utterance does not specify a zone. It is recommended to use a zone that describes the whole vehicle as the default rather than a zone describing a specific region. aace.carControl. assets.customAssetsPath string (file path) No Specifies the path to a JSON file defining additional assets.","title":"Configuration Schema Overview "},{"location":"modules/car-control/#power-controller-capability-configuration","text":"Click to expand or collapse description See [\"Alexa.PowerController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-powercontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.PowerController\", \"version\": \"3\", \"properties\": { \"supported\": [ { \"name\": \"powerState\" } ], \"proactivelyReported\": false, \"retrievable\": false } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"powerState\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"powerState\") can be retrieved by Alexa. **Accepted values:** `false` |","title":"Power Controller Capability Configuration "},{"location":"modules/car-control/#toggle-controller-capability-configuration","text":"Click to expand or collapse description See [\"Alexa.ToggleController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-togglecontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ToggleController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"proactivelyReported\": false, \"retrievable\": false, \"supported\": [ { \"name\": \"toggleState\" } ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {} } }, ... ] } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | instance | string | Yes | The identifier of this instance of Alexa.ToggleController on this endpoint. | | capabilityResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. **Note:** Only `\u201casset\u201d` type labels are supported. | | capabilityResources. friendlyNames[i]. assetId | string | Yes | The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at `aace.carControl.assets.customAssetsPath`. See the [\"Additional Notes about Assets\" section](#additional-notes-about-assets) for more details. | | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"toggleState\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"toggleState\") can be retrieved by Alexa. **Accepted values:** `false` | | semantics | object | No | Semantic annotations that enable mapping user utterances with directives targeting this capability instance. **Note:** `semantics.stateMappings` is not supported. | | semantics. actionMappings[i]. actions[j] | string | Yes, if `semantics` is present | The identifiers of the utterances that should trigger the specified directive. **Accepted values:** `\"Alexa.Actions.Open\"`: \"open {endpoint}\" `\"Alexa.Actions.Close\"`: \"close {endpoint}\" `\"Alexa.Actions.Raise\"`: \"raise {endpoint}\" `\"Alexa.Actions.Lower\"`: \"lower {endpoint}\" | | semantics. actionMappings[i]. directive. name | string | Yes, if `semantics` is present | **Accepted values:** `\"TurnOn\"`: The specified `actions` will trigger the \"TurnOn\" directive. The Engine will publish the `SetToggleControllerValue` message, with the `turnOn` attribute set to `true`. `\"TurnOff\"`: The specified `actions` will trigger the \"TurnOff\" directive. The Engine will publish the `SetToggleControllerValue` message, with the `turnOn` attribute set to `false`. |","title":"Toggle Controller Capability Configuration "},{"location":"modules/car-control/#mode-controller-capability-configuration","text":"Click to expand or collapse description See [\"Alexa.ModeController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-modecontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.ModeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"mode\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"ordered\": {{BOOLEAN}}, \"supportedModes\": [ { \"value\": \"{{STRING}}\", \"modeResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } } ] } }, ... ] }, \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | instance | string | Yes | The identifier of this instance of Alexa.ModeController on this endpoint. | | capabilityResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. **Note:** Only `\u201casset\u201d` type labels are supported. | | capabilityResources. friendlyNames[i]. assetId | string | Yes | The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at `aace.carControl.assets.customAssetsPath`. See the [\"Additional Notes about Assets\" section](#additional-notes-about-assets) for more details. | | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"mode\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"mode\") can be retrieved by Alexa. **Accepted values:** `false` | | configuration. ordered | boolean | Yes | Whether the modes of this capability instance are ordered, enabling iteration through them using the \"AdjustMode\" directive. | | configuration. supportedModes | list | Yes | A list of objects describing the available modes of this capability instance. If `ordered` is true, the order of the objects in this list implies the ordering of the modes. | | configuration. supportedModes[i]. value | string | Yes | The identifier of this mode on this capability instance. | | configuration. supportedModes[i]. modeResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this mode. **Note:** Only `\u201casset\u201d` type labels are supported. | | semantics | object | No | Semantic annotations that enable mapping user utterances with directives targeting this capability instance. **Note:** `semantics.stateMappings` is not supported. | | semantics. actionMappings[i]. actions[j] | string | Yes, if `semantics` is present | The identifiers of the utterances that should trigger the specified directive. **Accepted values:** `\"Alexa.Actions.Open\"`: \"open {endpoint}\" `\"Alexa.Actions.Close\"`: \"close {endpoint}\" `\"Alexa.Actions.Raise\"`: \"raise {endpoint}\" `\"Alexa.Actions.Lower\"`: \"lower {endpoint}\" | | semantics. actionMappings[i]. directive. name | string | Yes, if `semantics` is present | **Accepted values:** `\"SetMode\"`: The specified actions will trigger the \"SetMode\" directive with the specified `payload`. The Engine will publish the `SetModeControllerValue` message. `\"AdjustMode\"`: The specified actions will trigger the \"AdjustMode\" directive with the specified `payload`. The Engine will publish the `AdjustModeControllerValue` message. \"AdjustMode\" is accepted only if this capability instance is `ordered`. | | semantics. actionMappings[i]. directive. payload | object | Yes, if `semantics` is present | If `name` is \u201cSetMode\u201d, this is the \u201cSetMode\u201d directive payload object that contains the \u201cmode\u201d property and the corresponding value from `configuration.supportedModes[].value`. If `name` is \u201cAdjustMode\u201d, this is the \u201cAdjustMode\u201d directive payload object that contains the \u201cmodeDelta\u201d field and the corresponding number of modes to advance. |","title":"Mode Controller Capability Configuration "},{"location":"modules/car-control/#range-controller-capability-configuration","text":"Click to expand or collapse description See [\"Alexa.RangeController\" interface AVS documentation](https://developer.amazon.com/en-US/docs/alexa/alexa-voice-service/alexa-rangecontroller.html) for additional details, but note that only features described in this document are supported for car control. **Sample JSON Object** { \"type\": \"AlexaInterface\", \"interface\": \"Alexa.RangeController\", \"version\": \"3\", \"instance\": \"{{STRING}}\", \"capabilityResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] }, \"properties\": { \"supported\": [ { \"name\": \"rangeValue\" } ], \"proactivelyReported\": false, \"retrievable\": false }, \"configuration\": { \"supportedRange\": { \"minimumValue\": {{LONG}}, \"maximumValue\": {{LONG}}, \"precision\": {{LONG}} }, \"unitOfMeasure\": \"{{STRING}}\", \"presets\": [ { \"rangeValue\": {{LONG}}, \"presetResources\": { \"friendlyNames\": [ { \"@type\": \"asset\", \"value\": { \"assetId\": \"{{STRING}}\" } }, ... ] } }, ... ], \"semantics\": { \"actionMappings\": [ { \"@type\": \"ActionsToDirective\", \"actions\": [\"{{STRING}}\", ...], \"directive\": { \"name\": \"{{STRING}}\", \"payload\": {{OBJECT}} } }, ... ] } } } **Object Parameters** | Property | Type | Required | Description | |-|-|-|-| | instance | string | Yes | The identifier of this instance of Alexa.RangeController on this endpoint. | | capabilityResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this instance of this capability on this endpoint. **Note:** Only `\u201casset\u201d` type labels are supported. | | capabilityResources. friendlyNames[i]. assetId | string | Yes | The ID of an asset definition that includes the list of localized strings used to refer to this capability instance. The asset ID must be a valid ID from the automotive catalog of default assets or a custom assets definition configured in the file at `aace.carControl.assets.customAssetsPath`. See the [\"Additional Notes about Assets\" section](#additional-notes-about-assets) for more details. | | properties. proactivelyReported | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be proactively reported to Alexa via an event. **Accepted values:** `false` | | properties. retrievable | boolean | Yes | Whether the reportable state properties for this capability (i.e., \"rangeValue\") can be retrieved by Alexa. **Accepted values:** `false` | | configuration. supportedRange. minimumValue | long | Yes | The minimum value of the range this capability instance supports. | | configuration. supportedRange. maximumValue | long | Yes | The maximum value of the range this capability instance supports. | | configuration. supportedRange. precision | long | Yes | The amount by which the set value changes when iterating through the range. For example, if a user asks Alexa to increase the value but doesn't specify by how much, this value will be used. | | configuration. unitOfMeasure | string | No | The unit of measure for the range. | | configuration. presets | list | Yes | A list of objects describing values that can be invoked by name. For example, a `rangeValue` of 10 might be configured as the \"high\" preset. | | configuration. presets[i]. rangeValue | long | Yes | The value within the `supportedRange` that has an associated named preset. | | configuration. presets[i]. presetResources. friendlyNames | list | Yes | A list of label objects that describe the possible friendly names for this preset. **Note:** Only `\u201casset\u201d` type labels are supported. | | semantics | object | No | Semantic annotations that enable mapping user utterances with directives targeting this capability instance. **Note:** `semantics.stateMappings` is not supported. | | semantics. actionMappings[i]. actions[j] | string | Yes, if `semantics` is present | The identifiers of the utterances that should trigger the specified directive. **Accepted values:** `\"Alexa.Actions.Open\"`: \"open {endpoint}\" `\"Alexa.Actions.Close\"`: \"close {endpoint}\" `\"Alexa.Actions.Raise\"`: \"raise {endpoint}\" `\"Alexa.Actions.Lower\"`: \"lower {endpoint}\" | | semantics. actionMappings[i]. directive. name | string | Yes, if `semantics` is present | **Accepted values:** `\"SetRangeValue\"`: The specified actions will trigger the \"SetRangeValue\" directive with the specified `payload`. The Engine will publish the `SetRangeControllerValue` message. `\"AdjustRangeValue\"`: The specified actions will trigger the \"AdjustRangeValue\" directive with the specified `payload`. The Engine will publish the `AdjustRangeControllerValue` message. | | semantics. actionMappings[i]. directive. payload | object | Yes, if `semantics` is present | If `name` is \u201cSetRangeValue\u201d, this is the \u201cSetRangeValue\u201d directive payload object that contains the \"rangeValue\" property and the corresponding value between `configuration.supportedRange.minumumValue` and `configuration.supportedRange.maximumValue`. If `name` is \u201cAdjustRangeValue\u201d, this is the \u201cAdjustRangeValue\u201d directive payload object that contains the \u201crangeValueDelta\u201d field. |","title":"Range Controller Capability Configuration "},{"location":"modules/car-control/#additional-notes-about-assets","text":"The Car Control module provides the full list of asset IDs available in the default automotive catalog of assets in the CarControlAssets.h header file, which defines string constants for these asset IDs to be used when constructing configuration programmatically. The values of the constants are the same asset IDs that you should use if you construct your configuration in a JSON file. This module also provides a reference JSON file with sample definitions of the assets in the automotive catalog. Your implementation does not need to duplicate these asset definitions or specify the path to this file because the definitions also exist in the Alexa cloud. This copy of the file is a reference for you to see the synonyms and translations for the available assets. Note: Because the actual asset definitions are defined in the Alexa cloud, this reference file may be outdated or missing translations. The automotive catalog of assets defines assets for every feature officially supported by car control. The majority of your configuration will use these asset IDs. Amazon recommends that you not create new, custom assets for features that already exist in the default catalog. However, if your vehicle has a feature that cannot be described using the default assets (e.g., an endpoint with a proprietary name), create an additional JSON file defining a complementary set of assets to use alongside the default catalog. The format of this file must follow the same schema as the reference default assets JSON , and the definitions must include entries for each of the locales supported in the default catalog. Prefix every assetId in this file with \"My.\" , and specify the path to the file in the optional aace.carControl.assets.customAssetsPath field of configuration. Note for LVC: When using Local Voice Control and car control custom assets, there are two distinct configurations \u2014 the Auto SDK Engine and the LVC app \u2014 that require the path to the custom assets definition file. See the below subsections for details for this configuration on Linux or Android.","title":"Additional Notes about Assets "},{"location":"modules/car-control/#local-voice-control-custom-assets-for-linux-integration","text":"The default LVC app configuration for Linux expects any custom assets to be defined in a file called assets.json located at /opt/LVC/data/led-service/assets/assets.json . Use this path when you configure the aace.carControl.assets.customAssetsPath field in the Car Control module configuration.","title":"(Local Voice Control) Custom Assets for Linux Integration"},{"location":"modules/car-control/#local-voice-control-custom-assets-for-android-integration","text":"Local Voice Control Android integrations using the LVC APK implement the ILVCClient interface to configure Local Voice Control in the LVC APK (See the LVC extension documentation for more details). The \"CarControl.CustomAssetsFilePath\" field of the ILVCClient.getConfiguration() configuration schema specifies a path to the custom assets definition file, which must be accessible to the processes running the LVC APK services. When you integrate with AACS, you do not need to provide the CarControl.CustomAssetsFilePath field in any AACS configuration message; instead, your application should directly share permissions to the custom assets definition file using the AACS file sharing protocol. AACS will create a local copy of the file and use the path to its local copy to configure the LVC APK.","title":"(Local Voice Control) Custom Assets for Android Integration"},{"location":"modules/car-control/#sample-configuration","text":"The Car Control module provides a sample JSON file to configure the Auto SDK Engine with a vehicle fully equipped for every use case officially supported for car control. This file models each supported endpoint with a configuration of capabilities and zones that ensures all supported utterances for that endpoint work as expected. It is recommended that you construct the configuration for your application by selecting the parts of this sample that describe features supported by your vehicle. Make adjustments to the endpoints, such as modifying modes and range settings, as needed.","title":"Sample Configuration "},{"location":"modules/car-control/#configuration-for-linux-integration","text":"If your implementation constructs the Car Control module EngineConfiguration programmatically rather than with a JSON file, see the following example usage of the aace::carControl::config::CarControlConfiguration builder class that produces the same fully-equipped vehicle as the sample file: Click to expand or collapse CarControlConfiguration C++ sample code #include <AACE/CarControl/CarControlAssets.h> using namespace aace :: carControl :: config ; using namespace aace :: carControl :: assets ; // Auto SDK Engine configuration std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configuration ; auto config = aace :: carControl :: config :: CarControlConfiguration :: create (); config -> createZone ( \"zone.default\" ) . addAssetId ( alexa :: location :: ALL ) . addMembers ({ \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }) . createZone ( \"zone.driver\" ) . addAssetId ( alexa :: location :: DRIVER ) . addAssetId ( alexa :: location :: FRONT_LEFT ) . addMembers ({ \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }) . createZone ( \"zone.passenger\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addAssetId ( alexa :: location :: FRONT_RIGHT ) . addMembers ({ \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }) . createZone ( \"zone.front\" ) . addAssetId ( alexa :: location :: FRONT ) . addMembers ({ \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }) . createZone ( \"zone.rear\" ) . addAssetId ( alexa :: location :: REAR ) . addMembers ({ \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }) . createZone ( \"zone.left\" ) . addAssetId ( alexa :: location :: LEFT ) . addMembers ({ \"left.heater\" , \"driver.seat\" , \"driver.vent\" }) . createZone ( \"zone.right\" ) . addAssetId ( alexa :: location :: RIGHT ) . addMembers ({ \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }) . createZone ( \"zone.rear.driver\" ) . addAssetId ( alexa :: location :: REAR_DRIVER ) . addAssetId ( alexa :: location :: REAR_LEFT ) . addMembers ({ \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }) . createZone ( \"zone.rear.passenger\" ) . addAssetId ( alexa :: location :: REAR_PASSENGER ) . addAssetId ( alexa :: location :: REAR_RIGHT ) . addMembers ({ \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }) . createZone ( \"zone.secondRow\" ) . addAssetId ( alexa :: location :: SECOND_ROW ) . addMembers ({ \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }) . createZone ( \"zone.thirdRow\" ) . addAssetId ( alexa :: location :: THIRD_ROW ) . addMembers ({ \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }) . setDefaultZone ( \"zone.default\" ) // \"Car\" . createEndpoint ( \"car\" ) . addAssetId ( alexa :: device :: CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( alexa :: setting :: AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( alexa :: value :: INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( alexa :: value :: OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( alexa :: setting :: CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( alexa :: setting :: DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( alexa :: value :: COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( alexa :: value :: SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( alexa :: value :: SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( alexa :: setting :: TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( alexa :: setting :: HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( alexa :: setting :: WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( alexa :: setting :: AUTO_BRAKE_HOLD ) // Ambient Light . createEndpoint ( \"ambient.light\" ) . addAssetId ( alexa :: device :: AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( alexa :: setting :: COLOR ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"RED\" ) . addAssetId ( alexa :: color :: RED ) . addValue ( \"BLUE\" ) . addAssetId ( alexa :: color :: BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( alexa :: color :: GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( alexa :: color :: WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( alexa :: color :: ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( alexa :: color :: YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( alexa :: color :: INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( alexa :: color :: VIOLET ) // Air Conditioner . createEndpoint ( \"default.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Air Conditioner . createEndpoint ( \"front.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Air Conditioner . createEndpoint ( \"rear.ac\" ) . addAssetId ( alexa :: device :: AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( alexa :: setting :: MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( alexa :: setting :: ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( alexa :: setting :: AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( alexa :: setting :: MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( alexa :: setting :: INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Fan . createEndpoint ( \"default.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Fan . createEndpoint ( \"driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Fan . createEndpoint ( \"passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Front Fan . createEndpoint ( \"front.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Fan . createEndpoint ( \"rear.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Driver Fan . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Passenger Fan . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Fan . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Fan . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( alexa :: device :: FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: FAN_SPEED ) . addAssetId ( alexa :: setting :: SPEED ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Vent . createEndpoint ( \"default.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Driver Vent . createEndpoint ( \"driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Passenger Vent . createEndpoint ( \"passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Front Vent . createEndpoint ( \"front.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Vent . createEndpoint ( \"rear.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Driver Vent . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Rear Passenger Vent . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Second Row Vent . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Third Row Vent . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( alexa :: device :: VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"BODY\" ) . addAssetId ( alexa :: setting :: BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( alexa :: setting :: FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( alexa :: setting :: MIX_VENTS ) // Climate Control . createEndpoint ( \"climatecontrol\" ) . addAssetId ( alexa :: device :: CLIMATE_CONTROL ) . addAssetId ( alexa :: setting :: AUTO ) . addPowerController ( false ) // Heater . createEndpoint ( \"default.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Driver Heater . createEndpoint ( \"driver.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Passenger Heater . createEndpoint ( \"passenger.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Left Heater . createEndpoint ( \"left.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Right Heater . createEndpoint ( \"right.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Second Row Heater . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Third Row Heater . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: device :: COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , alexa :: unit :: FAHRENHEIT ) . addAssetId ( alexa :: setting :: TEMPERATURE ) . addAssetId ( alexa :: setting :: HEAT ) . addPreset ( 60 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 75 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 90 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Light . createEndpoint ( \"default.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Driver Light . createEndpoint ( \"driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Passenger Light . createEndpoint ( \"passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Front Light . createEndpoint ( \"front.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Light . createEndpoint ( \"rear.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Driver Light . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Rear Passenger Light . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Second Row Light . createEndpoint ( \"secondRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Third Row Light . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( alexa :: device :: LIGHT ) . addAssetId ( alexa :: device :: DOME_LIGHT ) . addAssetId ( alexa :: device :: CABIN_LIGHT ) . addPowerController ( false ) // Reading Light . createEndpoint ( \"default.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Reading Light . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Passenger Reading Light . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Front Reading Light . createEndpoint ( \"front.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Reading Light . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Driver Reading Light . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Rear Passenger Reading Light . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Second Row Reading Light . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Third Row Reading Light . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( alexa :: device :: READING_LIGHT ) . addPowerController ( false ) // Driver Cupholder . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Passenger Cupholder . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Front Cupholder . createEndpoint ( \"front.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Cupholder . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Driver Cupholder . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Rear Passenger Cupholder . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Second Row Cupholder . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Third Row Cupholder . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( alexa :: device :: CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( alexa :: device :: COOLER ) . addAssetId ( alexa :: setting :: COOLING ) // Driver Armrest . createEndpoint ( \"driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Passenger Armrest . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Front Armrest . createEndpoint ( \"front.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Armrest . createEndpoint ( \"rear.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Driver Armrest . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Rear Passenger Armrest . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Second Row Armrest . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Third Row Armrest . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( alexa :: device :: ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Driver Seat . createEndpoint ( \"driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Passenger Seat . createEndpoint ( \"passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Seat . createEndpoint ( \"front.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Seat . createEndpoint ( \"rear.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Driver Seat . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Rear Passenger Seat . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Second Row Seat . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Third Row Seat . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( alexa :: device :: SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) . addAssetId ( alexa :: device :: SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 2 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 3 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( alexa :: device :: VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( alexa :: setting :: STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( alexa :: value :: POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( alexa :: value :: POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( alexa :: value :: POSITION_THREE ) // Front Window . createEndpoint ( \"front.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Window . createEndpoint ( \"rear.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Driver Window . createEndpoint ( \"driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Passenger Window . createEndpoint ( \"passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Driver Window . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Rear Passenger Window . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Second Row Window . createEndpoint ( \"secondRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Third Row Window . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( alexa :: device :: WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: HEIGHT ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) // Front Windshield . createEndpoint ( \"front.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Rear Windshield . createEndpoint ( \"rear.windshield\" ) . addAssetId ( alexa :: device :: WINDOW ) . addAssetId ( alexa :: device :: WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( alexa :: setting :: DEFROST ) . addAssetId ( alexa :: setting :: WINDSHIELD_VENTS ) // Front Foglight . createEndpoint ( \"front.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Rear Foglight . createEndpoint ( \"rear.foglight\" ) . addAssetId ( alexa :: device :: FOG_LIGHT ) . addPowerController ( false ) // Hazard Light . createEndpoint ( \"hazardlight\" ) . addAssetId ( alexa :: device :: HAZARD_LIGHTS ) . addAssetId ( alexa :: device :: PARKING_LIGHTS ) . addPowerController ( false ) // Front Wipers . createEndpoint ( \"front.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Rear Wipers . createEndpoint ( \"rear.wipers\" ) . addAssetId ( alexa :: device :: WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( alexa :: setting :: SPEED ) . addValue ( \"LOW\" ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( alexa :: value :: MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // Sunroof . createEndpoint ( \"sunroof\" ) . addAssetId ( alexa :: device :: SUNROOF ) . addAssetId ( alexa :: device :: MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // Sunshade . createEndpoint ( \"sunshade\" ) . addAssetId ( alexa :: device :: SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 ) . addAssetId ( alexa :: setting :: POSITION ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: FULL ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addAssetId ( alexa :: value :: HALF ) . addActionSetRange ({ action :: OPEN , action :: LOWER }, 0 ) . addActionSetRange ({ action :: CLOSE , action :: RAISE }, 10 ) // HUD . createEndpoint ( \"hud\" ) . addAssetId ( alexa :: device :: HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: HUD ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) // IVI . createEndpoint ( \"ivi\" ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( alexa :: device :: DISPLAY_SCREEN ) . addAssetId ( alexa :: device :: INFO_SCREEN ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( alexa :: value :: LOW ) . addAssetId ( alexa :: value :: MINIMUM ) . addPreset ( 5 ) . addAssetId ( alexa :: value :: MEDIUM ) . addPreset ( 10 ) . addAssetId ( alexa :: value :: HIGH ) . addAssetId ( alexa :: value :: MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( alexa :: setting :: BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( alexa :: value :: OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Dynamics Coordinator Page . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( alexa :: value :: DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Performance Page . createEndpoint ( \"performancePage\" ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( alexa :: value :: PERFORMANCE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Home Page . createEndpoint ( \"homepage\" ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( alexa :: value :: HOME_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Bluetooth Page . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( alexa :: value :: BLUETOOTH_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Radio Page . createEndpoint ( \"radioPage\" ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( alexa :: value :: RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Settings Page . createEndpoint ( \"settingsPage\" ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( alexa :: value :: SETTINGS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Controls Page . createEndpoint ( \"controlsPage\" ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( alexa :: value :: CONTROLS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Navigation Page . createEndpoint ( \"navigationPage\" ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( alexa :: value :: NAVIGATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // GPS Page . createEndpoint ( \"gpsPage\" ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( alexa :: value :: GPS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Service Page . createEndpoint ( \"servicePage\" ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( alexa :: value :: SERVICE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Satellite Radio Page . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( alexa :: value :: SATELLITE_RADIO_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Information Page . createEndpoint ( \"informationPage\" ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( alexa :: value :: INFORMATION_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Vehicle Status Page . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( alexa :: value :: VEHICLE_STATUS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Multimedia Page . createEndpoint ( \"multimediaPage\" ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addAssetId ( alexa :: value :: MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( alexa :: value :: MULTIMEDIA_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Telephone Page . createEndpoint ( \"telephonePage\" ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( alexa :: value :: TELEPHONE_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Contacts Page . createEndpoint ( \"contactsPage\" ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( alexa :: value :: CONTACTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Alerts Page . createEndpoint ( \"alertsPage\" ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( alexa :: value :: ALERTS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // Notifications Page . createEndpoint ( \"notificationsPage\" ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( alexa :: value :: NOTIFICATIONS_PAGE ) . addActionTurnOff ({ action :: CLOSE }) . addActionTurnOn ({ action :: OPEN }) // 360 Camera . createEndpoint ( \"360Camera\" ) . addAssetId ( alexa :: device :: CAMERA_360 ) . addAssetId ( alexa :: device :: AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( alexa :: setting :: DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( alexa :: location :: FRONT ) . addValue ( \"REAR\" ) . addAssetId ( alexa :: location :: REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( alexa :: location :: DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( alexa :: location :: PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( alexa :: setting :: AUTO ) // Steering Wheel . createEndpoint ( \"steeringWheel\" ) . addAssetId ( alexa :: device :: STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( alexa :: device :: HEATER ) . addAssetId ( alexa :: setting :: HEAT ) // Hood . createEndpoint ( \"hood\" ) . addAssetId ( alexa :: device :: HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Trunk . createEndpoint ( \"trunk\" ) . addAssetId ( alexa :: device :: TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Charge Door . createEndpoint ( \"chargedoor\" ) . addAssetId ( alexa :: device :: CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ) // Gas Door . createEndpoint ( \"gasdoor\" ) . addAssetId ( alexa :: device :: GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( alexa :: setting :: POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( alexa :: value :: OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( alexa :: value :: CLOSED ) . addActionSetMode ({ action :: CLOSE }, \"CLOSED\" ) . addActionSetMode ({ action :: OPEN }, \"OPEN\" ); configuration . push_back ( config );","title":"Configuration for Linux Integration"},{"location":"modules/car-control/#configuration-for-android-integration","text":"To use the Car Control module Engine configuration with AACS, use \"aacs.carControl\" instead of \"aace.carControl\" in your AACS configuration file: { \"aacs.carControl\": { \"endpoints\": [ // list of endpoint definitions ], \"zones\": [ // list of zone definitions ], \"defaultZoneID\": \"{{STRING}}\", \"assets\": { \"customAssetsPath\": \"{{STRING}}\" }, } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory class [com.amazon.aace.carControl.CarControlConfiguration](https://gitlab.automotive.alexa.a2z.com/alexa-auto-hut/aac-sdk/-/blob/3.3/platforms/android/modules/car-control/src/main/java/com/amazon/aace/carControl/CarControlConfiguration.java) to programmatically construct the `EngineConfiguration` in the proper format, as shown in the example below. ###### CarControlConfiguration Java sample code import com.amazon.aace.carControl.CarControlAssets ; import com.amazon.aace.carControl.CarControlConfiguration ; import com.amazon.aace.core.config.EngineConfiguration ; // Auto SDK Engine configuration List < EngineConfiguration > configuration = new ArrayList <> (); CarControlConfiguration config = CarControlConfiguration . create (); config . createZone ( \"zone.default\" ) . addAssetId ( CarControlAssets . Location . ALL ) . addMembers ( new String [] { \"climatecontrol\" , \"default.ac\" , \"default.fan\" , \"default.vent\" , \"default.heater\" , \"default.light\" , \"default.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" }); config . createZone ( \"zone.driver\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addAssetId ( CarControlAssets . Location . FRONT_LEFT ) . addMembers ( new String [] { \"driver.fan\" , \"driver.vent\" , \"driver.heater\" , \"driver.light\" , \"driver.reading.light\" , \"driver.cupholder\" , \"driver.armrest\" , \"driver.seat\" , \"driver.window\" }); config . createZone ( \"zone.passenger\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addAssetId ( CarControlAssets . Location . FRONT_RIGHT ) . addMembers ( new String [] { \"passenger.fan\" , \"passenger.vent\" , \"passenger.heater\" , \"passenger.light\" , \"passenger.reading.light\" , \"passenger.cupholder\" , \"passenger.armrest\" , \"passenger.seat\" , \"passenger.window\" }); config . createZone ( \"zone.front\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addMembers ( new String [] { \"front.ac\" , \"front.fan\" , \"front.vent\" , \"front.light\" , \"front.reading.light\" , \"front.cupholder\" , \"front.armrest\" , \"front.seat\" , \"front.windshield\" , \"front.foglight\" , \"front.wipers\" , \"front.window\" }); config . createZone ( \"zone.rear\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addMembers ( new String [] { \"rear.ac\" , \"rear.fan\" , \"rear.vent\" , \"rear.light\" , \"rear.reading.light\" , \"rear.cupholder\" , \"rear.armrest\" , \"rear.seat\" , \"rear.windshield\" , \"rear.foglight\" , \"rear.wipers\" , \"rear.window\" }); config . createZone ( \"zone.left\" ) . addAssetId ( CarControlAssets . Location . LEFT ) . addMembers ( new String [] { \"left.heater\" , \"driver.seat\" , \"driver.vent\" }); config . createZone ( \"zone.right\" ) . addAssetId ( CarControlAssets . Location . RIGHT ) . addMembers ( new String [] { \"right.heater\" , \"passenger.seat\" , \"passenger.vent\" }); config . createZone ( \"zone.rear.driver\" ) . addAssetId ( CarControlAssets . Location . REAR_DRIVER ) . addAssetId ( CarControlAssets . Location . REAR_LEFT ) . addMembers ( new String [] { \"rear.driver.fan\" , \"rear.driver.vent\" , \"rear.driver.light\" , \"rear.driver.reading.light\" , \"rear.driver.cupholder\" , \"rear.driver.armrest\" , \"rear.driver.seat\" , \"rear.driver.window\" }); config . createZone ( \"zone.rear.passenger\" ) . addAssetId ( CarControlAssets . Location . REAR_PASSENGER ) . addAssetId ( CarControlAssets . Location . REAR_RIGHT ) . addMembers ( new String [] { \"rear.passenger.fan\" , \"rear.passenger.vent\" , \"rear.passenger.light\" , \"rear.passenger.reading.light\" , \"rear.passenger.cupholder\" , \"rear.passenger.armrest\" , \"rear.passenger.seat\" , \"rear.passenger.window\" }); config . createZone ( \"zone.secondRow\" ) . addAssetId ( CarControlAssets . Location . SECOND_ROW ) . addMembers ( new String [] { \"secondRow.fan\" , \"secondRow.vent\" , \"secondRow.light\" , \"secondRow.reading.light\" , \"secondRow.cupholder\" , \"secondRow.armrest\" , \"secondRow.seat\" , \"secondRow.window\" , \"secondRow.heater\" }); config . createZone ( \"zone.thirdRow\" ) . addAssetId ( CarControlAssets . Location . THIRD_ROW ) . addMembers ( new String [] { \"thirdRow.fan\" , \"thirdRow.vent\" , \"thirdRow.light\" , \"thirdRow.reading.light\" , \"thirdRow.cupholder\" , \"thirdRow.armrest\" , \"thirdRow.seat\" , \"thirdRow.window\" , \"thirdRow.heater\" }); config . setDefaultZone ( \"zone.default\" ); // \"Car\" config . createEndpoint ( \"car\" ) . addAssetId ( CarControlAssets . Device . CAR ) . addToggleController ( \"recirculate\" , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addModeController ( \"recirculatemode\" , false , false ) . addAssetId ( CarControlAssets . Setting . AIR_RECIRCULATION ) . addValue ( \"INSIDE\" ) . addAssetId ( CarControlAssets . Value . INSIDE_AIR ) . addValue ( \"OUTSIDE\" ) . addAssetId ( CarControlAssets . Value . OUTSIDE_AIR ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addToggleController ( \"climate.sync\" , false ) . addAssetId ( CarControlAssets . Setting . CLIMATE_SYNC ) . addModeController ( \"driveMode\" , false , false ) . addAssetId ( CarControlAssets . Setting . DRIVE_MODE ) . addValue ( \"ECO\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"COMFORT\" ) . addAssetId ( CarControlAssets . Value . COMFORT ) . addValue ( \"SPORT\" ) . addAssetId ( CarControlAssets . Value . SPORT ) . addValue ( \"SPORTPLUS\" ) . addAssetId ( CarControlAssets . Value . SPORT_PLUS ) . addToggleController ( \"towingMode\" , false ) . addAssetId ( CarControlAssets . Setting . TOWING_MODE ) . addToggleController ( \"hillAssist\" , false ) . addAssetId ( CarControlAssets . Setting . HILL_ASSIST ) . addToggleController ( \"windowLock\" , false ) . addAssetId ( CarControlAssets . Setting . WINDOW_LOCK ) . addToggleController ( \"autoBrakeHold\" , false ) . addAssetId ( CarControlAssets . Setting . AUTO_BRAKE_HOLD ); // Ambient Light config . createEndpoint ( \"ambient.light\" ) . addAssetId ( CarControlAssets . Device . AMBIENT_LIGHT ) . addPowerController ( false ) . addModeController ( \"color\" , false , false ) . addAssetId ( CarControlAssets . Setting . COLOR ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"RED\" ) . addAssetId ( CarControlAssets . Color . RED ) . addValue ( \"BLUE\" ) . addAssetId ( CarControlAssets . Color . BLUE ) . addValue ( \"GREEN\" ) . addAssetId ( CarControlAssets . Color . GREEN ) . addValue ( \"WHITE\" ) . addAssetId ( CarControlAssets . Color . WHITE ) . addValue ( \"ORANGE\" ) . addAssetId ( CarControlAssets . Color . ORANGE ) . addValue ( \"YELLOW\" ) . addAssetId ( CarControlAssets . Color . YELLOW ) . addValue ( \"INDIGO\" ) . addAssetId ( CarControlAssets . Color . INDIGO ) . addValue ( \"VIOLET\" ) . addAssetId ( CarControlAssets . Color . VIOLET ); // Air Conditioner config . createEndpoint ( \"default.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Air Conditioner config . createEndpoint ( \"front.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Air Conditioner config . createEndpoint ( \"rear.ac\" ) . addAssetId ( CarControlAssets . Device . AIR_CONDITIONER ) . addPowerController ( false ) . addModeController ( \"mode\" , false , false ) . addAssetId ( CarControlAssets . Setting . MODE ) . addValue ( \"ECONOMY\" ) . addAssetId ( CarControlAssets . Setting . ECONOMY ) . addValue ( \"AUTOMATIC\" ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addValue ( \"MANUAL\" ) . addAssetId ( CarControlAssets . Setting . MANUAL ) . addModeController ( \"intensity\" , false , true ) . addAssetId ( CarControlAssets . Setting . INTENSITY ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Fan config . createEndpoint ( \"default.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Fan config . createEndpoint ( \"driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Fan config . createEndpoint ( \"passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Front Fan config . createEndpoint ( \"front.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Fan config . createEndpoint ( \"rear.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Driver Fan config . createEndpoint ( \"rear.driver.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Passenger Fan config . createEndpoint ( \"rear.passenger.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Fan config . createEndpoint ( \"secondRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Fan config . createEndpoint ( \"thirdRow.fan\" ) . addAssetId ( CarControlAssets . Device . FAN ) . addPowerController ( false ) . addRangeController ( \"speed\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . FAN_SPEED ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Vent config . createEndpoint ( \"default.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Driver Vent config . createEndpoint ( \"driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Passenger Vent config . createEndpoint ( \"passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Front Vent config . createEndpoint ( \"front.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Vent config . createEndpoint ( \"rear.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Driver Vent config . createEndpoint ( \"rear.driver.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Rear Passenger Vent config . createEndpoint ( \"rear.passenger.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Second Row Vent config . createEndpoint ( \"secondRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Third Row Vent config . createEndpoint ( \"thirdRow.vent\" ) . addAssetId ( CarControlAssets . Device . VENT ) . addPowerController ( false ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"BODY\" ) . addAssetId ( CarControlAssets . Setting . BODY_VENTS ) . addValue ( \"FLOOR\" ) . addAssetId ( CarControlAssets . Setting . FLOOR_VENTS ) . addValue ( \"WINDSHIELD\" ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ) . addValue ( \"MIX\" ) . addAssetId ( CarControlAssets . Setting . MIX_VENTS ); // Climate Control config . createEndpoint ( \"climatecontrol\" ) . addAssetId ( CarControlAssets . Device . CLIMATE_CONTROL ) . addAssetId ( CarControlAssets . Setting . AUTO ) . addPowerController ( false ); // Heater config . createEndpoint ( \"default.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Driver Heater config . createEndpoint ( \"driver.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Passenger Heater config . createEndpoint ( \"passenger.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Left Heater config . createEndpoint ( \"left.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Right Heater config . createEndpoint ( \"right.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Second Row Heater config . createEndpoint ( \"secondRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Third Row Heater config . createEndpoint ( \"thirdRow.heater\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Device . COOLER ) . addPowerController ( false ) . addRangeController ( \"temperature\" , false , 60 , 90 , 1 , CarControlAssets . Unit . FAHRENHEIT ) . addAssetId ( CarControlAssets . Setting . TEMPERATURE ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addPreset ( 60 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 75 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 90 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Light config . createEndpoint ( \"default.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Driver Light config . createEndpoint ( \"driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Passenger Light config . createEndpoint ( \"passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Front Light config . createEndpoint ( \"front.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Light config . createEndpoint ( \"rear.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Driver Light config . createEndpoint ( \"rear.driver.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Rear Passenger Light config . createEndpoint ( \"rear.passenger.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Second Row Light config . createEndpoint ( \"secondRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Third Row Light config . createEndpoint ( \"thirdRow.light\" ) . addAssetId ( CarControlAssets . Device . LIGHT ) . addAssetId ( CarControlAssets . Device . DOME_LIGHT ) . addAssetId ( CarControlAssets . Device . CABIN_LIGHT ) . addPowerController ( false ); // Reading Light config . createEndpoint ( \"default.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Reading Light config . createEndpoint ( \"driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Passenger Reading Light config . createEndpoint ( \"passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Front Reading Light config . createEndpoint ( \"front.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Reading Light config . createEndpoint ( \"rear.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Driver Reading Light config . createEndpoint ( \"rear.driver.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Rear Passenger Reading Light config . createEndpoint ( \"rear.passenger.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Second Row Reading Light config . createEndpoint ( \"secondRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Third Row Reading Light config . createEndpoint ( \"thirdRow.reading.light\" ) . addAssetId ( CarControlAssets . Device . READING_LIGHT ) . addPowerController ( false ); // Driver Cupholder config . createEndpoint ( \"driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Passenger Cupholder config . createEndpoint ( \"passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Front Cupholder config . createEndpoint ( \"front.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Cupholder config . createEndpoint ( \"rear.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Driver Cupholder config . createEndpoint ( \"rear.driver.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Rear Passenger Cupholder config . createEndpoint ( \"rear.passenger.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Second Row Cupholder config . createEndpoint ( \"secondRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Third Row Cupholder config . createEndpoint ( \"thirdRow.cupholder\" ) . addAssetId ( CarControlAssets . Device . CUP_HOLDER ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addToggleController ( \"cooler\" , false ) . addAssetId ( CarControlAssets . Device . COOLER ) . addAssetId ( CarControlAssets . Setting . COOLING ); // Driver Armrest config . createEndpoint ( \"driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Passenger Armrest config . createEndpoint ( \"passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Front Armrest config . createEndpoint ( \"front.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Armrest config . createEndpoint ( \"rear.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Driver Armrest config . createEndpoint ( \"rear.driver.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Rear Passenger Armrest config . createEndpoint ( \"rear.passenger.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Second Row Armrest config . createEndpoint ( \"secondRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Third Row Armrest config . createEndpoint ( \"thirdRow.armrest\" ) . addAssetId ( CarControlAssets . Device . ARMREST ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Driver Seat config . createEndpoint ( \"driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Passenger Seat config . createEndpoint ( \"passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Seat config . createEndpoint ( \"front.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Seat config . createEndpoint ( \"rear.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Driver Seat config . createEndpoint ( \"rear.driver.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Rear Passenger Seat config . createEndpoint ( \"rear.passenger.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Second Row Seat config . createEndpoint ( \"secondRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Third Row Seat config . createEndpoint ( \"thirdRow.seat\" ) . addAssetId ( CarControlAssets . Device . SEAT ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addRangeController ( \"heaterintensity\" , false , 1 , 3 , 1 , \"\" ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ) . addAssetId ( CarControlAssets . Device . SEAT_HEATER ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 2 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 3 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addToggleController ( \"vent\" , false ) . addAssetId ( CarControlAssets . Device . VENT ) . addModeController ( \"position\" , false , true ) . addAssetId ( CarControlAssets . Setting . STORED_POSITION ) . addValue ( \"ONE\" ) . addAssetId ( CarControlAssets . Value . POSITION_ONE ) . addValue ( \"TWO\" ) . addAssetId ( CarControlAssets . Value . POSITION_TWO ) . addValue ( \"THREE\" ) . addAssetId ( CarControlAssets . Value . POSITION_THREE ); // Front Window config . createEndpoint ( \"front.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Window config . createEndpoint ( \"rear.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Driver Window config . createEndpoint ( \"driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Passenger Window config . createEndpoint ( \"passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Driver Window config . createEndpoint ( \"rear.driver.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Rear Passenger Window config . createEndpoint ( \"rear.passenger.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Second Row Window config . createEndpoint ( \"secondRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Third Row Window config . createEndpoint ( \"thirdRow.window\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addRangeController ( \"height\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . HEIGHT ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ); // Front Windshield config . createEndpoint ( \"front.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Rear Windshield config . createEndpoint ( \"rear.windshield\" ) . addAssetId ( CarControlAssets . Device . WINDOW ) . addAssetId ( CarControlAssets . Device . WINDSHIELD ) . addToggleController ( \"defroster\" , false ) . addAssetId ( CarControlAssets . Setting . DEFROST ) . addAssetId ( CarControlAssets . Setting . WINDSHIELD_VENTS ); // Front Foglight config . createEndpoint ( \"front.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Rear Foglight config . createEndpoint ( \"rear.foglight\" ) . addAssetId ( CarControlAssets . Device . FOG_LIGHT ) . addPowerController ( false ); // Hazard Light config . createEndpoint ( \"hazardlight\" ) . addAssetId ( CarControlAssets . Device . HAZARD_LIGHTS ) . addAssetId ( CarControlAssets . Device . PARKING_LIGHTS ) . addPowerController ( false ); // Front Wipers config . createEndpoint ( \"front.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Rear Wipers config . createEndpoint ( \"rear.wipers\" ) . addAssetId ( CarControlAssets . Device . WINDSHIELD_WIPERS ) . addPowerController ( false ) . addModeController ( \"speed\" , false , true ) . addAssetId ( CarControlAssets . Setting . SPEED ) . addValue ( \"LOW\" ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addValue ( \"MEDIUM\" ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addValue ( \"HIGH\" ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // Sunroof config . createEndpoint ( \"sunroof\" ) . addAssetId ( CarControlAssets . Device . SUNROOF ) . addAssetId ( CarControlAssets . Device . MOONROOF ) . addRangeController ( \"sunroof.position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // Sunshade config . createEndpoint ( \"sunshade\" ) . addAssetId ( CarControlAssets . Device . SUNSHADE ) . addRangeController ( \"position\" , false , 0 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . FULL ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addAssetId ( CarControlAssets . Value . HALF ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . OPEN , CarControlConfiguration . Action . LOWER }, 0 ) . addActionSetRange ( new String [] { CarControlConfiguration . Action . CLOSE , CarControlConfiguration . Action . RAISE }, 10 ); // HUD config . createEndpoint ( \"hud\" ) . addAssetId ( CarControlAssets . Device . HUD ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . HUD ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ); // IVI config . createEndpoint ( \"ivi\" ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addToggleController ( \"power\" , false ) . addAssetId ( CarControlAssets . Device . DISPLAY_SCREEN ) . addAssetId ( CarControlAssets . Device . INFO_SCREEN ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }) . addRangeController ( \"brightness\" , false , 1 , 10 , 1 , \"\" ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addPreset ( 1 ) . addAssetId ( CarControlAssets . Value . LOW ) . addAssetId ( CarControlAssets . Value . MINIMUM ) . addPreset ( 5 ) . addAssetId ( CarControlAssets . Value . MEDIUM ) . addPreset ( 10 ) . addAssetId ( CarControlAssets . Value . HIGH ) . addAssetId ( CarControlAssets . Value . MAXIMUM ) . addModeController ( \"autobrightness\" , false , false ) . addAssetId ( CarControlAssets . Setting . BRIGHTNESS ) . addValue ( \"OPTIMAL\" ) . addAssetId ( CarControlAssets . Value . OPTIMAL ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Dynamics Coordinator Page config . createEndpoint ( \"dynamicsCoordinatorPage\" ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addToggleController ( \"dynamicsCoordinator.screen\" , false ) . addAssetId ( CarControlAssets . Value . DYNAMIC_COORDINATOR_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Performance Page config . createEndpoint ( \"performancePage\" ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addToggleController ( \"performance.screen\" , false ) . addAssetId ( CarControlAssets . Value . PERFORMANCE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Home Page config . createEndpoint ( \"homepage\" ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addToggleController ( \"home.screen\" , false ) . addAssetId ( CarControlAssets . Value . HOME_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Bluetooth Page config . createEndpoint ( \"bluetoothPage\" ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addToggleController ( \"bluetooth.screen\" , false ) . addAssetId ( CarControlAssets . Value . BLUETOOTH_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Radio Page config . createEndpoint ( \"radioPage\" ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addToggleController ( \"radio.screen\" , false ) . addAssetId ( CarControlAssets . Value . RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Settings Page config . createEndpoint ( \"settingsPage\" ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addToggleController ( \"settings.screen\" , false ) . addAssetId ( CarControlAssets . Value . SETTINGS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Controls Page config . createEndpoint ( \"controlsPage\" ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addToggleController ( \"controls.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTROLS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Navigation Page config . createEndpoint ( \"navigationPage\" ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addToggleController ( \"navigation.screen\" , false ) . addAssetId ( CarControlAssets . Value . NAVIGATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // GPS Page config . createEndpoint ( \"gpsPage\" ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addToggleController ( \"gps.screen\" , false ) . addAssetId ( CarControlAssets . Value . GPS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Service Page config . createEndpoint ( \"servicePage\" ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addToggleController ( \"service.screen\" , false ) . addAssetId ( CarControlAssets . Value . SERVICE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Satellite Radio Page config . createEndpoint ( \"satelliteRadioPage\" ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addToggleController ( \"satelliteRadio.screen\" , false ) . addAssetId ( CarControlAssets . Value . SATELLITE_RADIO_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Information Page config . createEndpoint ( \"informationPage\" ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addToggleController ( \"information.screen\" , false ) . addAssetId ( CarControlAssets . Value . INFORMATION_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Vehicle Status Page config . createEndpoint ( \"vehicleStatusPage\" ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addToggleController ( \"vehicleStatus.screen\" , false ) . addAssetId ( CarControlAssets . Value . VEHICLE_STATUS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Multimedia Page config . createEndpoint ( \"multimediaPage\" ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addAssetId ( CarControlAssets . Value . MUSIC_PAGE ) . addToggleController ( \"multimedia.screen\" , false ) . addAssetId ( CarControlAssets . Value . MULTIMEDIA_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Telephone Page config . createEndpoint ( \"telephonePage\" ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addToggleController ( \"telephone.screen\" , false ) . addAssetId ( CarControlAssets . Value . TELEPHONE_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Contacts Page config . createEndpoint ( \"contactsPage\" ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addToggleController ( \"contacts.screen\" , false ) . addAssetId ( CarControlAssets . Value . CONTACTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Alerts Page config . createEndpoint ( \"alertsPage\" ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addToggleController ( \"alerts.screen\" , false ) . addAssetId ( CarControlAssets . Value . ALERTS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // Notifications Page config . createEndpoint ( \"notificationsPage\" ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addToggleController ( \"notifications.screen\" , false ) . addAssetId ( CarControlAssets . Value . NOTIFICATIONS_PAGE ) . addActionTurnOff ( new String [] { CarControlConfiguration . Action . CLOSE }) . addActionTurnOn ( new String [] { CarControlConfiguration . Action . OPEN }); // 360 Camera config . createEndpoint ( \"360Camera\" ) . addAssetId ( CarControlAssets . Device . CAMERA_360 ) . addAssetId ( CarControlAssets . Device . AVM_CAMERA ) . addPowerController ( false ) . addModeController ( \"direction\" , false , true ) . addAssetId ( CarControlAssets . Setting . DIRECTION ) . addValue ( \"FRONT\" ) . addAssetId ( CarControlAssets . Location . FRONT ) . addValue ( \"REAR\" ) . addAssetId ( CarControlAssets . Location . REAR ) . addValue ( \"DRIVER\" ) . addAssetId ( CarControlAssets . Location . DRIVER ) . addValue ( \"PASSENGER\" ) . addAssetId ( CarControlAssets . Location . PASSENGER ) . addValue ( \"AUTO\" ) . addAssetId ( CarControlAssets . Setting . AUTO ); // Steering Wheel config . createEndpoint ( \"steeringWheel\" ) . addAssetId ( CarControlAssets . Device . STEERING_WHEEL ) . addToggleController ( \"heater\" , false ) . addAssetId ( CarControlAssets . Device . HEATER ) . addAssetId ( CarControlAssets . Setting . HEAT ); // Hood config . createEndpoint ( \"hood\" ) . addAssetId ( CarControlAssets . Device . HOOD ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Trunk config . createEndpoint ( \"trunk\" ) . addAssetId ( CarControlAssets . Device . TRUNK ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Charge Door config . createEndpoint ( \"chargedoor\" ) . addAssetId ( CarControlAssets . Device . CHARGE_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); // Gas Door config . createEndpoint ( \"gasdoor\" ) . addAssetId ( CarControlAssets . Device . GAS_DOOR ) . addModeController ( \"position\" , false , false ) . addAssetId ( CarControlAssets . Setting . POSITION ) . addValue ( \"OPEN\" ) . addAssetId ( CarControlAssets . Value . OPEN ) . addValue ( \"CLOSED\" ) . addAssetId ( CarControlAssets . Value . CLOSED ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . CLOSE }, \"CLOSED\" ) . addActionSetMode ( new String [] { CarControlConfiguration . Action . OPEN }, \"OPEN\" ); configuration . add ( config );","title":"Configuration for Android Integration"},{"location":"modules/car-control/#using-the-car-control-module-aasb-messages","text":"The Auto SDK Engine provides an AASB message interface with topic CarControl for you to handle the car control directives from Alexa. The messages include an endpointId to identify the connected endpoint that Alexa identified to match the user's intent. For directives targeting primitive capability instances, the message includes the instanceId as well. The endpointId and instanceId match the configured IDs from aace.carControl.endpoints[i].endpointId and aace.carControl.endpoints[i].capabilities[j].instance , respectively.","title":"Using the Car Control Module AASB Messages"},{"location":"modules/car-control/#changing-the-power-state-of-an-endpoint","text":"When the user requests Alexa to turn an endpoint on or off, the Engine publishes a SetControllerValue message for power state . Your application must power on or off the endpoint and publish SetControllerReply message in response. Click to expand or collapse sequence diagram: Turning on AC Click to expand or collapse sequence diagram: Turning off AC","title":"Changing the power state of an endpoint"},{"location":"modules/car-control/#toggling-an-endpoint-property","text":"When the user requests Alexa to turn on or off a named property of an endpoint, the Engine publishes a SetControllerValue message for toggle of the setting . Your application must turn on or off the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Turning on the rear windshield defroster Click to expand or collapse sequence diagram: Turning off the rear windshield defroster","title":"Toggling an endpoint property"},{"location":"modules/car-control/#changing-the-mode-of-an-endpoint-property","text":"When the user requests Alexa to set the mode of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for mode of the setting . Your application must set the mode of the property and publish SetControllerValueReply` message in response. Click to expand or collapse sequence diagram: Setting the AC intensity to minimum When the user requests Alexa to increase or decrease the mode of a named property of an endpoint, the Engine publishes an AdjustControllerValue message for mode of the setting . Your application must adjust the mode of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the AC intensity","title":"Changing the mode of an endpoint property"},{"location":"modules/car-control/#changing-the-numeric-setting-of-an-endpoint-property","text":"When the user requests Alexa to set the numeric setting of a named property of an endpoint to a specific value, the Engine publishes a SetControllerValue message for the range setting . Your application must set the value of the property and publish SetControllerValueReply message in response. Click to expand or collapse sequence diagram: Setting the temperature to 70 When the user requests Alexa to adjust (increment or decrement) the numeric setting of a named property of an endpoint by a delta value, the Engine publishes a AdjustControllerValue message for the range setting . Your application must adjust the value of the property and publish AdjustControllerValueReply message in response. Click to expand or collapse sequence diagram: Increasing the temperature by 4","title":"Changing the numeric setting of an endpoint property"},{"location":"modules/car-control/#integrating-the-car-control-module-into-your-application","text":"","title":"Integrating the Car Control Module Into Your Application"},{"location":"modules/car-control/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to subscribe to \"CarControl\" AASB messages and publish replies. Click to expand or collapse C++ sample code #include <AACE/CarControl/CarControlConfiguration.h> #include <AACE/Core/MessageBroker.h> #include <AASB/Message/CarControl/CarControl/AdjustControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/AdjustModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetRangeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetModeControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetPowerControllerValueMessage.h> #include <AASB/Message/CarControl/CarControl/SetToggleControllerValueMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyCarControlHandler { static const std :: string AASB_TOPIC_CAR_CONTROL ( \"CarControl\" ); static const std :: string AASB_ACTION_SET_CONTROLLER_VALUE ( \"SetControllerValue\" ); static const std :: string AASB_ACTION_ADJUST_CONTROLLER_VALUE ( \"AdjustControllerValue\" ); // Subscribe to \"CarControl\" messages from the Engine void MyCarControlHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_SET_CONTROLLER_VALUE ); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAdjustControllerValueMessage ( message ); }, AASB_TOPIC_CAR_CONTROL , AASB_ACTION_ADJUST_CONTROLLER_VALUE ); } // Handle the messages from the Engine for \"SetControllerValue\" action void MyCarControlHandler::handleSetControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"POWER\" ) == 0 ) { SetPowerControllerValueMessage msg = json :: parse ( message ); setPowerControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"TOGGLE\" ) == 0 ) { SetToggleControllerValueMessage msg = json :: parse ( message ); setToggleControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . turnOn ); } else if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { SetRangeControllerValueMessage msg = json :: parse ( message ); setRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { SetModeControllerValueMessage msg = json :: parse ( message ); setModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . value ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::setPowerControllerValue ( const std :: string & messageId , const std :: string & endpointId , bool turnOn ) { if ( turnOn ) { // Power on the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Power off the endpoint represented by endpointId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setToggleControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , bool turnOn ) { if ( turnOn ) { // Turn on the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } else { // Turn off the endpoint property represented by endpointId and instanceId. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } } void MyCarControlHandler::setRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double value ) { // Set the numeric setting of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::setModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , const std :: string & value ) { // Set the mode of the property represented by endpointId and instanceId to the specified value. // When complete, call sendSetControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendSetControllerValueMessageReply ( const std :: string & messageId , bool successful ) { SetControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); } // Handle the messages from the Engine for \"AdjustControllerValue\" action void MyCarControlHandler::handleAdjustControllerValueMessage ( const std :: string & message ) { json msgJson = json :: parse ( message ); std :: string capabilityType = msgJson [ \"payload\" ][ \"capabilityType\" ]; if ( capabilityType . compare ( \"RANGE\" ) == 0 ) { AdjustRangeControllerValueMessage msg = json :: parse ( message ); adjustRangeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else if ( capabilityType . compare ( \"MODE\" ) == 0 ) { AdjustModeControllerValueMessage msg = json :: parse ( message ); adjustModeControllerValue ( msg . header . id , msg . payload . endpointId , msg . payload . instanceId , msg . payload . delta ); } else { // Error. Unsupported controller type in message } } void MyCarControlHandler::adjustRangeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the numeric setting of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::adjustModeControllerValue ( const std :: string & messageId , const std :: string & endpointId , const std :: string & instanceId , double delta ) { // Adjust the mode of the property represented by endpointId and instanceId by the specified delta. // When complete, call sendAdjustControllerValueMessageReply() with messageId and the result } void MyCarControlHandler::sendAdjustControllerValueMessageReply ( const std :: string & messageId , bool successful ) { AdjustControllerValueMessageReply msg ; msg . header . messageDescription . replyToId = messageId ; msg . payload . success = successful ; m_messageBroker -> publish ( msg . toString ()); }","title":"C++ MessageBroker Integration"},{"location":"modules/car-control/#aacs-android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS Car Control Library to integrate the Auto SDK Car Control module on Android. See the AACS Car Control Library documentation for more information.","title":"AACS Android integration "},{"location":"modules/car-control/aasb-docs/CarControl/","text":"CarControl Outgoing Messages AdjustControllerValue Adjusts the range setting identified by endpointId and instanceId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{double}} } } Payload Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta double Yes The delta by which to adjust the range setting. AdjustControllerValue Adjusts the mode of the setting identified by endpointId and instanceId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{Int}} } } Payload Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta Int Yes The delta by which to adjust the mode. SetControllerValue Sets the power state of the endpoint identified by endpointId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"turnOn\": {{Bool}} } } Payload Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. turnOn Bool Yes The power setting. True to turn on the endpoint or False to turn off. SetControllerValue Sets the range setting identified by endpointId and instanceId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{double}} } } Payload Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value double Yes The new range setting. SetControllerValue Sets the toggle state of the setting identified by endpointId and instanceId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"turnOn\": {{Bool}} } } Payload Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. turnOn Bool Yes The power state of the setting. True to turn on the setting or False to turn off. SetControllerValue Sets the mode of the setting identified by endpointId and instanceId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{String}} } } Payload Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value String Yes The new mode to set. Incoming Messages AdjustControllerValue Reply for AdjustControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted. AdjustControllerValueReply Reply for AdjustControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted. SetControllerValue Reply for SetControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully. SetControllerValueReply Reply for SetControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully.","title":"CarControl"},{"location":"modules/car-control/aasb-docs/CarControl/#carcontrol","text":"","title":"CarControl"},{"location":"modules/car-control/aasb-docs/CarControl/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/car-control/aasb-docs/CarControl/#adjustcontrollervalue","text":"Adjusts the range setting identified by endpointId and instanceId.","title":"AdjustControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{double}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta double Yes The delta by which to adjust the range setting.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#adjustcontrollervalue_1","text":"Adjusts the mode of the setting identified by endpointId and instanceId.","title":"AdjustControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"delta\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_1","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. delta Int Yes The delta by which to adjust the mode.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#setcontrollervalue","text":"Sets the power state of the endpoint identified by endpointId.","title":"SetControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"turnOn\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_2","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. turnOn Bool Yes The power setting. True to turn on the endpoint or False to turn off.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#setcontrollervalue_1","text":"Sets the range setting identified by endpointId and instanceId.","title":"SetControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{double}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_3","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value double Yes The new range setting.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#setcontrollervalue_2","text":"Sets the toggle state of the setting identified by endpointId and instanceId.","title":"SetControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"turnOn\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_4","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. turnOn Bool Yes The power state of the setting. True to turn on the setting or False to turn off.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#setcontrollervalue_3","text":"Sets the mode of the setting identified by endpointId and instanceId.","title":"SetControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"controllerType\": {{String}}, \"capabilityType\": {{String}}, \"endpointId\": {{String}}, \"controllerId\": {{String}}, \"instanceId\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_5","text":"Property Type Required Description Example controllerType String Yes This attribute is deprecated in 4.0. Please use capabilityType. capabilityType String Yes Capability type. endpointId String Yes The unique identifier of the endpoint. controllerId String Yes Controller Id. This attribute is deprecated in 4.0. Please use instanceId. instanceId String Yes The unique identifier of the setting. value String Yes The new mode to set.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/car-control/aasb-docs/CarControl/#adjustcontrollervalue_2","text":"Reply for AdjustControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"AdjustControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\" } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_6","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#adjustcontrollervaluereply","text":"Reply for AdjustControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"AdjustControllerValueReply"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"AdjustControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_7","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was successfully adjusted.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#setcontrollervalue_4","text":"Reply for SetControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"SetControllerValue"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\" } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_8","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully.","title":"Payload"},{"location":"modules/car-control/aasb-docs/CarControl/#setcontrollervaluereply","text":"Reply for SetControllerValue messages. Failure to send the asynchronous reply message within 5 seconds results in a timeout.","title":"SetControllerValueReply"},{"location":"modules/car-control/aasb-docs/CarControl/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CarControl\", \"action\": \"SetControllerValue\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/car-control/aasb-docs/CarControl/#payload_9","text":"Property Type Required Description Example success Bool Yes Whether the requested setting was updated successfully.","title":"Payload"},{"location":"modules/cbl/","text":"Code-Based Linking (CBL) Module The Code-Based Linking (CBL) module implements the CBL mechanism of acquiring Login with Amazon (LWA) access tokens. Table of Contents Code-Based Linking (CBL) Module Overview Using the Authorization Platform Interface to Carry out CBL Authorization Starting Authorization Receiving Events from Engine Setting Authorization Data Getting Authorization Data Canceling Authorization Logging Out Handling Errors Enabling User Profile Sequence Diagrams for CBL Overview Every request to Alexa Voice Service (AVS) requires a Login with Amazon (LWA) access token. The Alexa Auto SDK CBL module implements the CBL mechanism of acquiring such tokens. Use the Authorization AASB message interface to start, cancel, and log out of CBL authorization. For more information about how the Engine manages authorization, see Alexa Auto SDK Authorization . Note : CBL and other authorization methods, such as Auth Provider , are mutually exclusive. For example, if the device is already registered with Auth Provider, starting CBL authorization logs out the device from the previous authorization. Important!: This document is not yet updated is updated to reflect the Auto SDK 4.0 MessageBroker message API. Some sections still include text, code samples, or diagrams that show the deprecated Authorization platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analagous Authorization AASB messages with the MessageBroker. The concepts are the same between the two interfaces. This document will be fully updated in the next Auto SDK version. Using the Authorization Platform Interface to Carry out CBL Authorization This section describes how an application uses the Authorization platform interface to carry out CBL authorization. The service name used by Authorization for CBL authorization is alexa:cbl . Starting Authorization This section describes how the startAuthorization API is used for starting authorization. The data parameter in the request has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The following list describes what value to pass for the data parameter: * If the application is starting a new CBL authorization session, pass an empty string as the data parameter. The following syntax shows how to start a new authorization: startAuthorization( \"alexa:cbl\", \"\") If the application is starting a CBL authorization session with an existing refresh token, it provides the refresh token obtained previously from setAuthorizationData() , with the key as refreshToken . The following example shows how to start authorization and pass the refresh token: startAuthorization( \u201calexa:cbl\u201d, \"{\"refreshToken\":\u201cAtzr|IQEBLzAtAhRP\u201d}\") Note: With the Authorization platform interface, it is the responsibility of the application to start authorization at every Engine start. Each time the Engine is restarted, it does not automatically start the authorization that was previously in effect before the Engine restart. Receiving Events from Engine This section describes the protocol for getting the code pair and user profile data by using the eventReceived API. The Engine passes the code pair to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"cbl-code\", \"payload\": { \"code\":\"{STRING}\", \"url\":\"{STRING}\" } } The following example provides the application with the CBL code and URL: eventReceived( \"alexa:cbl\", \"{\"type\":\"cbl-code\", \"payload\":{\"code\":\"OC2EFA\",\"url\":\"some-url\"}}\" ) The Engine passes the user profile data to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"user-profile\", \"payload\": { \"name\": \"{STRING}\", \"email\": \"{STRING}\" } } The following example provides the user profile data for an application to use the logged-in user's name and email: eventReceived( \"alexa:cbl\", \"{\"type\":\"user-profile\",\"payload\":{\"name\":\"some-name\",\"email\":\"some-email\"}}\" ) Setting Authorization Data This section describes the protocol for storing the refresh token by using the setAuthorizationData API. The Engine passes the refresh token to the application by using the refreshToken parameter, as shown in the following example: setAuthorizationData( \"alexa:cbl\", \"refreshToken\", \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\" ); Note : It is the responsibility of the application to securely store authorization data, such as the refresh token, on the device. Getting Authorization Data This section describes the protocol for the Engine to get the refresh token from the application using the getAuthorizationData API. The Engine asks the application to provide the refresh token previously obtained from setAuthorizationData . If this is the first time the application tries to authorize the device, pass an empty string. The string returned for this API has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The Engine calls the getAuthorizationData method as follows: getAuthorizationData(\"alexa:cbl\",\"refreshToken\") The application returns the refresh token as in the following example: \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\" Canceling Authorization This section describes how the application cancels an authorization. The API to use is cancelAuthorization , which can cancel the authorization and stop the CBL work flow at any time. For example, cancellation can happen when the application is waiting for the user to enter the code pair or when the access token is being refreshed. If the device is already authorized, the API cancels the token refreshing process. Canceling authorization does not affect the device authorization state. Logging Out The API to use is logout . The application makes this API call to the Engine to log out. Handling Errors This section describes the errors reported by the Engine. The following list describes possible errors during authorization: UNKNOWN_ERROR is an unrecoverable error in the authorization process. TIMEOUT happens when the application's attempt to get the code pair from the LWA Service times out. CODE_PAIR_EXPIRED is caused by an expired code pair. The application must restart the authorization process and request a new code pair. AUTHORIZATION_EXPIRED is caused by an expired or a revoked refresh token. LOGOUT_FAILED happens when a logout attempt fails. START_AUTHORIZATION_FAILED happens when the authorization flow cannot start. The Engine notifies the application about any error during authorization. The following example shows how the Engine notifies the application when a code pair expires: authorizationError( \"alexa:cbl\", \"CODE_PAIR_EXPIRED\", \"\" ) Enabling User Profile If you want the Engine to pass information about logged-in users to the application, include the following code in the Engine configuration: { \"aace.cbl\": { \"enableUserProfile\": true } } You can also generate the configuration programmatically by using the following method: auto userProfileConfig = aace :: cbl :: config :: CBLConfiguration :: createCBLUserProfileConfig ( true ); engine -> configure ( { //other config objects..., userProfileConfig, ... } ); The user profile is passed via the eventReceived API as described in this section . Sequence Diagrams for CBL The following diagram illustrates the flow when authorization starts. The following diagram illustrates how the Authorization platform interface handles a refresh token. The following diagram illustrates the flow when authorization is canceled. The following diagram illustrates the flow when the application logs out of the authorization.","title":"Code-Based Linking (CBL) Module"},{"location":"modules/cbl/#code-based-linking-cbl-module","text":"The Code-Based Linking (CBL) module implements the CBL mechanism of acquiring Login with Amazon (LWA) access tokens.","title":"Code-Based Linking (CBL) Module"},{"location":"modules/cbl/#table-of-contents","text":"Code-Based Linking (CBL) Module Overview Using the Authorization Platform Interface to Carry out CBL Authorization Starting Authorization Receiving Events from Engine Setting Authorization Data Getting Authorization Data Canceling Authorization Logging Out Handling Errors Enabling User Profile Sequence Diagrams for CBL","title":"Table of Contents"},{"location":"modules/cbl/#overview","text":"Every request to Alexa Voice Service (AVS) requires a Login with Amazon (LWA) access token. The Alexa Auto SDK CBL module implements the CBL mechanism of acquiring such tokens. Use the Authorization AASB message interface to start, cancel, and log out of CBL authorization. For more information about how the Engine manages authorization, see Alexa Auto SDK Authorization . Note : CBL and other authorization methods, such as Auth Provider , are mutually exclusive. For example, if the device is already registered with Auth Provider, starting CBL authorization logs out the device from the previous authorization. Important!: This document is not yet updated is updated to reflect the Auto SDK 4.0 MessageBroker message API. Some sections still include text, code samples, or diagrams that show the deprecated Authorization platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analagous Authorization AASB messages with the MessageBroker. The concepts are the same between the two interfaces. This document will be fully updated in the next Auto SDK version.","title":"Overview"},{"location":"modules/cbl/#using-the-authorization-platform-interface-to-carry-out-cbl-authorization","text":"This section describes how an application uses the Authorization platform interface to carry out CBL authorization. The service name used by Authorization for CBL authorization is alexa:cbl .","title":"Using the Authorization Platform Interface to Carry out CBL Authorization"},{"location":"modules/cbl/#starting-authorization","text":"This section describes how the startAuthorization API is used for starting authorization. The data parameter in the request has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The following list describes what value to pass for the data parameter: * If the application is starting a new CBL authorization session, pass an empty string as the data parameter. The following syntax shows how to start a new authorization: startAuthorization( \"alexa:cbl\", \"\") If the application is starting a CBL authorization session with an existing refresh token, it provides the refresh token obtained previously from setAuthorizationData() , with the key as refreshToken . The following example shows how to start authorization and pass the refresh token: startAuthorization( \u201calexa:cbl\u201d, \"{\"refreshToken\":\u201cAtzr|IQEBLzAtAhRP\u201d}\") Note: With the Authorization platform interface, it is the responsibility of the application to start authorization at every Engine start. Each time the Engine is restarted, it does not automatically start the authorization that was previously in effect before the Engine restart.","title":"Starting Authorization"},{"location":"modules/cbl/#receiving-events-from-engine","text":"This section describes the protocol for getting the code pair and user profile data by using the eventReceived API. The Engine passes the code pair to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"cbl-code\", \"payload\": { \"code\":\"{STRING}\", \"url\":\"{STRING}\" } } The following example provides the application with the CBL code and URL: eventReceived( \"alexa:cbl\", \"{\"type\":\"cbl-code\", \"payload\":{\"code\":\"OC2EFA\",\"url\":\"some-url\"}}\" ) The Engine passes the user profile data to the application by using the event parameter, which contains the following JSON structure: { \"type\": \"user-profile\", \"payload\": { \"name\": \"{STRING}\", \"email\": \"{STRING}\" } } The following example provides the user profile data for an application to use the logged-in user's name and email: eventReceived( \"alexa:cbl\", \"{\"type\":\"user-profile\",\"payload\":{\"name\":\"some-name\",\"email\":\"some-email\"}}\" )","title":"Receiving Events from Engine"},{"location":"modules/cbl/#setting-authorization-data","text":"This section describes the protocol for storing the refresh token by using the setAuthorizationData API. The Engine passes the refresh token to the application by using the refreshToken parameter, as shown in the following example: setAuthorizationData( \"alexa:cbl\", \"refreshToken\", \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\" ); Note : It is the responsibility of the application to securely store authorization data, such as the refresh token, on the device.","title":"Setting Authorization Data"},{"location":"modules/cbl/#getting-authorization-data","text":"This section describes the protocol for the Engine to get the refresh token from the application using the getAuthorizationData API. The Engine asks the application to provide the refresh token previously obtained from setAuthorizationData . If this is the first time the application tries to authorize the device, pass an empty string. The string returned for this API has the following JSON structure: { \"refreshToken\":\"{STRING}\" } The Engine calls the getAuthorizationData method as follows: getAuthorizationData(\"alexa:cbl\",\"refreshToken\") The application returns the refresh token as in the following example: \"{\"refreshToken\":\"Atzr|IQEBLzAtAhRP\"}\"","title":"Getting Authorization Data"},{"location":"modules/cbl/#canceling-authorization","text":"This section describes how the application cancels an authorization. The API to use is cancelAuthorization , which can cancel the authorization and stop the CBL work flow at any time. For example, cancellation can happen when the application is waiting for the user to enter the code pair or when the access token is being refreshed. If the device is already authorized, the API cancels the token refreshing process. Canceling authorization does not affect the device authorization state.","title":"Canceling Authorization"},{"location":"modules/cbl/#logging-out","text":"The API to use is logout . The application makes this API call to the Engine to log out.","title":"Logging Out"},{"location":"modules/cbl/#handling-errors","text":"This section describes the errors reported by the Engine. The following list describes possible errors during authorization: UNKNOWN_ERROR is an unrecoverable error in the authorization process. TIMEOUT happens when the application's attempt to get the code pair from the LWA Service times out. CODE_PAIR_EXPIRED is caused by an expired code pair. The application must restart the authorization process and request a new code pair. AUTHORIZATION_EXPIRED is caused by an expired or a revoked refresh token. LOGOUT_FAILED happens when a logout attempt fails. START_AUTHORIZATION_FAILED happens when the authorization flow cannot start. The Engine notifies the application about any error during authorization. The following example shows how the Engine notifies the application when a code pair expires: authorizationError( \"alexa:cbl\", \"CODE_PAIR_EXPIRED\", \"\" )","title":"Handling Errors"},{"location":"modules/cbl/#enabling-user-profile","text":"If you want the Engine to pass information about logged-in users to the application, include the following code in the Engine configuration: { \"aace.cbl\": { \"enableUserProfile\": true } } You can also generate the configuration programmatically by using the following method: auto userProfileConfig = aace :: cbl :: config :: CBLConfiguration :: createCBLUserProfileConfig ( true ); engine -> configure ( { //other config objects..., userProfileConfig, ... } ); The user profile is passed via the eventReceived API as described in this section .","title":"Enabling User Profile"},{"location":"modules/cbl/#sequence-diagrams-for-cbl","text":"The following diagram illustrates the flow when authorization starts. The following diagram illustrates how the Authorization platform interface handles a refresh token. The following diagram illustrates the flow when authorization is canceled. The following diagram illustrates the flow when the application logs out of the authorization.","title":"Sequence Diagrams for CBL"},{"location":"modules/cbl/aasb-docs/CBL/","text":"CBL Outgoing Messages CBLStateChanged (Deprecated) Notifies the platform implementation of an authorization flow state change. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"CBLStateChanged\" } }, \"payload\": { \"state\": {{CBLState}}, \"reason\": {{CBLStateChangedReason}}, \"url\": {{String}}, \"code\": {{String}} } } Payload Property Type Required Description Example state CBLState Yes State of the CBL Authorization flow. reason CBLStateChangedReason Yes The state change reason. url String Yes The localeized url to enter the CBL code. code String Yes The CBL code. ClearRefreshToken (Deprecated) Notifies the platform implementation to clear the refresh token. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"ClearRefreshToken\" } } } SetRefreshToken (Deprecated) Notifies the platform implemnentation to set the refresh token. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetRefreshToken\" } }, \"payload\": { \"refreshToken\": {{String}} } } Payload Property Type Required Description Example refreshToken String Yes The refresh token. GetRefreshToken (Deprecated) Returns the refresh token stored by the platform implementation, otherwise return an empty string. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\" } } } GetRefreshTokenReply Reply for GetRefreshToken message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\", \"replyToId\": {{String}} } }, \"payload\": { \"refreshToken\": {{String}} } } Payload Property Type Required Description Example refreshToken String Yes The refresh token. SetUserProfile (Deprecated) Notifies the platform implementation about the user profile. This is notified only when requestUserProfile is enabled in the configuration. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetUserProfile\" } }, \"payload\": { \"name\": {{String}}, \"email\": {{String}} } } Payload Property Type Required Description Example name String Yes The logged in user name. email String Yes The logged in user email. Incoming Messages Start (Deprecated) Notifies the Engine to cancel the authorization process. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Start\" } } } Cancel (Deprecated) Notifies the Engine to cancel the authorization process. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Cancel\" } } } Reset (Deprecated) Notifies the Engine to reset the authorization state. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Reset\" } } } Enums CBLState Specifies the state of the authorization flow. Values Value Description \"STARTING\" CBL process is starting. \"REQUESTING_CODE_PAIR\" Initiating the process to request a code pair. \"CODE_PAIR_RECEIVED\" Code pair is received and is waiting on user to authenticate. \"REFRESHING_TOKEN\" Refreshing token stage has begun. \"REQUESTING_TOKEN\" Requesting for authorization token. \"STOPPING\" CBL process is ending. CBLStateChangedReason Specifies the reason for the state change. Values Value Description \"SUCCESS\" The CBL state changed successfully. \"ERROR\" Error occurred in the CBL process. \"TIMEOUT\" Request timed out. \"CODE_PAIR_EXPIRED\" Code pair has expired and user will need to initiate the authentication process again. \"AUTHORIZATION_EXPIRED\" The refresh token is invalid, revoked, or was issued to a different client. \"NONE\" No reason specified.","title":"CBL"},{"location":"modules/cbl/aasb-docs/CBL/#cbl","text":"","title":"CBL"},{"location":"modules/cbl/aasb-docs/CBL/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/cbl/aasb-docs/CBL/#cblstatechanged","text":"(Deprecated) Notifies the platform implementation of an authorization flow state change.","title":"CBLStateChanged"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"CBLStateChanged\" } }, \"payload\": { \"state\": {{CBLState}}, \"reason\": {{CBLStateChangedReason}}, \"url\": {{String}}, \"code\": {{String}} } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#payload","text":"Property Type Required Description Example state CBLState Yes State of the CBL Authorization flow. reason CBLStateChangedReason Yes The state change reason. url String Yes The localeized url to enter the CBL code. code String Yes The CBL code.","title":"Payload"},{"location":"modules/cbl/aasb-docs/CBL/#clearrefreshtoken","text":"(Deprecated) Notifies the platform implementation to clear the refresh token.","title":"ClearRefreshToken"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"ClearRefreshToken\" } } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#setrefreshtoken","text":"(Deprecated) Notifies the platform implemnentation to set the refresh token.","title":"SetRefreshToken"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetRefreshToken\" } }, \"payload\": { \"refreshToken\": {{String}} } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#payload_1","text":"Property Type Required Description Example refreshToken String Yes The refresh token.","title":"Payload"},{"location":"modules/cbl/aasb-docs/CBL/#getrefreshtoken","text":"(Deprecated) Returns the refresh token stored by the platform implementation, otherwise return an empty string.","title":"GetRefreshToken"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\" } } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#getrefreshtokenreply","text":"Reply for GetRefreshToken message.","title":"GetRefreshTokenReply"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"GetRefreshToken\", \"replyToId\": {{String}} } }, \"payload\": { \"refreshToken\": {{String}} } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#payload_2","text":"Property Type Required Description Example refreshToken String Yes The refresh token.","title":"Payload"},{"location":"modules/cbl/aasb-docs/CBL/#setuserprofile","text":"(Deprecated) Notifies the platform implementation about the user profile. This is notified only when requestUserProfile is enabled in the configuration.","title":"SetUserProfile"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"SetUserProfile\" } }, \"payload\": { \"name\": {{String}}, \"email\": {{String}} } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#payload_3","text":"Property Type Required Description Example name String Yes The logged in user name. email String Yes The logged in user email.","title":"Payload"},{"location":"modules/cbl/aasb-docs/CBL/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/cbl/aasb-docs/CBL/#start","text":"(Deprecated) Notifies the Engine to cancel the authorization process.","title":"Start"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Start\" } } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#cancel","text":"(Deprecated) Notifies the Engine to cancel the authorization process.","title":"Cancel"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Cancel\" } } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#reset","text":"(Deprecated) Notifies the Engine to reset the authorization state.","title":"Reset"},{"location":"modules/cbl/aasb-docs/CBL/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CBL\", \"action\": \"Reset\" } } }","title":"JSON Structure"},{"location":"modules/cbl/aasb-docs/CBL/#enums","text":"","title":"Enums"},{"location":"modules/cbl/aasb-docs/CBL/#cblstate","text":"Specifies the state of the authorization flow.","title":"CBLState"},{"location":"modules/cbl/aasb-docs/CBL/#values","text":"Value Description \"STARTING\" CBL process is starting. \"REQUESTING_CODE_PAIR\" Initiating the process to request a code pair. \"CODE_PAIR_RECEIVED\" Code pair is received and is waiting on user to authenticate. \"REFRESHING_TOKEN\" Refreshing token stage has begun. \"REQUESTING_TOKEN\" Requesting for authorization token. \"STOPPING\" CBL process is ending.","title":"Values"},{"location":"modules/cbl/aasb-docs/CBL/#cblstatechangedreason","text":"Specifies the reason for the state change.","title":"CBLStateChangedReason"},{"location":"modules/cbl/aasb-docs/CBL/#values_1","text":"Value Description \"SUCCESS\" The CBL state changed successfully. \"ERROR\" Error occurred in the CBL process. \"TIMEOUT\" Request timed out. \"CODE_PAIR_EXPIRED\" Code pair has expired and user will need to initiate the authentication process again. \"AUTHORIZATION_EXPIRED\" The refresh token is invalid, revoked, or was issued to a different client. \"NONE\" No reason specified.","title":"Values"},{"location":"modules/connectivity/","text":"Connectivity Module Table of Contents Overview Configuring the Connectivity Module Using the Connectivity AASB Messages Integrating the Connectivity Module Into Your Application Overview The Connectivity module for the Alexa Auto SDK creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. This module allows the automaker to create tiered access to Alexa for customers and offer up-sell opportunities to subscribe to a full connectivity plan. A customer who purchases an Alexa-enabled vehicle typically has to subscribe to the automaker\u2019s connectivity plans and accept the automaker's and network provider's terms and conditions to access Alexa. Without the Connectivity module, if the customer declines the terms and conditions, or does not have a data plan (for example, due to plan expiration), the customer loses access to Alexa. The Connectivity module, however, provides an option that allows the automaker to offer a reduced set of Alexa functionality and limited bandwidth consumption for little or no cost. In this low data consumption mode, utterances sent to the cloud are filtered by feature, because the Connectivity module offers a restricted set of features. For example, when a user accesses Alexa through the Connectivity module, an utterance requesting music streaming does not start the streaming but turns on the FM radio station that was last played. Features such as weather and traffic remain accessible. Your application's Connectivity module integration is responsible for: Providing the network identifier for Alexa to send to the mobile network operator (MNO) Providing the vehicle's connection properties and configurations to Alexa Configuring the Connectivity Module The Connectivity module does not require Engine configuration. Using the Connectivity AASB Messages Providing the Network Identifier The network identifier is agnostic of the data plan and is assigned when initially integrated into the vehicle. It links the device with the network provider and enables the network provider to identify and provide device connectivity. Examples of the network identifier are the Embedded SIM ID (eSIM ID) and a globally unique ID (GUID). Which ID to use depends on the implementation determined in agreement with Amazon, OEM, and MNO. Note: The network identifier is optional. If it is missing, the Engine will use vehicleIdentifier in the Engine configuration as the network identifier. To learn more about vehicle information in the Engine configuration, see the Core module README . During device discovery the Engine publishes the GetIdentifier message . To report the network identifier to Alexa, publish the GetIdentifierReply message . Click to expand or collapse sequence diagram: Providing the Network Identifier Providing the Connectivity Status When a client application intiates connection with Alexa or when Alexa requests a report of the current connectivity state, publish the ConnectivityStateChange message . In response, the Engine will publish the GetConnectivityState message to which your application must publish the GetConnectivityStateReply message containing the connectivity state. The Engine will then publish the ConnectivityStateChangeReply message to indicate if the connectivity state was processed successfully. Alexa parses the internet connectivity information from the vehicle and determines whether the customer is eligible for the full or partial Alexa experience. The connectivityState obtained in the GetConnectivityState reply payload has the following schema: { \"managedProvider\": { \"type\": \"{{STRING_ENUM}}\", \"id\": \"{{STRING}}\" }, \"termStatus\": \"{{STRING_ENUM}}\", \"termsVersion\": \"{{STRING}}\", \"dataPlan\": { \"type\": \"{{STRING_ENUM}}\", \"endDate\": \"{{STRING}}\" }, \"dataPlansAvailable\": [\"{{STRING}}\", \"{{STRING}}\", ...] } Click to expand or collapse details about the objects in the payload Property Type Description Required dataPlan Object It provides the active data plan type and end date. Yes (only when managedProvider.type is MANAGED ) dataPlan.type String Accepted values: PAID indicates that the device has an active data plan paid for by the customer. TRIAL indicates that the device has an active data plan which has been provided to the customer as a promotional event. AMAZON_SPONSORED indicates that the customer has not paid for a data plan or signed up for a free trial. The customer can connect to the internet via a plan sponsored by Amazon and can access a limited number of Alexa features. A customer with either of PAID or TRIAL data plan has unrestricted access to all Alexa features. Yes dataPlan.endDate String It specifies the date on which the trial data plan ends. If it is not set, there is no end date for the plan. The value is in the RFC 3339 format. Yes (only when dataPlan.type is TRIAL ) termsStatus String It indicates whether the customer has accepted the terms and conditions of the OEM and MNO. If it is not set, the behavior is the same as when it is set to DECLINED . Accepted values : ACCEPTED means that the customer has agreed to receive voice messages from Alexa, which enable the customer to use voice to purchase a data plan. DECLINED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. DEFERRED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. However, Alexa might remind the user to respond to the terms and conditions again. No, but recommended termsVersion String It indicates the version of the terms and conditions presented to the user. Do not use termsVersion if you do not use termsStatus . Maximum length is 250 characters. Note: If you implemented Auto SDK 3.1 with the Connectivity module, a default value is automatically assigned to termsVersion . For Auto SDK 3.2 or later, be sure to specify termsVersion . Otherwise, the MNO is not notified of the correct version of the terms and conditions presented to the user. Yes (only when termsStatus is provided) dataPlansAvailable String array It indicates the data plans that can be activated. Accepted values are PAID , AMAZON_SPONSORED , and TRIAL . For example, if the array is [\"TRIAL\", \"AMAZON_SPONSORED\", \"PAID\"] , Alexa encourages the user to upgrade from an AMAZON_SPONSORED plan to a TRIAL plan or from a TRIAL plan to a PAID plan. No managedProvider Object It provides information about the type of network connectivity that the device has. Yes managedProvider.type String Accepted Values: MANAGED means the device's internet connectivity is managed by a provider. The only possible provider that manages connectivity is Amazon. The Alexa experience is affected by the current connectivity state in the following ways: If the customer is on a paid or trial data plan, MANAGED has no effect on the customer's Alexa experience. If the customer does not have a paid or trial data plan, the customer, through the AlexaConnectivity platform interface, can access a limited number of Alexa features. NOT_MANAGED means the device's internet connectivity is not managed by a provider. For example, assign this value if the customer accesses the internet via a WiFi network or mobile hotspot. The customer can access all Alexa features, regardless of the current connectivity state. Yes managedProvider.id String It specifies the name of the provider that manages connectivity. The only accepted value is AMAZON . Yes (only when managedProvider.type is MANAGED ) Click to expand or collapse sequence diagram: Connectivity Report Activating Voice Up-Sell Conversation To activate the voice up-sell conversation with Alexa (e.g., to activate the trial or paid plan subscription), publish the SendConnectivityEvent message . The Engine publishes the SendConnectivityEventReply message specifying the delivery status of the event. The event sent in the SendConnectivityEvent message payload has the following schema: { \"type\": \"{{STRING}}\" } Note: Alexa requires the customer to have accepted the OEM and network provider's terms and conditions before starting the voice conversation. Click to expand or collapse details about the objects in the payload Property Type Description Required type String Represents the type of the connectivity event to Alexa. Accepted Values : ACTIVATE_TRIAL for Alexa to begin the trial data plan activation (if available). Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Note: If the platform implementation cannot determine the data plan type, use this event type. Alexa would first check the trial eligibility. If the customer is not eligible, Alexa begins the paid plan voice conversation. ACTIVATE_PAID_PLAN for Alexa to begin the paid data plan activation. Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Yes Click to expand or collapse sequence diagram: Send Connectivity Event Integrating the Connectivity Module Into Your Application C++ MessageBroker Integration Use the Engine's MessageBroker to publish \"Connectivity\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Connectivity/AlexaConnectivity/StatusCode.h> #include <AASB/Message/Connectivity/AlexaConnectivity/ConnectivityStateChangeMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetConnectivityStateMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetIdentifierMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/SendConnectivityEventMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAlexaConnectivityHandler { // Subscribe to messages from the Engine void MyAlexaConnectivityHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetConnectivityStateMessage ( message ); }, GetConnectivityStateMessage :: topic (), GetConnectivityStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetIdentifierMessage ( message ); }, GetIdentifierMessage :: topic (), GetIdentifierMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleConnectivityStateChangeReplyMessage ( message ); }, ConnectivityStateChangeMessageReply :: topic (), ConnectivityStateChangeMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendConnectivityEventReplyMessage ( message ); }, SendConnectivityEventMessageReply :: topic (), SendConnectivityEventMessageReply :: action ()); } // Handle the ConnectivityStateChange reply message from the Engine void MyAlexaConnectivityHandler::handleConnectivityStateChangeReplyMessage ( const std :: string & message ) { ConnectivityStateChangeMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; // ...Handle change in the connectivity state... } // Handle the SendConnectivityEvent reply message from the Engine void MyAlexaConnectivityHandler::handleSendConnectivityEventReplyMessage ( const std :: string & message ) { SendConnectivityEventMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; StatusCode statusCode = msg . payload . statusCode ; // ...Handle delivery status of the event... } // Handle the GetConnectivityState message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetConnectivityStateMessage ( const std :: string & message ) { GetConnectivityStateMessage msg = json :: parse ( message ); GetConnectivityStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . connectivityState = getConnectivityState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the GetIdentifier message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetIdentifierMessage ( const std :: string & message ) { GetIdentifierMessage msg = json :: parse ( message ); GetIdentifierMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . identifier = getIdentifier (); m_messageBroker -> publish ( replyMsg . toString ()); } // To report a connectivity status change to Alexa, publish a ConnectivityStateChange message to the Engine bool MyAlexaConnectivityHandler::connectivityStateChange () { ConnectivityStateChangeMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the ConnectivityStateChangeReply message // Return the success status from reply message payload } // To activate a voice up-sell conversation with Alexa, publish a SendConnectivityEvent message to the Engine StatusCode MyAlexaConnectivityHandler::sendConnectivityEvent ( const std :: string & event ) { SendConnectivityEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the SendConnectivityEventReply message // Return the statusCode from reply message payload } // Implement to retrieve the connectivity state std :: string MyAlexaConnectivityHandler::getConnectivityState (); // Implement to retrieve the identifier std :: string MyAlexaConnectivityHandler::getIdentifier (); }; Android Integration This lower data consumption mode for Alexa is not available in the Alexa Auto Client Service (AACS). If you are interested in creating tiered access to Alexa for customers you are required to implement it independently using AASB Messages.","title":"Connectivity Module"},{"location":"modules/connectivity/#connectivity-module","text":"Table of Contents Overview Configuring the Connectivity Module Using the Connectivity AASB Messages Integrating the Connectivity Module Into Your Application","title":"Connectivity Module"},{"location":"modules/connectivity/#overview","text":"The Connectivity module for the Alexa Auto SDK creates a lower data consumption mode for Alexa, allowing automakers to offer tiered functionality based on the status of their connectivity plans. By using this module, you can send the customer's connectivity status from the vehicle to Alexa, which determines whether the customer can enjoy a full or partial set of Alexa features. This module allows the automaker to create tiered access to Alexa for customers and offer up-sell opportunities to subscribe to a full connectivity plan. A customer who purchases an Alexa-enabled vehicle typically has to subscribe to the automaker\u2019s connectivity plans and accept the automaker's and network provider's terms and conditions to access Alexa. Without the Connectivity module, if the customer declines the terms and conditions, or does not have a data plan (for example, due to plan expiration), the customer loses access to Alexa. The Connectivity module, however, provides an option that allows the automaker to offer a reduced set of Alexa functionality and limited bandwidth consumption for little or no cost. In this low data consumption mode, utterances sent to the cloud are filtered by feature, because the Connectivity module offers a restricted set of features. For example, when a user accesses Alexa through the Connectivity module, an utterance requesting music streaming does not start the streaming but turns on the FM radio station that was last played. Features such as weather and traffic remain accessible. Your application's Connectivity module integration is responsible for: Providing the network identifier for Alexa to send to the mobile network operator (MNO) Providing the vehicle's connection properties and configurations to Alexa","title":"Overview "},{"location":"modules/connectivity/#configuring-the-connectivity-module","text":"The Connectivity module does not require Engine configuration.","title":"Configuring the Connectivity Module "},{"location":"modules/connectivity/#using-the-connectivity-aasb-messages","text":"","title":"Using the Connectivity AASB Messages "},{"location":"modules/connectivity/#providing-the-network-identifier","text":"The network identifier is agnostic of the data plan and is assigned when initially integrated into the vehicle. It links the device with the network provider and enables the network provider to identify and provide device connectivity. Examples of the network identifier are the Embedded SIM ID (eSIM ID) and a globally unique ID (GUID). Which ID to use depends on the implementation determined in agreement with Amazon, OEM, and MNO. Note: The network identifier is optional. If it is missing, the Engine will use vehicleIdentifier in the Engine configuration as the network identifier. To learn more about vehicle information in the Engine configuration, see the Core module README . During device discovery the Engine publishes the GetIdentifier message . To report the network identifier to Alexa, publish the GetIdentifierReply message . Click to expand or collapse sequence diagram: Providing the Network Identifier","title":"Providing the Network Identifier"},{"location":"modules/connectivity/#providing-the-connectivity-status","text":"When a client application intiates connection with Alexa or when Alexa requests a report of the current connectivity state, publish the ConnectivityStateChange message . In response, the Engine will publish the GetConnectivityState message to which your application must publish the GetConnectivityStateReply message containing the connectivity state. The Engine will then publish the ConnectivityStateChangeReply message to indicate if the connectivity state was processed successfully. Alexa parses the internet connectivity information from the vehicle and determines whether the customer is eligible for the full or partial Alexa experience. The connectivityState obtained in the GetConnectivityState reply payload has the following schema: { \"managedProvider\": { \"type\": \"{{STRING_ENUM}}\", \"id\": \"{{STRING}}\" }, \"termStatus\": \"{{STRING_ENUM}}\", \"termsVersion\": \"{{STRING}}\", \"dataPlan\": { \"type\": \"{{STRING_ENUM}}\", \"endDate\": \"{{STRING}}\" }, \"dataPlansAvailable\": [\"{{STRING}}\", \"{{STRING}}\", ...] } Click to expand or collapse details about the objects in the payload Property Type Description Required dataPlan Object It provides the active data plan type and end date. Yes (only when managedProvider.type is MANAGED ) dataPlan.type String Accepted values: PAID indicates that the device has an active data plan paid for by the customer. TRIAL indicates that the device has an active data plan which has been provided to the customer as a promotional event. AMAZON_SPONSORED indicates that the customer has not paid for a data plan or signed up for a free trial. The customer can connect to the internet via a plan sponsored by Amazon and can access a limited number of Alexa features. A customer with either of PAID or TRIAL data plan has unrestricted access to all Alexa features. Yes dataPlan.endDate String It specifies the date on which the trial data plan ends. If it is not set, there is no end date for the plan. The value is in the RFC 3339 format. Yes (only when dataPlan.type is TRIAL ) termsStatus String It indicates whether the customer has accepted the terms and conditions of the OEM and MNO. If it is not set, the behavior is the same as when it is set to DECLINED . Accepted values : ACCEPTED means that the customer has agreed to receive voice messages from Alexa, which enable the customer to use voice to purchase a data plan. DECLINED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. DEFERRED means that the customer does not accept the terms and conditions, and will not receive reminders from Alexa for a data plan upgrade. However, Alexa might remind the user to respond to the terms and conditions again. No, but recommended termsVersion String It indicates the version of the terms and conditions presented to the user. Do not use termsVersion if you do not use termsStatus . Maximum length is 250 characters. Note: If you implemented Auto SDK 3.1 with the Connectivity module, a default value is automatically assigned to termsVersion . For Auto SDK 3.2 or later, be sure to specify termsVersion . Otherwise, the MNO is not notified of the correct version of the terms and conditions presented to the user. Yes (only when termsStatus is provided) dataPlansAvailable String array It indicates the data plans that can be activated. Accepted values are PAID , AMAZON_SPONSORED , and TRIAL . For example, if the array is [\"TRIAL\", \"AMAZON_SPONSORED\", \"PAID\"] , Alexa encourages the user to upgrade from an AMAZON_SPONSORED plan to a TRIAL plan or from a TRIAL plan to a PAID plan. No managedProvider Object It provides information about the type of network connectivity that the device has. Yes managedProvider.type String Accepted Values: MANAGED means the device's internet connectivity is managed by a provider. The only possible provider that manages connectivity is Amazon. The Alexa experience is affected by the current connectivity state in the following ways: If the customer is on a paid or trial data plan, MANAGED has no effect on the customer's Alexa experience. If the customer does not have a paid or trial data plan, the customer, through the AlexaConnectivity platform interface, can access a limited number of Alexa features. NOT_MANAGED means the device's internet connectivity is not managed by a provider. For example, assign this value if the customer accesses the internet via a WiFi network or mobile hotspot. The customer can access all Alexa features, regardless of the current connectivity state. Yes managedProvider.id String It specifies the name of the provider that manages connectivity. The only accepted value is AMAZON . Yes (only when managedProvider.type is MANAGED ) Click to expand or collapse sequence diagram: Connectivity Report","title":"Providing the Connectivity Status"},{"location":"modules/connectivity/#activating-voice-up-sell-conversation","text":"To activate the voice up-sell conversation with Alexa (e.g., to activate the trial or paid plan subscription), publish the SendConnectivityEvent message . The Engine publishes the SendConnectivityEventReply message specifying the delivery status of the event. The event sent in the SendConnectivityEvent message payload has the following schema: { \"type\": \"{{STRING}}\" } Note: Alexa requires the customer to have accepted the OEM and network provider's terms and conditions before starting the voice conversation. Click to expand or collapse details about the objects in the payload Property Type Description Required type String Represents the type of the connectivity event to Alexa. Accepted Values : ACTIVATE_TRIAL for Alexa to begin the trial data plan activation (if available). Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Note: If the platform implementation cannot determine the data plan type, use this event type. Alexa would first check the trial eligibility. If the customer is not eligible, Alexa begins the paid plan voice conversation. ACTIVATE_PAID_PLAN for Alexa to begin the paid data plan activation. Alexa, upon receiving this event, may perform some validations and eligibility checks before starting the voice conversation. Yes Click to expand or collapse sequence diagram: Send Connectivity Event","title":"Activating Voice Up-Sell Conversation"},{"location":"modules/connectivity/#integrating-the-connectivity-module-into-your-application","text":"","title":"Integrating the Connectivity Module Into Your Application "},{"location":"modules/connectivity/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to publish \"Connectivity\" AASB messages and subscribe to their replies. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Connectivity/AlexaConnectivity/StatusCode.h> #include <AASB/Message/Connectivity/AlexaConnectivity/ConnectivityStateChangeMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetConnectivityStateMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/GetIdentifierMessage.h> #include <AASB/Message/Connectivity/AlexaConnectivity/SendConnectivityEventMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyAlexaConnectivityHandler { // Subscribe to messages from the Engine void MyAlexaConnectivityHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetConnectivityStateMessage ( message ); }, GetConnectivityStateMessage :: topic (), GetConnectivityStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetIdentifierMessage ( message ); }, GetIdentifierMessage :: topic (), GetIdentifierMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleConnectivityStateChangeReplyMessage ( message ); }, ConnectivityStateChangeMessageReply :: topic (), ConnectivityStateChangeMessageReply :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendConnectivityEventReplyMessage ( message ); }, SendConnectivityEventMessageReply :: topic (), SendConnectivityEventMessageReply :: action ()); } // Handle the ConnectivityStateChange reply message from the Engine void MyAlexaConnectivityHandler::handleConnectivityStateChangeReplyMessage ( const std :: string & message ) { ConnectivityStateChangeMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; // ...Handle change in the connectivity state... } // Handle the SendConnectivityEvent reply message from the Engine void MyAlexaConnectivityHandler::handleSendConnectivityEventReplyMessage ( const std :: string & message ) { SendConnectivityEventMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; StatusCode statusCode = msg . payload . statusCode ; // ...Handle delivery status of the event... } // Handle the GetConnectivityState message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetConnectivityStateMessage ( const std :: string & message ) { GetConnectivityStateMessage msg = json :: parse ( message ); GetConnectivityStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . connectivityState = getConnectivityState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the GetIdentifier message from the Engine and publish the reply message to the Engine void MyAlexaConnectivityHandler::handleGetIdentifierMessage ( const std :: string & message ) { GetIdentifierMessage msg = json :: parse ( message ); GetIdentifierMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . identifier = getIdentifier (); m_messageBroker -> publish ( replyMsg . toString ()); } // To report a connectivity status change to Alexa, publish a ConnectivityStateChange message to the Engine bool MyAlexaConnectivityHandler::connectivityStateChange () { ConnectivityStateChangeMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the ConnectivityStateChangeReply message // Return the success status from reply message payload } // To activate a voice up-sell conversation with Alexa, publish a SendConnectivityEvent message to the Engine StatusCode MyAlexaConnectivityHandler::sendConnectivityEvent ( const std :: string & event ) { SendConnectivityEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the SendConnectivityEventReply message // Return the statusCode from reply message payload } // Implement to retrieve the connectivity state std :: string MyAlexaConnectivityHandler::getConnectivityState (); // Implement to retrieve the identifier std :: string MyAlexaConnectivityHandler::getIdentifier (); };","title":"C++ MessageBroker Integration"},{"location":"modules/connectivity/#android-integration","text":"This lower data consumption mode for Alexa is not available in the Alexa Auto Client Service (AACS). If you are interested in creating tiered access to Alexa for customers you are required to implement it independently using AASB Messages.","title":"Android Integration"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/","text":"AlexaConnectivity Outgoing Messages GetConnectivityState Retrieve the connectivity state from the platform implementation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\" } } } GetConnectivityStateReply Reply for GetConnectivityState message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\", \"replyToId\": {{String}} } }, \"payload\": { \"connectivityState\": {{String}} } } Payload Property Type Required Description Example connectivityState String Yes A string representing the connectivity state in structured JSON format. GetIdentifier Retrieve the identifier from the platform implementation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\" } } } GetIdentifierReply Reply for GetIdentifier message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\", \"replyToId\": {{String}} } }, \"payload\": { \"identifier\": {{String}} } } Payload Property Type Required Description Example identifier String Yes A string representing the identifier. Incoming Messages ConnectivityStateChange Notifies the Engine of a change in the connectivity state. The Engine calls getConnectivityState to retrieve the the connectivity state and communicate any changes to Alexa. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\" } } } ConnectivityStateChangeReply Reply for ConnectivityStateChange message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } } Payload Property Type Required Description Example success Bool Yes Returns true if connectivity state was processed successfully, false otherwise. SendConnectivityEvent Notifies an event in the connectivity to the Engine. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\" } }, \"payload\": { \"event\": {{String}} } } Payload Property Type Required Description Example event String Yes The stringified JSON containing the event. SendConnectivityEventReply Reply for SendConnectivityEvent message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\", \"replyToId\": {{String}} } }, \"payload\": { \"statusCode\": {{StatusCode}} } } Payload Property Type Required Description Example statusCode StatusCode Yes Represents the delivery status of event. Enums StatusCode Values Value Description \"SUCCESS\" The event was sent to AVS successfully. \"FAIL\" The event was not sent to AVS successfully.","title":"AlexaConnectivity"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#alexaconnectivity","text":"","title":"AlexaConnectivity"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#getconnectivitystate","text":"Retrieve the connectivity state from the platform implementation.","title":"GetConnectivityState"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\" } } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#getconnectivitystatereply","text":"Reply for GetConnectivityState message.","title":"GetConnectivityStateReply"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetConnectivityState\", \"replyToId\": {{String}} } }, \"payload\": { \"connectivityState\": {{String}} } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#payload","text":"Property Type Required Description Example connectivityState String Yes A string representing the connectivity state in structured JSON format.","title":"Payload"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#getidentifier","text":"Retrieve the identifier from the platform implementation.","title":"GetIdentifier"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\" } } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#getidentifierreply","text":"Reply for GetIdentifier message.","title":"GetIdentifierReply"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"GetIdentifier\", \"replyToId\": {{String}} } }, \"payload\": { \"identifier\": {{String}} } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#payload_1","text":"Property Type Required Description Example identifier String Yes A string representing the identifier.","title":"Payload"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#connectivitystatechange","text":"Notifies the Engine of a change in the connectivity state. The Engine calls getConnectivityState to retrieve the the connectivity state and communicate any changes to Alexa.","title":"ConnectivityStateChange"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\" } } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#connectivitystatechangereply","text":"Reply for ConnectivityStateChange message.","title":"ConnectivityStateChangeReply"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"ConnectivityStateChange\", \"replyToId\": {{String}} } }, \"payload\": { \"success\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#payload_2","text":"Property Type Required Description Example success Bool Yes Returns true if connectivity state was processed successfully, false otherwise.","title":"Payload"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#sendconnectivityevent","text":"Notifies an event in the connectivity to the Engine.","title":"SendConnectivityEvent"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\" } }, \"payload\": { \"event\": {{String}} } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#payload_3","text":"Property Type Required Description Example event String Yes The stringified JSON containing the event.","title":"Payload"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#sendconnectivityeventreply","text":"Reply for SendConnectivityEvent message.","title":"SendConnectivityEventReply"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AlexaConnectivity\", \"action\": \"SendConnectivityEvent\", \"replyToId\": {{String}} } }, \"payload\": { \"statusCode\": {{StatusCode}} } }","title":"JSON Structure"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#payload_4","text":"Property Type Required Description Example statusCode StatusCode Yes Represents the delivery status of event.","title":"Payload"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#enums","text":"","title":"Enums"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#statuscode","text":"","title":"StatusCode"},{"location":"modules/connectivity/aasb-docs/AlexaConnectivity/#values","text":"Value Description \"SUCCESS\" The event was sent to AVS successfully. \"FAIL\" The event was not sent to AVS successfully.","title":"Values"},{"location":"modules/core/","text":"Core Module Table of Contents Core module overview Understand the Auto SDK API The Engine MessageBroker AASB message interfaces Manage the Engine lifecycle in your application Create the Engine Configure the Engine Specify configuration in a file Specify configuration programatically Subscribe to AASB messages Start the Engine Stop the Engine Shut down the Engine Configure the Core module (Required) Vehicle info configuration (Required) Storage configuration (Optional) Logger configuration (Optional) cURL configuration (Optional) AASB and MessageBroker configuration (Optional) Configure enabled interfaces (Optional) Configure the synchronous message timeout Understand the key core Engine services Authorization Audio input and output Runtime properties Provide core device status Report location with LocationProvider Report network status changes with NetworkInfoProvider Report data usage with DeviceUsage Core module overview The Alexa Auto SDK Core module is the heart of the SDK. The Core module acts as the foundation for all Auto SDK features by contributing the following essential elements to the SDK: - Defining the Auto SDK API for your application\u2014 Core defines the Engine and MessageBroker components. Alongside the Alexa Auto Services Bridge (AASB) messages defined by each Auto SDK module, these components comprise the core API for your application to access the features of Auto SDK. To learn about the API, see Understand the Auto SDK API . Providing an infrastructure to other modules\u2014 Core provides the base infrastructure of the Engine, which each Auto SDK module extends to add module-specific features. Core also defines the common Engine services for logging, audio I/O, authorization, and device settings. Each module uses these Engine services to provide its own module-specific features. To learn about the primary core services, see Understand the key core Engine services . Receiving core device statuses from your application\u2014 Core includes AASB message interfaces for your application to report essential information such as device location and network connection status. The Engine uses this information to provide a reliable experience to the user. To learn about the core device status interfaces, see Provide core device status . Important! : If you are an Android developer, your application will use the Alexa Auto Client Service (AACS) as its foundation. AACS implements much of the core Auto SDK setup, abstracting it from your application and exposing only a necessary subset of the Auto SDK API in an Android-specific way. Some of the information presented in this documentation and documentation for other SDK modules might not pertain to your application exactly as written for cases in which AACS provides the implementation or further abstracts it, so keep this in mind while reading. Use the module documentation to understand the underlying layers of Auto SDK, if interested, and to reference the Engine configuration and AASB message definitions for the features you do need to build into your application yourself. Understand the Auto SDK API The Engine , MessageBroker , and AASB message interfaces comprise the Auto SDK API. Your application uses these three components to build a complete Alexa client implementation for your vehicle. The Engine The Auto SDK Engine is a system of components that provide the core implementation of all Auto SDK features. With respect to Alexa, your application's Alexa client stack uses the Engine as the layer that sets up the connection to Alexa, publishes device capabilities, sends Alexa events, sequences Alexa directives, and more. Your application creates an instance of the Engine and uses a simple interface to manage the Engine lifecycle for the duration of the application run time. Aside from setting up the Engine, the primary responsibility of your application is to provide the platform-specific, customizable integration details that make Alexa and other core SDK features work for your vehicle, in particular. Platform-specific integration might include interacting with external libraries or the underlying software frameworks of your operating system to complete the Auto SDK client stack with deep integration into the applications on your system. The Engine implements as much of the general functionality as possible; for integration details that it can't implement, the Engine delegates responsibility to your application via AASB messages published through the MessageBroker . MessageBroker The MessageBroker is the bridge in the Alexa Auto Services Bridge (AASB). MessageBroker provides a publish and subscribe API to the Engine and your application for communication with each other. In order to consume a message that the Engine publishes to your application, your application uses MessageBroker to subscribe to the message by specifying the message topic and action as well as a function for MessageBroker to invoke to deliver the message. Similarly, the Engine uses MessageBroker to subscribe to messages published by your application. AASB message interfaces A typical Auto SDK module defines one or more AASB message interfaces. An interface groups logically related messages together with a topic . Within the topic , each interface has one or more actions to represent individual messages. I.e., a topic + action combination identifies a single message. For instance, the Alexa module defines many interfaces related to standard Alexa features. The Alexa module SpeechRecogizer interface defines messages for your application to publish to the Engine when the user invokes Alexa. It also defines messages the Engine publishes to your application to convey key events in the user speech stream. For example, your application publishes a SpeechRecognizer.StartCapture message when the user taps the Alexa invocation button: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"12345\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"StartCapture\" } }, \"payload\" : { \"initiator\" : \"TAP_TO_TALK\" } } The Engine subscribes to this message at startup time, so it is ready to consume the message when published by your application. In response to the message, the Engine sends the user speech audio to Alexa. Alexa processes the speech, and when she detects the user has finished speaking, the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message to your application: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"00876\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"EndOfSpeechDetected\" } } } Your application receives this message from MessageBroker if it subscribed to the SpeechRecognizer topic and EndOfSpeechDetected action. MessageBroker uses AASB messages as serialized JSON strings; however, for convenience, Auto SDK provides C++ wrapper classes for each message that help with the serialization and deserialization. The Auto SDK build system generates these wrapper classes as part of the build. Manage the Engine lifecycle in your application To use Auto SDK features, your application must instantiate and manage the lifecycle of the Engine. Create the Engine During the launch sequence of your application, create one instance of the Engine using the static function aace::core::Engine::create() : std :: shared_ptr < aace :: core :: Engine > engine = aace :: core :: Engine :: create (); A typical application creates the Engine once when the user turns on the vehicle ignition and uses the instance until the user turns off the vehicle ignition. Configure the Engine After creating the Engine instance, configure it with the required Engine configurations. Engine configuration uses JSON serialized as strings, but you pass the configurations to the Engine in one or more aace::core::config::EngineConfiguration wrapper objects. Auto SDK provides two options to generate EngineConfiguration objects: - Specify your Engine configuration in a JSON file and construct an EngineConfiguration from a path to the file - Build the configuration programatically using one of the configuration factory functions. You can choose either option or a combination of both. I.e., you can generate a single EngineConfiguration object that includes all configuration data for the Engine components you use, or you can break up the configuration data into logical sections and generate multiple EngineConfiguration objects. For example, you might generate one EngineConfiguration object for each module. To configure the Engine, call the Engine's configure() function, passing in the EngineConfiguration object(s): For a single EngineConfiguration object: engine->configure( config ); For multiple EngineConfiguration objects: engine->configure( { xConfig, yConfig, zConfig } ); replacing xConfig, yConfig, zConfig with logical names to identify the EngineConfiguration objects you generated. Note : For one Engine instance, you can call the configure() function only once, and you must call it before you subscribe to AASB messages with MessageBroker and before you start the Engine. Specify configuration in a file Auto SDK provides the ConfigurationFile class that reads the configuration from a specified JSON file path and creates an EngineConfiguration object from that configuration: aace :: core :: config :: ConfigurationFile :: create ( \u201c </ path / to / filename . json > \u201d ) You can include all the configuration data in a single JSON file to create a single EngineConfiguration object. For example, auto config = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / config / config . json \u201d ); Alternatively, you can break the configuration data into multiple JSON files to create multiple EngineConfiguration objects. For example, auto coreConfig = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / data / core - config . json \u201d ); auto alexaConfig = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / data / alexa - config . json \u201d ); auto navigationConfig = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / data / navigation - config . json \u201d ); See documentation for individual module features to see the format of their respective JSON configuration. For example, Core outlines its required configurations in Configure the Core module . Specify configuration programatically Each Auto SDK module that defines configuration provides a factory class with functions that return EngineConfiguration objects. The values a function puts in the configuration it creates correspond to the function parameters. For example, you can configure the Alexa module's alertsCapabilityAgent settings by using the AlexaConfiguration::createAlertsConfig() function: auto alertsConfig = aace :: alexa :: config :: AlexaConfiguration :: createAlertsConfig ( \"</some/directory/path/for/databases>\" ); Subscribe to AASB messages After you configure the Engine, use MessageBroker to subscribe to any AASB interface messages that your application will handle. For example, the following code uses the AASB message wrapper classes for the SpeechRecognizer interface to subscribe to messages from the Engine with SpeechRecognizer topic: #include <AASB/Message/Alexa/SpeechRecognizer/StopCaptureMessage.h> #include <AASB/Message/Alexa/SpeechRecognizer/EndOfSpeechDetectedMessage.h> #include <AASB/Message/Alexa/SpeechRecognizer/WakewordDetectedMessage.h> void SpeechRecognizerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleEndOfSpeechDetectedMessage ( message ); }, EndOfSpeechDetectedMessage :: topic (), EndOfSpeechDetectedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleWakewordDetectedMessage ( message ); }, WakewordDetectedMessage :: topic (), WakewordDetectedMessage :: action ()); } void SpeechRecognizerHandler::handleEndOfSpeechDetectedMessage ( const std :: string & message ) { // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message // Do something here! // Return quickly to avoid blocking MessageBroker's outgoing thread } void SpeechRecognizerHandler::handleWakewordDetectedMessage ( const std :: string & message ) { // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.WakewordDetected message // Do something here! // Return quickly to avoid blocking MessageBroker's outgoing thread } Note : For one Engine instance, you must subscribe to messages after configuring the Engine and before starting the Engine. Start the Engine After configuring the Engine and subscribing to AASB messages, start the Engine by calling the Engine's start() function: engine -> start (); Engine start initializes the internal Engine components for each Engine component your application uses. With respect to Alexa, it starts the connection to Alexa if there is an internet connection and an Alexa access token. Wait to publish messages to the Engine until after start() completes. Your application can start the Engine more than once in its lifetime, if needed, by stopping the Engine and starting it again. However, you cannot start the Engine again after shutting it down. Stop the Engine When your application needs to halt the operations of the Engine, stop the Engine by calling the Engine's stop() function: engine -> stop (); With respect to Alexa, stopping the Engine tears down the Alexa connection. Typically, Engine stop is a cleanup step before Engine shutdown. However, if you stopped the Engine at runtime and need to start it again, calling start() resumes Engine operations. With respect to Alexa, this includes reestablishing the Alexa connection. Shut down the Engine When your application is ready to exit, shut down the Engine by calling the Engine's shutdown() function. engine -> shutdown (); Make sure you also stop the Engine prior to shutting it down. After shutdown completes, you can safely dispose of the pointer to your Engine instance. You cannot use this instance of the Engine again. Configure the Core module The Core module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programatically with the relevant configuration factory functions. (Required) Vehicle info configuration Your application must provide the aace.vehicle configuration specified below. The properties of the vehicle configuration are used for analytics. { \"aace.vehicle\": { \"info\": { \"make\": {{STRING}}, \"model\": {{STRING}}, \"year\": {{STRING}}, \"trim\": {{STRING}}, \"geography\": {{STRING}}, \"version\": {{STRING}}, \"os\": {{STRING}}, \"arch\": {{STRING}}, \"language\": {{STRING}}, \"microphone\": {{STRING}}, \"vehicleIdentifier\": {{STRING}} } } } The following table describes the properties in the configuration: Property Type Required Description Example make string Yes The make of the vehicle \u2014 model string Yes The model of the vehicle \u2014 year integer as a string Yes The model year of the vehicle. The value must be an integer in the range 1900-2100. \"2019\" trim string No The trim package of the vehicle, identifying the vehicle's level of equipment or special features \"Sport\" geography string No The location of the vehicle \"US\", \"US-North\", \"WA\" version string No The client software version \"4.0\" os string No The operating system used by the head unit \"AndroidOreo_8.1\" arch string No The hardware architecture used by the head unit \"x86_64\" language string No The language or locale selected for Alexa by the vehicle owner \"en-US\", \"fr-CA\" microphone string No The type and arrangement of microphone used in the vehicle \"7 mic array, centrally mounted\" vehicleIdentifier string Yes An identifier for the vehicle \"1234abcd\" Auto SDK provides the VehicleConfiguration::createVehicleInfoConfig() factory function to generate the configuration programatically. Important! To pass the certification process, the vehicleIdentifier value you provide must NOT be the vehicle identification number (VIN). (Required) Storage configuration Your application must provide the aace.storage configuration specified below. The Engine uses the configured path to create a database to persist data across device reboots. { \"aace.storage\": { \"localStoragePath\": {{STRING}}, \"storageType\": \"sqlite\" } } The following table describes the properties in the configuration: Property Type Required Description Example localStoragePath string Yes The path to a directory for the Engine to create a database, including the database name \"/opt/AAC/data/aace-storage.db\" storageType string Yes The type of storage to use \"sqlite\" Note: This database is not the only one used by the Engine. Components in the Alexa module have similar configuration to store feature-specific settings and data. See Configure the Alexa module for details. (Optional) Logger configuration By default, the Engine writes logs to the console. You can configure the Engine to save logs to a file with the aace.logger configuration: { \"aace.logger\": { \"sinks\": [ { \"id\": {{STRING}}, \"type\": \"aace.logger.sink.file\", \"config\": { \"path\": {{STRING}}, \"prefix\": {{STRING}}, \"maxSize\": {{INTEGER}}, \"maxFiles\": {{INTEGER}, \"append\": {{BOOLEAN}} }, \"rules\": [ { \"level\": {{STRING}} } ] } ] } The following table describes the properties in the configuration: Property Type Required Description Example aace.logger. sinks[i]. id string Yes A unique identifier for the log sink. \"debug-logs\" aace.logger. sinks[i]. type string Yes The type of the log sink. Use \"aace.logger.sink.file\" to write logs to a file. \"aace.logger.sink.file\" aace.logger. sinks[i]. config. path string Yes An absolute path to a directory where the Engine creates the log file. \"/opt/AAC/data\" aace.logger. sinks[i]. config. prefix string Yes The prefix for the log file. \"auto-sdk\" aace.logger. sinks[i]. config. maxSize integer Yes The maximum size of the log file in bytes. 5242880 aace.logger. sinks[i]. config. maxFiles integer Yes The maximum number of logs files. 5 aace.logger. sinks[i]. config. append boolean Yes Use true to append logs to the existing file. Use false to overwrite the log files. false aace.logger. sinks[i]. rules[j]. level enum string Yes The log level used to filter logs written to the sink. Accepted values: \"VERBOSE\" \"INFO\" \"WARN\" \"ERROR\" \"CRITICAL\" \"METRIC\" \"VERBOSE\" Click to expand or collapse details\u2014 Generate the configuration programatically with the C++ factory function Auto SDK provides the LoggerConfiguration::createFileSinkConfig() factory function to generate the configuration programatically. #include \"AACE/Logger/Logger.h\" #include \"AACE/Logger/LoggerConfiguration.h\" auto fileSinkConfig = aace :: logger :: config :: LoggerConfiguration :: createFileSinkConfig ( \"debug-logs\" , aace :: logger :: LoggerEngineInterface :: Level :: VERBOSE , \"opt/AAC/data\" , \"auto-sdk\" , 5242880 , 5 , false ); engine -> configure ( { // ...other config objects..., fileSinkConfig } ); (Optional) cURL configuration The Auto SDK uses cURL for network connections. Your application can provide configuration to specify the cURL configuration: { \"aace.alexa\": { \"avsDeviceSDK\": { \"libcurlUtils\" { \"CURLOPT_CAPATH\": {{STRING}}, \"CURLOPT_INTERFACE\": {{STRING}}, \"CURLOPT_PROXY\": {{STRING}} } } } } The following table describes the properties in the configuration: Property Type Required Description Example CURLOPT_CAPATH string Yes The path to the directory containing the CA certificates \"/opt/AAC/certs\" CURLOPT_INTERFACE string Yes The outgoing network interface. Can be a network interface name, an IP address, or a host name \"wlan0\" CURLOPT_PROXY string No The address of the HTTP proxy \"http://127.0.0.1:8888\" Note: If the HTTP proxy requires credentials in HTTP headers to authenticate a user agent, you can specify the header with the PropertyManager interface by using the aace.network.httpProxyHeaders property name. You can also change the network interface at runtime with the aace.network.networkInterface property name. Auto SDK provides the AlexaConfiguration::createCurlConfig() factory function to generate the configuration programatically. (Optional) AASB and MessageBroker configuration (Optional) Configure enabled interfaces When you use a module, the Engine services of that module enable every interface defined in the module. This means that for every interface, if your application does not subscribe to the AASB messages of the interface, the Engine performs default handling for the messages you do not handle. To disable this setting, provide the following aace.messageBroker configuration object in your Engine configuration: { \"aace.messageBroker\": { \"autoEnableInterfaces\": false } } You can also change this enablement on a per-interface basis. The enabled setting tells the Engine service whether to enable the interface. If you don't want the Engine to provide a default handler for a particular interface, you can disable the interface using the following configuration: { \"aasb.<message_handler_engine_service_name>\": { \"<interface_name>\": { \"enabled\": false } } } For example, the below configuration disables the TemplateRuntime interface from the Alexa module and the LocationProvider interface from Core module. { \"aasb.alexa\": { \"TemplateRuntime\": { \"enabled\": false } }, \"aasb.location\": { \"LocationProvider\": { \"enabled\": false } } } (Optional) Configure the synchronous message timeout All the messages published by the Engine through MessageBroker are asynchronous; however, certain messages require your application to respond with a special synchronous-style Reply message. Your application must publish the reply quickly because the Engine blocks its execution thread while waiting for the response, and the MessageBroker cannot dispatch more messages while waiting. The following is an example of the Reply message for the LocationProvider.GetLocation message : { \"header\": { \"id\": \"4c4d13b6-6a8d-445b-931a-a3feb0878311\", \"messageType\": \"Reply\", \"version\": \"1.0\", \"messageDescription\": { \"replyToId\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\" } }, \"payload\": { \"location\": { \"latitude\": 37.410, \"longitude\": -122.025 } } } If your application does not publish the reply before the message timeout expires, the relevant Engine operation won't execute properly. The AASB message documentation for each interface specifies whether the interface requires any reply messages. The default timeout value for these messages is 500 milliseconds. In a busy system, the default timeout might not be long enough. You can configure this value by adding the optional field defaultMessageTimeout to the aace.messageBroker JSON object. The following example shows how to change the timeout to 1000 ms: { \"aace.messageBroker\": { \"defaultMessageTimeout\": 1000 } } Important! Since increasing the timeout increases the Engine's message processing time, use this configuration carefully. Consult with your Amazon Solutions Architect (SA) as needed. Understand the key core Engine services The Core module defines several Engine services for common functionality used by multiple Auto SDK modules. For example, the Core , Alexa , and Alexa Comms modules all require the application to play audio through platform-specific audio ouput channels. The Core module defines the core audio Engine service and corresponding AudioOutput AASB message interface, and all three modules use AudioOutput messages to request the application to play audio for their respective audio channels. The following list describes the primary core Engine services provided by the Core module. Each service defines to one or more important AASB message interfaces that your application is required to use. Note: This is not a list of every Engine service in the Core module. For the most part, every AASB interface defined by Core also corresponds to a Core module Engine service that other modules might care about. The following lists the foundational core services that matter most to your application; the Engine cannot function without these. Authorization The Authorization interface specifies messages for your application to initiate device authorization, terminate device authorization, or provide authorization data, such as Alexa access tokens, to the Engine. See Alexa Auto SDK Authorization for more information. Audio input and output The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each component that requests an audio channel specifies its audio channel type so your application can provide different microphone and media player implementations for each channel. See Alexa Auto SDK Audio Channels for more information. Runtime properties Different Auto SDK modules define properties based on their supported features. For example, the Alexa module requires a locale setting to notify Alexa which language to use when interacting with the user. The Core module provides a mechanism for Engine services to register properties they manage and listen to changes in properties managed by other modules. The PropertyManager interface specifies messages for your application and the Engine to query and update these properties. See Alexa Auto SDK Property Manager for more information. Provide core device status The Core module defines interfaces for your application to provide key \"core\" information about the status of the application or its runtime environment. Report location with LocationProvider Sometimes the user asks Alexa a question that requires she know the location in order to answer properly. For example, a user in San Francisco, California might say \"Alexa, what's the weather?\" . This user probably wants to hear Alexa say something like \"The weather in San Francisco is sixty-five degrees and overcast...\" rather than something like \"I can't find your exact location right now...\" . Similarly, the user might say \"Alexa, take me to the nearest Whole Foods\" and wants Alexa to start navigation to a Whole Foods that is actually nearby. To provide the user with accurate responses to local search commands, weather questions, and more, obtain the user's consent to share their location with Alexa and use the LocationProvider interface. Note: For Android applications, AACS provides a default implementation of LocationProvider . See the AACS Default Implementation documentation for more information. Your application should subscribe to the LocationProvider.GetLocation and LocationProvider.GetCountry messages to provide location data, such as geocoordinates and vehicle operating country, when the Engine requests it. These messages are synchronous-style and require your application to send the corresponding reply messages right away. To avoid blocking the MessageBroker outgoing thread and delaying user requests to Alexa, your application should keep the location data in a cache that you update frequently. Pull the location from the cache when the Engine requests it. The Engine won't publish the GetLocation message if it knows your application has lost access to the location data. Keep the Engine in sync with the state of your application's location provider availability by proactively publishing the LocationServiceAccessChanged message at startup and each time the state changes. For example, your application might publish this message with access set to DISABLED if the system revokes your application's access to location or if GPS turns off. Note: The Engine does not persist this state across device reboots. To ensure the Engine always knows the initial state of location availability, publish a LocationServiceAccessChanged message each time you start the Engine. This includes notifying the Engine that access is ENABLED . Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Location/LocationProvider/GetCountryMessage.h> #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> #include <AASB/Message/Location/LocationProvider/LocationServiceAccessChangedMessage.h> class MyLocationProviderHandler { // Call before you start the Engine void MyLocationProviderHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCountryMessage ( message ); }, GetCountryMessage :: topic (), GetCountryMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetLocationMessage ( message ); }, GetLocationMessage :: topic (), GetLocationMessage :: action ()); } void MyLocationProviderHandler::handleGetCountryMessage ( const std :: string & message ) { GetCountryMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto country = getCountryFromCache (); // implement this stub GetCountryMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . country = country ; m_messageBroker -> publish ( replyMsg . toString ()); } void MyLocationProviderHandler::handleGetLocationMessage ( const std :: string & message ) { GetLocationMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto location = getLocationFromCache (); // implement this stub GetLocationMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // parse \"location\" and populate the fields of the reply message aasb :: message :: location :: locationProvider :: Location replyLocation ; replyLocation . latitude = ... ; // the latitude from \"location\"; replyLocation . longitude = ... ; // the longitude from \"location\"; replyMsg . payload . location = replyLocation ; m_messageBroker -> publish ( replyMsg . toString ()); } // Call when the application access to location data changes // and after starting the Engine void MyLocationProviderHandler::locationServiceAccessChanged ( bool hasAccess ) { LocationServiceAccessChangedMessage msg ; if ( hasAccess ) { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: ENABLED ; } else { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: DISABLED ; } m_messageBroker -> publish ( msg . toString ()); } } Report network status changes with NetworkInfoProvider Your application should monitor the network connection and notify the Engine of changes in the status using the NetworkInfoProvider interface. The Engine uses this information to adjust its behavior, including tearing down the connection to Alexa cloud when your application reports that there is no internet connection. Although using NetworkInfoProvider is optional, you should use it so the Engine can avoid undesirable behavior; for instance, attempting to send events to Alexa when the lack of connectivity means the events are bound to fail. Note: You must use the NetworkInfoProvider interface if your application uses the Local Voice Control (LVC) extension. Note: For Android applications, AACS provides a default implementation of NetworkInfoProvider . See the AACS Default Implementation documentation for more information. Various Engine components want the initial network status at startup so they can adapt their initial behavior accordingly. Your application should subscribe to the NetworkInfoProvider.GetNetworkStatus and NetworkInfoProvider.GetWifiSignalStrength to answer the inital query from the Engine. These messages are synchronous-style and require your application to send the corresponding reply messages right away. At runtime, publish the NetworkInfoProvider.NetworkStatusChanged message to notify the Engine of any status changes. Report data usage with DeviceUsage Periodically publish the DeviceUsage.ReportNetworkDataUsage message (for example, at five minute intervals) to report network data usage to the Engine. If your application uses the Device Client Metrics (DCM) extension, the Engine tracks metrics with this information. The usage field in the payload is a JSON object as a string. The format of the JSON is the following: { \"startTimeStamp\" : {{LONG}}, \"endTimeStamp\" : {{LONG}}, \"networkInterfaceType\": \"{{STRING}}\", \"dataPlanType\" : \"{{STRING}}\", \"bytesUsage\" :{ \"rxBytes\" : {{LONG}}, \"txBytes\" : {{LONG}} } } The following table describes the properties in the JSON: Property Type Required Description Example startTimeStamp long Yes The starting timestamp in milliseconds for this network usage datapoint \u2014 endTimeStamp long Yes The ending timestamp in milliseconds for this network usage datapoint \u2014 networkInterfaceType string Yes The network interface name over which the data is recorded \"WIFI\", \"MOBILE\" dataPlanType string No The type of data plan the device is subscribed to. This is an optional field and should be provided if your application uses the AlexaConnectivity module. See AlexaConnectivity bytesUsage .rxBytes long Yes The bytes received over the network interface \u2014 bytesUsage .txBytes long Yes The bytes transmitted over the network interface \u2014","title":"Core Module <!-- omit in toc -->"},{"location":"modules/core/#core-module","text":"Table of Contents Core module overview Understand the Auto SDK API The Engine MessageBroker AASB message interfaces Manage the Engine lifecycle in your application Create the Engine Configure the Engine Specify configuration in a file Specify configuration programatically Subscribe to AASB messages Start the Engine Stop the Engine Shut down the Engine Configure the Core module (Required) Vehicle info configuration (Required) Storage configuration (Optional) Logger configuration (Optional) cURL configuration (Optional) AASB and MessageBroker configuration (Optional) Configure enabled interfaces (Optional) Configure the synchronous message timeout Understand the key core Engine services Authorization Audio input and output Runtime properties Provide core device status Report location with LocationProvider Report network status changes with NetworkInfoProvider Report data usage with DeviceUsage","title":"Core Module "},{"location":"modules/core/#core-module-overview","text":"The Alexa Auto SDK Core module is the heart of the SDK. The Core module acts as the foundation for all Auto SDK features by contributing the following essential elements to the SDK: - Defining the Auto SDK API for your application\u2014 Core defines the Engine and MessageBroker components. Alongside the Alexa Auto Services Bridge (AASB) messages defined by each Auto SDK module, these components comprise the core API for your application to access the features of Auto SDK. To learn about the API, see Understand the Auto SDK API . Providing an infrastructure to other modules\u2014 Core provides the base infrastructure of the Engine, which each Auto SDK module extends to add module-specific features. Core also defines the common Engine services for logging, audio I/O, authorization, and device settings. Each module uses these Engine services to provide its own module-specific features. To learn about the primary core services, see Understand the key core Engine services . Receiving core device statuses from your application\u2014 Core includes AASB message interfaces for your application to report essential information such as device location and network connection status. The Engine uses this information to provide a reliable experience to the user. To learn about the core device status interfaces, see Provide core device status . Important! : If you are an Android developer, your application will use the Alexa Auto Client Service (AACS) as its foundation. AACS implements much of the core Auto SDK setup, abstracting it from your application and exposing only a necessary subset of the Auto SDK API in an Android-specific way. Some of the information presented in this documentation and documentation for other SDK modules might not pertain to your application exactly as written for cases in which AACS provides the implementation or further abstracts it, so keep this in mind while reading. Use the module documentation to understand the underlying layers of Auto SDK, if interested, and to reference the Engine configuration and AASB message definitions for the features you do need to build into your application yourself.","title":"Core module overview"},{"location":"modules/core/#understand-the-auto-sdk-api","text":"The Engine , MessageBroker , and AASB message interfaces comprise the Auto SDK API. Your application uses these three components to build a complete Alexa client implementation for your vehicle.","title":"Understand the Auto SDK API"},{"location":"modules/core/#the-engine","text":"The Auto SDK Engine is a system of components that provide the core implementation of all Auto SDK features. With respect to Alexa, your application's Alexa client stack uses the Engine as the layer that sets up the connection to Alexa, publishes device capabilities, sends Alexa events, sequences Alexa directives, and more. Your application creates an instance of the Engine and uses a simple interface to manage the Engine lifecycle for the duration of the application run time. Aside from setting up the Engine, the primary responsibility of your application is to provide the platform-specific, customizable integration details that make Alexa and other core SDK features work for your vehicle, in particular. Platform-specific integration might include interacting with external libraries or the underlying software frameworks of your operating system to complete the Auto SDK client stack with deep integration into the applications on your system. The Engine implements as much of the general functionality as possible; for integration details that it can't implement, the Engine delegates responsibility to your application via AASB messages published through the MessageBroker .","title":"The Engine"},{"location":"modules/core/#messagebroker","text":"The MessageBroker is the bridge in the Alexa Auto Services Bridge (AASB). MessageBroker provides a publish and subscribe API to the Engine and your application for communication with each other. In order to consume a message that the Engine publishes to your application, your application uses MessageBroker to subscribe to the message by specifying the message topic and action as well as a function for MessageBroker to invoke to deliver the message. Similarly, the Engine uses MessageBroker to subscribe to messages published by your application.","title":"MessageBroker"},{"location":"modules/core/#aasb-message-interfaces","text":"A typical Auto SDK module defines one or more AASB message interfaces. An interface groups logically related messages together with a topic . Within the topic , each interface has one or more actions to represent individual messages. I.e., a topic + action combination identifies a single message. For instance, the Alexa module defines many interfaces related to standard Alexa features. The Alexa module SpeechRecogizer interface defines messages for your application to publish to the Engine when the user invokes Alexa. It also defines messages the Engine publishes to your application to convey key events in the user speech stream. For example, your application publishes a SpeechRecognizer.StartCapture message when the user taps the Alexa invocation button: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"12345\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"StartCapture\" } }, \"payload\" : { \"initiator\" : \"TAP_TO_TALK\" } } The Engine subscribes to this message at startup time, so it is ready to consume the message when published by your application. In response to the message, the Engine sends the user speech audio to Alexa. Alexa processes the speech, and when she detects the user has finished speaking, the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message to your application: { \"header\" : { \"version\" : \"4.0\" , \"messageType\" : \"Publish\" , \"id\" : \"00876\" , \"messageDescription\" : { \"topic\" : \"SpeechRecognizer\" , \"action\" : \"EndOfSpeechDetected\" } } } Your application receives this message from MessageBroker if it subscribed to the SpeechRecognizer topic and EndOfSpeechDetected action. MessageBroker uses AASB messages as serialized JSON strings; however, for convenience, Auto SDK provides C++ wrapper classes for each message that help with the serialization and deserialization. The Auto SDK build system generates these wrapper classes as part of the build.","title":"AASB message interfaces"},{"location":"modules/core/#manage-the-engine-lifecycle-in-your-application","text":"To use Auto SDK features, your application must instantiate and manage the lifecycle of the Engine.","title":"Manage the Engine lifecycle in your application"},{"location":"modules/core/#create-the-engine","text":"During the launch sequence of your application, create one instance of the Engine using the static function aace::core::Engine::create() : std :: shared_ptr < aace :: core :: Engine > engine = aace :: core :: Engine :: create (); A typical application creates the Engine once when the user turns on the vehicle ignition and uses the instance until the user turns off the vehicle ignition.","title":"Create the Engine"},{"location":"modules/core/#configure-the-engine","text":"After creating the Engine instance, configure it with the required Engine configurations. Engine configuration uses JSON serialized as strings, but you pass the configurations to the Engine in one or more aace::core::config::EngineConfiguration wrapper objects. Auto SDK provides two options to generate EngineConfiguration objects: - Specify your Engine configuration in a JSON file and construct an EngineConfiguration from a path to the file - Build the configuration programatically using one of the configuration factory functions. You can choose either option or a combination of both. I.e., you can generate a single EngineConfiguration object that includes all configuration data for the Engine components you use, or you can break up the configuration data into logical sections and generate multiple EngineConfiguration objects. For example, you might generate one EngineConfiguration object for each module. To configure the Engine, call the Engine's configure() function, passing in the EngineConfiguration object(s): For a single EngineConfiguration object: engine->configure( config ); For multiple EngineConfiguration objects: engine->configure( { xConfig, yConfig, zConfig } ); replacing xConfig, yConfig, zConfig with logical names to identify the EngineConfiguration objects you generated. Note : For one Engine instance, you can call the configure() function only once, and you must call it before you subscribe to AASB messages with MessageBroker and before you start the Engine.","title":"Configure the Engine"},{"location":"modules/core/#specify-configuration-in-a-file","text":"Auto SDK provides the ConfigurationFile class that reads the configuration from a specified JSON file path and creates an EngineConfiguration object from that configuration: aace :: core :: config :: ConfigurationFile :: create ( \u201c </ path / to / filename . json > \u201d ) You can include all the configuration data in a single JSON file to create a single EngineConfiguration object. For example, auto config = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / config / config . json \u201d ); Alternatively, you can break the configuration data into multiple JSON files to create multiple EngineConfiguration objects. For example, auto coreConfig = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / data / core - config . json \u201d ); auto alexaConfig = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / data / alexa - config . json \u201d ); auto navigationConfig = aace :: core :: config :: ConfigurationFile :: create ( \u201c / opt / AAC / data / navigation - config . json \u201d ); See documentation for individual module features to see the format of their respective JSON configuration. For example, Core outlines its required configurations in Configure the Core module .","title":"Specify configuration in a file"},{"location":"modules/core/#specify-configuration-programatically","text":"Each Auto SDK module that defines configuration provides a factory class with functions that return EngineConfiguration objects. The values a function puts in the configuration it creates correspond to the function parameters. For example, you can configure the Alexa module's alertsCapabilityAgent settings by using the AlexaConfiguration::createAlertsConfig() function: auto alertsConfig = aace :: alexa :: config :: AlexaConfiguration :: createAlertsConfig ( \"</some/directory/path/for/databases>\" );","title":"Specify configuration programatically"},{"location":"modules/core/#subscribe-to-aasb-messages","text":"After you configure the Engine, use MessageBroker to subscribe to any AASB interface messages that your application will handle. For example, the following code uses the AASB message wrapper classes for the SpeechRecognizer interface to subscribe to messages from the Engine with SpeechRecognizer topic: #include <AASB/Message/Alexa/SpeechRecognizer/StopCaptureMessage.h> #include <AASB/Message/Alexa/SpeechRecognizer/EndOfSpeechDetectedMessage.h> #include <AASB/Message/Alexa/SpeechRecognizer/WakewordDetectedMessage.h> void SpeechRecognizerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleEndOfSpeechDetectedMessage ( message ); }, EndOfSpeechDetectedMessage :: topic (), EndOfSpeechDetectedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleWakewordDetectedMessage ( message ); }, WakewordDetectedMessage :: topic (), WakewordDetectedMessage :: action ()); } void SpeechRecognizerHandler::handleEndOfSpeechDetectedMessage ( const std :: string & message ) { // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.EndOfSpeechDetected message // Do something here! // Return quickly to avoid blocking MessageBroker's outgoing thread } void SpeechRecognizerHandler::handleWakewordDetectedMessage ( const std :: string & message ) { // MessageBroker invokes this function when the Engine publishes a SpeechRecognizer.WakewordDetected message // Do something here! // Return quickly to avoid blocking MessageBroker's outgoing thread } Note : For one Engine instance, you must subscribe to messages after configuring the Engine and before starting the Engine.","title":"Subscribe to AASB messages"},{"location":"modules/core/#start-the-engine","text":"After configuring the Engine and subscribing to AASB messages, start the Engine by calling the Engine's start() function: engine -> start (); Engine start initializes the internal Engine components for each Engine component your application uses. With respect to Alexa, it starts the connection to Alexa if there is an internet connection and an Alexa access token. Wait to publish messages to the Engine until after start() completes. Your application can start the Engine more than once in its lifetime, if needed, by stopping the Engine and starting it again. However, you cannot start the Engine again after shutting it down.","title":"Start the Engine"},{"location":"modules/core/#stop-the-engine","text":"When your application needs to halt the operations of the Engine, stop the Engine by calling the Engine's stop() function: engine -> stop (); With respect to Alexa, stopping the Engine tears down the Alexa connection. Typically, Engine stop is a cleanup step before Engine shutdown. However, if you stopped the Engine at runtime and need to start it again, calling start() resumes Engine operations. With respect to Alexa, this includes reestablishing the Alexa connection.","title":"Stop the Engine"},{"location":"modules/core/#shut-down-the-engine","text":"When your application is ready to exit, shut down the Engine by calling the Engine's shutdown() function. engine -> shutdown (); Make sure you also stop the Engine prior to shutting it down. After shutdown completes, you can safely dispose of the pointer to your Engine instance. You cannot use this instance of the Engine again.","title":"Shut down the Engine"},{"location":"modules/core/#configure-the-core-module","text":"The Core module defines required and optional configuration objects that you include in the Engine configuration for your application. You can define the configuration objects in a file or construct them programatically with the relevant configuration factory functions.","title":"Configure the Core module"},{"location":"modules/core/#required-vehicle-info-configuration","text":"Your application must provide the aace.vehicle configuration specified below. The properties of the vehicle configuration are used for analytics. { \"aace.vehicle\": { \"info\": { \"make\": {{STRING}}, \"model\": {{STRING}}, \"year\": {{STRING}}, \"trim\": {{STRING}}, \"geography\": {{STRING}}, \"version\": {{STRING}}, \"os\": {{STRING}}, \"arch\": {{STRING}}, \"language\": {{STRING}}, \"microphone\": {{STRING}}, \"vehicleIdentifier\": {{STRING}} } } } The following table describes the properties in the configuration: Property Type Required Description Example make string Yes The make of the vehicle \u2014 model string Yes The model of the vehicle \u2014 year integer as a string Yes The model year of the vehicle. The value must be an integer in the range 1900-2100. \"2019\" trim string No The trim package of the vehicle, identifying the vehicle's level of equipment or special features \"Sport\" geography string No The location of the vehicle \"US\", \"US-North\", \"WA\" version string No The client software version \"4.0\" os string No The operating system used by the head unit \"AndroidOreo_8.1\" arch string No The hardware architecture used by the head unit \"x86_64\" language string No The language or locale selected for Alexa by the vehicle owner \"en-US\", \"fr-CA\" microphone string No The type and arrangement of microphone used in the vehicle \"7 mic array, centrally mounted\" vehicleIdentifier string Yes An identifier for the vehicle \"1234abcd\" Auto SDK provides the VehicleConfiguration::createVehicleInfoConfig() factory function to generate the configuration programatically. Important! To pass the certification process, the vehicleIdentifier value you provide must NOT be the vehicle identification number (VIN).","title":"(Required) Vehicle info configuration"},{"location":"modules/core/#required-storage-configuration","text":"Your application must provide the aace.storage configuration specified below. The Engine uses the configured path to create a database to persist data across device reboots. { \"aace.storage\": { \"localStoragePath\": {{STRING}}, \"storageType\": \"sqlite\" } } The following table describes the properties in the configuration: Property Type Required Description Example localStoragePath string Yes The path to a directory for the Engine to create a database, including the database name \"/opt/AAC/data/aace-storage.db\" storageType string Yes The type of storage to use \"sqlite\" Note: This database is not the only one used by the Engine. Components in the Alexa module have similar configuration to store feature-specific settings and data. See Configure the Alexa module for details.","title":"(Required) Storage configuration"},{"location":"modules/core/#optional-logger-configuration","text":"By default, the Engine writes logs to the console. You can configure the Engine to save logs to a file with the aace.logger configuration: { \"aace.logger\": { \"sinks\": [ { \"id\": {{STRING}}, \"type\": \"aace.logger.sink.file\", \"config\": { \"path\": {{STRING}}, \"prefix\": {{STRING}}, \"maxSize\": {{INTEGER}}, \"maxFiles\": {{INTEGER}, \"append\": {{BOOLEAN}} }, \"rules\": [ { \"level\": {{STRING}} } ] } ] } The following table describes the properties in the configuration: Property Type Required Description Example aace.logger. sinks[i]. id string Yes A unique identifier for the log sink. \"debug-logs\" aace.logger. sinks[i]. type string Yes The type of the log sink. Use \"aace.logger.sink.file\" to write logs to a file. \"aace.logger.sink.file\" aace.logger. sinks[i]. config. path string Yes An absolute path to a directory where the Engine creates the log file. \"/opt/AAC/data\" aace.logger. sinks[i]. config. prefix string Yes The prefix for the log file. \"auto-sdk\" aace.logger. sinks[i]. config. maxSize integer Yes The maximum size of the log file in bytes. 5242880 aace.logger. sinks[i]. config. maxFiles integer Yes The maximum number of logs files. 5 aace.logger. sinks[i]. config. append boolean Yes Use true to append logs to the existing file. Use false to overwrite the log files. false aace.logger. sinks[i]. rules[j]. level enum string Yes The log level used to filter logs written to the sink. Accepted values: \"VERBOSE\" \"INFO\" \"WARN\" \"ERROR\" \"CRITICAL\" \"METRIC\" \"VERBOSE\" Click to expand or collapse details\u2014 Generate the configuration programatically with the C++ factory function Auto SDK provides the LoggerConfiguration::createFileSinkConfig() factory function to generate the configuration programatically. #include \"AACE/Logger/Logger.h\" #include \"AACE/Logger/LoggerConfiguration.h\" auto fileSinkConfig = aace :: logger :: config :: LoggerConfiguration :: createFileSinkConfig ( \"debug-logs\" , aace :: logger :: LoggerEngineInterface :: Level :: VERBOSE , \"opt/AAC/data\" , \"auto-sdk\" , 5242880 , 5 , false ); engine -> configure ( { // ...other config objects..., fileSinkConfig } );","title":"(Optional) Logger configuration"},{"location":"modules/core/#optional-curl-configuration","text":"The Auto SDK uses cURL for network connections. Your application can provide configuration to specify the cURL configuration: { \"aace.alexa\": { \"avsDeviceSDK\": { \"libcurlUtils\" { \"CURLOPT_CAPATH\": {{STRING}}, \"CURLOPT_INTERFACE\": {{STRING}}, \"CURLOPT_PROXY\": {{STRING}} } } } } The following table describes the properties in the configuration: Property Type Required Description Example CURLOPT_CAPATH string Yes The path to the directory containing the CA certificates \"/opt/AAC/certs\" CURLOPT_INTERFACE string Yes The outgoing network interface. Can be a network interface name, an IP address, or a host name \"wlan0\" CURLOPT_PROXY string No The address of the HTTP proxy \"http://127.0.0.1:8888\" Note: If the HTTP proxy requires credentials in HTTP headers to authenticate a user agent, you can specify the header with the PropertyManager interface by using the aace.network.httpProxyHeaders property name. You can also change the network interface at runtime with the aace.network.networkInterface property name. Auto SDK provides the AlexaConfiguration::createCurlConfig() factory function to generate the configuration programatically.","title":"(Optional) cURL configuration"},{"location":"modules/core/#optional-aasb-and-messagebroker-configuration","text":"","title":"(Optional) AASB and MessageBroker configuration"},{"location":"modules/core/#optional-configure-enabled-interfaces","text":"When you use a module, the Engine services of that module enable every interface defined in the module. This means that for every interface, if your application does not subscribe to the AASB messages of the interface, the Engine performs default handling for the messages you do not handle. To disable this setting, provide the following aace.messageBroker configuration object in your Engine configuration: { \"aace.messageBroker\": { \"autoEnableInterfaces\": false } } You can also change this enablement on a per-interface basis. The enabled setting tells the Engine service whether to enable the interface. If you don't want the Engine to provide a default handler for a particular interface, you can disable the interface using the following configuration: { \"aasb.<message_handler_engine_service_name>\": { \"<interface_name>\": { \"enabled\": false } } } For example, the below configuration disables the TemplateRuntime interface from the Alexa module and the LocationProvider interface from Core module. { \"aasb.alexa\": { \"TemplateRuntime\": { \"enabled\": false } }, \"aasb.location\": { \"LocationProvider\": { \"enabled\": false } } }","title":"(Optional) Configure enabled interfaces"},{"location":"modules/core/#optional-configure-the-synchronous-message-timeout","text":"All the messages published by the Engine through MessageBroker are asynchronous; however, certain messages require your application to respond with a special synchronous-style Reply message. Your application must publish the reply quickly because the Engine blocks its execution thread while waiting for the response, and the MessageBroker cannot dispatch more messages while waiting. The following is an example of the Reply message for the LocationProvider.GetLocation message : { \"header\": { \"id\": \"4c4d13b6-6a8d-445b-931a-a3feb0878311\", \"messageType\": \"Reply\", \"version\": \"1.0\", \"messageDescription\": { \"replyToId\": \"23b578ed-6dc3-460a-998e-1647ba6cde42\" } }, \"payload\": { \"location\": { \"latitude\": 37.410, \"longitude\": -122.025 } } } If your application does not publish the reply before the message timeout expires, the relevant Engine operation won't execute properly. The AASB message documentation for each interface specifies whether the interface requires any reply messages. The default timeout value for these messages is 500 milliseconds. In a busy system, the default timeout might not be long enough. You can configure this value by adding the optional field defaultMessageTimeout to the aace.messageBroker JSON object. The following example shows how to change the timeout to 1000 ms: { \"aace.messageBroker\": { \"defaultMessageTimeout\": 1000 } } Important! Since increasing the timeout increases the Engine's message processing time, use this configuration carefully. Consult with your Amazon Solutions Architect (SA) as needed.","title":"(Optional) Configure the synchronous message timeout"},{"location":"modules/core/#understand-the-key-core-engine-services","text":"The Core module defines several Engine services for common functionality used by multiple Auto SDK modules. For example, the Core , Alexa , and Alexa Comms modules all require the application to play audio through platform-specific audio ouput channels. The Core module defines the core audio Engine service and corresponding AudioOutput AASB message interface, and all three modules use AudioOutput messages to request the application to play audio for their respective audio channels. The following list describes the primary core Engine services provided by the Core module. Each service defines to one or more important AASB message interfaces that your application is required to use. Note: This is not a list of every Engine service in the Core module. For the most part, every AASB interface defined by Core also corresponds to a Core module Engine service that other modules might care about. The following lists the foundational core services that matter most to your application; the Engine cannot function without these.","title":"Understand the key core Engine services"},{"location":"modules/core/#authorization","text":"The Authorization interface specifies messages for your application to initiate device authorization, terminate device authorization, or provide authorization data, such as Alexa access tokens, to the Engine. See Alexa Auto SDK Authorization for more information.","title":"Authorization"},{"location":"modules/core/#audio-input-and-output","text":"The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each component that requests an audio channel specifies its audio channel type so your application can provide different microphone and media player implementations for each channel. See Alexa Auto SDK Audio Channels for more information.","title":"Audio input and output"},{"location":"modules/core/#runtime-properties","text":"Different Auto SDK modules define properties based on their supported features. For example, the Alexa module requires a locale setting to notify Alexa which language to use when interacting with the user. The Core module provides a mechanism for Engine services to register properties they manage and listen to changes in properties managed by other modules. The PropertyManager interface specifies messages for your application and the Engine to query and update these properties. See Alexa Auto SDK Property Manager for more information.","title":"Runtime properties"},{"location":"modules/core/#provide-core-device-status","text":"The Core module defines interfaces for your application to provide key \"core\" information about the status of the application or its runtime environment.","title":"Provide core device status"},{"location":"modules/core/#report-location-with-locationprovider","text":"Sometimes the user asks Alexa a question that requires she know the location in order to answer properly. For example, a user in San Francisco, California might say \"Alexa, what's the weather?\" . This user probably wants to hear Alexa say something like \"The weather in San Francisco is sixty-five degrees and overcast...\" rather than something like \"I can't find your exact location right now...\" . Similarly, the user might say \"Alexa, take me to the nearest Whole Foods\" and wants Alexa to start navigation to a Whole Foods that is actually nearby. To provide the user with accurate responses to local search commands, weather questions, and more, obtain the user's consent to share their location with Alexa and use the LocationProvider interface. Note: For Android applications, AACS provides a default implementation of LocationProvider . See the AACS Default Implementation documentation for more information. Your application should subscribe to the LocationProvider.GetLocation and LocationProvider.GetCountry messages to provide location data, such as geocoordinates and vehicle operating country, when the Engine requests it. These messages are synchronous-style and require your application to send the corresponding reply messages right away. To avoid blocking the MessageBroker outgoing thread and delaying user requests to Alexa, your application should keep the location data in a cache that you update frequently. Pull the location from the cache when the Engine requests it. The Engine won't publish the GetLocation message if it knows your application has lost access to the location data. Keep the Engine in sync with the state of your application's location provider availability by proactively publishing the LocationServiceAccessChanged message at startup and each time the state changes. For example, your application might publish this message with access set to DISABLED if the system revokes your application's access to location or if GPS turns off. Note: The Engine does not persist this state across device reboots. To ensure the Engine always knows the initial state of location availability, publish a LocationServiceAccessChanged message each time you start the Engine. This includes notifying the Engine that access is ENABLED . Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Location/LocationProvider/GetCountryMessage.h> #include <AASB/Message/Location/LocationProvider/GetLocationMessage.h> #include <AASB/Message/Location/LocationProvider/LocationServiceAccessChangedMessage.h> class MyLocationProviderHandler { // Call before you start the Engine void MyLocationProviderHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCountryMessage ( message ); }, GetCountryMessage :: topic (), GetCountryMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetLocationMessage ( message ); }, GetLocationMessage :: topic (), GetLocationMessage :: action ()); } void MyLocationProviderHandler::handleGetCountryMessage ( const std :: string & message ) { GetCountryMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto country = getCountryFromCache (); // implement this stub GetCountryMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . country = country ; m_messageBroker -> publish ( replyMsg . toString ()); } void MyLocationProviderHandler::handleGetLocationMessage ( const std :: string & message ) { GetLocationMessage msg = json :: parse ( message ); // Quickly publish the GetCountry reply message auto location = getLocationFromCache (); // implement this stub GetLocationMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // parse \"location\" and populate the fields of the reply message aasb :: message :: location :: locationProvider :: Location replyLocation ; replyLocation . latitude = ... ; // the latitude from \"location\"; replyLocation . longitude = ... ; // the longitude from \"location\"; replyMsg . payload . location = replyLocation ; m_messageBroker -> publish ( replyMsg . toString ()); } // Call when the application access to location data changes // and after starting the Engine void MyLocationProviderHandler::locationServiceAccessChanged ( bool hasAccess ) { LocationServiceAccessChangedMessage msg ; if ( hasAccess ) { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: ENABLED ; } else { msg . payload . access = aasb :: message :: location :: locationProvider :: LocationServiceAccess :: DISABLED ; } m_messageBroker -> publish ( msg . toString ()); } }","title":"Report location with LocationProvider"},{"location":"modules/core/#report-network-status-changes-with-networkinfoprovider","text":"Your application should monitor the network connection and notify the Engine of changes in the status using the NetworkInfoProvider interface. The Engine uses this information to adjust its behavior, including tearing down the connection to Alexa cloud when your application reports that there is no internet connection. Although using NetworkInfoProvider is optional, you should use it so the Engine can avoid undesirable behavior; for instance, attempting to send events to Alexa when the lack of connectivity means the events are bound to fail. Note: You must use the NetworkInfoProvider interface if your application uses the Local Voice Control (LVC) extension. Note: For Android applications, AACS provides a default implementation of NetworkInfoProvider . See the AACS Default Implementation documentation for more information. Various Engine components want the initial network status at startup so they can adapt their initial behavior accordingly. Your application should subscribe to the NetworkInfoProvider.GetNetworkStatus and NetworkInfoProvider.GetWifiSignalStrength to answer the inital query from the Engine. These messages are synchronous-style and require your application to send the corresponding reply messages right away. At runtime, publish the NetworkInfoProvider.NetworkStatusChanged message to notify the Engine of any status changes.","title":"Report network status changes with NetworkInfoProvider"},{"location":"modules/core/#report-data-usage-with-deviceusage","text":"Periodically publish the DeviceUsage.ReportNetworkDataUsage message (for example, at five minute intervals) to report network data usage to the Engine. If your application uses the Device Client Metrics (DCM) extension, the Engine tracks metrics with this information. The usage field in the payload is a JSON object as a string. The format of the JSON is the following: { \"startTimeStamp\" : {{LONG}}, \"endTimeStamp\" : {{LONG}}, \"networkInterfaceType\": \"{{STRING}}\", \"dataPlanType\" : \"{{STRING}}\", \"bytesUsage\" :{ \"rxBytes\" : {{LONG}}, \"txBytes\" : {{LONG}} } } The following table describes the properties in the JSON: Property Type Required Description Example startTimeStamp long Yes The starting timestamp in milliseconds for this network usage datapoint \u2014 endTimeStamp long Yes The ending timestamp in milliseconds for this network usage datapoint \u2014 networkInterfaceType string Yes The network interface name over which the data is recorded \"WIFI\", \"MOBILE\" dataPlanType string No The type of data plan the device is subscribed to. This is an optional field and should be provided if your application uses the AlexaConnectivity module. See AlexaConnectivity bytesUsage .rxBytes long Yes The bytes received over the network interface \u2014 bytesUsage .txBytes long Yes The bytes transmitted over the network interface \u2014","title":"Report data usage with DeviceUsage"},{"location":"modules/core/AUDIO/","text":"Alexa Auto SDK Audio Channels Table of Contents Overview Understand audio input channels Understand audio output channels Access the audio stream for stream-based input and output Provide audio input Provide audio output Enable music ducking Overview The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide microphone and media player implementations specific to each channel type. The core audio Engine service provides audio I/O AASB message interfaces that are generic enough for your application to decide how to produce or play the audio. Understand audio input channels Your application uses the AudioInput AASB message interface to provide audio data to the Engine. The Engine defines the following audio input types to use with the AudioInput interface: VOICE\u2014 This audio input type provides user speech audio data. COMMUNICATION\u2014 This audio input type provides user speech audio data specific to Alexa-to-Alexa calling. For example, the Alexa Comms module Engine components request audio input with this type. LOOPBACK\u2014 This audio input type provides audio data recorded from the device's own speakers. For example, the Loopback Detector module Engine components request audio input with this type to detect Alexa saying her own name in the audio output. The audio input part of the core audio Engine service enables Engine components to share single producer, multi-consumer audio input in two key ways: Multiple Engine components might request audio input of the same type. For example, the Alexa module and Amazonlite module Engine components both want VOICE audio input. When the second component requests to open VOICE channel, the Engine won't ask your application for VOICE audio again because your application is already providing it. The Engine takes care of providing the same audio data to both consumers. Multiple Engine components might request audio input of \"different\" types that your application considers the same. For example, the Alexa module and Alexa Comms module want VOICE and COMMUNICATION audio input, respectively. Your application's specific integration might have one implementation for producing the user speech audio data. In this case, your application takes care of providing the same audio data to both consumers. Understand audio output channels The Engine uses the AudioOnput AASB message interface to request your application to play or perform other operations on audio output data. The Engine defines the following audio output types to use with the AudioOutput interface: TTS\u2014 This audio output type plays speech audio data. For example, Alexa's speech responses from the SpeechSynthesizer interface MUSIC This audio output type plays media. For example, Amazon Music from the AudioPlayer interface NOTIFICATION This audio output type plays notification audio cues. For example, short cues from the Notifications interface ALARM This audio output type plays alarms. For example, repeating alarm audio from the Alerts interface EARCON This audio output type plays Alexa attention state audio cues. For example, the audio cue to indicate Alexa started listening COMMUNICATION This audio output type plays the audio for Alexa-to-Alexa calling. For example, the \"other side\" of the user's Alexa-to-Alexa call placed using the Alexa Comms module. RINGTONE This audio output type plays ringtones. For example, the inbound or outbound ringing tone of the user's Alexa-to-Alexa call placed using the Alexa Comms module. Your application determines how to handle each different audio type. The simplest integration, for example, might play all audio output types with the same underlying media player implementation. A more sophisticated integration might provide different media player implementations depending on the audio type\u2014 for example, using a low-level audio implementation for NOTIFICATION and EARCON types, and a high-level implementation for TTS and MUSIC . The best approach depends on your system-specific use cases. Important! Even though your application might use the same media player implementation for multiple audio output types, the actual integration must be able to handle the Engine having multiple channels open at the same time; for example, there might be music buffered in the MUSIC channel media player while the user makes a quick Alexa-to-Alexa call using the RINGTONE and COMMUNICATION channels. The Engine is agnostic to how you buffer and control the audio, but it does require your integration to be capable of keeping the right state of all channels that are active at the same time. Access the audio stream for stream-based input and output Both the AudioInput and AudioOutput AASB message interfaces require your application to read from or write to a stream. These messages include an ID to identify the stream in the streamId field of the message payload. When your application receives a message with a streamId , use the MessageBroker openStream() function with streamId to get a reference to a MessageStream object wrapping the stream. Specify the operation mode (i.e., read or write) when opening the stream using the MessageStream::Mode enumerated types. If the MessageBroker cannot open the stream for the specified operation, the openStream() call will fail and return a null object. The following example demonstrates how your application would open an input stream after receiving the StartAudioInput message, and write data to the stream until it receives a StopAudioInput message for the same stream ID. #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); // open the stream for writing auto streamId = _msg . payload . streamId ; auto stream = messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); startAudioInput ( streamId , stream ) }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; stopAudioInput ( streamId ); }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } Provide audio input Your application subscribes to the AudioInput AASB messages published by the Engine. When some Engine component requests audio input (for example, when the user presses the tap-to-talk button from SpeechRecognizer ), the Engine publishes a StartAudioInput message that specifies the AudioInputType and stream ID. Your implementation must start writing audio data until the Engine publishes a StopAudioInput message for the stream ID. If two Engine components request audio from the same channel, your application will only receive a StartAudioInput message when the first component requests the audio. All of the Engine components that have requested audio from the same input channel will receive a callback internally when audio data is written to the interface. Your application will only receive a StopAudioInput message after the last Engine component has canceled its request to receive audio from the channel. Your application must provide audio input in the following format: 16bit Linear PCM 16kHz sample rate Single channel Signed, little endian byte order Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> class MyAudioInputHandler { // Subscribe to messages from the engine void MyAudioInputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartAudioInputMessage ( message ); }, StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopAudioInputMessage ( message ); }, StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); } void MyAudioInputHandler::handleStartAudioInputMessage ( const std :: string & message ) { StartAudioInputMessage msg = json :: parse ( message ); auto stream = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: WRITE ); // ...Handle starting audio input... } void MyAudioInputHandler::handleStopAudioInputMessage ( const std :: string & message ) { // ...Handle stopping audio input... } } Provide audio output Your application subscribes to the AudioOutput AASB messages published by the Engine. The Engine publishes either a PrepareStream message or a PrepareURL message to notify your application to create an audio stream or URL for playback. The characteristics of the audio that will be played on the channel are specified by the AudioOutputType in the payload. The Engine will perform actions on the audio output by publishing additional AudioOutput messages. See the AudioOutput AASB message documentation for details. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioOutput/GetDurationMessage.h> #include <AASB/Message/Audio/AudioOutput/GetNumBytesBufferedMessage.h> #include <AASB/Message/Audio/AudioOutput/GetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/MayDuckMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaErrorMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/MutedStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/PauseMessage.h> #include <AASB/Message/Audio/AudioOutput/PlayMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareStreamMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareURLMessage.h> #include <AASB/Message/Audio/AudioOutput/ResumeMessage.h> #include <AASB/Message/Audio/AudioOutput/SetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/StartDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopMessage.h> #include <AASB/Message/Audio/AudioOutput/VolumeChangedMessage.h> class MyAudioOutputHandler { // Subscribe to messages from the engine void MyAudioOutputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMutedStateChangedMessage ( message ); }, MutedStateChangedMessage :: topic (), MutedStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePauseMessage ( message ); }, PauseMessage :: topic (), PauseMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePlayMessage ( message ); }, PlayMessage :: topic (), PlayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareStreamMessage ( message ); }, PrepareStreamMessage :: topic (), PrepareStreamMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareURLMessage ( message ); }, PrepareURLMessage :: topic (), PrepareURLMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMayDuckMessage ( message ); }, MayDuckMessage :: topic (), MayDuckMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleResumeMessage ( message ); }, ResumeMessage :: topic (), ResumeMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetPositionMessage ( message ); }, SetPositionMessage :: topic (), SetPositionMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleVolumeChangedMessage ( message ); }, VolumeChangedMessage :: topic (), VolumeChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartDuckingMessage ( message ); }, StartDuckingMessage :: topic (), StartDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopDuckingMessage ( message ); }, StopDuckingMessage :: topic (), StopDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetDurationMessage ( message ); }, GetDurationMessage :: topic (), GetDurationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNumBytesBufferedMessage ( message ); }, GetNumBytesBufferedMessage :: topic (), GetNumBytesBufferedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPositionMessage ( message ); }, GetPositionMessage :: topic (), GetPositionMessage :: action ()); } void MyAudioOutputHandler::handleMutedStateChangedMessage ( const std :: string & message ) { // ...Handle muted state changed... } void MyAudioOutputHandler::handlePauseMessage ( const std :: string & message ) { // ...Handle pause... } void MyAudioOutputHandler::handlePlayMessage ( const std :: string & message ) { // ...Handle play... } void MyAudioOutputHandler::handlePrepareStreamMessage ( const std :: string & message ) { PrepareStreamMessage msg = json :: parse ( message ); auto stream = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // ...Handle prepare stream... } void MyAudioOutputHandler::handlePrepareURLMessage ( const std :: string & message ) { // ...Handle prepare URL... } void MyAudioOutputHandler::handleMayDuckMessage ( const std :: string & message ) { // ...Handle may duck... } void MyAudioOutputHandler::handleResumeMessage ( const std :: string & message ) { // ...Handle resume... } void MyAudioOutputHandler::handleSetPositionMessage ( const std :: string & message ) { // ...Handle set position... } void MyAudioOutputHandler::handleStopMessage ( const std :: string & message ) { // ...Handle stop... } void MyAudioOutputHandler::handleVolumeChangedMessage ( const std :: string & message ) { // ...Handle volume changed... } void MyAudioOutputHandler::handleStartDuckingMessage ( const std :: string & message ) { // ...Handle start ducking - reduce current media volume... } void MyAudioOutputHandler::handleStopDuckingMessage ( const std :: string & message ) { // ...Handle stop ducking - restore current media volume... } void MyAudioOutputHandler::handleGetDurationMessage ( const std :: string & message ) { GetDurationMessage msg = json :: parse ( message ); // Publish the reply message for GetDuration message. GetDurationMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // ...Handle getting duration... } void MyAudioOutputHandler::handleGetNumBytesBufferedMessage ( const std :: string & message ) { GetNumBytesBufferedMessage msg = json :: parse ( message ); // Publish the reply message for GetNumBytesBuffered message. GetNumBytesBufferedMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // ...Handle getting number of bytes buffered... } void MyAudioOutputHandler::handleGetPositionMessage ( const std :: string & message ) { GetPositionMessage msg = json :: parse ( message ); // Publish the reply message for GetPosition message. GetPositionMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // ...Handle getting position... } // To notify the Engine of an error during audio playback, // publish a MediaError message to the Engine void MyAudioOutputHandler::mediaError ( const std :: string & token , MediaError error , const std :: string & description ) { MediaErrorMessage msg ; msg . payload . token = token ; msg . payload . error = error ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } // To notify the Engine of an audio playback state change, // publish a MediaStateChanged message to the Engine void MyAudioOutputHandler::mediaStateChanged ( const std :: string & channel , const std :: string & token , MediaState state ) { MediaStateChangedMessage msg ; msg . payload . channel = channel ; msg . payload . token = token ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } } Enable music ducking The AudioOutput interfaces supports ducking the MUSIC channel. Your implementation can duck playing music when a high priority channel is in the focus or when any external application's audio channel is in focus. The Engine will publish a MayDuck message if the prepared media allows the application to duck the volume if any high priority audio stream is in focus. If this message is not published, your application can assume that media is not allowed to duck. The Engine will publish a StartDucking message to notify your application to reduce the playing volume and a StopDucking message to notify your application to restore the playing volume to its original level. If your application is handling an audio focus action due to audio events from other applications, your application must publish an AudioFocusEvent message with the right focus action. For example, if Alexa music is ducked because of navigation turn-by-turn instructions, your application is expected to report this to the Engine by publishing the AudioFocusEvent message with focus action REPORT_DUCKING_STARTED and publish the AudioFocusEvent message with focus action REPORT_DUCKING_STOPPED once volume is restored. Note: The following diagrams show sequences using the deprecated AudioOutput platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analagous AudioOutput AASB messages with the MessageBroker. The concepts are the same between the two interfaces. Click to expand or collapse sequence diagram: Duck volume when Alexa dialog or alert is in focus This diagram illustrates the sequence for your application to duck volume when Alexa dialog or alert is in focus. ![Duck_Alexa_Alert](./assets/diagrams/out/ducking.png) Click to expand or collapse sequence diagram: Duck volume when 3rd party high priority audio acitivity in focus This diagram illustrates the sequence for your application to duck volume when a 3rd party high priority audio activity is in focus. ![Duck_3rd](./assets/diagrams/out/ducking_3p_event.png) The Engine reqires configuration for your application to use the audio ducking feature. Provide the following JSON in your Engine configuration: { \"aace.alexa\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } } Alternativly, use the AlexaConfiguration::createDuckingConfig() factory function to generate the EngineConfiguration object. auto audioDuckingConfig = aace :: alexa :: config :: AlexaConfiguration :: createDuckingConfig ( true );","title":"Alexa Auto SDK Audio Channels <!-- omit in toc -->"},{"location":"modules/core/AUDIO/#alexa-auto-sdk-audio-channels","text":"Table of Contents Overview Understand audio input channels Understand audio output channels Access the audio stream for stream-based input and output Provide audio input Provide audio output Enable music ducking","title":"Alexa Auto SDK Audio Channels "},{"location":"modules/core/AUDIO/#overview","text":"The core audio Engine service provides a mechanism for Engine components of any module to open audio input and output channels in your application. Each Engine component that requests an audio channel specifies its audio channel type so your application can provide microphone and media player implementations specific to each channel type. The core audio Engine service provides audio I/O AASB message interfaces that are generic enough for your application to decide how to produce or play the audio.","title":"Overview"},{"location":"modules/core/AUDIO/#understand-audio-input-channels","text":"Your application uses the AudioInput AASB message interface to provide audio data to the Engine. The Engine defines the following audio input types to use with the AudioInput interface: VOICE\u2014 This audio input type provides user speech audio data. COMMUNICATION\u2014 This audio input type provides user speech audio data specific to Alexa-to-Alexa calling. For example, the Alexa Comms module Engine components request audio input with this type. LOOPBACK\u2014 This audio input type provides audio data recorded from the device's own speakers. For example, the Loopback Detector module Engine components request audio input with this type to detect Alexa saying her own name in the audio output. The audio input part of the core audio Engine service enables Engine components to share single producer, multi-consumer audio input in two key ways: Multiple Engine components might request audio input of the same type. For example, the Alexa module and Amazonlite module Engine components both want VOICE audio input. When the second component requests to open VOICE channel, the Engine won't ask your application for VOICE audio again because your application is already providing it. The Engine takes care of providing the same audio data to both consumers. Multiple Engine components might request audio input of \"different\" types that your application considers the same. For example, the Alexa module and Alexa Comms module want VOICE and COMMUNICATION audio input, respectively. Your application's specific integration might have one implementation for producing the user speech audio data. In this case, your application takes care of providing the same audio data to both consumers.","title":"Understand audio input channels"},{"location":"modules/core/AUDIO/#understand-audio-output-channels","text":"The Engine uses the AudioOnput AASB message interface to request your application to play or perform other operations on audio output data. The Engine defines the following audio output types to use with the AudioOutput interface: TTS\u2014 This audio output type plays speech audio data. For example, Alexa's speech responses from the SpeechSynthesizer interface MUSIC This audio output type plays media. For example, Amazon Music from the AudioPlayer interface NOTIFICATION This audio output type plays notification audio cues. For example, short cues from the Notifications interface ALARM This audio output type plays alarms. For example, repeating alarm audio from the Alerts interface EARCON This audio output type plays Alexa attention state audio cues. For example, the audio cue to indicate Alexa started listening COMMUNICATION This audio output type plays the audio for Alexa-to-Alexa calling. For example, the \"other side\" of the user's Alexa-to-Alexa call placed using the Alexa Comms module. RINGTONE This audio output type plays ringtones. For example, the inbound or outbound ringing tone of the user's Alexa-to-Alexa call placed using the Alexa Comms module. Your application determines how to handle each different audio type. The simplest integration, for example, might play all audio output types with the same underlying media player implementation. A more sophisticated integration might provide different media player implementations depending on the audio type\u2014 for example, using a low-level audio implementation for NOTIFICATION and EARCON types, and a high-level implementation for TTS and MUSIC . The best approach depends on your system-specific use cases. Important! Even though your application might use the same media player implementation for multiple audio output types, the actual integration must be able to handle the Engine having multiple channels open at the same time; for example, there might be music buffered in the MUSIC channel media player while the user makes a quick Alexa-to-Alexa call using the RINGTONE and COMMUNICATION channels. The Engine is agnostic to how you buffer and control the audio, but it does require your integration to be capable of keeping the right state of all channels that are active at the same time.","title":"Understand audio output channels"},{"location":"modules/core/AUDIO/#access-the-audio-stream-for-stream-based-input-and-output","text":"Both the AudioInput and AudioOutput AASB message interfaces require your application to read from or write to a stream. These messages include an ID to identify the stream in the streamId field of the message payload. When your application receives a message with a streamId , use the MessageBroker openStream() function with streamId to get a reference to a MessageStream object wrapping the stream. Specify the operation mode (i.e., read or write) when opening the stream using the MessageStream::Mode enumerated types. If the MessageBroker cannot open the stream for the specified operation, the openStream() call will fail and return a null object. The following example demonstrates how your application would open an input stream after receiving the StartAudioInput message, and write data to the stream until it receives a StopAudioInput message for the same stream ID. #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); // open the stream for writing auto streamId = _msg . payload . streamId ; auto stream = messageBroker -> openStream ( streamId , MessageStream :: Mode :: WRITE ); startAudioInput ( streamId , stream ) }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; stopAudioInput ( streamId ); }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! }","title":"Access the audio stream for stream-based input and output"},{"location":"modules/core/AUDIO/#provide-audio-input","text":"Your application subscribes to the AudioInput AASB messages published by the Engine. When some Engine component requests audio input (for example, when the user presses the tap-to-talk button from SpeechRecognizer ), the Engine publishes a StartAudioInput message that specifies the AudioInputType and stream ID. Your implementation must start writing audio data until the Engine publishes a StopAudioInput message for the stream ID. If two Engine components request audio from the same channel, your application will only receive a StartAudioInput message when the first component requests the audio. All of the Engine components that have requested audio from the same input channel will receive a callback internally when audio data is written to the interface. Your application will only receive a StopAudioInput message after the last Engine component has canceled its request to receive audio from the channel. Your application must provide audio input in the following format: 16bit Linear PCM 16kHz sample rate Single channel Signed, little endian byte order Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> class MyAudioInputHandler { // Subscribe to messages from the engine void MyAudioInputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartAudioInputMessage ( message ); }, StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopAudioInputMessage ( message ); }, StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); } void MyAudioInputHandler::handleStartAudioInputMessage ( const std :: string & message ) { StartAudioInputMessage msg = json :: parse ( message ); auto stream = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: WRITE ); // ...Handle starting audio input... } void MyAudioInputHandler::handleStopAudioInputMessage ( const std :: string & message ) { // ...Handle stopping audio input... } }","title":"Provide audio input"},{"location":"modules/core/AUDIO/#provide-audio-output","text":"Your application subscribes to the AudioOutput AASB messages published by the Engine. The Engine publishes either a PrepareStream message or a PrepareURL message to notify your application to create an audio stream or URL for playback. The characteristics of the audio that will be played on the channel are specified by the AudioOutputType in the payload. The Engine will perform actions on the audio output by publishing additional AudioOutput messages. See the AudioOutput AASB message documentation for details. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Audio/AudioOutput/GetDurationMessage.h> #include <AASB/Message/Audio/AudioOutput/GetNumBytesBufferedMessage.h> #include <AASB/Message/Audio/AudioOutput/GetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/MayDuckMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaErrorMessage.h> #include <AASB/Message/Audio/AudioOutput/MediaStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/MutedStateChangedMessage.h> #include <AASB/Message/Audio/AudioOutput/PauseMessage.h> #include <AASB/Message/Audio/AudioOutput/PlayMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareStreamMessage.h> #include <AASB/Message/Audio/AudioOutput/PrepareURLMessage.h> #include <AASB/Message/Audio/AudioOutput/ResumeMessage.h> #include <AASB/Message/Audio/AudioOutput/SetPositionMessage.h> #include <AASB/Message/Audio/AudioOutput/StartDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopDuckingMessage.h> #include <AASB/Message/Audio/AudioOutput/StopMessage.h> #include <AASB/Message/Audio/AudioOutput/VolumeChangedMessage.h> class MyAudioOutputHandler { // Subscribe to messages from the engine void MyAudioOutputHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMutedStateChangedMessage ( message ); }, MutedStateChangedMessage :: topic (), MutedStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePauseMessage ( message ); }, PauseMessage :: topic (), PauseMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePlayMessage ( message ); }, PlayMessage :: topic (), PlayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareStreamMessage ( message ); }, PrepareStreamMessage :: topic (), PrepareStreamMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareURLMessage ( message ); }, PrepareURLMessage :: topic (), PrepareURLMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleMayDuckMessage ( message ); }, MayDuckMessage :: topic (), MayDuckMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleResumeMessage ( message ); }, ResumeMessage :: topic (), ResumeMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSetPositionMessage ( message ); }, SetPositionMessage :: topic (), SetPositionMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleVolumeChangedMessage ( message ); }, VolumeChangedMessage :: topic (), VolumeChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartDuckingMessage ( message ); }, StartDuckingMessage :: topic (), StartDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopDuckingMessage ( message ); }, StopDuckingMessage :: topic (), StopDuckingMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetDurationMessage ( message ); }, GetDurationMessage :: topic (), GetDurationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNumBytesBufferedMessage ( message ); }, GetNumBytesBufferedMessage :: topic (), GetNumBytesBufferedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPositionMessage ( message ); }, GetPositionMessage :: topic (), GetPositionMessage :: action ()); } void MyAudioOutputHandler::handleMutedStateChangedMessage ( const std :: string & message ) { // ...Handle muted state changed... } void MyAudioOutputHandler::handlePauseMessage ( const std :: string & message ) { // ...Handle pause... } void MyAudioOutputHandler::handlePlayMessage ( const std :: string & message ) { // ...Handle play... } void MyAudioOutputHandler::handlePrepareStreamMessage ( const std :: string & message ) { PrepareStreamMessage msg = json :: parse ( message ); auto stream = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // ...Handle prepare stream... } void MyAudioOutputHandler::handlePrepareURLMessage ( const std :: string & message ) { // ...Handle prepare URL... } void MyAudioOutputHandler::handleMayDuckMessage ( const std :: string & message ) { // ...Handle may duck... } void MyAudioOutputHandler::handleResumeMessage ( const std :: string & message ) { // ...Handle resume... } void MyAudioOutputHandler::handleSetPositionMessage ( const std :: string & message ) { // ...Handle set position... } void MyAudioOutputHandler::handleStopMessage ( const std :: string & message ) { // ...Handle stop... } void MyAudioOutputHandler::handleVolumeChangedMessage ( const std :: string & message ) { // ...Handle volume changed... } void MyAudioOutputHandler::handleStartDuckingMessage ( const std :: string & message ) { // ...Handle start ducking - reduce current media volume... } void MyAudioOutputHandler::handleStopDuckingMessage ( const std :: string & message ) { // ...Handle stop ducking - restore current media volume... } void MyAudioOutputHandler::handleGetDurationMessage ( const std :: string & message ) { GetDurationMessage msg = json :: parse ( message ); // Publish the reply message for GetDuration message. GetDurationMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // ...Handle getting duration... } void MyAudioOutputHandler::handleGetNumBytesBufferedMessage ( const std :: string & message ) { GetNumBytesBufferedMessage msg = json :: parse ( message ); // Publish the reply message for GetNumBytesBuffered message. GetNumBytesBufferedMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // ...Handle getting number of bytes buffered... } void MyAudioOutputHandler::handleGetPositionMessage ( const std :: string & message ) { GetPositionMessage msg = json :: parse ( message ); // Publish the reply message for GetPosition message. GetPositionMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; // ...Handle getting position... } // To notify the Engine of an error during audio playback, // publish a MediaError message to the Engine void MyAudioOutputHandler::mediaError ( const std :: string & token , MediaError error , const std :: string & description ) { MediaErrorMessage msg ; msg . payload . token = token ; msg . payload . error = error ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } // To notify the Engine of an audio playback state change, // publish a MediaStateChanged message to the Engine void MyAudioOutputHandler::mediaStateChanged ( const std :: string & channel , const std :: string & token , MediaState state ) { MediaStateChangedMessage msg ; msg . payload . channel = channel ; msg . payload . token = token ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } }","title":"Provide audio output"},{"location":"modules/core/AUDIO/#enable-music-ducking","text":"The AudioOutput interfaces supports ducking the MUSIC channel. Your implementation can duck playing music when a high priority channel is in the focus or when any external application's audio channel is in focus. The Engine will publish a MayDuck message if the prepared media allows the application to duck the volume if any high priority audio stream is in focus. If this message is not published, your application can assume that media is not allowed to duck. The Engine will publish a StartDucking message to notify your application to reduce the playing volume and a StopDucking message to notify your application to restore the playing volume to its original level. If your application is handling an audio focus action due to audio events from other applications, your application must publish an AudioFocusEvent message with the right focus action. For example, if Alexa music is ducked because of navigation turn-by-turn instructions, your application is expected to report this to the Engine by publishing the AudioFocusEvent message with focus action REPORT_DUCKING_STARTED and publish the AudioFocusEvent message with focus action REPORT_DUCKING_STOPPED once volume is restored. Note: The following diagrams show sequences using the deprecated AudioOutput platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analagous AudioOutput AASB messages with the MessageBroker. The concepts are the same between the two interfaces. Click to expand or collapse sequence diagram: Duck volume when Alexa dialog or alert is in focus This diagram illustrates the sequence for your application to duck volume when Alexa dialog or alert is in focus. ![Duck_Alexa_Alert](./assets/diagrams/out/ducking.png) Click to expand or collapse sequence diagram: Duck volume when 3rd party high priority audio acitivity in focus This diagram illustrates the sequence for your application to duck volume when a 3rd party high priority audio activity is in focus. ![Duck_3rd](./assets/diagrams/out/ducking_3p_event.png) The Engine reqires configuration for your application to use the audio ducking feature. Provide the following JSON in your Engine configuration: { \"aace.alexa\" : { \"audioOutputType.music\" : { \"ducking\" : { \"enabled\" : true } } } } Alternativly, use the AlexaConfiguration::createDuckingConfig() factory function to generate the EngineConfiguration object. auto audioDuckingConfig = aace :: alexa :: config :: AlexaConfiguration :: createDuckingConfig ( true );","title":"Enable music ducking"},{"location":"modules/core/AUTHORIZATION/","text":"Alexa Auto SDK Authorization Table of Contents Overview Authorization interface specification Generic Authorization sequence diagrams Start authorization Cancel authorization Log out Authorize for Alexa with the CBL module Authorize for Alexa with an application-provided method Start authorization Receive events from the Engine Send events to the Engine Provide an access token Cancel authorization Log out Handle errors Optional Auth Provider Engine configuration Overview To make requests to services such as Alexa, the Auto SDK Engine requires authorization. For example, the Engine includes a Login with Amazon (LWA) access token in every request to Alexa. The access token authorizes the Engine to interact with Alexa on behalf of the user. For each service that requires authorization, there may be more than one method of performing the authorization; for instance, there are multiple methods of acquiring an LWA token that authorizes access to Alexa. See the Authorize an AVS Device for details of each method. The Auto SDK Core module provides an Engine service for managing the authorization with any arbitrary authorization provider. The Authorization interface specifies generic messages for your Auto SDK client application to initiate an authorization method, terminate an authorization method, or give provider-specific authorization data to the Engine. The actions the Engine takes in response to an Authorization message depend on which provider the message corresponds to as well as which software component is responsible for performing the authorization method. This following sections describe the Auto SDK Authorization interface followed by details to use the Authorization interface for LWA Alexa authorization in your application. To simplify your Alexa authorization implementation, the Engine provides an implementation of the code-based linking (CBL) LWA authorization method, which you can use in your application by integrating with the CBL module . Alternatively, your application can provide the implementation to fetch access tokens through any method you choose . Note: All diagrams in the following sections show sequences using the deprecated Authorization platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analagous Authorization AASB messages with the MessageBroker. The concepts are the same between the two interfaces. Important!: Logging out from CBL module or application-provided authorization clears the Auto SDK databases that store user data, such as alerts and settings. For example, when the user logs out, the Alexa module Engine components clear pending alerts in the alerts database to ensure that the next user who logs in does not receive any pending alerts. However, the Alexa module Engine components also clear the locale setting at log out and reset the setting to the default value from the Engine configuration. Therefore, if the device locale setting is different from the default locale when the next user signs in, you must set the locale before starting an authorization flow. Authorization interface specification The Authorization interface is generic enough to support authorization with any authorization provider and provide the Engine with any type of data relevant to that authorization provider. It is also generic enough to support different components owning the authorization process depending on the method. For example, your application might use the method in which the Engine acquires LWA Alexa access tokens, or it might use the method in which your application provides its own implementation to acquire LWA Alexa access tokens. In either case, your application interacts with the same Authorization API; only the protocol in the payload varies. The Engine supports a fixed set of providers, and each provider corresponds to a protcol your application uses in Authorization message payloads. See the Authorization message reference for details. Regardless of the authorizaton method you choose, your application will do the following general steps: Subscribe to the SetAuthorizationData message. The Engine publishes this message to tell your application to store provider-specific data. Subscribe to the GetAuthorizationData message. The Engine publishes this message to retrieve provider-specific data from your application. Your application publishes the synchronous-style reply message in response. Subscribe to the AuthorizationStateChanged message. The Engine publishes this message to notify your application of status changes during the authorization flow. Subscribe to the EventReceived message. The Engine publishes this message to notify your application of provider-specific events during the authorization flow. Subscribe to the AuthorizationError message. The Engine publishes this message to notify your application of errors in the authorization flow. Publish the StartAuthorization message to start the authorization flow. You must publish this message every time you start the Engine. The Engine does not persist the state across reboots. Publish the CancelAuthorization message to cancel the authorization flow. Publish the SendEvent message to notify the Engine about a provider-specifc event. Publish the Logout message to notify the Engine that the user signed out of your application. Generic Authorization sequence diagrams The following sequence diagrams show typical data flow when your application uses the Authorization interface. Start authorization Cancel authorization Log out Authorize for Alexa with the CBL module The Engine provides an implementation of the code-based linking method of acquiring LWA access tokens. To use the implementation, build the Auto SDK with the CBL module, link the library in your application, and follow the Authorization protocol specified in the CBL module documentation . Authorize for Alexa with an application-provided method This section uses the term \"Auth Provider authorization\" to refer to any general method through which your application aquires an Alexa access token to provide to the Engine. Note: Auth Provider authorization and other authorization methods, such as using the CBL module , are mutually exclusive. For example, if the application is already registered with CBL, starting Auth Provider authorization logs out the application from the previous authorization. The service name used with the Authorization interface for Auth Provider authorization is alexa:auth-provider . Start authorization To start authorization, publish the StartAuthorization message. The data parameter is empty. Receive events from the Engine The application receives an event from the Engine via EventReceived in the following scenarios: when the Engine requests the application to start authorization when the application needs to log out of the authorization To request the application to start authorization, the Engine passes the request to the application by using the event parameter. The parameter is a string containing JSON with the following structure: { \"type\": \"requestAuthorization\" } To log out, the event parameter is a string containing JSON with the following structure: { \"type\": \"logout\" } Send events to the Engine To notify the Engine of an authorization state change, the application uses the event parameter of the SendEvent message. The parameter is a string containing JSON with the following structure: { \"type\":\"authStateChangeEvent\", \"payload\": { \"state\": {{STRING}} } } The accepted state strings are AUTHORIZED and UNAUTHORIZED . The application needs to notify the Engine of an authorization state change for either of the following scenarios: * There is a request from Engine via EventReceived with type set to requestAuthorization . * The application transitions to a new state, e.g., from UNAUTHORIZED to AUTHORIZED . Provide an access token The Engine requests the application to get the access token by specifying accessToken as the key in the GetAuthorizationData message as follows. The application replies with the GetAuthorizationData reply message with the data parameter set to a string containing JSON, formatted like the following example: { \"accessToken\":\"Atza|AAAAAABBBBBBCCCCCC\" } Cancel authorization To cancel authorization, publish the CancelAuthorization message. Publish this message to cancel the authorization flow before publishing SendEvent . Canceling authorization does not affect the device authorization state. Log out To log out, publish the Logout message. Note: Your application must delete access and refresh tokens when the user signs out of their Amazon account. When the user wants to use Alexa again, and your application has no tokens, the user must sign in again. Note: Your application should stop the audio player if the user logs out of the application while music is playing. Handle errors The Engine notifies the application about any error during the authorization flow. The following list describes possible errors during authorization: UNKNOWN_ERROR : An unrecoverable error happens in the authorization flow. AUTH_FAILURE : An invalid or expired access token was provided. LOGOUT_FAILED : The Engine cannot complete the logout flow. START_AUTHORIZATION_FAILED : The Engine cannot start the authorization flow. In any of these scenarios, the Engine publishes AuthorizationError with error set to one of the values enumerated above. Optional Auth Provider Engine configuration By default, the Engine supports one Auth Provider authorization. However, if your application supports more than one, include the following JSON object in your Engine configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [<LIST_OF_PROVIDER_NAME_STRINGS>] } } } For example, if your application supports two Auth Provider authorizations, named \"serviceA\" and \"serviceB,\" provide the following configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [\"serviceA\" , \"serviceB\"] } } } With this configuration, the Engine uses the service names \"serviceA\" and \"serviceB\" with the Authorization messages interface instead of using the default Auth Provider service name alexa:auth-provider . The rest of the sequence is the same.","title":"Alexa Auto SDK Authorization <!-- omit in toc -->"},{"location":"modules/core/AUTHORIZATION/#alexa-auto-sdk-authorization","text":"Table of Contents Overview Authorization interface specification Generic Authorization sequence diagrams Start authorization Cancel authorization Log out Authorize for Alexa with the CBL module Authorize for Alexa with an application-provided method Start authorization Receive events from the Engine Send events to the Engine Provide an access token Cancel authorization Log out Handle errors Optional Auth Provider Engine configuration","title":"Alexa Auto SDK Authorization "},{"location":"modules/core/AUTHORIZATION/#overview","text":"To make requests to services such as Alexa, the Auto SDK Engine requires authorization. For example, the Engine includes a Login with Amazon (LWA) access token in every request to Alexa. The access token authorizes the Engine to interact with Alexa on behalf of the user. For each service that requires authorization, there may be more than one method of performing the authorization; for instance, there are multiple methods of acquiring an LWA token that authorizes access to Alexa. See the Authorize an AVS Device for details of each method. The Auto SDK Core module provides an Engine service for managing the authorization with any arbitrary authorization provider. The Authorization interface specifies generic messages for your Auto SDK client application to initiate an authorization method, terminate an authorization method, or give provider-specific authorization data to the Engine. The actions the Engine takes in response to an Authorization message depend on which provider the message corresponds to as well as which software component is responsible for performing the authorization method. This following sections describe the Auto SDK Authorization interface followed by details to use the Authorization interface for LWA Alexa authorization in your application. To simplify your Alexa authorization implementation, the Engine provides an implementation of the code-based linking (CBL) LWA authorization method, which you can use in your application by integrating with the CBL module . Alternatively, your application can provide the implementation to fetch access tokens through any method you choose . Note: All diagrams in the following sections show sequences using the deprecated Authorization platform interface of Auto SDK 3.3. Instead of the platform interface, your application will use the analagous Authorization AASB messages with the MessageBroker. The concepts are the same between the two interfaces. Important!: Logging out from CBL module or application-provided authorization clears the Auto SDK databases that store user data, such as alerts and settings. For example, when the user logs out, the Alexa module Engine components clear pending alerts in the alerts database to ensure that the next user who logs in does not receive any pending alerts. However, the Alexa module Engine components also clear the locale setting at log out and reset the setting to the default value from the Engine configuration. Therefore, if the device locale setting is different from the default locale when the next user signs in, you must set the locale before starting an authorization flow.","title":"Overview"},{"location":"modules/core/AUTHORIZATION/#authorization-interface-specification","text":"The Authorization interface is generic enough to support authorization with any authorization provider and provide the Engine with any type of data relevant to that authorization provider. It is also generic enough to support different components owning the authorization process depending on the method. For example, your application might use the method in which the Engine acquires LWA Alexa access tokens, or it might use the method in which your application provides its own implementation to acquire LWA Alexa access tokens. In either case, your application interacts with the same Authorization API; only the protocol in the payload varies. The Engine supports a fixed set of providers, and each provider corresponds to a protcol your application uses in Authorization message payloads. See the Authorization message reference for details. Regardless of the authorizaton method you choose, your application will do the following general steps: Subscribe to the SetAuthorizationData message. The Engine publishes this message to tell your application to store provider-specific data. Subscribe to the GetAuthorizationData message. The Engine publishes this message to retrieve provider-specific data from your application. Your application publishes the synchronous-style reply message in response. Subscribe to the AuthorizationStateChanged message. The Engine publishes this message to notify your application of status changes during the authorization flow. Subscribe to the EventReceived message. The Engine publishes this message to notify your application of provider-specific events during the authorization flow. Subscribe to the AuthorizationError message. The Engine publishes this message to notify your application of errors in the authorization flow. Publish the StartAuthorization message to start the authorization flow. You must publish this message every time you start the Engine. The Engine does not persist the state across reboots. Publish the CancelAuthorization message to cancel the authorization flow. Publish the SendEvent message to notify the Engine about a provider-specifc event. Publish the Logout message to notify the Engine that the user signed out of your application.","title":"Authorization interface specification"},{"location":"modules/core/AUTHORIZATION/#generic-authorization-sequence-diagrams","text":"The following sequence diagrams show typical data flow when your application uses the Authorization interface.","title":"Generic Authorization sequence diagrams"},{"location":"modules/core/AUTHORIZATION/#start-authorization","text":"","title":"Start authorization"},{"location":"modules/core/AUTHORIZATION/#cancel-authorization","text":"","title":"Cancel authorization"},{"location":"modules/core/AUTHORIZATION/#log-out","text":"","title":"Log out"},{"location":"modules/core/AUTHORIZATION/#authorize-for-alexa-with-the-cbl-module","text":"The Engine provides an implementation of the code-based linking method of acquiring LWA access tokens. To use the implementation, build the Auto SDK with the CBL module, link the library in your application, and follow the Authorization protocol specified in the CBL module documentation .","title":"Authorize for Alexa with the CBL module"},{"location":"modules/core/AUTHORIZATION/#authorize-for-alexa-with-an-application-provided-method","text":"This section uses the term \"Auth Provider authorization\" to refer to any general method through which your application aquires an Alexa access token to provide to the Engine. Note: Auth Provider authorization and other authorization methods, such as using the CBL module , are mutually exclusive. For example, if the application is already registered with CBL, starting Auth Provider authorization logs out the application from the previous authorization. The service name used with the Authorization interface for Auth Provider authorization is alexa:auth-provider .","title":"Authorize for Alexa with an application-provided method"},{"location":"modules/core/AUTHORIZATION/#start-authorization_1","text":"To start authorization, publish the StartAuthorization message. The data parameter is empty.","title":"Start authorization"},{"location":"modules/core/AUTHORIZATION/#receive-events-from-the-engine","text":"The application receives an event from the Engine via EventReceived in the following scenarios: when the Engine requests the application to start authorization when the application needs to log out of the authorization To request the application to start authorization, the Engine passes the request to the application by using the event parameter. The parameter is a string containing JSON with the following structure: { \"type\": \"requestAuthorization\" } To log out, the event parameter is a string containing JSON with the following structure: { \"type\": \"logout\" }","title":"Receive events from the Engine"},{"location":"modules/core/AUTHORIZATION/#send-events-to-the-engine","text":"To notify the Engine of an authorization state change, the application uses the event parameter of the SendEvent message. The parameter is a string containing JSON with the following structure: { \"type\":\"authStateChangeEvent\", \"payload\": { \"state\": {{STRING}} } } The accepted state strings are AUTHORIZED and UNAUTHORIZED . The application needs to notify the Engine of an authorization state change for either of the following scenarios: * There is a request from Engine via EventReceived with type set to requestAuthorization . * The application transitions to a new state, e.g., from UNAUTHORIZED to AUTHORIZED .","title":"Send events to the Engine"},{"location":"modules/core/AUTHORIZATION/#provide-an-access-token","text":"The Engine requests the application to get the access token by specifying accessToken as the key in the GetAuthorizationData message as follows. The application replies with the GetAuthorizationData reply message with the data parameter set to a string containing JSON, formatted like the following example: { \"accessToken\":\"Atza|AAAAAABBBBBBCCCCCC\" }","title":"Provide an access token"},{"location":"modules/core/AUTHORIZATION/#cancel-authorization_1","text":"To cancel authorization, publish the CancelAuthorization message. Publish this message to cancel the authorization flow before publishing SendEvent . Canceling authorization does not affect the device authorization state.","title":"Cancel authorization"},{"location":"modules/core/AUTHORIZATION/#log-out_1","text":"To log out, publish the Logout message. Note: Your application must delete access and refresh tokens when the user signs out of their Amazon account. When the user wants to use Alexa again, and your application has no tokens, the user must sign in again. Note: Your application should stop the audio player if the user logs out of the application while music is playing.","title":"Log out"},{"location":"modules/core/AUTHORIZATION/#handle-errors","text":"The Engine notifies the application about any error during the authorization flow. The following list describes possible errors during authorization: UNKNOWN_ERROR : An unrecoverable error happens in the authorization flow. AUTH_FAILURE : An invalid or expired access token was provided. LOGOUT_FAILED : The Engine cannot complete the logout flow. START_AUTHORIZATION_FAILED : The Engine cannot start the authorization flow. In any of these scenarios, the Engine publishes AuthorizationError with error set to one of the values enumerated above.","title":"Handle errors"},{"location":"modules/core/AUTHORIZATION/#optional-auth-provider-engine-configuration","text":"By default, the Engine supports one Auth Provider authorization. However, if your application supports more than one, include the following JSON object in your Engine configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [<LIST_OF_PROVIDER_NAME_STRINGS>] } } } For example, if your application supports two Auth Provider authorizations, named \"serviceA\" and \"serviceB,\" provide the following configuration: { \"aace.alexa\" : { \"authProvider\" : { \"providers\" : [\"serviceA\" , \"serviceB\"] } } } With this configuration, the Engine uses the service names \"serviceA\" and \"serviceB\" with the Authorization messages interface instead of using the default Auth Provider service name alexa:auth-provider . The rest of the sequence is the same.","title":"Optional Auth Provider Engine configuration"},{"location":"modules/core/RUNTIME_PROPERTIES/","text":"Alexa Auto SDK Property Manager Table of Contents Overview Use the Property Manager AASB messages Property Definitions Alexa Core Overview Certain modules in the Auto SDK define constants (for example FIRMWARE_VERSION and LOCALE ) that are used to get and set the values of runtime properties in the Engine. Changes to property values may also be initiated from the Alexa Voice Service (AVS). For example, the TIMEZONE property may be changed through AVS when the user changes the timezone setting in the Alexa Companion App. The Auto SDK Core module provides the Property Manager service with corresponding AASB interface PropertyManager . Property Manager maintains the runtime properties by storing properties and listeners to the properties and delegating the SetProperty and GetProperty messages calls from your application to the respective Engine services. The Engine also publishes PropertyChanged and PropertyStateChanged messages to notify your application about property value changes originating in the Engine. Use the Property Manager AASB messages To change a property value, publish a SetProperty message. The Engine publishes a PropertyStateChanged message indicating the success or failure of the request. To retrieve a property value, publish a GetProperty message. The Engine publishes synchronous-style a GetProperty reply with the value of the property. When a change in a property value occurs in the Engine that is not initiated by your application, the Engine publishes a PropertyChanged message. Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PropertyManager/PropertyManager/GetPropertyMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/PropertyChangedMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/SetPropertyMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPropertyManagerHandler { // Subscribe to messages from the engine void MyPropertyManagerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyChangedMessage ( message ); }, PropertyChangedMessage :: topic (), PropertyChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyStateChangedMessage ( message ); }, PropertyStateChangedMessage :: topic (), PropertyStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); } void MyPropertyManagerHandler::handlePropertyChangedMessage ( const std :: string & message ) { PropertyChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string newValue = msg . payload . newValue ; // ...Handle property changed... } void MyPropertyManagerHandler::handlePropertyStateChangedMessage ( const std :: string & message ) { PropertyStateChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string value = msg . payload . value ; std :: string state = msg . payload . state // ...Handle property state changed... } void MyPropertyManagerHandler::handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string value = msg . payload . value ; // ...Handle the value for the message... } // Call to set a property void MyPropertyManagerHandler::setProperty ( const std :: string & name , const std :: string & value ) { ] SetPropertyMessage msg ; msg . payload . name = name ; msg . payload . value = value ; m_messageBroker -> publish ( msg . toString ()); } // Call to get a property std :: string MyPropertyManagerHandler::getProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetProperty reply message // Return the value from reply message payload } } Property Definitions The definitions of the properties used with the SetProperty and GetProperty messages are defined by the Auto SDK modules that manage the properties. Alexa The Alexa module provides the following properties: \"aace.alexa.wakewordSupported\" This read-only property is used with GetProperty to check if wake word support is enabled in the Engine. If wake word is not supported in the Engine, attempts to enable wake word with the SpeechRecognizer will fail. \"aace.alexa.system.firmwareVersion\" This property is used with SetProperty to change the firmware version that is reported to AVS. The value must be a positive, 32-bit signed integer represented as a string. \"aace.alexa.setting.locale\" This property is used with SetProperty to change the current locale setting for Alexa. The value must be one of the following: A valid locale accepted by AVS as a string. E.g. \"en-US\" A valid locale pair. The format is a string containing two valid locales separated with a forward slash. E.g. \"en-US/es-US\" Note: For a list of the Alexa Voice Service (AVS) supported locales, see the [Alexa Voice Service (AVS) documentation](https://developer.amazon.com/docs/alexa-voice-service/system.html#locales \"aace.alexa.countrySupported\" This read-only property is used with GetProperty to check if the vehicle's country is supported. \"aace.alexa.wakewordEnabled\" This property is used with SetProperty to change the current wake word enabled setting. The value must be a boolean represented as a string, i.e. \"true\" or \"false\". Use GetProperty with this property to check whether wake word is enabled. \"aace.alexa.timezone\" This property is used with SetProperty to change the current timezone setting of the device. The value must be a valid timezone accepted by AVS. Use GetProperty to get the Engine's current timezone setting. Core The Core module provides the following properties: \"aace.core.version\" This property is used with GetProperty to return the Auto SDK version. \"aace.vehicle.operatingCountry\" This property is used with SetProperty to change the current operating country. The value must be a valid 2-letter ISO country code. \"aace.network.networkInterface\" This property is used with SetProperty to set the network interface for the network connection. The value must be an IP address or network interface name. \"aace.network.httpProxyHeaders\" This property is used with SetProperty to set the custom HTTP header to pass in the HTTP request sent to a proxy. The headers should be \\n separated. For example, \"Proxy-Authorization: Bearer 1234\" (should not be CRLF-terminated) Note: To apply the custom headers you are required to specify the CURLOPT_PROXY` in the Engine configuration. The specified headers will be applied to all subsequent requests sent to a proxy.","title":"Alexa Auto SDK Property Manager <!-- omit in toc -->"},{"location":"modules/core/RUNTIME_PROPERTIES/#alexa-auto-sdk-property-manager","text":"Table of Contents Overview Use the Property Manager AASB messages Property Definitions Alexa Core","title":"Alexa Auto SDK Property Manager "},{"location":"modules/core/RUNTIME_PROPERTIES/#overview","text":"Certain modules in the Auto SDK define constants (for example FIRMWARE_VERSION and LOCALE ) that are used to get and set the values of runtime properties in the Engine. Changes to property values may also be initiated from the Alexa Voice Service (AVS). For example, the TIMEZONE property may be changed through AVS when the user changes the timezone setting in the Alexa Companion App. The Auto SDK Core module provides the Property Manager service with corresponding AASB interface PropertyManager . Property Manager maintains the runtime properties by storing properties and listeners to the properties and delegating the SetProperty and GetProperty messages calls from your application to the respective Engine services. The Engine also publishes PropertyChanged and PropertyStateChanged messages to notify your application about property value changes originating in the Engine.","title":"Overview"},{"location":"modules/core/RUNTIME_PROPERTIES/#use-the-property-manager-aasb-messages","text":"To change a property value, publish a SetProperty message. The Engine publishes a PropertyStateChanged message indicating the success or failure of the request. To retrieve a property value, publish a GetProperty message. The Engine publishes synchronous-style a GetProperty reply with the value of the property. When a change in a property value occurs in the Engine that is not initiated by your application, the Engine publishes a PropertyChanged message. Click to expand or collapse C++ example code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PropertyManager/PropertyManager/GetPropertyMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/PropertyChangedMessage.h> #include <AASB/Message/PropertyManager/PropertyManager/SetPropertyMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPropertyManagerHandler { // Subscribe to messages from the engine void MyPropertyManagerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyChangedMessage ( message ); }, PropertyChangedMessage :: topic (), PropertyChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePropertyStateChangedMessage ( message ); }, PropertyStateChangedMessage :: topic (), PropertyStateChangedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetPropertyReplyMessage ( message ); }, GetPropertyMessage :: topic (), GetPropertyMessage :: action ()); } void MyPropertyManagerHandler::handlePropertyChangedMessage ( const std :: string & message ) { PropertyChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string newValue = msg . payload . newValue ; // ...Handle property changed... } void MyPropertyManagerHandler::handlePropertyStateChangedMessage ( const std :: string & message ) { PropertyStateChangedMessage msg = json :: parse ( message ); std :: string name = msg . payload . name ; std :: string value = msg . payload . value ; std :: string state = msg . payload . state // ...Handle property state changed... } void MyPropertyManagerHandler::handleGetPropertyReplyMessage ( const std :: string & message ) { GetPropertyMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string value = msg . payload . value ; // ...Handle the value for the message... } // Call to set a property void MyPropertyManagerHandler::setProperty ( const std :: string & name , const std :: string & value ) { ] SetPropertyMessage msg ; msg . payload . name = name ; msg . payload . value = value ; m_messageBroker -> publish ( msg . toString ()); } // Call to get a property std :: string MyPropertyManagerHandler::getProperty ( const std :: string & name ) { GetPropertyMessage msg ; msg . payload . name = name ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetProperty reply message // Return the value from reply message payload } }","title":"Use the Property Manager AASB messages"},{"location":"modules/core/RUNTIME_PROPERTIES/#property-definitions","text":"The definitions of the properties used with the SetProperty and GetProperty messages are defined by the Auto SDK modules that manage the properties.","title":"Property Definitions"},{"location":"modules/core/RUNTIME_PROPERTIES/#alexa","text":"The Alexa module provides the following properties: \"aace.alexa.wakewordSupported\" This read-only property is used with GetProperty to check if wake word support is enabled in the Engine. If wake word is not supported in the Engine, attempts to enable wake word with the SpeechRecognizer will fail. \"aace.alexa.system.firmwareVersion\" This property is used with SetProperty to change the firmware version that is reported to AVS. The value must be a positive, 32-bit signed integer represented as a string. \"aace.alexa.setting.locale\" This property is used with SetProperty to change the current locale setting for Alexa. The value must be one of the following: A valid locale accepted by AVS as a string. E.g. \"en-US\" A valid locale pair. The format is a string containing two valid locales separated with a forward slash. E.g. \"en-US/es-US\" Note: For a list of the Alexa Voice Service (AVS) supported locales, see the [Alexa Voice Service (AVS) documentation](https://developer.amazon.com/docs/alexa-voice-service/system.html#locales \"aace.alexa.countrySupported\" This read-only property is used with GetProperty to check if the vehicle's country is supported. \"aace.alexa.wakewordEnabled\" This property is used with SetProperty to change the current wake word enabled setting. The value must be a boolean represented as a string, i.e. \"true\" or \"false\". Use GetProperty with this property to check whether wake word is enabled. \"aace.alexa.timezone\" This property is used with SetProperty to change the current timezone setting of the device. The value must be a valid timezone accepted by AVS. Use GetProperty to get the Engine's current timezone setting.","title":"Alexa"},{"location":"modules/core/RUNTIME_PROPERTIES/#core","text":"The Core module provides the following properties: \"aace.core.version\" This property is used with GetProperty to return the Auto SDK version. \"aace.vehicle.operatingCountry\" This property is used with SetProperty to change the current operating country. The value must be a valid 2-letter ISO country code. \"aace.network.networkInterface\" This property is used with SetProperty to set the network interface for the network connection. The value must be an IP address or network interface name. \"aace.network.httpProxyHeaders\" This property is used with SetProperty to set the custom HTTP header to pass in the HTTP request sent to a proxy. The headers should be \\n separated. For example, \"Proxy-Authorization: Bearer 1234\" (should not be CRLF-terminated) Note: To apply the custom headers you are required to specify the CURLOPT_PROXY` in the Engine configuration. The specified headers will be applied to all subsequent requests sent to a proxy.","title":"Core"},{"location":"modules/core/aasb-docs/AudioInput/","text":"AudioInput Outgoing Messages StopAudioInput Notifies the platform implementation to stop writing audio samples to the Engine. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StopAudioInput\" } }, \"payload\": { \"streamId\": {{String}} } } Payload Property Type Required Description Example streamId String Yes Stream ID that is used to write audio data to. 4f52d5a6-2b36-4723-93d5-4e569be99961 StartAudioInput Notifies the platform implementation to start writing audio samples to the Engine. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StartAudioInput\" } }, \"payload\": { \"name\": {{String}}, \"audioType\": {{AudioInputAudioType}}, \"streamId\": {{String}} } } Payload Property Type Required Description Example name String Yes Name of the Engine component that is requesting audio. audioType AudioInputAudioType Yes The type of audio data being requested. streamId String Yes Stream ID that is used to write audio data to. Enums AudioInputAudioType Values Value Description \"VOICE\" Voice audio type. \"COMMUNICATION\" Communication audio type. \"LOOPBACK\" Loopback audio type.","title":"AudioInput"},{"location":"modules/core/aasb-docs/AudioInput/#audioinput","text":"","title":"AudioInput"},{"location":"modules/core/aasb-docs/AudioInput/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/core/aasb-docs/AudioInput/#stopaudioinput","text":"Notifies the platform implementation to stop writing audio samples to the Engine.","title":"StopAudioInput"},{"location":"modules/core/aasb-docs/AudioInput/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StopAudioInput\" } }, \"payload\": { \"streamId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioInput/#payload","text":"Property Type Required Description Example streamId String Yes Stream ID that is used to write audio data to. 4f52d5a6-2b36-4723-93d5-4e569be99961","title":"Payload"},{"location":"modules/core/aasb-docs/AudioInput/#startaudioinput","text":"Notifies the platform implementation to start writing audio samples to the Engine.","title":"StartAudioInput"},{"location":"modules/core/aasb-docs/AudioInput/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioInput\", \"action\": \"StartAudioInput\" } }, \"payload\": { \"name\": {{String}}, \"audioType\": {{AudioInputAudioType}}, \"streamId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioInput/#payload_1","text":"Property Type Required Description Example name String Yes Name of the Engine component that is requesting audio. audioType AudioInputAudioType Yes The type of audio data being requested. streamId String Yes Stream ID that is used to write audio data to.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioInput/#enums","text":"","title":"Enums"},{"location":"modules/core/aasb-docs/AudioInput/#audioinputaudiotype","text":"","title":"AudioInputAudioType"},{"location":"modules/core/aasb-docs/AudioInput/#values","text":"Value Description \"VOICE\" Voice audio type. \"COMMUNICATION\" Communication audio type. \"LOOPBACK\" Loopback audio type.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/","text":"AudioOutput Outgoing Messages GetNumBytesBuffered Returns the amount of audio data buffered. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. GetNumBytesBufferedReply Reply for GetNumBytesBuffered message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\", \"replyToId\": {{String}} } }, \"payload\": { \"bufferedBytes\": {{Int}} } } Payload Property Type Required Description Example bufferedBytes Int Yes The number of bytes of the audio data buffered, or 0 if it's unknown. Resume Notifies the platform implementation to resume an audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Resume\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Play Notifies the platform implementation to play an audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Play\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being played. SetPosition Notifies the platform implementation to set the playback position of the current audio source in the platform media player. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"SetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"position\": {{Int}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. position Int Yes The playback position in milliseconds to set in the platform media player. Prepare Notifies the platform implementation to prepare an audio URL for playback. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": {{String}}, \"url\": {{String}}, \"repeating\": {{Bool}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio source. source String Yes Stream source description. url String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. GetPosition Returns the current playback position of the platform media player. If the audio source is not playing, the most recent position played should be returned. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. GetPositionReply Reply for GetPosition message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"position\": {{Int}} } } Payload Property Type Required Description Example position Int Yes The platform media player's playback position in milliseconds. Pause Notifies the platform implementation to pause an audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Pause\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being paused. GetDuration Request the duration of the current audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. GetDurationReply Reply for GetDuration message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"duration\": {{Int}} } } Payload Property Type Required Description Example duration Int Yes The duration of the current audio source. If the duration is unknown, then -1 should be returned. Stop Notifies the platform implementation to stop an audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Stop\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Prepare Notifies the platform implementation to prepare an audio stream for playback. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": {{String}}, \"streamId\": {{String}}, \"repeating\": {{Bool}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio stream. source String Yes Stream source description. streamId String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. MutedStateChanged Notifies the platform implementation that the muted state has changed for an audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"state\": {{MutedState}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. state MutedState Yes The muted state to apply to the audio source. VolumeChanged Notifies the platform implementation that the volume has changed for an audio source. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"channel\": {{String}}, \"volume\": {{Float}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. volume Float Yes The playback position in milliseconds to set in the platform media player. MayDuck Notifies the platform implementation only if prepared media may duck the volume. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MayDuck\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. StartDucking Notifies the platform implementation to move the playback in background. If platform implementation supports audio ducking, reduce the media player volume according to platform guidelines. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StartDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. StopDucking Notifies the platform implementation to move the playback in foreground. If platform implementation supports audio ducking, restore the media player volume to original value. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StopDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. Incoming Messages MediaError Notifies the Engine of an error during audio playback. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaError\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"error\": {{MediaError}}, \"description\": {{String}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. error MediaError Yes The error encountered by the platform media player during playback. description String No A description of the error. MediaStateChanged Notifies the Engine of an audio playback state change in the platform implementation. Must be called when the platform media player transitions between stopped and playing states. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"state\": {{MediaState}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. state MediaState Yes The new playback state of the platform media player. AudioFocusEvent Report the engine about the Audio Focus action. Request engine to perform the action mentioned in the parameter. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"AudioFocusEvent\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"focusAction\": {{FocusAction}} } } Payload Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. focusAction FocusAction Yes Report the engine what focus action client has taken due to the external audio focus event. Type Definitions AudioStreamProperty JSON Structure { \"name\": {{String}}, \"value\": {{String}} } Properties Property Type Required Description Example name String Yes Stream property name. value String Yes Stream property value. Enums MediaState Values Value Description \"STOPPED\" The audio source is not currently playing. It may have paused, stopped, or finished. \"PLAYING\" The audio source is currently playing. \"BUFFERING\" The audio source is currently buffering data. MediaError Values Value Description \"MEDIA_ERROR_UNKNOWN\" An unknown error occurred. \"MEDIA_ERROR_INVALID_REQUEST\" The server recognized the request as malformed (e.g. bad request, unauthorized, forbidden, not found, etc). \"MEDIA_ERROR_SERVICE_UNAVAILABLE\" The client was unable to reach the service. \"MEDIA_ERROR_INTERNAL_SERVER_ERROR\" The server accepted the request but was unable to process it as expected. \"MEDIA_ERROR_INTERNAL_DEVICE_ERROR\" There was an internal error on the client. AudioOutputAudioType Values Value Description \"TTS\" Text-to-Speech audio type. \"MUSIC\" Music audio type. \"NOTIFICATION\" Notification audio type. \"ALARM\" Alarm audio type. \"EARCON\" Earcon audio type. \"COMMUNICATION\" Communication audio type. \"RINGTONE\" Ringtone audio type. AudioStreamEncoding Values Value Description \"UNKNOWN\" Unknown encoding type. \"LPCM\" LPCM encoding type. \"MP3\" MP3 encoding type. \"OPUS\" Opus encoding type. MutedState Values Value Description \"MUTED\" Muted audio state. \"UNMUTED\" Unmuted audio state. AudioOutputSourceType Values Value Description \"URI\" URI source type. \"STREAM\" Stream audio type. FocusAction Values Value Description \"REPORT_DUCKING_STARTED\" This action informs Alexa engine that ducking is initiated by platform interface. Highly recommended to provide information so that engine would not override the action. \"REPORT_DUCKING_STOPPED\" This action informs Alexa engine that ducking is stopped by platform interface. Highly recommended to provide information so that engine can duck if required.","title":"AudioOutput"},{"location":"modules/core/aasb-docs/AudioOutput/#audiooutput","text":"","title":"AudioOutput"},{"location":"modules/core/aasb-docs/AudioOutput/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/core/aasb-docs/AudioOutput/#getnumbytesbuffered","text":"Returns the amount of audio data buffered.","title":"GetNumBytesBuffered"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#getnumbytesbufferedreply","text":"Reply for GetNumBytesBuffered message.","title":"GetNumBytesBufferedReply"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetNumBytesBuffered\", \"replyToId\": {{String}} } }, \"payload\": { \"bufferedBytes\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_1","text":"Property Type Required Description Example bufferedBytes Int Yes The number of bytes of the audio data buffered, or 0 if it's unknown.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#resume","text":"Notifies the platform implementation to resume an audio source.","title":"Resume"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Resume\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_2","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#play","text":"Notifies the platform implementation to play an audio source.","title":"Play"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Play\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_3","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being played.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#setposition","text":"Notifies the platform implementation to set the playback position of the current audio source in the platform media player.","title":"SetPosition"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"SetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"position\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_4","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. position Int Yes The playback position in milliseconds to set in the platform media player.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#prepare","text":"Notifies the platform implementation to prepare an audio URL for playback.","title":"Prepare"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": {{String}}, \"url\": {{String}}, \"repeating\": {{Bool}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_5","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio source. source String Yes Stream source description. url String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#getposition","text":"Returns the current playback position of the platform media player. If the audio source is not playing, the most recent position played should be returned.","title":"GetPosition"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_6","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#getpositionreply","text":"Reply for GetPosition message.","title":"GetPositionReply"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetPosition\", \"replyToId\": {{String}} } }, \"payload\": { \"position\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_7","text":"Property Type Required Description Example position Int Yes The platform media player's playback position in milliseconds.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#pause","text":"Notifies the platform implementation to pause an audio source.","title":"Pause"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Pause\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_8","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source being paused.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#getduration","text":"Request the duration of the current audio source.","title":"GetDuration"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_9","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#getdurationreply","text":"Reply for GetDuration message.","title":"GetDurationReply"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"GetDuration\", \"replyToId\": {{String}} } }, \"payload\": { \"duration\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_10","text":"Property Type Required Description Example duration Int Yes The duration of the current audio source. If the duration is unknown, then -1 should be returned.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#stop","text":"Notifies the platform implementation to stop an audio source.","title":"Stop"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Stop\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_11","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#prepare_1","text":"Notifies the platform implementation to prepare an audio stream for playback.","title":"Prepare"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"Prepare\" } }, \"payload\": { \"channel\": {{String}}, \"audioType\": {{AudioOutputAudioType}}, \"token\": {{String}}, \"source\": {{String}}, \"streamId\": {{String}}, \"repeating\": {{Bool}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_12","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. audioType AudioOutputAudioType Yes The type of audio data to be played. token String Yes A unique token for this audio stream. source String Yes Stream source description. streamId String Yes The URL audio stream being provided. repeating Bool Yes True if the platform should loop the audio when playing. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#mutedstatechanged","text":"Notifies the platform implementation that the muted state has changed for an audio source.","title":"MutedStateChanged"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MutedStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"state\": {{MutedState}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_13","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. state MutedState Yes The muted state to apply to the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#volumechanged","text":"Notifies the platform implementation that the volume has changed for an audio source.","title":"VolumeChanged"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_14","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"VolumeChanged\" } }, \"payload\": { \"channel\": {{String}}, \"volume\": {{Float}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_14","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. volume Float Yes The playback position in milliseconds to set in the platform media player.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#mayduck","text":"Notifies the platform implementation only if prepared media may duck the volume.","title":"MayDuck"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_15","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MayDuck\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_15","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#startducking","text":"Notifies the platform implementation to move the playback in background. If platform implementation supports audio ducking, reduce the media player volume according to platform guidelines.","title":"StartDucking"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_16","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StartDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_16","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#stopducking","text":"Notifies the platform implementation to move the playback in foreground. If platform implementation supports audio ducking, restore the media player volume to original value.","title":"StopDucking"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_17","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"StopDucking\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_17","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/core/aasb-docs/AudioOutput/#mediaerror","text":"Notifies the Engine of an error during audio playback.","title":"MediaError"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_18","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaError\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"error\": {{MediaError}}, \"description\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_18","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. error MediaError Yes The error encountered by the platform media player during playback. description String No A description of the error.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#mediastatechanged","text":"Notifies the Engine of an audio playback state change in the platform implementation. Must be called when the platform media player transitions between stopped and playing states.","title":"MediaStateChanged"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_19","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"MediaStateChanged\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"state\": {{MediaState}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_19","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. state MediaState Yes The new playback state of the platform media player.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#audiofocusevent","text":"Report the engine about the Audio Focus action. Request engine to perform the action mentioned in the parameter.","title":"AudioFocusEvent"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_20","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"AudioOutput\", \"action\": \"AudioFocusEvent\" } }, \"payload\": { \"channel\": {{String}}, \"token\": {{String}}, \"focusAction\": {{FocusAction}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#payload_20","text":"Property Type Required Description Example channel String Yes Name of the channel that is providing audio. token String Yes The unique token of the audio source. focusAction FocusAction Yes Report the engine what focus action client has taken due to the external audio focus event.","title":"Payload"},{"location":"modules/core/aasb-docs/AudioOutput/#type-definitions","text":"","title":"Type Definitions"},{"location":"modules/core/aasb-docs/AudioOutput/#audiostreamproperty","text":"","title":"AudioStreamProperty"},{"location":"modules/core/aasb-docs/AudioOutput/#json-structure_21","text":"{ \"name\": {{String}}, \"value\": {{String}} }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/AudioOutput/#properties","text":"Property Type Required Description Example name String Yes Stream property name. value String Yes Stream property value.","title":"Properties"},{"location":"modules/core/aasb-docs/AudioOutput/#enums","text":"","title":"Enums"},{"location":"modules/core/aasb-docs/AudioOutput/#mediastate","text":"","title":"MediaState"},{"location":"modules/core/aasb-docs/AudioOutput/#values","text":"Value Description \"STOPPED\" The audio source is not currently playing. It may have paused, stopped, or finished. \"PLAYING\" The audio source is currently playing. \"BUFFERING\" The audio source is currently buffering data.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/#mediaerror_1","text":"","title":"MediaError"},{"location":"modules/core/aasb-docs/AudioOutput/#values_1","text":"Value Description \"MEDIA_ERROR_UNKNOWN\" An unknown error occurred. \"MEDIA_ERROR_INVALID_REQUEST\" The server recognized the request as malformed (e.g. bad request, unauthorized, forbidden, not found, etc). \"MEDIA_ERROR_SERVICE_UNAVAILABLE\" The client was unable to reach the service. \"MEDIA_ERROR_INTERNAL_SERVER_ERROR\" The server accepted the request but was unable to process it as expected. \"MEDIA_ERROR_INTERNAL_DEVICE_ERROR\" There was an internal error on the client.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/#audiooutputaudiotype","text":"","title":"AudioOutputAudioType"},{"location":"modules/core/aasb-docs/AudioOutput/#values_2","text":"Value Description \"TTS\" Text-to-Speech audio type. \"MUSIC\" Music audio type. \"NOTIFICATION\" Notification audio type. \"ALARM\" Alarm audio type. \"EARCON\" Earcon audio type. \"COMMUNICATION\" Communication audio type. \"RINGTONE\" Ringtone audio type.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/#audiostreamencoding","text":"","title":"AudioStreamEncoding"},{"location":"modules/core/aasb-docs/AudioOutput/#values_3","text":"Value Description \"UNKNOWN\" Unknown encoding type. \"LPCM\" LPCM encoding type. \"MP3\" MP3 encoding type. \"OPUS\" Opus encoding type.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/#mutedstate","text":"","title":"MutedState"},{"location":"modules/core/aasb-docs/AudioOutput/#values_4","text":"Value Description \"MUTED\" Muted audio state. \"UNMUTED\" Unmuted audio state.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/#audiooutputsourcetype","text":"","title":"AudioOutputSourceType"},{"location":"modules/core/aasb-docs/AudioOutput/#values_5","text":"Value Description \"URI\" URI source type. \"STREAM\" Stream audio type.","title":"Values"},{"location":"modules/core/aasb-docs/AudioOutput/#focusaction","text":"","title":"FocusAction"},{"location":"modules/core/aasb-docs/AudioOutput/#values_6","text":"Value Description \"REPORT_DUCKING_STARTED\" This action informs Alexa engine that ducking is initiated by platform interface. Highly recommended to provide information so that engine would not override the action. \"REPORT_DUCKING_STOPPED\" This action informs Alexa engine that ducking is stopped by platform interface. Highly recommended to provide information so that engine can duck if required.","title":"Values"},{"location":"modules/core/aasb-docs/Authorization/","text":"Authorization Outgoing Messages GetAuthorizationData Get the authorization data from the platform implementation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. GetAuthorizationDataReply Reply for GetAuthorizationData message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\", \"replyToId\": {{String}} } }, \"payload\": { \"data\": {{String}} } } Payload Property Type Required Description Example data String Yes The data associated with the key if available, otherwise an empty string. AuthorizationError Notifies the platform implementation of an authorization error. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationError\" } }, \"payload\": { \"service\": {{String}}, \"error\": {{String}}, \"message\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. error String Yes The authorization error that occurred. message String Yes The message describing the authorization error. SetAuthorizationData Notifies the platform implementation to store authorization data. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}}, \"data\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. data String Yes The value of the data. EventReceived Notifies the platform implementation of a received authorization event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"EventReceived\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the received event. AuthorizationStateChanged Notifies the platform implementation that the authorization state changed. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" } }, \"payload\": { \"service\": {{String}}, \"state\": {{AuthorizationState}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. state AuthorizationState Yes The new authorization state. Incoming Messages SendEvent Notifies the Engine of an authorization event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SendEvent\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the payload of the event. CancelAuthorization Notifies the Engine to cancel the authorization process. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"CancelAuthorization\" } }, \"payload\": { \"service\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. Logout Notifies the Engine that device has been logged out. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"Logout\" } }, \"payload\": { \"service\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. StartAuthorization Notifies the Engine to start the authorization process. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"StartAuthorization\" } }, \"payload\": { \"service\": {{String}}, \"data\": {{String}} } } Payload Property Type Required Description Example service String Yes The service used for authorization. data String Yes The value of the data. Enums AuthorizationState Values Value Description \"UNAUTHORIZED\" Device is unauthorized. \"AUTHORIZING\" Device authorization is in progress. \"AUTHORIZED\" Device is authorized.","title":"Authorization"},{"location":"modules/core/aasb-docs/Authorization/#authorization","text":"","title":"Authorization"},{"location":"modules/core/aasb-docs/Authorization/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/core/aasb-docs/Authorization/#getauthorizationdata","text":"Get the authorization data from the platform implementation.","title":"GetAuthorizationData"},{"location":"modules/core/aasb-docs/Authorization/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload","text":"Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#getauthorizationdatareply","text":"Reply for GetAuthorizationData message.","title":"GetAuthorizationDataReply"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"GetAuthorizationData\", \"replyToId\": {{String}} } }, \"payload\": { \"data\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_1","text":"Property Type Required Description Example data String Yes The data associated with the key if available, otherwise an empty string.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#authorizationerror","text":"Notifies the platform implementation of an authorization error.","title":"AuthorizationError"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationError\" } }, \"payload\": { \"service\": {{String}}, \"error\": {{String}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_2","text":"Property Type Required Description Example service String Yes The service used for authorization. error String Yes The authorization error that occurred. message String Yes The message describing the authorization error.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#setauthorizationdata","text":"Notifies the platform implementation to store authorization data.","title":"SetAuthorizationData"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SetAuthorizationData\" } }, \"payload\": { \"service\": {{String}}, \"key\": {{String}}, \"data\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_3","text":"Property Type Required Description Example service String Yes The service used for authorization. key String Yes The key for the requested data. data String Yes The value of the data.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#eventreceived","text":"Notifies the platform implementation of a received authorization event.","title":"EventReceived"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"EventReceived\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_4","text":"Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the received event.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#authorizationstatechanged","text":"Notifies the platform implementation that the authorization state changed.","title":"AuthorizationStateChanged"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"AuthorizationStateChanged\" } }, \"payload\": { \"service\": {{String}}, \"state\": {{AuthorizationState}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_5","text":"Property Type Required Description Example service String Yes The service used for authorization. state AuthorizationState Yes The new authorization state.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/core/aasb-docs/Authorization/#sendevent","text":"Notifies the Engine of an authorization event.","title":"SendEvent"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"SendEvent\" } }, \"payload\": { \"service\": {{String}}, \"event\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_6","text":"Property Type Required Description Example service String Yes The service used for authorization. event String Yes The JSON string representing the payload of the event.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#cancelauthorization","text":"Notifies the Engine to cancel the authorization process.","title":"CancelAuthorization"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"CancelAuthorization\" } }, \"payload\": { \"service\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_7","text":"Property Type Required Description Example service String Yes The service used for authorization.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#logout","text":"Notifies the Engine that device has been logged out.","title":"Logout"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"Logout\" } }, \"payload\": { \"service\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_8","text":"Property Type Required Description Example service String Yes The service used for authorization.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#startauthorization","text":"Notifies the Engine to start the authorization process.","title":"StartAuthorization"},{"location":"modules/core/aasb-docs/Authorization/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Authorization\", \"action\": \"StartAuthorization\" } }, \"payload\": { \"service\": {{String}}, \"data\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/Authorization/#payload_9","text":"Property Type Required Description Example service String Yes The service used for authorization. data String Yes The value of the data.","title":"Payload"},{"location":"modules/core/aasb-docs/Authorization/#enums","text":"","title":"Enums"},{"location":"modules/core/aasb-docs/Authorization/#authorizationstate","text":"","title":"AuthorizationState"},{"location":"modules/core/aasb-docs/Authorization/#values","text":"Value Description \"UNAUTHORIZED\" Device is unauthorized. \"AUTHORIZING\" Device authorization is in progress. \"AUTHORIZED\" Device is authorized.","title":"Values"},{"location":"modules/core/aasb-docs/DeviceUsage/","text":"DeviceUsage Incoming Messages ReportNetworkDataUsage Report network usage data to the Engine. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceUsage\", \"action\": \"ReportNetworkDataUsage\" } }, \"payload\": { \"usage\": {{String}} } } Payload Property Type Required Description Example usage String Yes A JSON String representation of the network usage data of the application. See the Core module documentation for complete details of the schema.","title":"DeviceUsage"},{"location":"modules/core/aasb-docs/DeviceUsage/#deviceusage","text":"","title":"DeviceUsage"},{"location":"modules/core/aasb-docs/DeviceUsage/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/core/aasb-docs/DeviceUsage/#reportnetworkdatausage","text":"Report network usage data to the Engine.","title":"ReportNetworkDataUsage"},{"location":"modules/core/aasb-docs/DeviceUsage/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"DeviceUsage\", \"action\": \"ReportNetworkDataUsage\" } }, \"payload\": { \"usage\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/DeviceUsage/#payload","text":"Property Type Required Description Example usage String Yes A JSON String representation of the network usage data of the application. See the Core module documentation for complete details of the schema.","title":"Payload"},{"location":"modules/core/aasb-docs/LocationProvider/","text":"LocationProvider Outgoing Messages GetCountry Requests the ISO country code for the current geolocation of the device. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\" } } } GetCountryReply Reply for GetCountry message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\", \"replyToId\": {{String}} } }, \"payload\": { \"country\": {{String}} } } Payload Property Type Required Description Example country String Yes The current country. GetLocation Requests the current geolocation of the device. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\" } } } GetLocationReply Reply for GetLocation message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\", \"replyToId\": {{String}} } }, \"payload\": { \"location\": {{Location}} } } Payload Property Type Required Description Example location Location Yes The current location. Incoming Messages LocationServiceAccessChanged Notifies the Engine of a change in location service access. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"LocationServiceAccessChanged\" } }, \"payload\": { \"access\": {{LocationServiceAccess}} } } Payload Property Type Required Description Example access LocationServiceAccess Yes Describes the access to the geolocation service on the device. Type Definitions Location JSON Structure { \"latitude\": {{Float}}, \"longitude\": {{Float}}, \"altitude\": {{Float}}, \"accuracy\": {{Float}} } Properties Property Type Required Description Example latitude Float Yes Location latitude. Use -1 if the location is not available. longitude Float Yes Location longitude. Use -1 if the location is not available. altitude Float No (default: -1 ) A location altitude in meters. accuracy Float No (default: -1 ) A location accuracy in meters. Enums LocationServiceAccess Values Value Description \"DISABLED\" The location service on the device is disabled (e.g., GPS is turned off). \"ENABLED\" The location service on the device is enabled (e.g., GPS is turned on).","title":"LocationProvider"},{"location":"modules/core/aasb-docs/LocationProvider/#locationprovider","text":"","title":"LocationProvider"},{"location":"modules/core/aasb-docs/LocationProvider/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/core/aasb-docs/LocationProvider/#getcountry","text":"Requests the ISO country code for the current geolocation of the device.","title":"GetCountry"},{"location":"modules/core/aasb-docs/LocationProvider/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\" } } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/LocationProvider/#getcountryreply","text":"Reply for GetCountry message.","title":"GetCountryReply"},{"location":"modules/core/aasb-docs/LocationProvider/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetCountry\", \"replyToId\": {{String}} } }, \"payload\": { \"country\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/LocationProvider/#payload","text":"Property Type Required Description Example country String Yes The current country.","title":"Payload"},{"location":"modules/core/aasb-docs/LocationProvider/#getlocation","text":"Requests the current geolocation of the device.","title":"GetLocation"},{"location":"modules/core/aasb-docs/LocationProvider/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\" } } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/LocationProvider/#getlocationreply","text":"Reply for GetLocation message.","title":"GetLocationReply"},{"location":"modules/core/aasb-docs/LocationProvider/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"GetLocation\", \"replyToId\": {{String}} } }, \"payload\": { \"location\": {{Location}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/LocationProvider/#payload_1","text":"Property Type Required Description Example location Location Yes The current location.","title":"Payload"},{"location":"modules/core/aasb-docs/LocationProvider/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/core/aasb-docs/LocationProvider/#locationserviceaccesschanged","text":"Notifies the Engine of a change in location service access.","title":"LocationServiceAccessChanged"},{"location":"modules/core/aasb-docs/LocationProvider/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"LocationProvider\", \"action\": \"LocationServiceAccessChanged\" } }, \"payload\": { \"access\": {{LocationServiceAccess}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/LocationProvider/#payload_2","text":"Property Type Required Description Example access LocationServiceAccess Yes Describes the access to the geolocation service on the device.","title":"Payload"},{"location":"modules/core/aasb-docs/LocationProvider/#type-definitions","text":"","title":"Type Definitions"},{"location":"modules/core/aasb-docs/LocationProvider/#location","text":"","title":"Location"},{"location":"modules/core/aasb-docs/LocationProvider/#json-structure_5","text":"{ \"latitude\": {{Float}}, \"longitude\": {{Float}}, \"altitude\": {{Float}}, \"accuracy\": {{Float}} }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/LocationProvider/#properties","text":"Property Type Required Description Example latitude Float Yes Location latitude. Use -1 if the location is not available. longitude Float Yes Location longitude. Use -1 if the location is not available. altitude Float No (default: -1 ) A location altitude in meters. accuracy Float No (default: -1 ) A location accuracy in meters.","title":"Properties"},{"location":"modules/core/aasb-docs/LocationProvider/#enums","text":"","title":"Enums"},{"location":"modules/core/aasb-docs/LocationProvider/#locationserviceaccess","text":"","title":"LocationServiceAccess"},{"location":"modules/core/aasb-docs/LocationProvider/#values","text":"Value Description \"DISABLED\" The location service on the device is disabled (e.g., GPS is turned off). \"ENABLED\" The location service on the device is enabled (e.g., GPS is turned on).","title":"Values"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/","text":"NetworkInfoProvider Outgoing Messages GetWifiSignalStrength Requests the signal strength (RSSI) of the WiFi connection on the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\" } } } GetWifiSignalStrengthReply Reply for GetWifiSignalStrength message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\", \"replyToId\": {{String}} } }, \"payload\": { \"wifiSignalStrength\": {{Int}} } } Payload Property Type Required Description Example wifiSignalStrength Int Yes The RSSI of the WiFi connection. GetNetworkStatus Requests the network connection status on the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\" } } } GetNetworkStatusReply Reply for GetNetworkStatus message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\", \"replyToId\": {{String}} } }, \"payload\": { \"status\": {{NetworkStatus}} } } Payload Property Type Required Description Example status NetworkStatus Yes The network connection status Incoming Messages NetworkStatusChanged Notifies the Engine of a network status change on the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"NetworkStatusChanged\" } }, \"payload\": { \"status\": {{NetworkStatus}}, \"wifiSignalStrength\": {{Int}} } } Payload Property Type Required Description Example status NetworkStatus Yes The connection status CONNECTED wifiSignalStrength Int Yes The RSSI of the WiFi connection. Enums NetworkStatus Values Value Description \"UNKNOWN\" The network status is unknown \"DISCONNECTED\" The network is disconnected. \"DISCONNECTING\" The network is disconnecting \"CONNECTED\" The network is connected \"CONNECTING\" The network is connecting","title":"NetworkInfoProvider"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#networkinfoprovider","text":"","title":"NetworkInfoProvider"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#getwifisignalstrength","text":"Requests the signal strength (RSSI) of the WiFi connection on the platform.","title":"GetWifiSignalStrength"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\" } } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#getwifisignalstrengthreply","text":"Reply for GetWifiSignalStrength message.","title":"GetWifiSignalStrengthReply"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetWifiSignalStrength\", \"replyToId\": {{String}} } }, \"payload\": { \"wifiSignalStrength\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#payload","text":"Property Type Required Description Example wifiSignalStrength Int Yes The RSSI of the WiFi connection.","title":"Payload"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#getnetworkstatus","text":"Requests the network connection status on the platform.","title":"GetNetworkStatus"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\" } } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#getnetworkstatusreply","text":"Reply for GetNetworkStatus message.","title":"GetNetworkStatusReply"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"GetNetworkStatus\", \"replyToId\": {{String}} } }, \"payload\": { \"status\": {{NetworkStatus}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#payload_1","text":"Property Type Required Description Example status NetworkStatus Yes The network connection status","title":"Payload"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#networkstatuschanged","text":"Notifies the Engine of a network status change on the platform.","title":"NetworkStatusChanged"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"NetworkInfoProvider\", \"action\": \"NetworkStatusChanged\" } }, \"payload\": { \"status\": {{NetworkStatus}}, \"wifiSignalStrength\": {{Int}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#payload_2","text":"Property Type Required Description Example status NetworkStatus Yes The connection status CONNECTED wifiSignalStrength Int Yes The RSSI of the WiFi connection.","title":"Payload"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#enums","text":"","title":"Enums"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#networkstatus","text":"","title":"NetworkStatus"},{"location":"modules/core/aasb-docs/NetworkInfoProvider/#values","text":"Value Description \"UNKNOWN\" The network status is unknown \"DISCONNECTED\" The network is disconnected. \"DISCONNECTING\" The network is disconnecting \"CONNECTED\" The network is connected \"CONNECTING\" The network is connecting","title":"Values"},{"location":"modules/core/aasb-docs/PropertyManager/","text":"PropertyManager Outgoing Messages PropertyChanged Notifies the platform implementation about a change in a property value in the Engine that is not initiated by the platform implementation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyChanged\" } }, \"payload\": { \"name\": {{String}}, \"newValue\": {{String}} } } Payload Property Type Required Description Example name String Yes Name of the property. newValue String Yes The new value of the property. PropertyStateChanged Notifies the platform implementation of the status of a property change after a call to setProperty(). JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyStateChanged\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}}, \"state\": {{PropertyState}} } } Payload Property Type Required Description Example name String Yes Name of the property. value String Yes The value of the property. state PropertyState Yes The property state. Incoming Messages GetProperty Retrieves the property setting from the Engine. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\" } }, \"payload\": { \"name\": {{String}} } } Payload Property Type Required Description Example name String Yes The property name. GetPropertyReply Reply for GetProperty message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\", \"replyToId\": {{String}} } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } } Payload Property Type Required Description Example name String Yes The property name. value String Yes The property value. SetProperty Sets the property setting in the Engine. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"SetProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } } Payload Property Type Required Description Example name String Yes The property name. value String Yes The property value. Enums PropertyState Values Value Description \"SUCCEEDED\" The property change was successful. \"FAILED\" The property change failed.","title":"PropertyManager"},{"location":"modules/core/aasb-docs/PropertyManager/#propertymanager","text":"","title":"PropertyManager"},{"location":"modules/core/aasb-docs/PropertyManager/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/core/aasb-docs/PropertyManager/#propertychanged","text":"Notifies the platform implementation about a change in a property value in the Engine that is not initiated by the platform implementation.","title":"PropertyChanged"},{"location":"modules/core/aasb-docs/PropertyManager/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyChanged\" } }, \"payload\": { \"name\": {{String}}, \"newValue\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/PropertyManager/#payload","text":"Property Type Required Description Example name String Yes Name of the property. newValue String Yes The new value of the property.","title":"Payload"},{"location":"modules/core/aasb-docs/PropertyManager/#propertystatechanged","text":"Notifies the platform implementation of the status of a property change after a call to setProperty().","title":"PropertyStateChanged"},{"location":"modules/core/aasb-docs/PropertyManager/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"PropertyStateChanged\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}}, \"state\": {{PropertyState}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/PropertyManager/#payload_1","text":"Property Type Required Description Example name String Yes Name of the property. value String Yes The value of the property. state PropertyState Yes The property state.","title":"Payload"},{"location":"modules/core/aasb-docs/PropertyManager/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/core/aasb-docs/PropertyManager/#getproperty","text":"Retrieves the property setting from the Engine.","title":"GetProperty"},{"location":"modules/core/aasb-docs/PropertyManager/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\" } }, \"payload\": { \"name\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/PropertyManager/#payload_2","text":"Property Type Required Description Example name String Yes The property name.","title":"Payload"},{"location":"modules/core/aasb-docs/PropertyManager/#getpropertyreply","text":"Reply for GetProperty message.","title":"GetPropertyReply"},{"location":"modules/core/aasb-docs/PropertyManager/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"GetProperty\", \"replyToId\": {{String}} } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/PropertyManager/#payload_3","text":"Property Type Required Description Example name String Yes The property name. value String Yes The property value.","title":"Payload"},{"location":"modules/core/aasb-docs/PropertyManager/#setproperty","text":"Sets the property setting in the Engine.","title":"SetProperty"},{"location":"modules/core/aasb-docs/PropertyManager/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PropertyManager\", \"action\": \"SetProperty\" } }, \"payload\": { \"name\": {{String}}, \"value\": {{String}} } }","title":"JSON Structure"},{"location":"modules/core/aasb-docs/PropertyManager/#payload_4","text":"Property Type Required Description Example name String Yes The property name. value String Yes The property value.","title":"Payload"},{"location":"modules/core/aasb-docs/PropertyManager/#enums","text":"","title":"Enums"},{"location":"modules/core/aasb-docs/PropertyManager/#propertystate","text":"","title":"PropertyState"},{"location":"modules/core/aasb-docs/PropertyManager/#values","text":"Value Description \"SUCCEEDED\" The property change was successful. \"FAILED\" The property change failed.","title":"Values"},{"location":"modules/custom-domain/","text":"Custom Domain Module The Alexa Auto SDK Custom Domain module creates a bi-directional communication channel between your device and your cloud custom skills, allowing you to build customized experience with your in-vehicle Alexa Custom Assistant. By using this module, you can instruct Auto SDK to send data (in Events and Contexts) from your device to your cloud custom skills that can consume the data, and also receive the data (in Directives) dispatched by the skills to the device. Table of Contents Overview Prerequisites Auto SDK Custom Domain Sequence Diagrams Required Engine Configuration Using the Custom Domain Module AASB Messages Receiving and handling a custom directive Reporting a directive handling result When a directive is cancelled Sending a custom event Providing custom states in context Overview The Custom Domain module provides a platform interface that you can implement to enable the bi-directional communication between your device and your custom skills in the cloud. Since Auto SDK is built on top of Alexa Voice Service (AVS) Device SDK which utilizes directives and events to achieve the communication with Alexa Cloud, this module enables your device to receive custom directives from your skills and send custom events, contexts to your skills that can process them. Prerequisites To use Custom Domain module, please contact your Solution Architect to onboard your device type, vendor ID, custom skill IDs, custom interface names, etc. Auto SDK Custom Domain Sequence Diagrams This diagram illustrates the sequence of receiving custom directives and sending custom events. This diagram illustrates the sequence of providing custom states in the context when required. The event that requires context could be from the device, Auto SDK, or AVS itself and it could be custom or non-custom ones. For any AVS event, as long as it requires context, which is queried by the ContextManager , the Auto SDK Engine publishes GetContext message, and the registered custom states should be provided by replying the message. Required Engine Configuration The Custom Domain module requires proper Engine Configuration for your custom interfaces. Below is the expected configuration format. Sample JSON Object \"aace.customDomain\" : { \"interfaces\": [ { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\" \"states\": [\"{{String}}\", \"{{String}}\", ...] }, { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\", \"states\": [\"{{String}}\", \"{{String}}\", ...] }, ... ] } Object Parameters Field Type Required Description aace.customDomain. interfaces list Yes The list of custom interfaces for the communication between your device and skills. aace.customDomain. interfaces[i].namespace string Yes The namespace of the custom interface. The string must follow the convention Custom.<vendorId>.<customInterfaceName> , where the vendorId must match your actual vendorId that should be onboarded and allow-listed, and the customInterfaceName is a string of your own choice based on the responsibility of the interface. The namespace must match with the one you specified in your Skill Manifest. aace.customDomain. interfaces[i].version string Yes The version of the custom interface in string. The version should follow the versioning convention <major>.<minor> . e.g. \"1.0\". aace.customDomain. interfaces[i].states list No Optional. The list of the custom state names for a custom interface. It must be provided if custom states are available for this interface. The custom state names must match with the ones you specified in your Skill Manifest. Note: On AACS and AACS Sample App, this module is disabled by default. Please refer to AACS Configuration README to enable the module through AACS configuration file. If your product does not use AACS but uses AASB messages and if you do not intend to enable the communication between the vehicle and your cloud Alexa skills, you can disable this module by providing the block below in the Engine Configuration. \"aasb.customDomain\": { \"CustomDomain\": { \"enabled\": false } } Using the Custom Domain Module AASB Messages Receiving and handling a custom directive Custom directives carry the information from your custom skills to the device. When a new directive arrives, the Engine publishes HandleDirective message with directive metadata including namespace, name, payload, etc. Only directives with custom namespaces configured in the Engine Configuration will be received. Reporting a directive handling result After handling a directive, your application is responsible for reporting the directive handling result by publishing ReportDirectiveHandlingResult message with the necessary directive metadata. When a directive is cancelled It is possible that the arrived directive is cancelled by AVS due to associated directives (e.g. a Speak directive) is not handled properly or an error occurs. In this case, the Engine publishes CancelDirective message to inform your application that a directive is cancelled. Depending on the use case, your application might need to process the cancellation accordingly and inform the user that a previous directive is cancelled. Sending a custom event Custom events carry the information from your application to your skills. Your application can inform the Engine to send a custom event to the Alexa cloud by publishing SendEvent message with required event metadata. Only custom events with configured custom namespaces in the Engine Configuration will be sent to the Alexa cloud, and only events with custom namespaces registered and onboarded with the cloud services can be received by your skill. If the custom event should be sent with context, set requiresContext to true in the AASB message payload. Optionally, you can also include the custom context (if available) for the custom event's namespace in the SendEvent message, and it's recommended to do so to avoid the unnecessary GetContext messages from the Engine. If the custom event is in response to a custom directive, make sure the correlationToken for the event matches with the one the directive has. Your application can also send proactive events, which can trigger a skill session without user interaction. correlationToken is not required for proactive events. Providing custom states in Context Context communicates the state of the device client components to AVS. A context object reflects the state of client components immediately before its associated event is sent. Please refer to AVS documentation for more information on Context. The Engine publishes GetContext message to query the custom context with a specific configured custom namespace. Your device is expected to reply back the custom context quickly, and should provide the custom context in a String representation of a JSON object in GetContextReply message . Below is the expected JSON structure for the custom context, which needs to be serialized to a single String to be included in the GetContext message reply. The context states should match the ones specified in the Custom Domain Engine Configuration. { \"context\": [ { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, ... ] } Object Parameters | Field | Type | Required | Description | |-|-|-|-| |context | list | Yes | List of custom states to be reported.| |context[i].name | string | Yes | The name of the custom context property state.| |context[i].value | string/object/number | Yes| The value of the context property state. | |context[i].timeOfSample | string | No | The time at which the property value was recorded in ISO-8601 representation. If omitted, the default value is the current time recorded when AVS constructs the context. | |context[i].uncertaintyInMilliseconds | integer | No | The number of milliseconds that have elapsed since the property value was last confirmed. If omitted, the default value is 0. |","title":"Custom Domain Module"},{"location":"modules/custom-domain/#custom-domain-module","text":"The Alexa Auto SDK Custom Domain module creates a bi-directional communication channel between your device and your cloud custom skills, allowing you to build customized experience with your in-vehicle Alexa Custom Assistant. By using this module, you can instruct Auto SDK to send data (in Events and Contexts) from your device to your cloud custom skills that can consume the data, and also receive the data (in Directives) dispatched by the skills to the device.","title":"Custom Domain Module"},{"location":"modules/custom-domain/#table-of-contents","text":"Overview Prerequisites Auto SDK Custom Domain Sequence Diagrams Required Engine Configuration Using the Custom Domain Module AASB Messages Receiving and handling a custom directive Reporting a directive handling result When a directive is cancelled Sending a custom event Providing custom states in context","title":"Table of Contents"},{"location":"modules/custom-domain/#overview","text":"The Custom Domain module provides a platform interface that you can implement to enable the bi-directional communication between your device and your custom skills in the cloud. Since Auto SDK is built on top of Alexa Voice Service (AVS) Device SDK which utilizes directives and events to achieve the communication with Alexa Cloud, this module enables your device to receive custom directives from your skills and send custom events, contexts to your skills that can process them.","title":"Overview"},{"location":"modules/custom-domain/#prerequisites","text":"To use Custom Domain module, please contact your Solution Architect to onboard your device type, vendor ID, custom skill IDs, custom interface names, etc.","title":"Prerequisites"},{"location":"modules/custom-domain/#auto-sdk-custom-domain-sequence-diagrams","text":"This diagram illustrates the sequence of receiving custom directives and sending custom events. This diagram illustrates the sequence of providing custom states in the context when required. The event that requires context could be from the device, Auto SDK, or AVS itself and it could be custom or non-custom ones. For any AVS event, as long as it requires context, which is queried by the ContextManager , the Auto SDK Engine publishes GetContext message, and the registered custom states should be provided by replying the message.","title":"Auto SDK Custom Domain Sequence Diagrams"},{"location":"modules/custom-domain/#required-engine-configuration","text":"The Custom Domain module requires proper Engine Configuration for your custom interfaces. Below is the expected configuration format. Sample JSON Object \"aace.customDomain\" : { \"interfaces\": [ { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\" \"states\": [\"{{String}}\", \"{{String}}\", ...] }, { \"namespace\": \"{{String}}\", \"version\": \"{{String}}\", \"states\": [\"{{String}}\", \"{{String}}\", ...] }, ... ] } Object Parameters Field Type Required Description aace.customDomain. interfaces list Yes The list of custom interfaces for the communication between your device and skills. aace.customDomain. interfaces[i].namespace string Yes The namespace of the custom interface. The string must follow the convention Custom.<vendorId>.<customInterfaceName> , where the vendorId must match your actual vendorId that should be onboarded and allow-listed, and the customInterfaceName is a string of your own choice based on the responsibility of the interface. The namespace must match with the one you specified in your Skill Manifest. aace.customDomain. interfaces[i].version string Yes The version of the custom interface in string. The version should follow the versioning convention <major>.<minor> . e.g. \"1.0\". aace.customDomain. interfaces[i].states list No Optional. The list of the custom state names for a custom interface. It must be provided if custom states are available for this interface. The custom state names must match with the ones you specified in your Skill Manifest. Note: On AACS and AACS Sample App, this module is disabled by default. Please refer to AACS Configuration README to enable the module through AACS configuration file. If your product does not use AACS but uses AASB messages and if you do not intend to enable the communication between the vehicle and your cloud Alexa skills, you can disable this module by providing the block below in the Engine Configuration. \"aasb.customDomain\": { \"CustomDomain\": { \"enabled\": false } }","title":"Required Engine Configuration"},{"location":"modules/custom-domain/#using-the-custom-domain-module-aasb-messages","text":"","title":"Using the Custom Domain Module AASB Messages"},{"location":"modules/custom-domain/#receiving-and-handling-a-custom-directive","text":"Custom directives carry the information from your custom skills to the device. When a new directive arrives, the Engine publishes HandleDirective message with directive metadata including namespace, name, payload, etc. Only directives with custom namespaces configured in the Engine Configuration will be received.","title":"Receiving and handling a custom directive"},{"location":"modules/custom-domain/#reporting-a-directive-handling-result","text":"After handling a directive, your application is responsible for reporting the directive handling result by publishing ReportDirectiveHandlingResult message with the necessary directive metadata.","title":"Reporting a directive handling result"},{"location":"modules/custom-domain/#when-a-directive-is-cancelled","text":"It is possible that the arrived directive is cancelled by AVS due to associated directives (e.g. a Speak directive) is not handled properly or an error occurs. In this case, the Engine publishes CancelDirective message to inform your application that a directive is cancelled. Depending on the use case, your application might need to process the cancellation accordingly and inform the user that a previous directive is cancelled.","title":"When a directive is cancelled"},{"location":"modules/custom-domain/#sending-a-custom-event","text":"Custom events carry the information from your application to your skills. Your application can inform the Engine to send a custom event to the Alexa cloud by publishing SendEvent message with required event metadata. Only custom events with configured custom namespaces in the Engine Configuration will be sent to the Alexa cloud, and only events with custom namespaces registered and onboarded with the cloud services can be received by your skill. If the custom event should be sent with context, set requiresContext to true in the AASB message payload. Optionally, you can also include the custom context (if available) for the custom event's namespace in the SendEvent message, and it's recommended to do so to avoid the unnecessary GetContext messages from the Engine. If the custom event is in response to a custom directive, make sure the correlationToken for the event matches with the one the directive has. Your application can also send proactive events, which can trigger a skill session without user interaction. correlationToken is not required for proactive events.","title":"Sending a custom event"},{"location":"modules/custom-domain/#providing-custom-states-in-context","text":"Context communicates the state of the device client components to AVS. A context object reflects the state of client components immediately before its associated event is sent. Please refer to AVS documentation for more information on Context. The Engine publishes GetContext message to query the custom context with a specific configured custom namespace. Your device is expected to reply back the custom context quickly, and should provide the custom context in a String representation of a JSON object in GetContextReply message . Below is the expected JSON structure for the custom context, which needs to be serialized to a single String to be included in the GetContext message reply. The context states should match the ones specified in the Custom Domain Engine Configuration. { \"context\": [ { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, { \"name\": \"{{String}}\", \"value\": {{Object}} | \"{{String}}\" | {{Long}}, \"timeOfSample\": \"{{String}}\", \"uncertaintyInMilliseconds\": {{Long}} }, ... ] } Object Parameters | Field | Type | Required | Description | |-|-|-|-| |context | list | Yes | List of custom states to be reported.| |context[i].name | string | Yes | The name of the custom context property state.| |context[i].value | string/object/number | Yes| The value of the context property state. | |context[i].timeOfSample | string | No | The time at which the property value was recorded in ISO-8601 representation. If omitted, the default value is the current time recorded when AVS constructs the context. | |context[i].uncertaintyInMilliseconds | integer | No | The number of milliseconds that have elapsed since the property value was last confirmed. If omitted, the default value is 0. |","title":"Providing custom states in Context"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/","text":"CustomDomain Outgoing Messages HandleDirective Notifies the platform on a new custom directive. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"HandleDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"directivePayload\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } } Payload Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive to be handled. directiveName String Yes The name of the custom directive. directivePayload String Yes An opaque JSON payload sent to the device. correlationToken String Yes An opaque token that must be included in any events responding to this directive. messageId String Yes A unique ID used to identify a specific directive. Used to report directive handling result. CancelDirective Notifies the platform to cancel the specific directive with given messageId. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"CancelDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } } Payload Property Type Required Description Example directiveNamespace String Yes The namespace of the cancelled directive. directiveName String Yes The name of the cancelled directive. correlationToken String Yes The correlationToken of the cancelled directive. messageId String Yes A unique ID used to identify a specific directive. GetContext Called to query the current custom states under given namespace from the device. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\" } }, \"payload\": { \"contextNamespace\": {{String}} } } Payload Property Type Required Description Example contextNamespace String Yes The namespace of the queried context. GetContextReply Reply for GetContext message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\", \"replyToId\": {{String}} } }, \"payload\": { \"customContext\": {{String}} } } Payload Property Type Required Description Example customContext String Yes The context for the queried namespace in a String representation of a valid JSON object (escaped). You can find the defined structure of context JSON in Custom Domain Platform Interface. Incoming Messages ReportDirectiveHandlingResult Notifies the engine about the result of a directive handling. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"ReportDirectiveHandlingResult\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"messageId\": {{String}}, \"result\": {{ResultType}} } } Payload Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive. messageId String Yes The messageId that uniquely identifies which directive this report is for. result ResultType Yes The result of the handling. SendEvent Notifes the engine to send a custom event. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"SendEvent\" } }, \"payload\": { \"eventNamespace\": {{String}}, \"eventName\": {{String}}, \"eventPayload\": {{String}}, \"requiresContext\": {{Bool}}, \"correlationToken\": {{String}}, \"customContext\": {{String}} } } Payload Property Type Required Description Example eventNamespace String Yes The namespace of the custom event to be sent. eventName String Yes The name of the event. eventPayload String Yes An opaque JSON payload in the format of escaped JSON string sent to the cloud with the event. requiresContext Bool Yes A boolean indicating if this event must be sent with context. correlationToken String No The token correlating this event to a directive. Required only if this event is sent as a response to a directive. customContext String No The context corresponding to eventNamespace in a String representation of a valid JSON object (escaped). It's optional but recommended to provide the context with the event to reduce the amount of AASB message transactions. You can find the defined structure of context JSON in Custom Domain Platform Interface. Enums ResultType Values Value Description \"UNEXPECTED_INFORMATION_RECEIVED\" The directive sent to your client was malformed or the payload does not conform to the directive specification. \"UNSUPPORTED_OPERATION\" The operation specified by the namespace/name in the directive's header are not supported by the client. \"INTERNAL_ERROR\" An error occurred while the device was handling the directive and the error does not fall into the specified categories. \"SUCCESS\" The directive handling is successful.","title":"CustomDomain"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#customdomain","text":"","title":"CustomDomain"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#handledirective","text":"Notifies the platform on a new custom directive.","title":"HandleDirective"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"HandleDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"directivePayload\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#payload","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive to be handled. directiveName String Yes The name of the custom directive. directivePayload String Yes An opaque JSON payload sent to the device. correlationToken String Yes An opaque token that must be included in any events responding to this directive. messageId String Yes A unique ID used to identify a specific directive. Used to report directive handling result.","title":"Payload"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#canceldirective","text":"Notifies the platform to cancel the specific directive with given messageId.","title":"CancelDirective"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"CancelDirective\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"directiveName\": {{String}}, \"correlationToken\": {{String}}, \"messageId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#payload_1","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the cancelled directive. directiveName String Yes The name of the cancelled directive. correlationToken String Yes The correlationToken of the cancelled directive. messageId String Yes A unique ID used to identify a specific directive.","title":"Payload"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#getcontext","text":"Called to query the current custom states under given namespace from the device.","title":"GetContext"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\" } }, \"payload\": { \"contextNamespace\": {{String}} } }","title":"JSON Structure"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#payload_2","text":"Property Type Required Description Example contextNamespace String Yes The namespace of the queried context.","title":"Payload"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#getcontextreply","text":"Reply for GetContext message.","title":"GetContextReply"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"GetContext\", \"replyToId\": {{String}} } }, \"payload\": { \"customContext\": {{String}} } }","title":"JSON Structure"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#payload_3","text":"Property Type Required Description Example customContext String Yes The context for the queried namespace in a String representation of a valid JSON object (escaped). You can find the defined structure of context JSON in Custom Domain Platform Interface.","title":"Payload"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#reportdirectivehandlingresult","text":"Notifies the engine about the result of a directive handling.","title":"ReportDirectiveHandlingResult"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"ReportDirectiveHandlingResult\" } }, \"payload\": { \"directiveNamespace\": {{String}}, \"messageId\": {{String}}, \"result\": {{ResultType}} } }","title":"JSON Structure"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#payload_4","text":"Property Type Required Description Example directiveNamespace String Yes The namespace of the custom directive. messageId String Yes The messageId that uniquely identifies which directive this report is for. result ResultType Yes The result of the handling.","title":"Payload"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#sendevent","text":"Notifes the engine to send a custom event.","title":"SendEvent"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"CustomDomain\", \"action\": \"SendEvent\" } }, \"payload\": { \"eventNamespace\": {{String}}, \"eventName\": {{String}}, \"eventPayload\": {{String}}, \"requiresContext\": {{Bool}}, \"correlationToken\": {{String}}, \"customContext\": {{String}} } }","title":"JSON Structure"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#payload_5","text":"Property Type Required Description Example eventNamespace String Yes The namespace of the custom event to be sent. eventName String Yes The name of the event. eventPayload String Yes An opaque JSON payload in the format of escaped JSON string sent to the cloud with the event. requiresContext Bool Yes A boolean indicating if this event must be sent with context. correlationToken String No The token correlating this event to a directive. Required only if this event is sent as a response to a directive. customContext String No The context corresponding to eventNamespace in a String representation of a valid JSON object (escaped). It's optional but recommended to provide the context with the event to reduce the amount of AASB message transactions. You can find the defined structure of context JSON in Custom Domain Platform Interface.","title":"Payload"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#enums","text":"","title":"Enums"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#resulttype","text":"","title":"ResultType"},{"location":"modules/custom-domain/aasb-docs/CustomDomain/#values","text":"Value Description \"UNEXPECTED_INFORMATION_RECEIVED\" The directive sent to your client was malformed or the payload does not conform to the directive specification. \"UNSUPPORTED_OPERATION\" The operation specified by the namespace/name in the directive's header are not supported by the client. \"INTERNAL_ERROR\" An error occurred while the device was handling the directive and the error does not fall into the specified categories. \"SUCCESS\" The directive handling is successful.","title":"Values"},{"location":"modules/loopback-detector/","text":"Loopback Detector Module Table of Contents Overview Configuring the Loopback Detector Module Setting up the Loopback Detector Module Overview The Loopback Detector module enables your Alexa Auto SDK client application to monitor wake word detection to cancel out self references. In some environments where acoustic echo cancellation capabilities are limited, the microphone may pick up the wake word from speakers, which will cause false wake word detection. For example, if the user says \"Alexa, what's your name?\", Alexa responds with \"My name is Alexa\", which may cause false wake word detection and interrupt the current speech output. The Loopback Detector module solves this issue by capturing speaker reference \"loopback\" audio and trying to detect the wake word at the same time. Configuring the Loopback Detector Module The Loopback Detector module can be optionally configured with the following configuration structure: { \"aace.loopbackDetector\" : { \"wakewordEngine\" : \"<WAKEWORD ENGINE NAME>\" } } Setting up the Loopback Detector Module Providing Audio The Loopback Detector module requests audio through the StartAudioInput AASB message. The StartAudioInput message payload contains a field audioType set to LOOPBACK . The StopAudioInput AASB message is sent to request that audio input be stopped. The example below shows how to handle the StartAudioInput and StopAudioInput messages. #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; // Loopback stream id std :: string m_streamId ; // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); m_streamId = _msg . payload . streamId ; auto audioType = _msg . payload . audioType ; if ( audioType == \"LOOPBACK\" ) { // open the stream for writing auto stream = messageBroker -> openStream ( m_streamId , MessageStream :: Mode :: WRITE ); if ( stream != nullptr ) startAudioInput ( m_streamId , stream ) } }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; if ( streamId == m_streamId ) { stopAudioInput ( streamId ); m_streamId = \"\" ; } }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } This audio source should be the final mix of audio output (i.e. speaker reference/monitor). +> Note: If you are using the System Audio module, see the System Audio module README for details about how to specify LOOPBACK audio input provider. Building with the Loopback Detector Module To build the Alexa Auto SDK with the Loopback Detector module, simply include the module when running the Auto SDK builder: $ builder/build.py -m loopback-detector Example Setup in Ubuntu Linux Here is an example of how to provide loopback audio into the Alexa Auto SDK. You will need the following software running on a Linux system: PulseAudio GStreamer Advanced Linux Sound Architecture (ALSA) snd_aloop module If you are using the System Audio module , the Auto SDK (and all other applications on Linux) will use PulseAudio to output audio by default. PulseAudio mixes all audio then plays it through a hardware device. We need to capture this \"final mix result\" into the GStreamer pipeline and pass it through directly into the ALSA loopback device so the Auto SDK can capture this audio. To do this, follow these steps: Make sure the snd_aloop module is loaded into kernel by running sudo modprobe snd_aloop . Use this command to launch the GStreamer pipeline: gst-launch-1.0 -v autoaudiosrc ! audio/x-raw,format=S16LE,channels=1,rate=16000,layout=interleaved ! audioconvert ! audioresample ! alsasink device=hw:Loopback,0,0 Note: You need to keep this process throughout the testing. 1. Open the PulseAudio control panel ( pavucontrol ), and go to the Recording panel. 1. You will see that the gst-launch-1.0 process is capturing the audio. Change the audio source to Monitor of Built-in Audio Analog Stereo . 1. Set the SampleApp Record Stream to microphone device . At this point, all speaker outputs (through PulseAudio) will be eventually routed to the ALSA loopback device. If you are using the System Audio module, ensure the LOOPBACK type and loopback device are configured correctly. \"aace.systemAudio\": { \"AudioInputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" }, \"loopback\": { \"module\": \"GStreamer\", \"card\": \"hw:Loopback,1,0\", \"shared\": true } }, \"types\": { \"LOOPBACK\": \"loopback\" } }, \"AudioOutputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" } } } } After this, the Auto SDK can capture audio loopback from the hw:Loopback,1,0 device. The following diagram illustrates how the audio output data is routed to the Loopback Detector on Linux:","title":"Loopback Detector Module"},{"location":"modules/loopback-detector/#loopback-detector-module","text":"Table of Contents Overview Configuring the Loopback Detector Module Setting up the Loopback Detector Module","title":"Loopback Detector Module"},{"location":"modules/loopback-detector/#overview","text":"The Loopback Detector module enables your Alexa Auto SDK client application to monitor wake word detection to cancel out self references. In some environments where acoustic echo cancellation capabilities are limited, the microphone may pick up the wake word from speakers, which will cause false wake word detection. For example, if the user says \"Alexa, what's your name?\", Alexa responds with \"My name is Alexa\", which may cause false wake word detection and interrupt the current speech output. The Loopback Detector module solves this issue by capturing speaker reference \"loopback\" audio and trying to detect the wake word at the same time.","title":"Overview"},{"location":"modules/loopback-detector/#configuring-the-loopback-detector-module","text":"The Loopback Detector module can be optionally configured with the following configuration structure: { \"aace.loopbackDetector\" : { \"wakewordEngine\" : \"<WAKEWORD ENGINE NAME>\" } }","title":"Configuring the Loopback Detector Module"},{"location":"modules/loopback-detector/#setting-up-the-loopback-detector-module","text":"","title":"Setting up the Loopback Detector Module"},{"location":"modules/loopback-detector/#providing-audio","text":"The Loopback Detector module requests audio through the StartAudioInput AASB message. The StartAudioInput message payload contains a field audioType set to LOOPBACK . The StopAudioInput AASB message is sent to request that audio input be stopped. The example below shows how to handle the StartAudioInput and StopAudioInput messages. #include <AASB/Message/Audio/AudioInput/StartAudioInputMessage.h> #include <AASB/Message/Audio/AudioInput/StopAudioInputMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; // Loopback stream id std :: string m_streamId ; // subscribe to the StartAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StartAudioInputMessage _msg = json :: parse ( msg ); m_streamId = _msg . payload . streamId ; auto audioType = _msg . payload . audioType ; if ( audioType == \"LOOPBACK\" ) { // open the stream for writing auto stream = messageBroker -> openStream ( m_streamId , MessageStream :: Mode :: WRITE ); if ( stream != nullptr ) startAudioInput ( m_streamId , stream ) } }), StartAudioInputMessage :: topic (), StartAudioInputMessage :: action ()); // subscribe to the StopAudioInput message messageBroker -> subscribe ([ = ]( const std :: string & msg ) { // parse the json message StopAudioInputMessage _msg = json :: parse ( msg ); auto streamId = _msg . payload . streamId ; if ( streamId == m_streamId ) { stopAudioInput ( streamId ); m_streamId = \"\" ; } }), StopAudioInputMessage :: topic (), StopAudioInputMessage :: action ()); void startAudioInput ( const std :: string & streamId , std :: shared_ptr < MessageStream > stream ) { // On another thread, write data to the stream until // you receive a StopAudioInput message with the same streamId // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } void stopAudioInput ( const std :: string & streamId ) { // Stop writing audio data to the stream // ... // Return quickly to avoid blocking the MessageBroker's outgoing thread! } This audio source should be the final mix of audio output (i.e. speaker reference/monitor). +> Note: If you are using the System Audio module, see the System Audio module README for details about how to specify LOOPBACK audio input provider.","title":"Providing Audio"},{"location":"modules/loopback-detector/#building-with-the-loopback-detector-module","text":"To build the Alexa Auto SDK with the Loopback Detector module, simply include the module when running the Auto SDK builder: $ builder/build.py -m loopback-detector","title":"Building with the Loopback Detector Module"},{"location":"modules/loopback-detector/#example-setup-in-ubuntu-linux","text":"Here is an example of how to provide loopback audio into the Alexa Auto SDK. You will need the following software running on a Linux system: PulseAudio GStreamer Advanced Linux Sound Architecture (ALSA) snd_aloop module If you are using the System Audio module , the Auto SDK (and all other applications on Linux) will use PulseAudio to output audio by default. PulseAudio mixes all audio then plays it through a hardware device. We need to capture this \"final mix result\" into the GStreamer pipeline and pass it through directly into the ALSA loopback device so the Auto SDK can capture this audio. To do this, follow these steps: Make sure the snd_aloop module is loaded into kernel by running sudo modprobe snd_aloop . Use this command to launch the GStreamer pipeline: gst-launch-1.0 -v autoaudiosrc ! audio/x-raw,format=S16LE,channels=1,rate=16000,layout=interleaved ! audioconvert ! audioresample ! alsasink device=hw:Loopback,0,0 Note: You need to keep this process throughout the testing. 1. Open the PulseAudio control panel ( pavucontrol ), and go to the Recording panel. 1. You will see that the gst-launch-1.0 process is capturing the audio. Change the audio source to Monitor of Built-in Audio Analog Stereo . 1. Set the SampleApp Record Stream to microphone device . At this point, all speaker outputs (through PulseAudio) will be eventually routed to the ALSA loopback device. If you are using the System Audio module, ensure the LOOPBACK type and loopback device are configured correctly. \"aace.systemAudio\": { \"AudioInputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" }, \"loopback\": { \"module\": \"GStreamer\", \"card\": \"hw:Loopback,1,0\", \"shared\": true } }, \"types\": { \"LOOPBACK\": \"loopback\" } }, \"AudioOutputProvider\": { \"devices\": { \"default\": { \"module\": \"GStreamer\" } } } } After this, the Auto SDK can capture audio loopback from the hw:Loopback,1,0 device. The following diagram illustrates how the audio output data is routed to the Loopback Detector on Linux:","title":"Example Setup in Ubuntu Linux"},{"location":"modules/messaging/","text":"Messaging Module Table of Contents Overview Managing Messaging Sessions Configuring the Messaging Module Using the Messaging Module AASB Messages Integrating the Messaging Module Into Your Application Overview The Alexa Auto SDK Messaging module enables your Alexa Auto SDK client application to use the Short Message Service (SMS) capabilities of Alexa, independent of the messaging device's connection mechanism. The SMS features of this module include reading messages, sending messages, and replying to messages as they are read. The user must connect their device and consent to allow Alexa to read and send SMS messages through the messaging device. The Messaging feature can use phone numbers directly or use phone contacts uploaded via the Address Book module . Managing Messaging Sessions The application is responsible for managing the life cycle of the messaging session, including enhancing the end user experience by: Uploading unread SMS messages when the messaging device is connected, so they are ready for readout. Uploading new SMS messages when they are received on the messaging device. Updating the status of messages when notified to do so. Responding to messaging requests with appropriate successful or failure responses. Alexa will not notify the user when new SMS messages are available, your implementation is responsible for providing new message notifications. Configuring the Messaging Module The Messaging module does not require Engine configuration. Using the Messaging Module AASB Messages Sending Messages When Alexa sends a request to the Engine to deliver a message, the Engine publishes the SendMessage message including the text and URL for the audio from which the message was created. Publish either the SendMessageSucceeded message or SendMessageFailed message indicating either the success or failure of the request. Click to expand or collapse sequence diagram: Sending Messages Reading Messages When a user requests for Alexa to read messages, your application's Messaging module integration must upload a conversation report containing all unread messages. Once Alexa requests a conversation report upload, the Engine publishes the UploadConversations message . Publish the ConversationsReport message to notify the Engine to upload a conversation report to the cloud. Note: Messages are grouped by conversation, each given a unique identifier. Conversations also have unique identifiers and contain the list of recipient phone numbers included in the conversation, but not the phone number of the messaging device. After Alexa reads a message, it notifies the application that the message was read and should exclude the read message in subsequent conversation report uploads. The Engine publishes the UpdateMessagesStatus message to update the status of the SMS messages. Publish either the UpdateMessagesStatusSucceeded message or UpdateMessageStatusFailed message indicating the success of the message status update. After Alexa reads all messages, or if message readout is interrupted, Alexa requests the upload of a new conversation report. In this way, Alexa stays in sync with unread messages on the messaging device. Note: Unread messages are stored in the cloud for 12 hours before being deleted. By design Alexa will read a limited number of unread messages with a 'read messages' utterance. Therefore, it may be necessary to issue additional read messages requests to head all messages. Click to expand or collapse sequence diagram: Reading Messages and Replying Replying to Message The user can request to reply to a message after Alexa reads the message or as it is being read. Replying is always done within the context of the currently read message. Click to expand or collapse sequence diagram: Replying to Message Updating Messaging Endpoint State When connection to a calling device is established or broken and/or the user grants or denies permissions to read and send messages, publish the UpdateMessagingEndpointState message to update Alexa with the state of the messaging device. Click to expand or collapse sequence diagram: Connecting/Disconnecting Calling Device Click to expand or collapse sequence diagram: Granting/Denying Permissions to Read and Send Messages Integrating the Messaging Module Into Your Application C++ MessageBroker Integration Use the Engine's MessageBroker to subscribe to and publish \"Messaging\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Messaging/Messaging/ConnectionState.h> #include <AASB/Message/Messaging/Messaging/ErrorCode.h> #include <AASB/Message/Messaging/Messaging/PermissionState.h> #include <AASB/Message/Messaging/Messaging/ConversationsReportMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageFailedMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusFailedMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagingEndpointStateMessage.h> #include <AASB/Message/Messaging/Messaging/UploadConversationsMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyMessagingHandler { // Subscribe to messages from the Engine void MyMessagingHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendMessageMessage ( message ); }, SendMessageMessage :: topic (), SendMessageMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUpdateMessagesStatusMessage ( message ); }, UpdateMessagesStatusMessage :: topic (), UpdateMessagesStatusMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUploadConversationsMessage ( message ); }, UploadConversationsMessage :: topic (), UploadConversationsMessage :: action ()); } // Handle the SendMessage message from the Engine void MyMessagingHandler::handleSendMessageMessage ( const std :: string & message ) { SendMessageMessage msg = json :: parse ( message ); sendMessage ( msg . payload . token , msg . payload . message , msg . payload . recipients ); } // Handle the UpdateMessagesStatus message from the Engine void MyMessagingHandler::handleUpdateMessagesStatusMessage ( const std :: string & message ) { UpdateMessagesStatusMessage msg = json :: parse ( message ); updateMessagesStatus ( msg . payload . token , msg . payload . conversationId , msg . payload . status ); } // Handle the UploadConversations message from the Engine void MyMessagingHandler::handleUploadConversationsMessage ( const std :: string & message ) { UploadConversationsMessage msg = json :: parse ( message ); uploadConversations ( msg . payload . token ); } // To upload a conversations report to Alexa, publish a ConversationsReport message to the Engine void MyMessagingHandler::conversationsReport ( const std :: string & token , const std :: string & conversations ) { ConversationsReportMessage msg ; msg . payload . token = token ; msg . payload . conversations = conversations ; m_messageBroker -> publish ( msg . toString ()); } // When the message fails to send, publish a SendMessageFailed message to the Engine void MyMessagingHandler::sendMessageFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { SendMessageFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message is successfully sent, publish a SendMessageSucceeded message to the Engine void MyMessagingHandler::sendMessageSucceeded ( const std :: string & token ) { SendMessageSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update fails, publish a UpdateMessagesStatusFailed message to the Engine void MyMessagingHandler::updateMessagesStatusFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { UpdateMessagesStatusFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update succeeds, publish an UpdateMessagesStatusSucceeded message to the Engine void MyMessagingHandler::updateMessagesStatusSucceeded ( const std :: string & token ) { UpdateMessagesStatusSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // To update the messaging endpoint state, publish an UpdateMessagingEndpointState message to the Engine void MyMessagingHandler::updateMessagingEndpointState ( ConnectionState connectionState , PermissionState sendPermission , PermissionState readPermission ) { UpdateMessagingEndpointStateMessage msg ; msg . payload . connectionState = connectionState ; msg . payload . sendPermission = sendPermission ; msg . payload . readPermission = readPermission ; m_messageBroker -> publish ( msg . toString ()); } void MyMessagingHandler::sendMessage ( const std :: string & token , const std :: string & message , const std :: string & recipients ) { // Parse list of recipients to extract the phone number(s) // Send message using the connected messaging device // Send response of the result using the received token // If message was sent successfully then call sendMessageSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message sendMessageFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to send message\" ); } void MyMessagingHandler::updateMessagesStatus ( const std :: string & token , const std :: string & conversationId , const std :: string & status ) { // Remove unread messages specified in 'status' from the conversation that matches the 'conversationId' // Send response of the result using the received token // If messages status was updated successfully then call updateMessagesStatusSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message updateMessagesStatusFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to update message status\" ); } // Alexa is requesting that a conversation report is uploaded so it can sync up the // status of messages on the cloud void MyMessagingHandler::uploadConversations ( const std :: string & token ) { conversationsReport ( token , storedConversations ); } }; Android Integration Short Message Service (SMS) support is not yet available in the Alexa Auto Client Service (AACS). If you are interested in using the SMS capabilities of Alexa you are required to implement it independently using AASB Messages.","title":"Messaging Module"},{"location":"modules/messaging/#messaging-module","text":"Table of Contents Overview Managing Messaging Sessions Configuring the Messaging Module Using the Messaging Module AASB Messages Integrating the Messaging Module Into Your Application","title":"Messaging Module"},{"location":"modules/messaging/#overview","text":"The Alexa Auto SDK Messaging module enables your Alexa Auto SDK client application to use the Short Message Service (SMS) capabilities of Alexa, independent of the messaging device's connection mechanism. The SMS features of this module include reading messages, sending messages, and replying to messages as they are read. The user must connect their device and consent to allow Alexa to read and send SMS messages through the messaging device. The Messaging feature can use phone numbers directly or use phone contacts uploaded via the Address Book module .","title":"Overview "},{"location":"modules/messaging/#managing-messaging-sessions","text":"The application is responsible for managing the life cycle of the messaging session, including enhancing the end user experience by: Uploading unread SMS messages when the messaging device is connected, so they are ready for readout. Uploading new SMS messages when they are received on the messaging device. Updating the status of messages when notified to do so. Responding to messaging requests with appropriate successful or failure responses. Alexa will not notify the user when new SMS messages are available, your implementation is responsible for providing new message notifications.","title":"Managing Messaging Sessions "},{"location":"modules/messaging/#configuring-the-messaging-module","text":"The Messaging module does not require Engine configuration.","title":"Configuring the Messaging Module "},{"location":"modules/messaging/#using-the-messaging-module-aasb-messages","text":"","title":"Using the Messaging Module AASB Messages "},{"location":"modules/messaging/#sending-messages","text":"When Alexa sends a request to the Engine to deliver a message, the Engine publishes the SendMessage message including the text and URL for the audio from which the message was created. Publish either the SendMessageSucceeded message or SendMessageFailed message indicating either the success or failure of the request. Click to expand or collapse sequence diagram: Sending Messages","title":"Sending Messages"},{"location":"modules/messaging/#reading-messages","text":"When a user requests for Alexa to read messages, your application's Messaging module integration must upload a conversation report containing all unread messages. Once Alexa requests a conversation report upload, the Engine publishes the UploadConversations message . Publish the ConversationsReport message to notify the Engine to upload a conversation report to the cloud. Note: Messages are grouped by conversation, each given a unique identifier. Conversations also have unique identifiers and contain the list of recipient phone numbers included in the conversation, but not the phone number of the messaging device. After Alexa reads a message, it notifies the application that the message was read and should exclude the read message in subsequent conversation report uploads. The Engine publishes the UpdateMessagesStatus message to update the status of the SMS messages. Publish either the UpdateMessagesStatusSucceeded message or UpdateMessageStatusFailed message indicating the success of the message status update. After Alexa reads all messages, or if message readout is interrupted, Alexa requests the upload of a new conversation report. In this way, Alexa stays in sync with unread messages on the messaging device. Note: Unread messages are stored in the cloud for 12 hours before being deleted. By design Alexa will read a limited number of unread messages with a 'read messages' utterance. Therefore, it may be necessary to issue additional read messages requests to head all messages. Click to expand or collapse sequence diagram: Reading Messages and Replying","title":"Reading Messages"},{"location":"modules/messaging/#replying-to-message","text":"The user can request to reply to a message after Alexa reads the message or as it is being read. Replying is always done within the context of the currently read message. Click to expand or collapse sequence diagram: Replying to Message","title":"Replying to Message"},{"location":"modules/messaging/#updating-messaging-endpoint-state","text":"When connection to a calling device is established or broken and/or the user grants or denies permissions to read and send messages, publish the UpdateMessagingEndpointState message to update Alexa with the state of the messaging device. Click to expand or collapse sequence diagram: Connecting/Disconnecting Calling Device Click to expand or collapse sequence diagram: Granting/Denying Permissions to Read and Send Messages","title":"Updating Messaging Endpoint State"},{"location":"modules/messaging/#integrating-the-messaging-module-into-your-application","text":"","title":"Integrating the Messaging Module Into Your Application "},{"location":"modules/messaging/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to subscribe to and publish \"Messaging\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Messaging/Messaging/ConnectionState.h> #include <AASB/Message/Messaging/Messaging/ErrorCode.h> #include <AASB/Message/Messaging/Messaging/PermissionState.h> #include <AASB/Message/Messaging/Messaging/ConversationsReportMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageFailedMessage.h> #include <AASB/Message/Messaging/Messaging/SendMessageSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusFailedMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagesStatusSucceededMessage.h> #include <AASB/Message/Messaging/Messaging/UpdateMessagingEndpointStateMessage.h> #include <AASB/Message/Messaging/Messaging/UploadConversationsMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyMessagingHandler { // Subscribe to messages from the Engine void MyMessagingHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendMessageMessage ( message ); }, SendMessageMessage :: topic (), SendMessageMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUpdateMessagesStatusMessage ( message ); }, UpdateMessagesStatusMessage :: topic (), UpdateMessagesStatusMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleUploadConversationsMessage ( message ); }, UploadConversationsMessage :: topic (), UploadConversationsMessage :: action ()); } // Handle the SendMessage message from the Engine void MyMessagingHandler::handleSendMessageMessage ( const std :: string & message ) { SendMessageMessage msg = json :: parse ( message ); sendMessage ( msg . payload . token , msg . payload . message , msg . payload . recipients ); } // Handle the UpdateMessagesStatus message from the Engine void MyMessagingHandler::handleUpdateMessagesStatusMessage ( const std :: string & message ) { UpdateMessagesStatusMessage msg = json :: parse ( message ); updateMessagesStatus ( msg . payload . token , msg . payload . conversationId , msg . payload . status ); } // Handle the UploadConversations message from the Engine void MyMessagingHandler::handleUploadConversationsMessage ( const std :: string & message ) { UploadConversationsMessage msg = json :: parse ( message ); uploadConversations ( msg . payload . token ); } // To upload a conversations report to Alexa, publish a ConversationsReport message to the Engine void MyMessagingHandler::conversationsReport ( const std :: string & token , const std :: string & conversations ) { ConversationsReportMessage msg ; msg . payload . token = token ; msg . payload . conversations = conversations ; m_messageBroker -> publish ( msg . toString ()); } // When the message fails to send, publish a SendMessageFailed message to the Engine void MyMessagingHandler::sendMessageFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { SendMessageFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message is successfully sent, publish a SendMessageSucceeded message to the Engine void MyMessagingHandler::sendMessageSucceeded ( const std :: string & token ) { SendMessageSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update fails, publish a UpdateMessagesStatusFailed message to the Engine void MyMessagingHandler::updateMessagesStatusFailed ( const std :: string & token , ErrorCode code , const std :: string & message ) { UpdateMessagesStatusFailedMessage msg ; msg . payload . token = token ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the message status update succeeds, publish an UpdateMessagesStatusSucceeded message to the Engine void MyMessagingHandler::updateMessagesStatusSucceeded ( const std :: string & token ) { UpdateMessagesStatusSucceededMessage msg ; msg . payload . token = token ; m_messageBroker -> publish ( msg . toString ()); } // To update the messaging endpoint state, publish an UpdateMessagingEndpointState message to the Engine void MyMessagingHandler::updateMessagingEndpointState ( ConnectionState connectionState , PermissionState sendPermission , PermissionState readPermission ) { UpdateMessagingEndpointStateMessage msg ; msg . payload . connectionState = connectionState ; msg . payload . sendPermission = sendPermission ; msg . payload . readPermission = readPermission ; m_messageBroker -> publish ( msg . toString ()); } void MyMessagingHandler::sendMessage ( const std :: string & token , const std :: string & message , const std :: string & recipients ) { // Parse list of recipients to extract the phone number(s) // Send message using the connected messaging device // Send response of the result using the received token // If message was sent successfully then call sendMessageSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message sendMessageFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to send message\" ); } void MyMessagingHandler::updateMessagesStatus ( const std :: string & token , const std :: string & conversationId , const std :: string & status ) { // Remove unread messages specified in 'status' from the conversation that matches the 'conversationId' // Send response of the result using the received token // If messages status was updated successfully then call updateMessagesStatusSucceeded ( token ); // Otherwise, notify of error using code from @c ErrorCode enum and corresponding error message updateMessagesStatusFailed ( token , ErrorCode :: GENERIC_FAILURE , \"Unable to update message status\" ); } // Alexa is requesting that a conversation report is uploaded so it can sync up the // status of messages on the cloud void MyMessagingHandler::uploadConversations ( const std :: string & token ) { conversationsReport ( token , storedConversations ); } };","title":"C++ MessageBroker Integration"},{"location":"modules/messaging/#android-integration","text":"Short Message Service (SMS) support is not yet available in the Alexa Auto Client Service (AACS). If you are interested in using the SMS capabilities of Alexa you are required to implement it independently using AASB Messages.","title":"Android Integration"},{"location":"modules/messaging/aasb-docs/Messaging/","text":"Messaging Outgoing Messages SendMessage Send SMS message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessage\" } }, \"payload\": { \"token\": {{String}}, \"message\": {{String}}, \"recipients\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. message String Yes Body of the SMS text message to be sent. recipients String Yes String in JSON format containing the recipient of the SMS message. UpdateMessagesStatus Update status of SMS messages. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatus\" } }, \"payload\": { \"token\": {{String}}, \"conversationId\": {{String}}, \"status\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. conversationId String Yes The id of the conversation whose messages need to be updated. status String Yes String in JSON format representing the message ids and status to be updated. UploadConversations Upload SMS unread messages message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UploadConversations\" } }, \"payload\": { \"token\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. Incoming Messages UpdateMessagesStatusFailed Notifies the Engine the message status update failed. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error. UpdateMessagingEndpointState Notifies the Engine of updates to the messaging endpoint state. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagingEndpointState\" } }, \"payload\": { \"connectionState\": {{ConnectionState}}, \"sendPermission\": {{PermissionState}}, \"readPermission\": {{PermissionState}} } } Payload Property Type Required Description Example connectionState ConnectionState Yes The value for the connection state. sendPermission PermissionState Yes The value for the send permission. readPermission PermissionState Yes The value for the read permission. SendMessageSucceeded Notifies the Engine that message send was successful. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageSucceeded\" } }, \"payload\": { \"token\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. SendMessageFailed Notifies the Engine the message send failed. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error. ConversationsReport Notifies the Engine to upload conversations report to the cloud. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"ConversationsReport\" } }, \"payload\": { \"token\": {{String}}, \"conversations\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. conversations String Yes String in JSON format representing all conversations with unread SMS messages. UpdateMessagesStatusSucceeded Notifies the Engine that message status was successful. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusSucceeded\" } }, \"payload\": { \"token\": {{String}} } } Payload Property Type Required Description Example token String Yes Token id for send message request. Enums ConnectionState Values Value Description \"DISCONNECTED\" Messaging device is disconnected. \"CONNECTED\" Messaging device is connected. PermissionState Values Value Description \"OFF\" Permission is not granted. \"ON\" Permission is granted. ErrorCode Values Value Description \"GENERIC_FAILURE\" Generic error handling SMS request. \"NO_CONNECTIVITY\" Messaging device is not connected. \"NO_PERMISSION\" Permission denied.","title":"Messaging"},{"location":"modules/messaging/aasb-docs/Messaging/#messaging","text":"","title":"Messaging"},{"location":"modules/messaging/aasb-docs/Messaging/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/messaging/aasb-docs/Messaging/#sendmessage","text":"Send SMS message.","title":"SendMessage"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessage\" } }, \"payload\": { \"token\": {{String}}, \"message\": {{String}}, \"recipients\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload","text":"Property Type Required Description Example token String Yes Token id for send message request. message String Yes Body of the SMS text message to be sent. recipients String Yes String in JSON format containing the recipient of the SMS message.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#updatemessagesstatus","text":"Update status of SMS messages.","title":"UpdateMessagesStatus"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatus\" } }, \"payload\": { \"token\": {{String}}, \"conversationId\": {{String}}, \"status\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_1","text":"Property Type Required Description Example token String Yes Token id for send message request. conversationId String Yes The id of the conversation whose messages need to be updated. status String Yes String in JSON format representing the message ids and status to be updated.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#uploadconversations","text":"Upload SMS unread messages message.","title":"UploadConversations"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UploadConversations\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_2","text":"Property Type Required Description Example token String Yes Token id for send message request.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/messaging/aasb-docs/Messaging/#updatemessagesstatusfailed","text":"Notifies the Engine the message status update failed.","title":"UpdateMessagesStatusFailed"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_3","text":"Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#updatemessagingendpointstate","text":"Notifies the Engine of updates to the messaging endpoint state.","title":"UpdateMessagingEndpointState"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagingEndpointState\" } }, \"payload\": { \"connectionState\": {{ConnectionState}}, \"sendPermission\": {{PermissionState}}, \"readPermission\": {{PermissionState}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_4","text":"Property Type Required Description Example connectionState ConnectionState Yes The value for the connection state. sendPermission PermissionState Yes The value for the send permission. readPermission PermissionState Yes The value for the read permission.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#sendmessagesucceeded","text":"Notifies the Engine that message send was successful.","title":"SendMessageSucceeded"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageSucceeded\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_5","text":"Property Type Required Description Example token String Yes Token id for send message request.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#sendmessagefailed","text":"Notifies the Engine the message send failed.","title":"SendMessageFailed"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"SendMessageFailed\" } }, \"payload\": { \"token\": {{String}}, \"code\": {{ErrorCode}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_6","text":"Property Type Required Description Example token String Yes Token id for send message request. code ErrorCode Yes The error code identifying the failure. message String No The message explaining the error.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#conversationsreport","text":"Notifies the Engine to upload conversations report to the cloud.","title":"ConversationsReport"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"ConversationsReport\" } }, \"payload\": { \"token\": {{String}}, \"conversations\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_7","text":"Property Type Required Description Example token String Yes Token id for send message request. conversations String Yes String in JSON format representing all conversations with unread SMS messages.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#updatemessagesstatussucceeded","text":"Notifies the Engine that message status was successful.","title":"UpdateMessagesStatusSucceeded"},{"location":"modules/messaging/aasb-docs/Messaging/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Messaging\", \"action\": \"UpdateMessagesStatusSucceeded\" } }, \"payload\": { \"token\": {{String}} } }","title":"JSON Structure"},{"location":"modules/messaging/aasb-docs/Messaging/#payload_8","text":"Property Type Required Description Example token String Yes Token id for send message request.","title":"Payload"},{"location":"modules/messaging/aasb-docs/Messaging/#enums","text":"","title":"Enums"},{"location":"modules/messaging/aasb-docs/Messaging/#connectionstate","text":"","title":"ConnectionState"},{"location":"modules/messaging/aasb-docs/Messaging/#values","text":"Value Description \"DISCONNECTED\" Messaging device is disconnected. \"CONNECTED\" Messaging device is connected.","title":"Values"},{"location":"modules/messaging/aasb-docs/Messaging/#permissionstate","text":"","title":"PermissionState"},{"location":"modules/messaging/aasb-docs/Messaging/#values_1","text":"Value Description \"OFF\" Permission is not granted. \"ON\" Permission is granted.","title":"Values"},{"location":"modules/messaging/aasb-docs/Messaging/#errorcode","text":"","title":"ErrorCode"},{"location":"modules/messaging/aasb-docs/Messaging/#values_2","text":"Value Description \"GENERIC_FAILURE\" Generic error handling SMS request. \"NO_CONNECTIVITY\" Messaging device is not connected. \"NO_PERMISSION\" Permission denied.","title":"Values"},{"location":"modules/navigation/","text":"Navigation Module Table of Contents Overview Configuring the Navigation Module Using the Navigation AASB Messages Providing the Current Navigation State Starting Navigation Stopping Navigation Adding a Waypoint Canceling a Waypoint Showing Previous Waypoints Navigating to a Previous Waypoint Getting Turn and Lane Guidance Information Getting Road Regulation Information Controlling the Display Showing Alternative Routes Integrating the Navigation Module Into Your Application Overview The Navigation module enables your Alexa Auto SDK client application to use the navigation capabilities of Alexa and provides support for Alexa to interface with the onboard navigation system. Your integration is responsible for handling navigation actions when notified to do so by the Engine. How these requests are handled is based on your navigation provider. Configuring the Navigation Module To inform Alexa which navigation provider is used on the head unit, configure the Navigation module. Sometimes Alexa needs to query a cloud navigation provider API to fulfill a user request. Knowing which provider is used on the device allows for better customer experience because Alexa's results can more closely match what the user sees on the screen in the navigation app. To configure the Navigation module, use the \"aace.navigation\" JSON object specified below in your Engine configuration: { \"aace.navigation\": { \"providerName\": \"{{STRING}}\" } } Property Type Required Description Example aace.navigation.providerName string No The navigation service provider name. Accepted values: \"HERE\" (default) \"TOMTOM\" \"TELENAV\" \"HERE\" Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::navigation::config::NavigationConfiguration::createNavigationConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse NavigationConfiguration C++ sample code #include <AACE/Navigation/NavigationConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto navigationConfig = aace :: navigation :: config :: NavigationConfiguration :: createNavigationConfig ( \"HERE\" ); configurations . push_back ( navigationConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations ); Android Integration To use the Navigation module Engine configuration with AACS, use \"aacs.navigation\" instead of \"aace.navigation\" in your AACS configuration file: { \"aacs.navigation\": { \"providerName\": \"{{STRING}}\" } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory method com.amazon.aace.navigation.config.NavigationConfiguration.createNavigationConfig to programmatically construct the EngineConfiguration in the proper format. import com.amazon.aace.navigation.config.NavigationConfiguration ; // Configure the Engine EngineConfiguration navigationConfiguration = NavigationConfiguration . createNavigationConfig ( \"HERE\" ); mEngine . configure ( new EngineConfiguration [] { // other config objects, navigationConfiguration , // ... }); Using the Navigation AASB Messages Providing the Current Navigation State The navigation state context informs Alexa whether the device is navigating and provides Alexa with the user's routing information or the destination set by the user. Such information is necessary for Alexa to respond to route-based utterances, allowing the user to use the following features: Adding or removing waypoints Obtaining Estimated Time of Arrival (ETA) Obtaining Distance To Arrival (DTA) When the user requests navigation information based on the current route, the Engine publishes the GetNavigationState message . The implementation should respond with the GetNavigationStateReply message containing the navigation state passed as a JSON string payload. Note: Returning the navigation state must be quick. If querying the navigation provider for state information takes significant time, Amazon recommends that the application periodically query the provider to update the state in a cache. Then the application can obtain the information each time the Engine requests the navigation state. The following table explains the properties in the JSON. Property Type Required Description state String Yes The navigation device state. Accepted values: \"NAVIGATING\" : Navigation engine is navigating to a predefined destination set. \"NOT_NAVIGATING\" : Navigation is not in progress. shapes Array of arrays Yes (if state is \"NAVIGATING\" ) The array contains an ordered list of coordinates depicting the route from the source to destination. Each coordinate is a latitude-longitude pair, specified as an array of doubles (in that order). The array can be empty. The maximum number of coordinates is 100. Special considerations: The set of coordinates might not represent the complete route. Shapes are provider specific. The shape of a route can correspond to one of these versions: a complete route, a route for a view port, or a route defined for a particular distance. It is recommended to use one mile spacing between each coordinate in the shapes array. The coordinates in the array are ordered in the same direction as the user is driving. waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. Expand the section below for more information. Note: Can be empty except when state is \"NAVIGATING\" . Click to expand or collapse the properties of waypoints object Property Type Required Description type String Yes Type of the location on the route. Accepted values: SOURCE : The location from which the user starts driving. DESTINATION : Final location to which the user wants to navigate to. INTERIM : Intermediate stop where the user wants to navigate to before reaching the destination. estimatedTimeOfArrival Object No (Applicable only if type is \"DESTINATION\" or \"INTERIM\" .) Time of arrival at the waypoint, specified in the ISO-8601 time format. estimatedTimeOfArrival.ideal String No Expected arrival time without considering traffic, diversions, etc. estimatedTimeOfArrival.predicted String Yes Expected arrival time, after considering traffic conditions. If the ideal ETA and predicted ETA match, only the predicted ETA will be populated. address Object No Address of the waypoint specified in multiple string fields, such as addressLine1 , city , etc. Note: countryCode is a 3-letter country code in ISO 3166-1 alpha-3 format. name String No Name of the waypoint (e.g., \"work\" or \"Starbucks\"). coordinate Array Yes An array consisting of the waypoint's latitude and longitude (in that order). The data type of latitude and longitude is double. pointOfInterest Object No Information about the waypoint if the waypoint is also a point of interest (POI). Expand the section below for more information. Click to expand or collapse the properties of pointOfInterest object Property Type Required Description id String No (recommended if available) ID for the POI known to Alexa. If id is provided, you can omit other properties of pointOfInterest . If the waypoint is added by the user via the navigation app, omit id because Alexa cannot recognize any ID assigned by the app. You can specify the ID if the waypoint is added by Alexa (e.g., by the utterance \"Alexa, navigate to Whole Foods along the way\"). It is specified in the StartNavigation message payload received from Alexa. hoursOfOperation Array No Hours of operation for the POI. hoursOfOperation.dayOfWeek String Y Day of week for this day. Accepted values: \"MONDAY\" , \"TUESDAY\" , \"WEDNESDAY\" , \"THURSDAY\" , \"FRIDAY\" , \"SATURDAY\" , \"SUNDAY\" . hoursOfOperation.hours Array Yes List of times when the POI is open or closed for the day, specified in ISO 8601 format with the timezone offset (time difference from UTC). Properties in the array are: open : Time at which the POI is open. close : Time at which the POI is closed. Timezone considerations: If the user and the POI are in different timezones, hours are converted to the timezone of the POI. If timezone offset is omitted, the time is assumed to be a UTC time and then converted to the POI's timezone. Note: Hours for the next 7 days are provided by the data provider. hoursOfOperation.type String Yes Status of the current operation. Accepted values: \"OPEN_DURING_HOURS\" , \"OPEN_24_HOURS\" , \"CLOSED\" , \"UNKNOWN\" , \"HOLIDAY\" . phoneNumber String No Phone number of the POI in E.164 format. Examples of Navigation State Payload Click to expand or collapse example Navigation State payload when navigation is in progress { \"state\" : \"NAVIGATING\" , \"waypoints\" : [ { \"type\" : \"SOURCE\" , \"address\" : { \"addressLine1\" : \"2795 Augustine Drive\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Santa Clara\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"95054\" }, \"name\" : \"work\" , \"coordinate\" : [ 37.3809462 , -121.9794846 ] }, { \"type\" : \"INTERIM\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:00:00-08:00\" , \"predicted\" : \"2019-12-09T17:10:00-08:00\" }, \"address\" : { \"addressLine1\" : \"750 Castro Street\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Mountain View\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"94041\" }, \"name\" : \"Starbucks\" , \"coordinate\" : [ 37.3809461 , -122.0830221 ], \"pointOfInterest\" : { \"id\" : \"AlexaLocalSearch:eyJpZCI6InllbHA6OnRGV01ySS1VWERGa09FcnZ6eXJ0clEiLCJjb3ZlcnMiOnsiUExBQ0VTX1JFUE8iOiJ5ZWxwOjp0RldNckktVVhERmtPRXJ2enlydHJRIn0sInF1ZXJ5SWQiOiItNjYxMzI1NTYxIiwiZGRiVGFibGVOYW1lIjoiZXMtbHNzLTIwMjEwNjE2Iiwid2VibGFiQWxsb2NhdGlvbnMiOnsiQUxTU19XRUJMQUJfT05CT0FSRF9URVNUSU5HXzI4MDI4NiI6IlQxIiwiQUxFWEFfTE9DQUxTRUFSQ0hfUExBQ0VUWVBFX0NMQVNTSUZJRVJfMzA4MTY5IjoiQyIsIkFMRVhBX0xPQ0FMX1NFQVJDSF9MMlJfRU5USVRZX1NIQURPV18yOTA5MDUiOiJDIiwiQUxFWEFfTE9DQUxfU0VBUkNIX1RSSUdHRVJfQU1CSUdVT1VTX1FVRVJZX0lERU5USUZJQ0FUSU9OXzMyNjMxNSI6IlQxIn19\" , \"phoneNumber\" : \"+14084968523\" } }, { \"type\" : \"DESTINATION\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:30:00-08:00\" , \"predicted\" : \"2019-12-09T17:40:00-08:00\" }, \"address\" : { \"addressLine1\" : \"4800 El Camino Real\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Los Altos\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"\" , \"postalCode\" : \"94022\" }, \"name\" : \"Whole Foods Market\" , \"coordinate\" : [ 37.3991897 , -122.1106268 ], \"pointOfInterest\" : { \"hoursOfOperation\" : [ { \"dayOfWeek\" : \"MONDAY\" , \"hours\" : [ { \"open\" : \"08:00:00-08:00\" , \"close\" : \"22:00:00-08:00\" } ], \"type\" : \"OPEN_DURING_HOURS\" } ] } } ], \"shapes\" : [ [ \"37.380946\" , \"-121.9794846\" ], [ \"37.380545\" , \"-122.073252\" ], ... ] } Click to expand or collapse example Navigation State payload when navigation no navigation is in progress { \"state\" : \"NOT_NAVIGATING\" , \"waypoints\" :[], \"shapes\" :[] } Starting Navigation To start navigation, the Engine publishes the StartNavigation message passing a JSON string payload containing the destination information. The following table explains the properties in the JSON. Property Type Required Description transportationMode String No The mode of transportation. Accepted Values: \"BIKING\" \"DRIVING\" \"TRANSIT\" \"WALKING\" waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. The properties use the same schema used for state reporting. See the Providing the Current Navigation State section. Click to expand or collapse the StartNavigation message payload schema { \"transportationMode\": \"DRIVING\", \"waypoints\":[ { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\" }, { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\":\"{{STRING}}\", \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\", \"pointOfInterest\":{ \"id\":\"{{STRING}}\", \"hoursOfOperation\":[ { \"dayOfWeek\":\"{{STRING}}\", \"hours\":[ { \"open\":\"{{STRING}}\", \"close\":\"{{STRING}}\" } ], \"type\":\"{{STRING}}\" } ], \"phoneNumber\":\"{{STRING}}\" } } ] } } Note: The waypoints in the route are determined by Alexa either through a proximity search or by resolving the user's uploaded navigation favorite name to its location. Your implementation should calculate the route from the SOURCE waypoint to the DESTINATION waypoint, with stops along the way at INTERIM waypoints in the order in which they appear in the payload. If there are multiple routes, your implementation should either pick the fastest route if no user interaction is possible, or let the user choose the route. After the route is chosen, your implementation should start navigation. If navigation starts successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Starting Navigation Stopping Navigation To stop navigation, the Engine publishes the CancelNavigation message . Consequently, when the Engine publishes the next GetNavigationState message the state should be NOT_NAVIGATING . Click to expand or collapse sequence diagram: Stopping Navigation Adding a Waypoint If the user wants to add a waypoint, the Engine publishes the StartNavigation message . If navigation is in progress or route is present, the route to the final destination is changed by including the additional waypoint. Your implementation should calculate or re-calculate the route with the information of the waypoint. If the waypoint is added successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Adding a Waypoint Canceling a Waypoint If the user wants to cancel a waypoint, the Engine publishes the StartNavigation message after receiving the directive from Alexa with the updated waypoints. Your implementation should start navigation using the updated waypoints. If navigation is started successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Canceling a Waypoint Showing Previous Waypoints If the user wants to display previous waypoints, the Engine publishes the ShowPreviousWaypoints message . Each waypoint displayed includes at least the address. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_WAYPOINTS_SHOWN event. Otherwise, it should publish the NavigationError message with the SHOW_PREVIOUS_WAYPOINTS_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Note: It is the responsibility of the navigation provider to store and provide the previous destination list to the user. Click to expand or collapse sequence diagram: Showing Previous Waypoints Navigating to a Previous Waypoint If the user wants to navigate to a previous waypoint, the Engine publishes the NavigateToPreviousWaypoint message . The navigation app retrieves the most recently used destination, calculates a route from the current location, selects the fastest route or a route preferred by the user, and starts navigation. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the PREVIOUS_NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Click to expand or collapse sequence diagram: Navigating to a Previous Waypoint Getting Turn and Lane Guidance Information If the user wants to get turn and lane guidance, the Engine publishes the AnnounceManeuver message , passing a JSON string payload containing the manueuver information. The following table explains the properties in the JSON. Property Type Required Description type String Yes Specifies the type of information requested. Accepted values: \"TURN\" : The user asks about a turn. (e.g., \"What's my next turn?\") \"EXIT\" : The user asks about a freeway exit. (e.g., \"What's my next exit?\") \"ENTER\" : The user asks about how to get onto a street. (e.g., \"Which lane should I be to get onto the US-101?\") \"MERGE\" : The user asks about the merge onto a street. (e.g., \"Alexa, which lane do i need to merge onto the highway?\") \"LANE\" : The user asks for lane guidance. (e.g., \"Alexa, which lane to take?\") targetLocation Object No Describes the location for which maneuver information is requested. If the target location is a POI, user place, or street address, Alexa provides at least one field in this object. If the utterance does not include a location (e.g., \"Alexa, what's my next turn?\"), targetLocation is omitted. targetLocation.name String No Specifies the name of the location (e.g., \"HOME\" or \"WORK\") for which the user requests the maneuver instruction. targetLocation.address Object No Specifies the address for which the user requests the maneuver instruction. The object contains multiple string fields, which together form the complete address. targetLocation.coordinate Array No The array value specifies the latitude and longitude of the target location. Data type for the values in the array is double. Click to expand or collapse the AnnounceManeuver message schema { \"type\": \"{{STRING}}\", \"targetLocation\" : { \"name\": \"{{STRING}}\", \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\": [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ] } } Your implementation should provide the navigation instruction as follows: * If `targetLocation` is omitted, announce the next maneuver along the route. * If `targetLocation` is specified and the location is along the route, announce the maneuver about the location. If `targetLocation` is specified but the location is not along the route, calculate the route to the location, announce maneuver from the user's current location to the target location, and inform the user the target location is NOT along the current route. If the device can provide the maneuver instruction successfully, your implementation should publish the [`NavigationEvent` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationevent) with one of the following events: > **events:** `TURN_GUIDANCE_ANNOUNCED`, `EXIT_GUIDANCE_ANNOUNCED`, `ENTER_GUIDANCE_ANNOUNCED`, `MERGE_GUIDANCE_ANNOUNCED`, `LANE_GUIDANCE_ANNOUNCED` Otherwise, your implementation should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with a type and code from the following: > **types:** `TURN_GUIDANCE_FAILED`, `EXIT_GUIDANCE_FAILED`, `ENTER_GUIDANCE_FAILED`, `MERGE_GUIDANCE_FAILED`, `LANE_GUIDANCE_FAILED`\\ > **codes:** `INTERNAL_SERVICE_ERROR`, `ROUTE_NOT_FOUND`, `NOT_SUPPORTED` Click to expand or collapse sequence diagram: Getting Turn and Lane Guidance Information ![Announce_Maneuver_Guidance](./assets/announce_maneuver.png) ### Getting Road Regulation Information If the user wants to get road regulation information, the Engine publishes the [`AnnounceRoadRegulation` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#announceroadregulation), which passes a payload with the following schema: { \"type\": \"{{STRING}}\" } | Property | Type | Required | Description | |-|-|-|-| | type | String | Yes | Type of road regulation requested. **Accepted values:** `\"SPEED_LIMIT\"` specifies the speed limit at the current position (e.g., when the user asks, \"Alexa, what is the speed limit?\"). `\"CARPOOL_RULES\"` specifies the carpool regulations on the current highway (e.g., when the user asks, \"Alexa, is carpool free now?\"). | If the device can provide the road regulation information successfully, your implementation should publish the [`NavigationEvent` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationevent) with a `SPEED_LIMIT_REGULATION_ANNOUNCED` or `CARPOOL_RULES_REGULATION_ANNOUNCED` event. Otherwise, it should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with the `SPEED_LIMIT_REGULATION_FAILED` or `CARPOOL_RULES_REGULATION_FAILED` type, and `INTERNAL_SERVICE_ERROR` or `NOT_SUPPORTED` code. Click to expand or collapse sequence diagram: Getting Road Regulation Information ![Announce_Road_Regulation_Guidance](./assets/announce_road_regulation.png) ### Controlling the Display If the user wants to control the map display on the screen, the Engine publishes the [`ControlDisplay` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#controldisplay). If the device can adjust the display successfully, your implementation should publish the [`NavigationEvent` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationevent) with one of the following event: > **events:** `ROUTE_OVERVIEW_SHOWN`, `DIRECTIONS_LIST_SHOWN`, `ZOOMED_IN`, `ZOOMED_OUT`, `MAP_CENTERED`, `ORIENTED_NORTH`, `SCROLLED_NORTH`, `SCROLLED_UP`, `SCROLLED_EAST`, `SCROLLED_RIGHT`, `SCROLLED_SOUTH`, `SCROLLED_DOWN`, `SCROLLED_WEST`, `SCROLLED_LEFT`, `ROUTE_GUIDANCE_MUTED`, `ROUTE_GUIDANCE_UNMUTED` Otherwise, your implementation should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with a type and code from the following: > **types:** `ROUTE_OVERVIEW_FAILED`, `DIRECTIONS_LIST_FAILED`, `ZOOMED_IN_FAILED`, `ZOOMED_OUT_FAILED`, `MAP_CENTERED_FAILED`, `ORIENTED_NORTH_FAILED`, `SCROLLED_NORTH_FAILED`, `SCROLLED_UP_FAILED`, `SCROLLED_EAST_FAILED`, `SCROLLED_RIGHT_FAILED`, `SCROLLED_SOUTH_FAILED`, `SCROLLED_DOWN_FAILED`, `SCROLLED_WEST_FAILED`, `SCROLLED_LEFT_FAILED`, `ROUTE_GUIDANCE_MUTED_FAILED`, `ROUTE_GUIDANCE_UNMUTED_FAILED`\\ > **codes:** `INTERNAL_SERVICE_ERROR`, `ROUTE_NOT_FOUND`, `NOT_SUPPORTED`, `NOT_ALLOWED` Click to expand or collapse sequence diagram: Controlling the Display ![Map_Control](./assets/map_control.png) ### Showing Alternative Routes If the user wants to display alternative routes, the Engine publishes the [`ShowAlternativeRoutes` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#showalternativeroutes), which passes the type of alternate route to be displayed. If the device can display the alternative route successfully, your implementation should publish the [`ShowAlternativeRoutesSucceeded` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#showalternativeroutessucceeded) with a payload containing information about the alternative route. The following table explains the properties in the JSON. | Property | Type | Required | Description | |-|-|-|-| | inquiryType | String | Yes | The type of alternative routes based on the user's preference. **Accepted values:** `\"DEFAULT\"`, which means there is no preference as to whether the alternate route saves time or distance. `\"SHORTER_TIME\"`, which means the alternate route saves time. `\"SHORTER_DISTANCE\"`, which means the alternate route saves distance. | alternateRoute | Object | Yes | Information about the best route that matches the preference specified by `inquiryType`. | alternateRoute.labels | Array of strings |Yes | Unique names within a route (e.g., names of highways) used to distinguish between alternative routes. Each label might contain the direction of the route. | alternateRoute.savings | Array | No | List of savings achieved by the route. | alternateRoute.savings.type | String | Yes | The type of savings. **Accepted values:** `\"DISTANCE\"` or `\"TIME\"`. | alternateRoute.savings.amount | Float | Yes | The amount of savings achieved by the route. Alexa uses prescribed unit to convert the amount of savings to improve user experience, if needed. | alternateRoute.savings.unit | String | Yes | Measurement unit of the savings. **Accepted values:** `\"MINUTE\"`, `\"HOUR\"`, `\"YARD\"`, `\"FOOT\"`, `\"MILE\"`, `\"METER\"`, or `\"KILOMETER\"`. Click to expand or collapse the ShowAlternativeRoutesSucceeded message schema { \"inquiryType\": \"{{STRING}}\", \"alternateRoute\": { \"labels\": [\"{{STRING}}\"], \"savings\": [ { \"type\": \"{{STRING}}\", \"amount\": \"{{FLOAT}}\", \"unit\": \"{{STRING}}\" } ] } } Otherwise, your implementation should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with a type and code from the following: > **types:** `DEFAULT_ALTERNATE_ROUTES_FAILED`, `SHORTER_TIME_ROUTES_FAILED`, `SHORTER_DISTANCE_ROUTES_FAILED`\\ > **codes:** `INTERNAL_SERVICE_ERROR`, `ROUTE_NOT_FOUND`, `NOT_SUPPORTED`, `NOT_ALLOWED` Click to expand or collapse sequence diagram: Showing Alternative Routes ![Show_Alternate_Routes](./assets/show_alternate_routes.png) ## Integrating the Navigation Module Into Your Application ### C++ MessageBroker Integration Use the Engine's `MessageBroker` to subscribe to and publish *\"Navigation\"* AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Navigation/Navigation/AlternateRouteType.h> #include <AASB/Message/Navigation/Navigation/ControlDisplay.h> #include <AASB/Message/Navigation/Navigation/ErrorCode.h> #include <AASB/Message/Navigation/Navigation/ErrorType.h> #include <AASB/Message/Navigation/Navigation/EventName.h> #include <AASB/Message/Navigation/Navigation/RoadRegulation.h> #include <AASB/Message/Navigation/Navigation/AnnounceManeuverMessage.h> #include <AASB/Message/Navigation/Navigation/AnnounceRoadRegulationMessage.h> #include <AASB/Message/Navigation/Navigation/CancelNavigationMessage.h> #include <AASB/Message/Navigation/Navigation/ControlDisplayMessage.h> #include <AASB/Message/Navigation/Navigation/GetNavigationStateMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationErrorMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationEventMessage.h> #include <AASB/Message/Navigation/Navigation/NavigateToPreviousWaypointMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesSucceededMessage.h> #include <AASB/Message/Navigation/Navigation/ShowPreviousWaypointsMessage.h> #include <AASB/Message/Navigation/Navigation/StartNavigationMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyNavigationHandler { void MyNavigationHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceManeuverMessage ( message ); }, AnnounceManeuverMessage :: topic (), AnnounceManeuverMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceRoadRegulationMessage ( message ); }, AnnounceRoadRegulationMessage :: topic (), AnnounceRoadRegulationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCancelNavigationMessage ( message ); }, CancelNavigationMessage :: topic (), CancelNavigationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleControlDisplayMessage ( message ); }, ControlDisplayMessage :: topic (), ControlDisplayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNavigationStateMessage ( message ); }, GetNavigationStateMessage :: topic (), GetNavigationStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleNavigateToPreviousWaypointMessage ( message ); }, NavigateToPreviousWaypointMessage :: topic (), NavigateToPreviousWaypointMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowAlternativeRoutesMessage ( message ); }, ShowAlternativeRoutesMessage :: topic (), ShowAlternativeRoutesMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowPreviousWaypointsMessage ( message ); }, ShowPreviousWaypointsMessage :: topic (), ShowPreviousWaypointsMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartNavigationMessage ( message ); }, StartNavigationMessage :: topic (), StartNavigationMessage :: action ()); } // Handle the AnnounceManeuver message from the Engine void MyNavigationHandler::handleAnnounceManeuverMessage ( const std :: string & message ) { AnnounceManeuverMessage msg = json :: parse ( message ); announceManeuver ( msg . payload . payload ); } // Handle the AnnounceRoadRegulation message from the Engine void MyNavigationHandler::handleAnnounceRoadRegulationMessage ( const std :: string & message ) { AnnounceRoadRegulationMessage msg = json :: parse ( message ); announceRoadRegulation ( msg . payload . roadRegulation ); } // Handle the CancelNavigation message from the Engine void MyNavigationHandler::handleCancelNavigationMessage ( const std :: string & message ) { cancelNavigation (); } // Handle the ControlDisplay message from the Engine void MyNavigationHandler::handleControlDisplayMessage ( const std :: string & message ) { ControlDisplayMessage msg = json :: parse ( message ); controlDisplay ( msg . payload . controlDisplay ); } // Handle the GetNavigationState message from the Engine and publish the // reply message containing the current navigation state void MyNavigationHandler::handleGetNavigationStateMessage ( const std :: string & message ) { GetNavigationStateMessage msg = json :: parse ( message ); GetNavigationStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . navigationState = getNavigationState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the NavigateToPreviousWaypoint message from the Engine void MyNavigationHandler::handleNavigateToPreviousWaypointMessage ( const std :: string & message ) { navigateToPreviousWaypoint (); } // Handle the ShowAlternativeRoutes message from the Engine void MyNavigationHandler::handleShowAlternativeRoutesMessage ( const std :: string & message ) { ShowAlternativeRoutesMessage msg = json :: parse ( message ); showAlternativeRoutes ( msg . payload . alternateRouteType ); } // Handle the ShowPreviousWaypoints message from the Engine void MyNavigationHandler::handleShowPreviousWaypointsMessage ( const std :: string & message ) { showPreviousWaypoints (); } // Handle the StartNavigation message from the Engine void MyNavigationHandler::handleStartNavigationMessage ( const std :: string & message ) { StartNavigationMessage msg = json :: parse ( message ); startNavigation ( msg . payload . payload ); } void MyNavigationHandler::navigationError ( ErrorType type , ErrorCode code , const std :: string & description ) { NavigationErrorMessage msg ; msg . payload . type = type ; msg . payload . code = code ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::navigationEvent ( EventName event ) { NavigationEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::showAlternativeRoutesSucceeded ( const std :: string & payload ) { ShowAlternativeRoutesSucceededMessage msg ; msg . payload . payload = payload ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::startNavigation ( const std :: string & payload ) { // Update the previous destinations list // Call navigationEvent(EventName::NAVIGATION_STARTED) // If error occurs call navigationError() with ErrorType::NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void MyNavigationHandler::navigateToPreviousWaypoint () { // Call navigationEvent(EventName::PREVIOUS_NAVIGATION_STARTED) // If any error occurs call navigationError() with ErrorType::PREVIOUS_NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showPreviousWaypoints () { // Call navigationEvent(EventName::PREVIOUS_WAYPOINTS_SHOWN) // If error occurs call navigationError() with ErrorType::SHOW_PREVIOUS_WAYPOINTS_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showAlternativeRoutes ( AlternateRouteType alternateRouteType ) { // Based on the AlternativeRouteType obtain the alternative route information // Call showAlternativeRoutesSucceeded() // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::controlDisplay ( ControlDisplay controlDisplay ) { // Call navigationEvent() for the requested map control request // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceManeuver ( const std :: string & payload ) { // Call navigationEvent() for the requested manueuver instruction // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceRoadRegulation ( RoadRegulation roadRegulation ) { // Call navigationEvent() for the requested road regulation // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } bool NavigationHandler::cancelNavigation () { // Clear the navigation state } std :: string NavigationHandler::getNavigationState () { // Return current navigation state } }; ### Android Integration The Alexa Auto Client Service (AACS) provides the `Navigation App Component` to integrate the Auto SDK `Navigation` module on Android. See the [AACS Navigation App Component documentation](../../aacs/android/app-components/alexa-auto-navigation/README.md) for more information.","title":"Navigation Module"},{"location":"modules/navigation/#navigation-module","text":"","title":"Navigation Module"},{"location":"modules/navigation/#table-of-contents","text":"Overview Configuring the Navigation Module Using the Navigation AASB Messages Providing the Current Navigation State Starting Navigation Stopping Navigation Adding a Waypoint Canceling a Waypoint Showing Previous Waypoints Navigating to a Previous Waypoint Getting Turn and Lane Guidance Information Getting Road Regulation Information Controlling the Display Showing Alternative Routes Integrating the Navigation Module Into Your Application","title":"Table of Contents"},{"location":"modules/navigation/#overview","text":"The Navigation module enables your Alexa Auto SDK client application to use the navigation capabilities of Alexa and provides support for Alexa to interface with the onboard navigation system. Your integration is responsible for handling navigation actions when notified to do so by the Engine. How these requests are handled is based on your navigation provider.","title":"Overview "},{"location":"modules/navigation/#configuring-the-navigation-module","text":"To inform Alexa which navigation provider is used on the head unit, configure the Navigation module. Sometimes Alexa needs to query a cloud navigation provider API to fulfill a user request. Knowing which provider is used on the device allows for better customer experience because Alexa's results can more closely match what the user sees on the screen in the navigation app. To configure the Navigation module, use the \"aace.navigation\" JSON object specified below in your Engine configuration: { \"aace.navigation\": { \"providerName\": \"{{STRING}}\" } } Property Type Required Description Example aace.navigation.providerName string No The navigation service provider name. Accepted values: \"HERE\" (default) \"TOMTOM\" \"TELENAV\" \"HERE\" Like all Auto SDK Engine configurations, you can either define this JSON in a file and construct an EngineConfiguration from that file, or you can use the provided configuration factory function aace::navigation::config::NavigationConfiguration::createNavigationConfig to programmatically construct the EngineConfiguration in the proper format. Click to expand or collapse NavigationConfiguration C++ sample code #include <AACE/Navigation/NavigationConfiguration.h> std :: vector < std :: shared_ptr < aace :: core :: config :: EngineConfiguration >> configurations ; auto navigationConfig = aace :: navigation :: config :: NavigationConfiguration :: createNavigationConfig ( \"HERE\" ); configurations . push_back ( navigationConfig ); // ... create other EngineConfiguration objects and add them to configurations... m_engine -> configure ( configurations );","title":"Configuring the Navigation Module "},{"location":"modules/navigation/#android-integration","text":"To use the Navigation module Engine configuration with AACS, use \"aacs.navigation\" instead of \"aace.navigation\" in your AACS configuration file: { \"aacs.navigation\": { \"providerName\": \"{{STRING}}\" } } Click to expand or collapse details for Android integration without AACS AACS is the recommended way to integrate Auto SDK for Android. However, if your integration does not use AACS, you can use the Java factory method com.amazon.aace.navigation.config.NavigationConfiguration.createNavigationConfig to programmatically construct the EngineConfiguration in the proper format. import com.amazon.aace.navigation.config.NavigationConfiguration ; // Configure the Engine EngineConfiguration navigationConfiguration = NavigationConfiguration . createNavigationConfig ( \"HERE\" ); mEngine . configure ( new EngineConfiguration [] { // other config objects, navigationConfiguration , // ... });","title":"Android Integration "},{"location":"modules/navigation/#using-the-navigation-aasb-messages","text":"","title":"Using the Navigation AASB Messages "},{"location":"modules/navigation/#providing-the-current-navigation-state","text":"The navigation state context informs Alexa whether the device is navigating and provides Alexa with the user's routing information or the destination set by the user. Such information is necessary for Alexa to respond to route-based utterances, allowing the user to use the following features: Adding or removing waypoints Obtaining Estimated Time of Arrival (ETA) Obtaining Distance To Arrival (DTA) When the user requests navigation information based on the current route, the Engine publishes the GetNavigationState message . The implementation should respond with the GetNavigationStateReply message containing the navigation state passed as a JSON string payload. Note: Returning the navigation state must be quick. If querying the navigation provider for state information takes significant time, Amazon recommends that the application periodically query the provider to update the state in a cache. Then the application can obtain the information each time the Engine requests the navigation state. The following table explains the properties in the JSON. Property Type Required Description state String Yes The navigation device state. Accepted values: \"NAVIGATING\" : Navigation engine is navigating to a predefined destination set. \"NOT_NAVIGATING\" : Navigation is not in progress. shapes Array of arrays Yes (if state is \"NAVIGATING\" ) The array contains an ordered list of coordinates depicting the route from the source to destination. Each coordinate is a latitude-longitude pair, specified as an array of doubles (in that order). The array can be empty. The maximum number of coordinates is 100. Special considerations: The set of coordinates might not represent the complete route. Shapes are provider specific. The shape of a route can correspond to one of these versions: a complete route, a route for a view port, or a route defined for a particular distance. It is recommended to use one mile spacing between each coordinate in the shapes array. The coordinates in the array are ordered in the same direction as the user is driving. waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. Expand the section below for more information. Note: Can be empty except when state is \"NAVIGATING\" . Click to expand or collapse the properties of waypoints object Property Type Required Description type String Yes Type of the location on the route. Accepted values: SOURCE : The location from which the user starts driving. DESTINATION : Final location to which the user wants to navigate to. INTERIM : Intermediate stop where the user wants to navigate to before reaching the destination. estimatedTimeOfArrival Object No (Applicable only if type is \"DESTINATION\" or \"INTERIM\" .) Time of arrival at the waypoint, specified in the ISO-8601 time format. estimatedTimeOfArrival.ideal String No Expected arrival time without considering traffic, diversions, etc. estimatedTimeOfArrival.predicted String Yes Expected arrival time, after considering traffic conditions. If the ideal ETA and predicted ETA match, only the predicted ETA will be populated. address Object No Address of the waypoint specified in multiple string fields, such as addressLine1 , city , etc. Note: countryCode is a 3-letter country code in ISO 3166-1 alpha-3 format. name String No Name of the waypoint (e.g., \"work\" or \"Starbucks\"). coordinate Array Yes An array consisting of the waypoint's latitude and longitude (in that order). The data type of latitude and longitude is double. pointOfInterest Object No Information about the waypoint if the waypoint is also a point of interest (POI). Expand the section below for more information. Click to expand or collapse the properties of pointOfInterest object Property Type Required Description id String No (recommended if available) ID for the POI known to Alexa. If id is provided, you can omit other properties of pointOfInterest . If the waypoint is added by the user via the navigation app, omit id because Alexa cannot recognize any ID assigned by the app. You can specify the ID if the waypoint is added by Alexa (e.g., by the utterance \"Alexa, navigate to Whole Foods along the way\"). It is specified in the StartNavigation message payload received from Alexa. hoursOfOperation Array No Hours of operation for the POI. hoursOfOperation.dayOfWeek String Y Day of week for this day. Accepted values: \"MONDAY\" , \"TUESDAY\" , \"WEDNESDAY\" , \"THURSDAY\" , \"FRIDAY\" , \"SATURDAY\" , \"SUNDAY\" . hoursOfOperation.hours Array Yes List of times when the POI is open or closed for the day, specified in ISO 8601 format with the timezone offset (time difference from UTC). Properties in the array are: open : Time at which the POI is open. close : Time at which the POI is closed. Timezone considerations: If the user and the POI are in different timezones, hours are converted to the timezone of the POI. If timezone offset is omitted, the time is assumed to be a UTC time and then converted to the POI's timezone. Note: Hours for the next 7 days are provided by the data provider. hoursOfOperation.type String Yes Status of the current operation. Accepted values: \"OPEN_DURING_HOURS\" , \"OPEN_24_HOURS\" , \"CLOSED\" , \"UNKNOWN\" , \"HOLIDAY\" . phoneNumber String No Phone number of the POI in E.164 format.","title":"Providing the Current Navigation State "},{"location":"modules/navigation/#examples-of-navigation-state-payload","text":"Click to expand or collapse example Navigation State payload when navigation is in progress { \"state\" : \"NAVIGATING\" , \"waypoints\" : [ { \"type\" : \"SOURCE\" , \"address\" : { \"addressLine1\" : \"2795 Augustine Drive\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Santa Clara\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"95054\" }, \"name\" : \"work\" , \"coordinate\" : [ 37.3809462 , -121.9794846 ] }, { \"type\" : \"INTERIM\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:00:00-08:00\" , \"predicted\" : \"2019-12-09T17:10:00-08:00\" }, \"address\" : { \"addressLine1\" : \"750 Castro Street\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Mountain View\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"USA\" , \"postalCode\" : \"94041\" }, \"name\" : \"Starbucks\" , \"coordinate\" : [ 37.3809461 , -122.0830221 ], \"pointOfInterest\" : { \"id\" : \"AlexaLocalSearch:eyJpZCI6InllbHA6OnRGV01ySS1VWERGa09FcnZ6eXJ0clEiLCJjb3ZlcnMiOnsiUExBQ0VTX1JFUE8iOiJ5ZWxwOjp0RldNckktVVhERmtPRXJ2enlydHJRIn0sInF1ZXJ5SWQiOiItNjYxMzI1NTYxIiwiZGRiVGFibGVOYW1lIjoiZXMtbHNzLTIwMjEwNjE2Iiwid2VibGFiQWxsb2NhdGlvbnMiOnsiQUxTU19XRUJMQUJfT05CT0FSRF9URVNUSU5HXzI4MDI4NiI6IlQxIiwiQUxFWEFfTE9DQUxTRUFSQ0hfUExBQ0VUWVBFX0NMQVNTSUZJRVJfMzA4MTY5IjoiQyIsIkFMRVhBX0xPQ0FMX1NFQVJDSF9MMlJfRU5USVRZX1NIQURPV18yOTA5MDUiOiJDIiwiQUxFWEFfTE9DQUxfU0VBUkNIX1RSSUdHRVJfQU1CSUdVT1VTX1FVRVJZX0lERU5USUZJQ0FUSU9OXzMyNjMxNSI6IlQxIn19\" , \"phoneNumber\" : \"+14084968523\" } }, { \"type\" : \"DESTINATION\" , \"estimatedTimeOfArrival\" : { \"ideal\" : \"2019-12-09T17:30:00-08:00\" , \"predicted\" : \"2019-12-09T17:40:00-08:00\" }, \"address\" : { \"addressLine1\" : \"4800 El Camino Real\" , \"addressLine2\" : \"\" , \"addressLine3\" : \"\" , \"city\" : \"Los Altos\" , \"districtOrCounty\" : \"\" , \"stateOrRegion\" : \"CA\" , \"countryCode\" : \"\" , \"postalCode\" : \"94022\" }, \"name\" : \"Whole Foods Market\" , \"coordinate\" : [ 37.3991897 , -122.1106268 ], \"pointOfInterest\" : { \"hoursOfOperation\" : [ { \"dayOfWeek\" : \"MONDAY\" , \"hours\" : [ { \"open\" : \"08:00:00-08:00\" , \"close\" : \"22:00:00-08:00\" } ], \"type\" : \"OPEN_DURING_HOURS\" } ] } } ], \"shapes\" : [ [ \"37.380946\" , \"-121.9794846\" ], [ \"37.380545\" , \"-122.073252\" ], ... ] } Click to expand or collapse example Navigation State payload when navigation no navigation is in progress { \"state\" : \"NOT_NAVIGATING\" , \"waypoints\" :[], \"shapes\" :[] }","title":"Examples of Navigation State Payload"},{"location":"modules/navigation/#starting-navigation","text":"To start navigation, the Engine publishes the StartNavigation message passing a JSON string payload containing the destination information. The following table explains the properties in the JSON. Property Type Required Description transportationMode String No The mode of transportation. Accepted Values: \"BIKING\" \"DRIVING\" \"TRANSIT\" \"WALKING\" waypoints Array Yes List of objects, each representing a waypoint that is a stop on the route. The properties use the same schema used for state reporting. See the Providing the Current Navigation State section. Click to expand or collapse the StartNavigation message payload schema { \"transportationMode\": \"DRIVING\", \"waypoints\":[ { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\" }, { \"type\":\"{{STRING}}\", \"estimatedTimeOfArrival\":{ \"ideal\":\"{{STRING}}\", \"predicted\":\"{{STRING}}\" }, \"address\":\"{{STRING}}\", \"coordinate\":[ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ], \"name\":\"{{STRING}}\", \"pointOfInterest\":{ \"id\":\"{{STRING}}\", \"hoursOfOperation\":[ { \"dayOfWeek\":\"{{STRING}}\", \"hours\":[ { \"open\":\"{{STRING}}\", \"close\":\"{{STRING}}\" } ], \"type\":\"{{STRING}}\" } ], \"phoneNumber\":\"{{STRING}}\" } } ] } } Note: The waypoints in the route are determined by Alexa either through a proximity search or by resolving the user's uploaded navigation favorite name to its location. Your implementation should calculate the route from the SOURCE waypoint to the DESTINATION waypoint, with stops along the way at INTERIM waypoints in the order in which they appear in the payload. If there are multiple routes, your implementation should either pick the fastest route if no user interaction is possible, or let the user choose the route. After the route is chosen, your implementation should start navigation. If navigation starts successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Starting Navigation","title":"Starting Navigation"},{"location":"modules/navigation/#stopping-navigation","text":"To stop navigation, the Engine publishes the CancelNavigation message . Consequently, when the Engine publishes the next GetNavigationState message the state should be NOT_NAVIGATING . Click to expand or collapse sequence diagram: Stopping Navigation","title":"Stopping Navigation"},{"location":"modules/navigation/#adding-a-waypoint","text":"If the user wants to add a waypoint, the Engine publishes the StartNavigation message . If navigation is in progress or route is present, the route to the final destination is changed by including the additional waypoint. Your implementation should calculate or re-calculate the route with the information of the waypoint. If the waypoint is added successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Adding a Waypoint","title":"Adding a Waypoint"},{"location":"modules/navigation/#canceling-a-waypoint","text":"If the user wants to cancel a waypoint, the Engine publishes the StartNavigation message after receiving the directive from Alexa with the updated waypoints. Your implementation should start navigation using the updated waypoints. If navigation is started successfully, your implementation should publish the NavigationEvent message with a NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or ROUTE_NOT_FOUND code. Click to expand or collapse sequence diagram: Canceling a Waypoint","title":"Canceling a Waypoint"},{"location":"modules/navigation/#showing-previous-waypoints","text":"If the user wants to display previous waypoints, the Engine publishes the ShowPreviousWaypoints message . Each waypoint displayed includes at least the address. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_WAYPOINTS_SHOWN event. Otherwise, it should publish the NavigationError message with the SHOW_PREVIOUS_WAYPOINTS_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Note: It is the responsibility of the navigation provider to store and provide the previous destination list to the user. Click to expand or collapse sequence diagram: Showing Previous Waypoints","title":"Showing Previous Waypoints"},{"location":"modules/navigation/#navigating-to-a-previous-waypoint","text":"If the user wants to navigate to a previous waypoint, the Engine publishes the NavigateToPreviousWaypoint message . The navigation app retrieves the most recently used destination, calculates a route from the current location, selects the fastest route or a route preferred by the user, and starts navigation. If the device can successfully display the previous waypoints, your implementation should publish the NavigationEvent message with a PREVIOUS_NAVIGATION_STARTED event. Otherwise, it should publish the NavigationError message with the PREVIOUS_NAVIGATION_START_FAILED type, and INTERNAL_SERVICE_ERROR or NO_PREVIOUS_WAYPOINTS code. Click to expand or collapse sequence diagram: Navigating to a Previous Waypoint","title":"Navigating to a Previous Waypoint"},{"location":"modules/navigation/#getting-turn-and-lane-guidance-information","text":"If the user wants to get turn and lane guidance, the Engine publishes the AnnounceManeuver message , passing a JSON string payload containing the manueuver information. The following table explains the properties in the JSON. Property Type Required Description type String Yes Specifies the type of information requested. Accepted values: \"TURN\" : The user asks about a turn. (e.g., \"What's my next turn?\") \"EXIT\" : The user asks about a freeway exit. (e.g., \"What's my next exit?\") \"ENTER\" : The user asks about how to get onto a street. (e.g., \"Which lane should I be to get onto the US-101?\") \"MERGE\" : The user asks about the merge onto a street. (e.g., \"Alexa, which lane do i need to merge onto the highway?\") \"LANE\" : The user asks for lane guidance. (e.g., \"Alexa, which lane to take?\") targetLocation Object No Describes the location for which maneuver information is requested. If the target location is a POI, user place, or street address, Alexa provides at least one field in this object. If the utterance does not include a location (e.g., \"Alexa, what's my next turn?\"), targetLocation is omitted. targetLocation.name String No Specifies the name of the location (e.g., \"HOME\" or \"WORK\") for which the user requests the maneuver instruction. targetLocation.address Object No Specifies the address for which the user requests the maneuver instruction. The object contains multiple string fields, which together form the complete address. targetLocation.coordinate Array No The array value specifies the latitude and longitude of the target location. Data type for the values in the array is double. Click to expand or collapse the AnnounceManeuver message schema { \"type\": \"{{STRING}}\", \"targetLocation\" : { \"name\": \"{{STRING}}\", \"address\": { \"addressLine1\": \"{{STRING}}\", \"addressLine2\": \"{{STRING}}\", \"addressLine3\": \"{{STRING}}\", \"city\": \"{{STRING}}\", \"districtOrCounty\": \"{{STRING}}\", \"stateOrRegion\": \"{{STRING}}\", \"countryCode\": \"{{STRING}}\", \"postalCode\": \"{{STRING}}\" }, \"coordinate\": [ {{LATITUDE_DOUBLE}}, {{LONGITUDE_DOUBLE}} ] } } Your implementation should provide the navigation instruction as follows: * If `targetLocation` is omitted, announce the next maneuver along the route. * If `targetLocation` is specified and the location is along the route, announce the maneuver about the location. If `targetLocation` is specified but the location is not along the route, calculate the route to the location, announce maneuver from the user's current location to the target location, and inform the user the target location is NOT along the current route. If the device can provide the maneuver instruction successfully, your implementation should publish the [`NavigationEvent` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationevent) with one of the following events: > **events:** `TURN_GUIDANCE_ANNOUNCED`, `EXIT_GUIDANCE_ANNOUNCED`, `ENTER_GUIDANCE_ANNOUNCED`, `MERGE_GUIDANCE_ANNOUNCED`, `LANE_GUIDANCE_ANNOUNCED` Otherwise, your implementation should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with a type and code from the following: > **types:** `TURN_GUIDANCE_FAILED`, `EXIT_GUIDANCE_FAILED`, `ENTER_GUIDANCE_FAILED`, `MERGE_GUIDANCE_FAILED`, `LANE_GUIDANCE_FAILED`\\ > **codes:** `INTERNAL_SERVICE_ERROR`, `ROUTE_NOT_FOUND`, `NOT_SUPPORTED` Click to expand or collapse sequence diagram: Getting Turn and Lane Guidance Information ![Announce_Maneuver_Guidance](./assets/announce_maneuver.png) ### Getting Road Regulation Information If the user wants to get road regulation information, the Engine publishes the [`AnnounceRoadRegulation` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#announceroadregulation), which passes a payload with the following schema: { \"type\": \"{{STRING}}\" } | Property | Type | Required | Description | |-|-|-|-| | type | String | Yes | Type of road regulation requested. **Accepted values:** `\"SPEED_LIMIT\"` specifies the speed limit at the current position (e.g., when the user asks, \"Alexa, what is the speed limit?\"). `\"CARPOOL_RULES\"` specifies the carpool regulations on the current highway (e.g., when the user asks, \"Alexa, is carpool free now?\"). | If the device can provide the road regulation information successfully, your implementation should publish the [`NavigationEvent` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationevent) with a `SPEED_LIMIT_REGULATION_ANNOUNCED` or `CARPOOL_RULES_REGULATION_ANNOUNCED` event. Otherwise, it should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with the `SPEED_LIMIT_REGULATION_FAILED` or `CARPOOL_RULES_REGULATION_FAILED` type, and `INTERNAL_SERVICE_ERROR` or `NOT_SUPPORTED` code. Click to expand or collapse sequence diagram: Getting Road Regulation Information ![Announce_Road_Regulation_Guidance](./assets/announce_road_regulation.png) ### Controlling the Display If the user wants to control the map display on the screen, the Engine publishes the [`ControlDisplay` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#controldisplay). If the device can adjust the display successfully, your implementation should publish the [`NavigationEvent` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationevent) with one of the following event: > **events:** `ROUTE_OVERVIEW_SHOWN`, `DIRECTIONS_LIST_SHOWN`, `ZOOMED_IN`, `ZOOMED_OUT`, `MAP_CENTERED`, `ORIENTED_NORTH`, `SCROLLED_NORTH`, `SCROLLED_UP`, `SCROLLED_EAST`, `SCROLLED_RIGHT`, `SCROLLED_SOUTH`, `SCROLLED_DOWN`, `SCROLLED_WEST`, `SCROLLED_LEFT`, `ROUTE_GUIDANCE_MUTED`, `ROUTE_GUIDANCE_UNMUTED` Otherwise, your implementation should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with a type and code from the following: > **types:** `ROUTE_OVERVIEW_FAILED`, `DIRECTIONS_LIST_FAILED`, `ZOOMED_IN_FAILED`, `ZOOMED_OUT_FAILED`, `MAP_CENTERED_FAILED`, `ORIENTED_NORTH_FAILED`, `SCROLLED_NORTH_FAILED`, `SCROLLED_UP_FAILED`, `SCROLLED_EAST_FAILED`, `SCROLLED_RIGHT_FAILED`, `SCROLLED_SOUTH_FAILED`, `SCROLLED_DOWN_FAILED`, `SCROLLED_WEST_FAILED`, `SCROLLED_LEFT_FAILED`, `ROUTE_GUIDANCE_MUTED_FAILED`, `ROUTE_GUIDANCE_UNMUTED_FAILED`\\ > **codes:** `INTERNAL_SERVICE_ERROR`, `ROUTE_NOT_FOUND`, `NOT_SUPPORTED`, `NOT_ALLOWED` Click to expand or collapse sequence diagram: Controlling the Display ![Map_Control](./assets/map_control.png) ### Showing Alternative Routes If the user wants to display alternative routes, the Engine publishes the [`ShowAlternativeRoutes` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#showalternativeroutes), which passes the type of alternate route to be displayed. If the device can display the alternative route successfully, your implementation should publish the [`ShowAlternativeRoutesSucceeded` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#showalternativeroutessucceeded) with a payload containing information about the alternative route. The following table explains the properties in the JSON. | Property | Type | Required | Description | |-|-|-|-| | inquiryType | String | Yes | The type of alternative routes based on the user's preference. **Accepted values:** `\"DEFAULT\"`, which means there is no preference as to whether the alternate route saves time or distance. `\"SHORTER_TIME\"`, which means the alternate route saves time. `\"SHORTER_DISTANCE\"`, which means the alternate route saves distance. | alternateRoute | Object | Yes | Information about the best route that matches the preference specified by `inquiryType`. | alternateRoute.labels | Array of strings |Yes | Unique names within a route (e.g., names of highways) used to distinguish between alternative routes. Each label might contain the direction of the route. | alternateRoute.savings | Array | No | List of savings achieved by the route. | alternateRoute.savings.type | String | Yes | The type of savings. **Accepted values:** `\"DISTANCE\"` or `\"TIME\"`. | alternateRoute.savings.amount | Float | Yes | The amount of savings achieved by the route. Alexa uses prescribed unit to convert the amount of savings to improve user experience, if needed. | alternateRoute.savings.unit | String | Yes | Measurement unit of the savings. **Accepted values:** `\"MINUTE\"`, `\"HOUR\"`, `\"YARD\"`, `\"FOOT\"`, `\"MILE\"`, `\"METER\"`, or `\"KILOMETER\"`. Click to expand or collapse the ShowAlternativeRoutesSucceeded message schema { \"inquiryType\": \"{{STRING}}\", \"alternateRoute\": { \"labels\": [\"{{STRING}}\"], \"savings\": [ { \"type\": \"{{STRING}}\", \"amount\": \"{{FLOAT}}\", \"unit\": \"{{STRING}}\" } ] } } Otherwise, your implementation should publish the [`NavigationError` message](https://alexa.github.io/alexa-auto-sdk/docs/sdk-docs/modules/navigation/aasb-docs/Navigation/index.html#navigationerror) with a type and code from the following: > **types:** `DEFAULT_ALTERNATE_ROUTES_FAILED`, `SHORTER_TIME_ROUTES_FAILED`, `SHORTER_DISTANCE_ROUTES_FAILED`\\ > **codes:** `INTERNAL_SERVICE_ERROR`, `ROUTE_NOT_FOUND`, `NOT_SUPPORTED`, `NOT_ALLOWED` Click to expand or collapse sequence diagram: Showing Alternative Routes ![Show_Alternate_Routes](./assets/show_alternate_routes.png) ## Integrating the Navigation Module Into Your Application ### C++ MessageBroker Integration Use the Engine's `MessageBroker` to subscribe to and publish *\"Navigation\"* AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/Navigation/Navigation/AlternateRouteType.h> #include <AASB/Message/Navigation/Navigation/ControlDisplay.h> #include <AASB/Message/Navigation/Navigation/ErrorCode.h> #include <AASB/Message/Navigation/Navigation/ErrorType.h> #include <AASB/Message/Navigation/Navigation/EventName.h> #include <AASB/Message/Navigation/Navigation/RoadRegulation.h> #include <AASB/Message/Navigation/Navigation/AnnounceManeuverMessage.h> #include <AASB/Message/Navigation/Navigation/AnnounceRoadRegulationMessage.h> #include <AASB/Message/Navigation/Navigation/CancelNavigationMessage.h> #include <AASB/Message/Navigation/Navigation/ControlDisplayMessage.h> #include <AASB/Message/Navigation/Navigation/GetNavigationStateMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationErrorMessage.h> #include <AASB/Message/Navigation/Navigation/NavigationEventMessage.h> #include <AASB/Message/Navigation/Navigation/NavigateToPreviousWaypointMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesMessage.h> #include <AASB/Message/Navigation/Navigation/ShowAlternativeRoutesSucceededMessage.h> #include <AASB/Message/Navigation/Navigation/ShowPreviousWaypointsMessage.h> #include <AASB/Message/Navigation/Navigation/StartNavigationMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyNavigationHandler { void MyNavigationHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceManeuverMessage ( message ); }, AnnounceManeuverMessage :: topic (), AnnounceManeuverMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnnounceRoadRegulationMessage ( message ); }, AnnounceRoadRegulationMessage :: topic (), AnnounceRoadRegulationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCancelNavigationMessage ( message ); }, CancelNavigationMessage :: topic (), CancelNavigationMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleControlDisplayMessage ( message ); }, ControlDisplayMessage :: topic (), ControlDisplayMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetNavigationStateMessage ( message ); }, GetNavigationStateMessage :: topic (), GetNavigationStateMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleNavigateToPreviousWaypointMessage ( message ); }, NavigateToPreviousWaypointMessage :: topic (), NavigateToPreviousWaypointMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowAlternativeRoutesMessage ( message ); }, ShowAlternativeRoutesMessage :: topic (), ShowAlternativeRoutesMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleShowPreviousWaypointsMessage ( message ); }, ShowPreviousWaypointsMessage :: topic (), ShowPreviousWaypointsMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStartNavigationMessage ( message ); }, StartNavigationMessage :: topic (), StartNavigationMessage :: action ()); } // Handle the AnnounceManeuver message from the Engine void MyNavigationHandler::handleAnnounceManeuverMessage ( const std :: string & message ) { AnnounceManeuverMessage msg = json :: parse ( message ); announceManeuver ( msg . payload . payload ); } // Handle the AnnounceRoadRegulation message from the Engine void MyNavigationHandler::handleAnnounceRoadRegulationMessage ( const std :: string & message ) { AnnounceRoadRegulationMessage msg = json :: parse ( message ); announceRoadRegulation ( msg . payload . roadRegulation ); } // Handle the CancelNavigation message from the Engine void MyNavigationHandler::handleCancelNavigationMessage ( const std :: string & message ) { cancelNavigation (); } // Handle the ControlDisplay message from the Engine void MyNavigationHandler::handleControlDisplayMessage ( const std :: string & message ) { ControlDisplayMessage msg = json :: parse ( message ); controlDisplay ( msg . payload . controlDisplay ); } // Handle the GetNavigationState message from the Engine and publish the // reply message containing the current navigation state void MyNavigationHandler::handleGetNavigationStateMessage ( const std :: string & message ) { GetNavigationStateMessage msg = json :: parse ( message ); GetNavigationStateMessageReply replyMsg ; replyMsg . header . messageDescription . replyToId = msg . header . id ; replyMsg . payload . navigationState = getNavigationState (); m_messageBroker -> publish ( replyMsg . toString ()); } // Handle the NavigateToPreviousWaypoint message from the Engine void MyNavigationHandler::handleNavigateToPreviousWaypointMessage ( const std :: string & message ) { navigateToPreviousWaypoint (); } // Handle the ShowAlternativeRoutes message from the Engine void MyNavigationHandler::handleShowAlternativeRoutesMessage ( const std :: string & message ) { ShowAlternativeRoutesMessage msg = json :: parse ( message ); showAlternativeRoutes ( msg . payload . alternateRouteType ); } // Handle the ShowPreviousWaypoints message from the Engine void MyNavigationHandler::handleShowPreviousWaypointsMessage ( const std :: string & message ) { showPreviousWaypoints (); } // Handle the StartNavigation message from the Engine void MyNavigationHandler::handleStartNavigationMessage ( const std :: string & message ) { StartNavigationMessage msg = json :: parse ( message ); startNavigation ( msg . payload . payload ); } void MyNavigationHandler::navigationError ( ErrorType type , ErrorCode code , const std :: string & description ) { NavigationErrorMessage msg ; msg . payload . type = type ; msg . payload . code = code ; msg . payload . description = description ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::navigationEvent ( EventName event ) { NavigationEventMessage msg ; msg . payload . event = event ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::showAlternativeRoutesSucceeded ( const std :: string & payload ) { ShowAlternativeRoutesSucceededMessage msg ; msg . payload . payload = payload ; m_messageBroker -> publish ( msg . toString ()); } void MyNavigationHandler::startNavigation ( const std :: string & payload ) { // Update the previous destinations list // Call navigationEvent(EventName::NAVIGATION_STARTED) // If error occurs call navigationError() with ErrorType::NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void MyNavigationHandler::navigateToPreviousWaypoint () { // Call navigationEvent(EventName::PREVIOUS_NAVIGATION_STARTED) // If any error occurs call navigationError() with ErrorType::PREVIOUS_NAVIGATION_START_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showPreviousWaypoints () { // Call navigationEvent(EventName::PREVIOUS_WAYPOINTS_SHOWN) // If error occurs call navigationError() with ErrorType::SHOW_PREVIOUS_WAYPOINTS_FAILED and the ErrorCode describing the type of failure } void NavigationHandler::showAlternativeRoutes ( AlternateRouteType alternateRouteType ) { // Based on the AlternativeRouteType obtain the alternative route information // Call showAlternativeRoutesSucceeded() // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::controlDisplay ( ControlDisplay controlDisplay ) { // Call navigationEvent() for the requested map control request // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceManeuver ( const std :: string & payload ) { // Call navigationEvent() for the requested manueuver instruction // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } void NavigationHandler::announceRoadRegulation ( RoadRegulation roadRegulation ) { // Call navigationEvent() for the requested road regulation // If error occurs call navigationError() with ErrorType and ErrorCode describing failure } bool NavigationHandler::cancelNavigation () { // Clear the navigation state } std :: string NavigationHandler::getNavigationState () { // Return current navigation state } }; ### Android Integration The Alexa Auto Client Service (AACS) provides the `Navigation App Component` to integrate the Auto SDK `Navigation` module on Android. See the [AACS Navigation App Component documentation](../../aacs/android/app-components/alexa-auto-navigation/README.md) for more information.","title":"Getting Turn and Lane Guidance Information"},{"location":"modules/navigation/aasb-docs/Navigation/","text":"Navigation Outgoing Messages ShowAlternativeRoutes Notifies the platform implementation to show alternative routes. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutes\" } }, \"payload\": { \"alternateRouteType\": {{AlternateRouteType}} } } Payload Property Type Required Description Example alternateRouteType AlternateRouteType Yes alternateRouteType The type of alternate route requested. ShowPreviousWaypoints Notifies the platform implementation to display list of previous waypoints. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowPreviousWaypoints\" } } } ControlDisplay Notifies the platform implementation to perform user interaction with the onscreen map application. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ControlDisplay\" } }, \"payload\": { \"controlDisplay\": {{ControlDisplay}} } } Payload Property Type Required Description Example controlDisplay ControlDisplay Yes the user requested map control. AnnounceRoadRegulation Notifies the platform implementation to give details about road regulations about the road segments that the user is on. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceRoadRegulation\" } }, \"payload\": { \"roadRegulation\": {{RoadRegulation}} } } Payload Property Type Required Description Example roadRegulation RoadRegulation Yes Type of road regulation requested. CancelNavigation Notifies the platform implementation to cancel navigation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"CancelNavigation\" } } } AnnounceManeuver Notifies the platform implementation to give details about a maneuver to next waypoint on the route or a completely different waypoint off route. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceManeuver\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes JSON data containing the manueuver information. NavigateToPreviousWaypoint Notifies the platform implementation to start navigation to the previous waypoint. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigateToPreviousWaypoint\" } } } GetNavigationState Retrieve the navigation state from the platform. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\" } } } GetNavigationStateReply Reply for GetNavigationState message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\", \"replyToId\": {{String}} } }, \"payload\": { \"navigationState\": {{String}} } } Payload Property Type Required Description Example navigationState String Yes the current NavigationState JSON payload. StartNavigation Notifies the platform implementation to start the navigation. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"StartNavigation\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes JSON data containing the destination information. Incoming Messages ShowAlternativeRoutesSucceeded Notifies AVS of successful showing of alternative routes to the user. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutesSucceeded\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes data containing the alternative route information. NavigationError Notifies the Engine of error in handling a Navigation directive. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationError\" } }, \"payload\": { \"type\": {{ErrorType}}, \"code\": {{ErrorCode}}, \"description\": {{String}} } } Payload Property Type Required Description Example type ErrorType Yes ErrorType describing which operation failed. code ErrorCode Yes ErrorCode describing the type of failure. description String Yes String providing additional information. NavigationEvent Notifies the Engine of successful handling of a Navigation directive. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationEvent\" } }, \"payload\": { \"event\": {{EventName}} } } Payload Property Type Required Description Example event EventName Yes EventName describing which operation was successful. Enums AlternateRouteType Values Value Description \"DEFAULT\" description for DEFAULT. \"SHORTER_TIME\" description for SHORTER_TIME. \"SHORTER_DISTANCE\" description for SHORTER_DISTANCE. ControlDisplay Values Value Description \"SHOW_ROUTE_OVERVIEW\" description for SHOW_ROUTE_OVERVIEW. \"SHOW_DIRECTIONS_LIST\" description for SHOW_DIRECTIONS_LIST. \"ZOOM_IN\" description for ZOOM_IN. \"ZOOM_OUT\" description for ZOOM_OUT. \"CENTER_MAP_ON_CURRENT_LOCATION\" description for CENTER_MAP_ON_CURRENT_LOCATION. \"ORIENT_NORTH\" description for ORIENT_NORTH. \"SCROLL_NORTH\" description for SCROLL_NORTH. \"SCROLL_UP\" description for SCROLL_UP. \"SCROLL_EAST\" description for SCROLL_EAST. \"SCROLL_RIGHT\" description for SCROLL_RIGHT. \"SCROLL_SOUTH\" description for SCROLL_SOUTH. \"SCROLL_DOWN\" description for SCROLL_DOWN. \"SCROLL_WEST\" description for SCROLL_WEST. \"SCROLL_LEFT\" description for SCROLL_LEFT. \"MUTE_ROUTE_GUIDANCE\" navigation sounds off. \"UNMUTE_ROUTE_GUIDANCE\" navigation sounds on. RoadRegulation Values Value Description \"SPEED_LIMIT\" description for SHOW_ROUTE_OVERVIEW. \"CARPOOL_RULES\" description for SHOW_DIRECTIONS_LIST. ErrorType Values Value Description \"NAVIGATION_START_FAILED\" Navigation failed to start. Send in response to startNavigation() directive. \"SHOW_PREVIOUS_WAYPOINTS_FAILED\" List of previous waypoints failed to display. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_START_FAILED\" The previous navigation route failed to start. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_FAILED\" Overview of route was failed to display. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_FAILED\" List of directions was failed to display. Send in response to controlDisplay() directive. \"ZOOM_IN_FAILED\" Map zoom-in unsuccessful. Send in response to controlDisplay() directive. \"ZOOM_OUT_FAILED\" Map zoom-out unsuccessful. Send in response to controlDisplay() directive. \"CENTER_FAILED\" Map centering unsuccessful. Send in response to controlDisplay() directive. \"ORIENT_NORTH_FAILED\" Map alignment to north unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_NORTH_FAILED\" Moving map North was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_UP_FAILED\" Moving map upwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_EAST_FAILED\" Moving map East was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_RIGHT_FAILED\" Moving map rightwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_SOUTH_FAILED\" Moving map South was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_DOWN_FAILED\" Moving map downwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_WEST_FAILED\" Moving map west was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_LEFT_FAILED\" Moving map leftwards was unsuccessful. Send in response to controlDisplay() directive. \"MUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be muted. Send in response to controlDisplay() directive. \"UNMUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_FAILED\" Displaying default alternate routes was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_FAILED\" Displaying alternate routes with shorter times was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_FAILED\" Displaying alternate routes with shorter distances was unsuccessful. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_FAILED\" Next turn announcement was unsuccessful. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_FAILED\" Next exit announcement was unsuccessful. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_FAILED\" Announcement for entering directions was unsuccessful. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_FAILED\" Announcement for merging directions was unsuccessful. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_FAILED\" Lane guidance announcement was unsuccessful. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_FAILED\" Current speed limit announcement was unsuccessful. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_FAILED\" Carpool status announcement was unsuccessful. Send in response to announceRoadRegulation() directive. ErrorCode Values Value Description \"INTERNAL_SERVICE_ERROR\" Failure caused by an unexpected service or client implementation error. \"ROUTE_NOT_FOUND\" Failed because the route could not be found. \"NO_PREVIOUS_WAYPOINTS\" Failed because there are no previous waypoints available. \"NOT_SUPPORTED\" The operation requested is not supported or implemented. \"NOT_ALLOWED\" The operation requested can't be performed now. EventName Values Value Description \"NAVIGATION_STARTED\" Navigation was started. Send in response to startNavigation() directive. \"PREVIOUS_WAYPOINTS_SHOWN\" List of previous waypoints was displayed. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_STARTED\" The previous navigation route was started. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_SHOWN\" Overview of route was displayed. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_SHOWN\" List of directions was displayed. Send in response to controlDisplay() directive. \"ZOOMED_IN\" Map successfully zoomed in. Send in response to controlDisplay() directive. \"ZOOMED_OUT\" Map successfully zoomed out. Send in response to controlDisplay() directive. \"MAP_CENTERED\" Map successfully centered. Send in response to controlDisplay() directive. \"ORIENTED_NORTH\" Map successfully aligned with north up. Send in response to controlDisplay() directive. \"SCROLLED_NORTH\" Map successfully moved in North direction. Send in response to controlDisplay() directive. \"SCROLLED_UP\" Map successfully moved upwards. Send in response to controlDisplay() directive. \"SCROLLED_EAST\" Map successfully moved in East direction. Send in response to controlDisplay() directive. \"SCROLLED_RIGHT\" Map successfully moved rightwards. Send in response to controlDisplay() directive. \"SCROLLED_SOUTH\" Map successfully moved in South direction. Send in response to controlDisplay() directive. \"SCROLLED_DOWN\" Map successfully moved downwards. Send in response to controlDisplay() directive. \"SCROLLED_WEST\" Map successfully moved in West direction. Send in response to controlDisplay() directive. \"SCROLLED_LEFT\" Map successfully moved leftwards. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_MUTED\" Map sounds were muted. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_UNMUTED\" Map sounds were unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_SHOWN\" Default alternate routes were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_SHOWN\" Alternate routes with shorter times were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_SHOWN\" Alternate routes with shorter distances were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_ANNOUNCED\" Next turn was successfully announced. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_ANNOUNCED\" Next exit was successfully announced. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_ANNOUNCED\" Directions for entering successfully announced. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_ANNOUNCED\" Directions for merging successfully announced. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_ANNOUNCED\" Lane guidance was successfully announced. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_ANNOUNCED\" Current speed limit successfully announced. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_ANNOUNCED\" Carpool status successfully announced. Send in response to announceRoadRegulation() directive.","title":"Navigation"},{"location":"modules/navigation/aasb-docs/Navigation/#navigation","text":"","title":"Navigation"},{"location":"modules/navigation/aasb-docs/Navigation/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/navigation/aasb-docs/Navigation/#showalternativeroutes","text":"Notifies the platform implementation to show alternative routes.","title":"ShowAlternativeRoutes"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutes\" } }, \"payload\": { \"alternateRouteType\": {{AlternateRouteType}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload","text":"Property Type Required Description Example alternateRouteType AlternateRouteType Yes alternateRouteType The type of alternate route requested.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#showpreviouswaypoints","text":"Notifies the platform implementation to display list of previous waypoints.","title":"ShowPreviousWaypoints"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowPreviousWaypoints\" } } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#controldisplay","text":"Notifies the platform implementation to perform user interaction with the onscreen map application.","title":"ControlDisplay"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ControlDisplay\" } }, \"payload\": { \"controlDisplay\": {{ControlDisplay}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_1","text":"Property Type Required Description Example controlDisplay ControlDisplay Yes the user requested map control.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#announceroadregulation","text":"Notifies the platform implementation to give details about road regulations about the road segments that the user is on.","title":"AnnounceRoadRegulation"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceRoadRegulation\" } }, \"payload\": { \"roadRegulation\": {{RoadRegulation}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_2","text":"Property Type Required Description Example roadRegulation RoadRegulation Yes Type of road regulation requested.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#cancelnavigation","text":"Notifies the platform implementation to cancel navigation.","title":"CancelNavigation"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"CancelNavigation\" } } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#announcemaneuver","text":"Notifies the platform implementation to give details about a maneuver to next waypoint on the route or a completely different waypoint off route.","title":"AnnounceManeuver"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"AnnounceManeuver\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_3","text":"Property Type Required Description Example payload String Yes JSON data containing the manueuver information.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#navigatetopreviouswaypoint","text":"Notifies the platform implementation to start navigation to the previous waypoint.","title":"NavigateToPreviousWaypoint"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigateToPreviousWaypoint\" } } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#getnavigationstate","text":"Retrieve the navigation state from the platform.","title":"GetNavigationState"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\" } } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#getnavigationstatereply","text":"Reply for GetNavigationState message.","title":"GetNavigationStateReply"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"GetNavigationState\", \"replyToId\": {{String}} } }, \"payload\": { \"navigationState\": {{String}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_4","text":"Property Type Required Description Example navigationState String Yes the current NavigationState JSON payload.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#startnavigation","text":"Notifies the platform implementation to start the navigation.","title":"StartNavigation"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"StartNavigation\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_5","text":"Property Type Required Description Example payload String Yes JSON data containing the destination information.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/navigation/aasb-docs/Navigation/#showalternativeroutessucceeded","text":"Notifies AVS of successful showing of alternative routes to the user.","title":"ShowAlternativeRoutesSucceeded"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"ShowAlternativeRoutesSucceeded\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_6","text":"Property Type Required Description Example payload String Yes data containing the alternative route information.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#navigationerror","text":"Notifies the Engine of error in handling a Navigation directive.","title":"NavigationError"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationError\" } }, \"payload\": { \"type\": {{ErrorType}}, \"code\": {{ErrorCode}}, \"description\": {{String}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_7","text":"Property Type Required Description Example type ErrorType Yes ErrorType describing which operation failed. code ErrorCode Yes ErrorCode describing the type of failure. description String Yes String providing additional information.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#navigationevent","text":"Notifies the Engine of successful handling of a Navigation directive.","title":"NavigationEvent"},{"location":"modules/navigation/aasb-docs/Navigation/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"Navigation\", \"action\": \"NavigationEvent\" } }, \"payload\": { \"event\": {{EventName}} } }","title":"JSON Structure"},{"location":"modules/navigation/aasb-docs/Navigation/#payload_8","text":"Property Type Required Description Example event EventName Yes EventName describing which operation was successful.","title":"Payload"},{"location":"modules/navigation/aasb-docs/Navigation/#enums","text":"","title":"Enums"},{"location":"modules/navigation/aasb-docs/Navigation/#alternateroutetype","text":"","title":"AlternateRouteType"},{"location":"modules/navigation/aasb-docs/Navigation/#values","text":"Value Description \"DEFAULT\" description for DEFAULT. \"SHORTER_TIME\" description for SHORTER_TIME. \"SHORTER_DISTANCE\" description for SHORTER_DISTANCE.","title":"Values"},{"location":"modules/navigation/aasb-docs/Navigation/#controldisplay_1","text":"","title":"ControlDisplay"},{"location":"modules/navigation/aasb-docs/Navigation/#values_1","text":"Value Description \"SHOW_ROUTE_OVERVIEW\" description for SHOW_ROUTE_OVERVIEW. \"SHOW_DIRECTIONS_LIST\" description for SHOW_DIRECTIONS_LIST. \"ZOOM_IN\" description for ZOOM_IN. \"ZOOM_OUT\" description for ZOOM_OUT. \"CENTER_MAP_ON_CURRENT_LOCATION\" description for CENTER_MAP_ON_CURRENT_LOCATION. \"ORIENT_NORTH\" description for ORIENT_NORTH. \"SCROLL_NORTH\" description for SCROLL_NORTH. \"SCROLL_UP\" description for SCROLL_UP. \"SCROLL_EAST\" description for SCROLL_EAST. \"SCROLL_RIGHT\" description for SCROLL_RIGHT. \"SCROLL_SOUTH\" description for SCROLL_SOUTH. \"SCROLL_DOWN\" description for SCROLL_DOWN. \"SCROLL_WEST\" description for SCROLL_WEST. \"SCROLL_LEFT\" description for SCROLL_LEFT. \"MUTE_ROUTE_GUIDANCE\" navigation sounds off. \"UNMUTE_ROUTE_GUIDANCE\" navigation sounds on.","title":"Values"},{"location":"modules/navigation/aasb-docs/Navigation/#roadregulation","text":"","title":"RoadRegulation"},{"location":"modules/navigation/aasb-docs/Navigation/#values_2","text":"Value Description \"SPEED_LIMIT\" description for SHOW_ROUTE_OVERVIEW. \"CARPOOL_RULES\" description for SHOW_DIRECTIONS_LIST.","title":"Values"},{"location":"modules/navigation/aasb-docs/Navigation/#errortype","text":"","title":"ErrorType"},{"location":"modules/navigation/aasb-docs/Navigation/#values_3","text":"Value Description \"NAVIGATION_START_FAILED\" Navigation failed to start. Send in response to startNavigation() directive. \"SHOW_PREVIOUS_WAYPOINTS_FAILED\" List of previous waypoints failed to display. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_START_FAILED\" The previous navigation route failed to start. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_FAILED\" Overview of route was failed to display. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_FAILED\" List of directions was failed to display. Send in response to controlDisplay() directive. \"ZOOM_IN_FAILED\" Map zoom-in unsuccessful. Send in response to controlDisplay() directive. \"ZOOM_OUT_FAILED\" Map zoom-out unsuccessful. Send in response to controlDisplay() directive. \"CENTER_FAILED\" Map centering unsuccessful. Send in response to controlDisplay() directive. \"ORIENT_NORTH_FAILED\" Map alignment to north unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_NORTH_FAILED\" Moving map North was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_UP_FAILED\" Moving map upwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_EAST_FAILED\" Moving map East was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_RIGHT_FAILED\" Moving map rightwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_SOUTH_FAILED\" Moving map South was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_DOWN_FAILED\" Moving map downwards was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_WEST_FAILED\" Moving map west was unsuccessful. Send in response to controlDisplay() directive. \"SCROLL_LEFT_FAILED\" Moving map leftwards was unsuccessful. Send in response to controlDisplay() directive. \"MUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be muted. Send in response to controlDisplay() directive. \"UNMUTED_ROUTE_GUIDANCE_FAILED\" Map sounds failed to be unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_FAILED\" Displaying default alternate routes was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_FAILED\" Displaying alternate routes with shorter times was unsuccessful. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_FAILED\" Displaying alternate routes with shorter distances was unsuccessful. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_FAILED\" Next turn announcement was unsuccessful. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_FAILED\" Next exit announcement was unsuccessful. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_FAILED\" Announcement for entering directions was unsuccessful. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_FAILED\" Announcement for merging directions was unsuccessful. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_FAILED\" Lane guidance announcement was unsuccessful. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_FAILED\" Current speed limit announcement was unsuccessful. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_FAILED\" Carpool status announcement was unsuccessful. Send in response to announceRoadRegulation() directive.","title":"Values"},{"location":"modules/navigation/aasb-docs/Navigation/#errorcode","text":"","title":"ErrorCode"},{"location":"modules/navigation/aasb-docs/Navigation/#values_4","text":"Value Description \"INTERNAL_SERVICE_ERROR\" Failure caused by an unexpected service or client implementation error. \"ROUTE_NOT_FOUND\" Failed because the route could not be found. \"NO_PREVIOUS_WAYPOINTS\" Failed because there are no previous waypoints available. \"NOT_SUPPORTED\" The operation requested is not supported or implemented. \"NOT_ALLOWED\" The operation requested can't be performed now.","title":"Values"},{"location":"modules/navigation/aasb-docs/Navigation/#eventname","text":"","title":"EventName"},{"location":"modules/navigation/aasb-docs/Navigation/#values_5","text":"Value Description \"NAVIGATION_STARTED\" Navigation was started. Send in response to startNavigation() directive. \"PREVIOUS_WAYPOINTS_SHOWN\" List of previous waypoints was displayed. Send in response to showPreviousWaypoints() directive. \"PREVIOUS_NAVIGATION_STARTED\" The previous navigation route was started. Send in response to navigateToPreviousWaypoint() directive. \"ROUTE_OVERVIEW_SHOWN\" Overview of route was displayed. Send in response to controlDisplay() directive. \"DIRECTIONS_LIST_SHOWN\" List of directions was displayed. Send in response to controlDisplay() directive. \"ZOOMED_IN\" Map successfully zoomed in. Send in response to controlDisplay() directive. \"ZOOMED_OUT\" Map successfully zoomed out. Send in response to controlDisplay() directive. \"MAP_CENTERED\" Map successfully centered. Send in response to controlDisplay() directive. \"ORIENTED_NORTH\" Map successfully aligned with north up. Send in response to controlDisplay() directive. \"SCROLLED_NORTH\" Map successfully moved in North direction. Send in response to controlDisplay() directive. \"SCROLLED_UP\" Map successfully moved upwards. Send in response to controlDisplay() directive. \"SCROLLED_EAST\" Map successfully moved in East direction. Send in response to controlDisplay() directive. \"SCROLLED_RIGHT\" Map successfully moved rightwards. Send in response to controlDisplay() directive. \"SCROLLED_SOUTH\" Map successfully moved in South direction. Send in response to controlDisplay() directive. \"SCROLLED_DOWN\" Map successfully moved downwards. Send in response to controlDisplay() directive. \"SCROLLED_WEST\" Map successfully moved in West direction. Send in response to controlDisplay() directive. \"SCROLLED_LEFT\" Map successfully moved leftwards. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_MUTED\" Map sounds were muted. Send in response to controlDisplay() directive. \"ROUTE_GUIDANCE_UNMUTED\" Map sounds were unmuted. Send in response to controlDisplay() directive. \"DEFAULT_ALTERNATE_ROUTES_SHOWN\" Default alternate routes were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_TIME_ROUTES_SHOWN\" Alternate routes with shorter times were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"SHORTER_DISTANCE_ROUTES_SHOWN\" Alternate routes with shorter distances were successfully found and displayed. Send in response to showAlternativeRoutes() directive. \"TURN_GUIDANCE_ANNOUNCED\" Next turn was successfully announced. Send in response to announceManeuver() directive. \"EXIT_GUIDANCE_ANNOUNCED\" Next exit was successfully announced. Send in response to announceManeuver() directive. \"ENTER_GUIDANCE_ANNOUNCED\" Directions for entering successfully announced. Send in response to announceManeuver() directive. \"MERGE_GUIDANCE_ANNOUNCED\" Directions for merging successfully announced. Send in response to announceManeuver() directive. \"LANE_GUIDANCE_ANNOUNCED\" Lane guidance was successfully announced. Send in response to announceManeuver() directive. \"SPEED_LIMIT_REGULATION_ANNOUNCED\" Current speed limit successfully announced. Send in response to announceRoadRegulation() directive. \"CARPOOL_RULES_REGULATION_ANNOUNCED\" Carpool status successfully announced. Send in response to announceRoadRegulation() directive.","title":"Values"},{"location":"modules/phone-control/","text":"Phone Call Controller Module Table of Contents Overview Configuring the Phone Call Controller Module Using the Phone Call Controller AASB Messages Integrating the Phone Call Controller Module Into Your Application Overview The Phone Call Controller module enables your Alexa Auto SDK client application to use the phone call control capabilities of Alexa, independent of the connection mechanism to the calling device. By using this module in your application, you allow the end user to interact with new or ongoing calls using Alexa, and you provide Alexa with the state of the calling device. The Phone Call Controller uses phone contacts uploaded via the Address Book module . Your application's Phone Call Controller module integration is responsible for managing the lifecycle of the call session, including enhancing the end user experience by: Preventing Alexa Text To Speech (TTS) from being fed back into the microphone when the user triggers Alexa during a call. To accomplish this, your implementation should stop feeding the microphone input into the call channel until Alexa returns to the idle state, and it should also specify strong echo cancellation. Lowering the audio level of previous media in response to an incoming call until the call is answered or declined (if ducking is supported) and pausing the media if the call is answered. Maintaining the last dialed number to support redialing. Configuring the Phone Call Controller Module The Phone Call Controller module does not require Engine configuration. Using the Phone Call Controller AASB Messages Changing Connection State When connection to a calling device is established or terminated, publish the ConnectionStateChanged message . Click to expand or collapse sequence diagram: Connection State Changed Updating Device Configuration To update the device configuration of the connected calling device, publish the DeviceConfigurationUpdated message . Note: The Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Click to expand or collapse sequence diagram: Device Configuration Updated Calling Whether the call is initiated by Alexa or by the user, during the call session your application is responsible for publishing CallStateChanged messages to inform the Engine of the progression of the call (e.g., call is answered, call ended) while the Engine publishes messages to the application in order to handle user interactions with the call (e.g., answer, dial, stop). Regardless of whether the call is inbound or outbound: * During a call if the user asks Alexa to press the keypad, the Engine publishes the SendDTMF message . Your application must handle this message and publish either the SendDTMFSucceeded message or SendDTMFFailed message to indicate its completion or failure, respectively. * If an error occurrs during an active call or call setup, publish the CallFailed message specifying the error. * When the user asks Alexa to hang up a call, cancel a call setup, or decline an incoming call the Engine publishes the Stop message . Inbound Calling When an inbound call is detected, publish the CreateCallId message . In response, the Engine will publish the CreateCallId reply containing a unique identifier for the call. Once an inbound call alert is received, your application must publish the CallStateChanged message indicating the call is now in the CALL_RECEIVED state. When the inbound call begins ringing, publish the CallStateChanged message, this time specifying the INBOUND_RINGING call state. If the user asks Alexa to answer the inbound call, the Engine publishes the Answer message . Publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Note: When a caller id is received for an inbound call, publish the CallerIdReceived message . Click to expand or collapse sequence diagram: Inbound Calling Outbound Calling When a user asks Alexa to dial a number or call an uploaded contact, the Engine publishes the Dial message . Alternatively, if the user asks Alexa to redial the last dialed number, the Engine publishes the Redial message . In both cases, your application must publish the CallStateChanged message indicating the call is now in the DIALING state. Once the outgoing call setup is complete and outbound ringing has started, publish the CallStateChanged message specifying the OUTBOUND_RINGING call state. If the call is answered and in progress, publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Click to expand or collapse sequence diagram: Outbound Calling Integrating the Phone Call Controller Module Into Your Application Use the Engine's MessageBroker to subscribe to and publish \"PhoneCallController\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallingDeviceConfigurationProperty.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DTMFError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/AnswerMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallerIdReceivedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CreateCallIdMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DeviceConfigurationUpdatedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/RedialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFSucceededMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/StopMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPhoneCallControllerHandler { // Subscribe to messages from the Engine void MyPhoneCallControllerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnswerMessage ( message ); }, AnswerMessage :: topic (), AnswerMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleDialMessage ( message ); }, DialMessage :: topic (), DialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRedialMessage ( message ); }, RedialMessage :: topic (), RedialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendDMTFMessage ( message ); }, SendDTMFMessage :: topic (), SendDTMFMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCreateCallIdReplyMessage ( message ); }, CreateCallIdMessageReply :: topic (), CreateCallIdMessageReply :: action ()); } // Handle the Answer message from the Engine void MyPhoneCallControllerHandler::handleAnswerMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); answer ( msg . payload . payload ); } // Handle the Dial message from the Engine void MyPhoneCallControllerHandler::handleDialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); std :: string payload = msg . payload . payload ; dial ( msg . payload . payload ); } // Handle the Redial message from the Engine void MyPhoneCallControllerHandler::handleRedialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); redial ( msg . payload . payload ); } // Handle the SendDTMF message from the Engine void MyPhoneCallControllerHandler::handleSendDMTFMessage ( const std :: string & message ) { SendDTMFMessage msg = json :: parse ( message ); sendDTMF ( msg . payload . payload ); } // Handle the Stop message from the Engine void MyPhoneCallControllerHandler::handleStopMessage ( const std :: string & message ) { StopMessage msg = json :: parse ( message ); stop ( msg . payload . payload ); } // Handle the CreateCallId reply message from the Engine void MyPhoneCallControllerHandler::handleCreateCallIdReplyMessage ( const std :: string & message ) { CreateCallIdMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string callId = msg . payload . callId ; // ...Handle the generated call id... } // When an error occurrs during an active call or call setup, publish a CallFailed // message to the Engine void MyPhoneCallControllerHandler::callFailed ( const std :: string & callId , CallError code , const std :: string & message ) { CallFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the call state changes, publish a CallStateChanged message to the Engine void MyPhoneCallControllerHandler::callStateChanged ( CallState state , const std :: string & callId , const std :: string & callerId ) { CallStateChangedMessage msg ; msg . payload . state = state ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When a caller id is received for an inbound call, publish a CallerIdReceived // message to the Engine void MyPhoneCallControllerHandler::callerIdReceived ( const std :: string & callId , const std :: string & callerId ) { CallerIdReceivedMessage msg ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When connection to a calling device is established or broken, publish a // ConnectionStateChanged message to the Engine void MyPhoneCallControllerHandler::connectionStateChanged ( ConnectionState state ) { ConnectionStateChangedMessage msg ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } // To generate an identifier for a call, publish a CreateCallId message to the Engine std :: string MyPhoneCallControllerHandler::createCallId () { CreateCallIdMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the CreateCallIdReply message // Return the unique identifier from reply message payload } // When a feature of the calling device changes, publish a // DeviceConfigurationUpdated message to the Engine void MyPhoneCallControllerHandler::deviceConfigurationUpdated ( std :: unordered_map < CallingDeviceConfigurationProperty , bool > configurationMap ) { json configuration ; for ( auto it : configurationMap ) { configuration [ configurationFeatureToString ( it . first )] = it . second ; } DeviceConfigurationUpdatedMessage msg ; msg . payload . configurationMap = configuration . dump (); m_messageBroker -> publish ( msg . toString ()); } // When the DTMF signal is delivered, publish a SendDTMFSucceeded message to the Engine void MyPhoneCallControllerHandler::sendDTMFSucceeded ( const std :: string & callId ) { SendDTMFSucceededMessage msg ; msg . payload . callId = callId ; m_messageBroker -> publish ( msg . toString ()); } // When sending the DTMF signal failed, publish a SendDTMFFailed message to the Engine void MyPhoneCallControllerHandler::sendDTMFFailed ( const std :: string & callId , DTMFError code , const std :: string & message ) { SendDTMFFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } void MyPhoneCallControllerHandler::answer ( const std :: string & payload ) { // Answer the inbound call } void MyPhoneCallControllerHandler::dial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::redial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::stop ( const std :: string & payload ) { // Stop the call } void MyPhoneCallControllerHandler::sendDTMF ( const std :: string & payload ) { // Send a DTMF signal } // Implement to convert CallingDeviceConfigurationProperty to string std :: string MyPhoneCallControllerHandler::configurationFeatureToString ( CallingDeviceConfigurationProperty feature ); }; Android Integration The Alexa Auto Client Service (AACS) provides the AACS Telephony Library to integrate the Auto SDK Phone Call Controller module on Android. See the AACS Telephony Library documentation for more information.","title":"Phone Call Controller Module"},{"location":"modules/phone-control/#phone-call-controller-module","text":"Table of Contents Overview Configuring the Phone Call Controller Module Using the Phone Call Controller AASB Messages Integrating the Phone Call Controller Module Into Your Application","title":"Phone Call Controller Module"},{"location":"modules/phone-control/#overview","text":"The Phone Call Controller module enables your Alexa Auto SDK client application to use the phone call control capabilities of Alexa, independent of the connection mechanism to the calling device. By using this module in your application, you allow the end user to interact with new or ongoing calls using Alexa, and you provide Alexa with the state of the calling device. The Phone Call Controller uses phone contacts uploaded via the Address Book module . Your application's Phone Call Controller module integration is responsible for managing the lifecycle of the call session, including enhancing the end user experience by: Preventing Alexa Text To Speech (TTS) from being fed back into the microphone when the user triggers Alexa during a call. To accomplish this, your implementation should stop feeding the microphone input into the call channel until Alexa returns to the idle state, and it should also specify strong echo cancellation. Lowering the audio level of previous media in response to an incoming call until the call is answered or declined (if ducking is supported) and pausing the media if the call is answered. Maintaining the last dialed number to support redialing.","title":"Overview "},{"location":"modules/phone-control/#configuring-the-phone-call-controller-module","text":"The Phone Call Controller module does not require Engine configuration.","title":"Configuring the Phone Call Controller Module "},{"location":"modules/phone-control/#using-the-phone-call-controller-aasb-messages","text":"","title":"Using the Phone Call Controller AASB Messages "},{"location":"modules/phone-control/#changing-connection-state","text":"When connection to a calling device is established or terminated, publish the ConnectionStateChanged message . Click to expand or collapse sequence diagram: Connection State Changed","title":"Changing Connection State"},{"location":"modules/phone-control/#updating-device-configuration","text":"To update the device configuration of the connected calling device, publish the DeviceConfigurationUpdated message . Note: The Auto SDK only supports updates to DTMF_SUPPORTED to enable or disable SendDTMF . Click to expand or collapse sequence diagram: Device Configuration Updated","title":"Updating Device Configuration"},{"location":"modules/phone-control/#calling","text":"Whether the call is initiated by Alexa or by the user, during the call session your application is responsible for publishing CallStateChanged messages to inform the Engine of the progression of the call (e.g., call is answered, call ended) while the Engine publishes messages to the application in order to handle user interactions with the call (e.g., answer, dial, stop). Regardless of whether the call is inbound or outbound: * During a call if the user asks Alexa to press the keypad, the Engine publishes the SendDTMF message . Your application must handle this message and publish either the SendDTMFSucceeded message or SendDTMFFailed message to indicate its completion or failure, respectively. * If an error occurrs during an active call or call setup, publish the CallFailed message specifying the error. * When the user asks Alexa to hang up a call, cancel a call setup, or decline an incoming call the Engine publishes the Stop message .","title":"Calling"},{"location":"modules/phone-control/#inbound-calling","text":"When an inbound call is detected, publish the CreateCallId message . In response, the Engine will publish the CreateCallId reply containing a unique identifier for the call. Once an inbound call alert is received, your application must publish the CallStateChanged message indicating the call is now in the CALL_RECEIVED state. When the inbound call begins ringing, publish the CallStateChanged message, this time specifying the INBOUND_RINGING call state. If the user asks Alexa to answer the inbound call, the Engine publishes the Answer message . Publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Note: When a caller id is received for an inbound call, publish the CallerIdReceived message . Click to expand or collapse sequence diagram: Inbound Calling","title":"Inbound Calling"},{"location":"modules/phone-control/#outbound-calling","text":"When a user asks Alexa to dial a number or call an uploaded contact, the Engine publishes the Dial message . Alternatively, if the user asks Alexa to redial the last dialed number, the Engine publishes the Redial message . In both cases, your application must publish the CallStateChanged message indicating the call is now in the DIALING state. Once the outgoing call setup is complete and outbound ringing has started, publish the CallStateChanged message specifying the OUTBOUND_RINGING call state. If the call is answered and in progress, publish the CallStateChanged message indicating the call is now ACTIVE . Whenever the user asks Alexa to end the call, the Engine publishes the Stop message. Publish the CallStateChanged message to indicate that the call is now IDLE . Click to expand or collapse sequence diagram: Outbound Calling","title":"Outbound Calling"},{"location":"modules/phone-control/#integrating-the-phone-call-controller-module-into-your-application","text":"Use the Engine's MessageBroker to subscribe to and publish \"PhoneCallController\" AASB messages. Click to expand or collapse C++ sample code #include <AACE/Core/MessageBroker.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallingDeviceConfigurationProperty.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionState.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DTMFError.h> #include <AASB/Message/PhoneCallController/PhoneCallController/AnswerMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallerIdReceivedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CallStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/ConnectionStateChangedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/CreateCallIdMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DeviceConfigurationUpdatedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/DialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/RedialMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFFailedMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/SendDTMFSucceededMessage.h> #include <AASB/Message/PhoneCallController/PhoneCallController/StopMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyPhoneCallControllerHandler { // Subscribe to messages from the Engine void MyPhoneCallControllerHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleAnswerMessage ( message ); }, AnswerMessage :: topic (), AnswerMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleDialMessage ( message ); }, DialMessage :: topic (), DialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleRedialMessage ( message ); }, RedialMessage :: topic (), RedialMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleSendDMTFMessage ( message ); }, SendDTMFMessage :: topic (), SendDTMFMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleStopMessage ( message ); }, StopMessage :: topic (), StopMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleCreateCallIdReplyMessage ( message ); }, CreateCallIdMessageReply :: topic (), CreateCallIdMessageReply :: action ()); } // Handle the Answer message from the Engine void MyPhoneCallControllerHandler::handleAnswerMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); answer ( msg . payload . payload ); } // Handle the Dial message from the Engine void MyPhoneCallControllerHandler::handleDialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); std :: string payload = msg . payload . payload ; dial ( msg . payload . payload ); } // Handle the Redial message from the Engine void MyPhoneCallControllerHandler::handleRedialMessage ( const std :: string & message ) { AnswerMessage msg = json :: parse ( message ); redial ( msg . payload . payload ); } // Handle the SendDTMF message from the Engine void MyPhoneCallControllerHandler::handleSendDMTFMessage ( const std :: string & message ) { SendDTMFMessage msg = json :: parse ( message ); sendDTMF ( msg . payload . payload ); } // Handle the Stop message from the Engine void MyPhoneCallControllerHandler::handleStopMessage ( const std :: string & message ) { StopMessage msg = json :: parse ( message ); stop ( msg . payload . payload ); } // Handle the CreateCallId reply message from the Engine void MyPhoneCallControllerHandler::handleCreateCallIdReplyMessage ( const std :: string & message ) { CreateCallIdMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string callId = msg . payload . callId ; // ...Handle the generated call id... } // When an error occurrs during an active call or call setup, publish a CallFailed // message to the Engine void MyPhoneCallControllerHandler::callFailed ( const std :: string & callId , CallError code , const std :: string & message ) { CallFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } // When the call state changes, publish a CallStateChanged message to the Engine void MyPhoneCallControllerHandler::callStateChanged ( CallState state , const std :: string & callId , const std :: string & callerId ) { CallStateChangedMessage msg ; msg . payload . state = state ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When a caller id is received for an inbound call, publish a CallerIdReceived // message to the Engine void MyPhoneCallControllerHandler::callerIdReceived ( const std :: string & callId , const std :: string & callerId ) { CallerIdReceivedMessage msg ; msg . payload . callId = callId ; msg . payload . callerId = callerId ; m_messageBroker -> publish ( msg . toString ()); } // When connection to a calling device is established or broken, publish a // ConnectionStateChanged message to the Engine void MyPhoneCallControllerHandler::connectionStateChanged ( ConnectionState state ) { ConnectionStateChangedMessage msg ; msg . payload . state = state ; m_messageBroker -> publish ( msg . toString ()); } // To generate an identifier for a call, publish a CreateCallId message to the Engine std :: string MyPhoneCallControllerHandler::createCallId () { CreateCallIdMessage msg ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the CreateCallIdReply message // Return the unique identifier from reply message payload } // When a feature of the calling device changes, publish a // DeviceConfigurationUpdated message to the Engine void MyPhoneCallControllerHandler::deviceConfigurationUpdated ( std :: unordered_map < CallingDeviceConfigurationProperty , bool > configurationMap ) { json configuration ; for ( auto it : configurationMap ) { configuration [ configurationFeatureToString ( it . first )] = it . second ; } DeviceConfigurationUpdatedMessage msg ; msg . payload . configurationMap = configuration . dump (); m_messageBroker -> publish ( msg . toString ()); } // When the DTMF signal is delivered, publish a SendDTMFSucceeded message to the Engine void MyPhoneCallControllerHandler::sendDTMFSucceeded ( const std :: string & callId ) { SendDTMFSucceededMessage msg ; msg . payload . callId = callId ; m_messageBroker -> publish ( msg . toString ()); } // When sending the DTMF signal failed, publish a SendDTMFFailed message to the Engine void MyPhoneCallControllerHandler::sendDTMFFailed ( const std :: string & callId , DTMFError code , const std :: string & message ) { SendDTMFFailedMessage msg ; msg . payload . callId = callId ; msg . payload . code = code ; msg . payload . message = message ; m_messageBroker -> publish ( msg . toString ()); } void MyPhoneCallControllerHandler::answer ( const std :: string & payload ) { // Answer the inbound call } void MyPhoneCallControllerHandler::dial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::redial ( const std :: string & payload ) { // Initiate an outbound call } void MyPhoneCallControllerHandler::stop ( const std :: string & payload ) { // Stop the call } void MyPhoneCallControllerHandler::sendDTMF ( const std :: string & payload ) { // Send a DTMF signal } // Implement to convert CallingDeviceConfigurationProperty to string std :: string MyPhoneCallControllerHandler::configurationFeatureToString ( CallingDeviceConfigurationProperty feature ); };","title":"Integrating the Phone Call Controller Module Into Your Application "},{"location":"modules/phone-control/#android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS Telephony Library to integrate the Auto SDK Phone Call Controller module on Android. See the AACS Telephony Library documentation for more information.","title":"Android Integration"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/","text":"PhoneCallController Outgoing Messages SendDTMF Notifies the platform implementation to send a DTMF signal to the calling device. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMF\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes Details of the DTMF request in structured JSON format. Dial Notifies the platform implementation to initiate an outgoing phone call to the destination address. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Dial\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes Details of the dial request in structured JSON format. Redial Notifies the platform implementation to redial the last called phone number. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Redial\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes Details of the redial request in structured JSON format. Stop Notifies the platform implementation to end an ongoing call or stop inbound or outbound call setup. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Stop\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes Details of the stop request in structured JSON format. Answer Notifies the platform implementation to answer an inbound call. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Answer\" } }, \"payload\": { \"payload\": {{String}} } } Payload Property Type Required Description Example payload String Yes Details of the answer request in structured JSON format. Incoming Messages CreateCallId Generates a unique identifier for a call. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\" } } } CreateCallIdReply Reply for CreateCallId message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\", \"replyToId\": {{String}} } }, \"payload\": { \"callId\": {{String}} } } Payload Property Type Required Description Example callId String Yes Unique identifier for a call. CallStateChanged Notifies the Engine of a change in the state of an ongoing call. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallStateChanged\" } }, \"payload\": { \"state\": {{CallState}}, \"callId\": {{String}}, \"callerId\": {{String}} } } Payload Property Type Required Description Example state CallState Yes The state of the call. callId String Yes The unique identifier associated with the call. callerId String No The identifier for a contact. SendDTMFSucceeded Notifies the Engine that sending the DTMF signal succeeded. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFSucceeded\" } }, \"payload\": { \"callId\": {{String}} } } Payload Property Type Required Description Example callId String Yes The unique identifier for the associated call. ConnectionStateChanged Notifies the Engine of a change in connection to a calling device. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"ConnectionStateChanged\" } }, \"payload\": { \"state\": {{ConnectionState}} } } Payload Property Type Required Description Example state ConnectionState Yes The state of connection to a calling device. CallFailed Notifies the Engine of an error related to a call. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{CallError}}, \"message\": {{String}} } } Payload Property Type Required Description Example callId String Yes The unique identifier for the call associated with the error. code CallError Yes The error type. message String No A description of the error. CallerIdReceived Notifies the Engine that a caller id was received for an inbound call. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallerIdReceived\" } }, \"payload\": { \"callId\": {{String}}, \"callerId\": {{String}} } } Payload Property Type Required Description Example callId String Yes The unique identifier for the call associated with the callId. callerId String Yes The caller's identifier or phone number. DeviceConfigurationUpdated Notifies the Engine of the calling feature configuration of the connected calling device. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"DeviceConfigurationUpdated\" } }, \"payload\": { \"configurationMap\": {{String}} } } Payload Property Type Required Description Example configurationMap String Yes A map of configuration properties to the boolean state of the properties. SendDTMFFailed Notifies the Engine that the DTMF signal could not be delivered to the remote party. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{DTMFError}}, \"message\": {{String}} } } Payload Property Type Required Description Example callId String Yes callId The unique identifier for the associated call. code DTMFError Yes The error type. message String No A description of the error. Enums CallingDeviceConfigurationProperty Values Value Description \"DTMF_SUPPORTED\" Whether the device supports DTMF signaling. ConnectionState Values Value Description \"CONNECTED\" A calling device is connected. \"DISCONNECTED\" No calling device is connected. DTMFError Values Value Description \"CALL_NOT_IN_PROGRESS\" There is no active call through which a DTMF signal can be sent. \"DTMF_FAILED\" Generic DTMF error. CallError Values Value Description \"NO_CARRIER\" No carrier is available on the calling device. \"BUSY\" The calling device is busy when setting up an outbound call, such as when a call is already in progress. \"NO_ANSWER\" The remote party did not answer the call. \"NO_NUMBER_FOR_REDIAL\" Redial was requested, but there is no previously dialed number available. \"OTHER\" Generic error. CallState Values Value Description \"IDLE\" The call is not in an active state. \"DIALING\" The outbound call is initiated by the user. Call setup is in progress. \"OUTBOUND_RINGING\" The outbound call has been set up, and the remote party is alerted. \"ACTIVE\" The call is active, and media is being transmitted between the caller and remote party. \"CALL_RECEIVED\" An alert for the inbound call has been received. \"INBOUND_RINGING\" The inbound call is ringing.","title":"PhoneControl"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#phonecallcontroller","text":"","title":"PhoneCallController"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#senddtmf","text":"Notifies the platform implementation to send a DTMF signal to the calling device.","title":"SendDTMF"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMF\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload","text":"Property Type Required Description Example payload String Yes Details of the DTMF request in structured JSON format.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#dial","text":"Notifies the platform implementation to initiate an outgoing phone call to the destination address.","title":"Dial"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Dial\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_1","text":"Property Type Required Description Example payload String Yes Details of the dial request in structured JSON format.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#redial","text":"Notifies the platform implementation to redial the last called phone number.","title":"Redial"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Redial\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_2","text":"Property Type Required Description Example payload String Yes Details of the redial request in structured JSON format.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#stop","text":"Notifies the platform implementation to end an ongoing call or stop inbound or outbound call setup.","title":"Stop"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Stop\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_3","text":"Property Type Required Description Example payload String Yes Details of the stop request in structured JSON format.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#answer","text":"Notifies the platform implementation to answer an inbound call.","title":"Answer"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"Answer\" } }, \"payload\": { \"payload\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_4","text":"Property Type Required Description Example payload String Yes Details of the answer request in structured JSON format.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#createcallid","text":"Generates a unique identifier for a call.","title":"CreateCallId"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_5","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\" } } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#createcallidreply","text":"Reply for CreateCallId message.","title":"CreateCallIdReply"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_6","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CreateCallId\", \"replyToId\": {{String}} } }, \"payload\": { \"callId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_5","text":"Property Type Required Description Example callId String Yes Unique identifier for a call.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#callstatechanged","text":"Notifies the Engine of a change in the state of an ongoing call.","title":"CallStateChanged"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_7","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallStateChanged\" } }, \"payload\": { \"state\": {{CallState}}, \"callId\": {{String}}, \"callerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_6","text":"Property Type Required Description Example state CallState Yes The state of the call. callId String Yes The unique identifier associated with the call. callerId String No The identifier for a contact.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#senddtmfsucceeded","text":"Notifies the Engine that sending the DTMF signal succeeded.","title":"SendDTMFSucceeded"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_8","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFSucceeded\" } }, \"payload\": { \"callId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_7","text":"Property Type Required Description Example callId String Yes The unique identifier for the associated call.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#connectionstatechanged","text":"Notifies the Engine of a change in connection to a calling device.","title":"ConnectionStateChanged"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_9","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"ConnectionStateChanged\" } }, \"payload\": { \"state\": {{ConnectionState}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_8","text":"Property Type Required Description Example state ConnectionState Yes The state of connection to a calling device.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#callfailed","text":"Notifies the Engine of an error related to a call.","title":"CallFailed"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_10","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{CallError}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_9","text":"Property Type Required Description Example callId String Yes The unique identifier for the call associated with the error. code CallError Yes The error type. message String No A description of the error.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#calleridreceived","text":"Notifies the Engine that a caller id was received for an inbound call.","title":"CallerIdReceived"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_11","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"CallerIdReceived\" } }, \"payload\": { \"callId\": {{String}}, \"callerId\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_10","text":"Property Type Required Description Example callId String Yes The unique identifier for the call associated with the callId. callerId String Yes The caller's identifier or phone number.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#deviceconfigurationupdated","text":"Notifies the Engine of the calling feature configuration of the connected calling device.","title":"DeviceConfigurationUpdated"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_12","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"DeviceConfigurationUpdated\" } }, \"payload\": { \"configurationMap\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_11","text":"Property Type Required Description Example configurationMap String Yes A map of configuration properties to the boolean state of the properties.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#senddtmffailed","text":"Notifies the Engine that the DTMF signal could not be delivered to the remote party.","title":"SendDTMFFailed"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#json-structure_13","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"PhoneCallController\", \"action\": \"SendDTMFFailed\" } }, \"payload\": { \"callId\": {{String}}, \"code\": {{DTMFError}}, \"message\": {{String}} } }","title":"JSON Structure"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#payload_12","text":"Property Type Required Description Example callId String Yes callId The unique identifier for the associated call. code DTMFError Yes The error type. message String No A description of the error.","title":"Payload"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#enums","text":"","title":"Enums"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#callingdeviceconfigurationproperty","text":"","title":"CallingDeviceConfigurationProperty"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#values","text":"Value Description \"DTMF_SUPPORTED\" Whether the device supports DTMF signaling.","title":"Values"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#connectionstate","text":"","title":"ConnectionState"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#values_1","text":"Value Description \"CONNECTED\" A calling device is connected. \"DISCONNECTED\" No calling device is connected.","title":"Values"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#dtmferror","text":"","title":"DTMFError"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#values_2","text":"Value Description \"CALL_NOT_IN_PROGRESS\" There is no active call through which a DTMF signal can be sent. \"DTMF_FAILED\" Generic DTMF error.","title":"Values"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#callerror","text":"","title":"CallError"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#values_3","text":"Value Description \"NO_CARRIER\" No carrier is available on the calling device. \"BUSY\" The calling device is busy when setting up an outbound call, such as when a call is already in progress. \"NO_ANSWER\" The remote party did not answer the call. \"NO_NUMBER_FOR_REDIAL\" Redial was requested, but there is no previously dialed number available. \"OTHER\" Generic error.","title":"Values"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#callstate","text":"","title":"CallState"},{"location":"modules/phone-control/aasb-docs/PhoneCallController/#values_4","text":"Value Description \"IDLE\" The call is not in an active state. \"DIALING\" The outbound call is initiated by the user. Call setup is in progress. \"OUTBOUND_RINGING\" The outbound call has been set up, and the remote party is alerted. \"ACTIVE\" The call is active, and media is being transmitted between the caller and remote party. \"CALL_RECEIVED\" An alert for the inbound call has been received. \"INBOUND_RINGING\" The inbound call is ringing.","title":"Values"},{"location":"modules/system-audio/","text":"Alexa Auto SDK System Audio Module The System Audio module provides the default audio capturing and playback functionality for macOS, Linux, and QNX. Table of Contents What's Included Supported Audio Backends Getting Started Configuring System Audio Playlist URL Support What's Included The System Audio module contains the platform implementations of: aace::audio::AudioOutput and aace::audio::AudioOutputProvider for audio playback capability aace::audio::AudioInput and aace::audio::AudioInputProvider for audio capturing capability Supported Audio Backends Currently the System Audio module supports: GStreamer tested on: Ubuntu Linux (18.04 and 20.04) Note: Ensure installing at least gstreamer1.0-plugins-base and gstreamer1.0-plugins-good . It is recommended to install gstreamer1.0-plugins-bad for playing content from Amazon Music (which uses HLS) and other Music Service Providers. Refer to https://gstreamer.freedesktop.org/documentation/installing/on-linux.html for instructions. Note: GStreamer on Poky Linux for iMX8 does not support Audible or Amazon Music playback. Automotive Grade Linux with 4A framework support (FF or GG) Poky Linux armv7hf and armv8 macOS x86_64 with GStreamer installed by Homebrew OpenMAX AL (Encoded audio playback only) tested with: QNX Multimedia Suite 2.0 on QNX 7.0.0 armv8 QNX Sound Architecture (QSA) (Raw audio only) tested with: QNX 7.0.0 armv8 Note: You'll need a QNX Multimedia Suite license to use OpenMAX AL, and both OpenMAX AL and QSA are required in order to enable full functionality on QNX. Getting Started Prerequisites You'll need GStreamer development packages such as libgstreamer1.0-dev and libgstreamer-plugins-base1.0-dev . Building the Alexa Auto SDK with the System Audio Module The Alexa Auto SDK Builder automatically includes the System Audio module when you build the C++ sample app. You can include it explicitly by specifying -o aac_modules=aac-module-system-audio,... to the build command. Running the C++ Sample App with the Audio Configuration When you run the C++ Sample App, a config-system-audio.json file with default audio settings for Linux platforms is provided under shared/system-audio/config . Changing the Default Audio Settings for Linux (required for Poky 32) If you need to modify the configuration defined in the config-system-audio.json file for your Linux platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/linux directory) as necessary. Note: For Poky 32 boards, you must set \"shared\" to \"true\" in the \"default\" node. Save the config-system-audio.json file to the same directory other config files reside. Include a --config path/to/config-system-audio.json line when you run the C++ Sample App. Changing the Default Audio Settings for QNX (required) The default audio settings will not work for QNX. To modify the configuration defined in the config-system-audio.json file for your QNX platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/neutrino directory) as necessary. See the default QNX configuration for guidance. Save the config-system-audio.json file to the same directory other config files reside. Include a --config /opt/AAC/etc/config-system-audio.json line when you run the C++ Sample App. Note: You may need to set the AAL_CAPATH system environment value to specify which path should OpenMAX AL used for CURLOPT_CAPATH internally. If you don't set the AAL_CAPATH system environment variable, /etc/ssl/certs will be used by default. Configuring System Audio For complex audio setup, you may need to write your own config file. To use this file, save it as config-system-audio.json and include a --config path/to/config-system-audio.json line when you run the C++ Sample App. Here is the config file template: { \"aace.systemAudio\" : { \"<provider>\" : { \"enabled\" : <boolea n > , \"devices\" : { \"<device-name>\" : { \"module\" : \"<module-name>\" , \"card\" : \"<id>\" , \"rate\" : \"<sample-rate>\" , \"shared\" : <boolea n > } }, \"types\" : { \"<type>\" : \"<device-name>\" } } } } aace.systemAudio.<provider> : Set to AudioInputProvider or AudioOutputProvider . You can write a configuration for each <provider> , depending on the direction (input or output). aace.systemAudio.<provider>.enabled : Set to true or false . Setting this parameter to false disables the registration of the <provider> platform implementation. The default setting is true . aace.systemAudio.<provider>.devices.<device-name> : Set to any \"<device-name>\" or to default . If you set the \"<device-name>\" to \"default\" audio will be routed by default if there is no explicit \"<device-name> \" available for the configured \"<type>\" . You can configure multiple devices, depending on your platform. \"module\" : Specify a \"<module-name>\" to explicitly define which audio backend to use. By default, \"module\" is set to an empty string, which configures the system audio module to use whatever backend is available. \"card\" : Specify the card id for the specific audio backend you defined with the \"<module-name>\" parameter. By default, \"card\" is set to an empty string since by default \"<module-name>\" is not defined. \"rate\" : Specify the sample rate of audio input. By default the \"rate\" is set to 0 . \"shared\" (AudioInputProvider only) : Set to true or false . Set \"shared: to true for Poky 32 boards or in cases where the device should be shared within the Auto SDK Engine; otherwise, the System Audio module will try to open the device for every audio input type. The \"shared\" option is useful when the underlying backend doesn't support the input splitter. By default \"shared\" is set to false . aace.systemAudio.<provider>.types.<type> : Use the \"type\" option to specify which device should be used for various types of audio. If you do not explicitly specify a device, the default type is used. See aace::audio::AudioInputProvider::AudioInputType and aace::audio::AudioOutputProvider::AudioOutputType for the possible \"<type>\" values. Default QNX Configuration Here is the default configuration for QNX platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"QSA\" , \"shared\" : true } } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"OpenMAX AL\" }, \"raw\" : { \"module\" : \"QSA\" } }, \"types\" : { \"COMMUNICATION\" : \"raw\" } } } } If you use this configuration: The audio capturing for all types will use QSA , but it will be shared. This means that only a single PCM channel will be opened by the Engine. The audio playback for all types except COMMUNICATION will use OpenMAX AL . COMMUNICATION audio will use QSA instead. Note that the multiple PCM channels will be opened for each types. Linux Configuration Example Here is a configuration example for Linux platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" }, \"loopback\" : { \"module\" : \"GStreamer\" , \"card\" : \"hw:Loopback,1,0\" , \"shared\" : true } }, \"types\" : { \"LOOPBACK\" : \"loopback\" } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" } } } } } The above example shows how you could provide \"Speaker reference\" into the engine. Specifying Input and Output Device The card field specifies the audio input source and audio output sink. For devices using module GStreamer , the card field can be one of the following values: If the card field is an empty string or not specified at all, the input device will be decided by GStreamer autoaudiosrc plugin and the output device will be decided by GStreamer autoaudiosink plugin automatically. If none of the above matches, the string will be treated as an Advanced Linux Sound Architecture (ALSA) device name. You can use aplay -L or arecord -L to list available audio output and input devices. Playlist URL Support The System Audio module supports playback of playlist URL from media streaming services (such as TuneIn) based on PlaylistParser provided by AVS Device SDK. The current supported formats include M3U and PLS. Note that only the first playable entry will be played in the current implementation. Choosing a variant based on stream information or continuing playback of the second or later entry is not supported right now. After the user asks Alexa to play on TuneIn, if Alexa acknowledges the request but says TuneIn is not available, the parser displays the following error: 2021-03-02 05:04:25.745 [AVS] E PlaylistParser:doDepthFirstSearch:url=http\\://www.podtrac.com/pts/redirect.mp3/chtbl.com/track/5899E/traffic.megaphone.fm/HSW1953246087.mp3:getHeaderFailed To avoid this error, provide a valid cacert.pem to CURLOPT_CAINFO in the Auto SDK configuration. Download the cacert.pem file from here . \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"/path/to/certs\", \"CURLOPT_CAINFO\": \"/path/to/cacert.pem\" }","title":"Alexa Auto SDK System Audio Module"},{"location":"modules/system-audio/#alexa-auto-sdk-system-audio-module","text":"The System Audio module provides the default audio capturing and playback functionality for macOS, Linux, and QNX. Table of Contents What's Included Supported Audio Backends Getting Started Configuring System Audio Playlist URL Support","title":"Alexa Auto SDK System Audio Module"},{"location":"modules/system-audio/#whats-included","text":"The System Audio module contains the platform implementations of: aace::audio::AudioOutput and aace::audio::AudioOutputProvider for audio playback capability aace::audio::AudioInput and aace::audio::AudioInputProvider for audio capturing capability","title":"What's Included "},{"location":"modules/system-audio/#supported-audio-backends","text":"Currently the System Audio module supports: GStreamer tested on: Ubuntu Linux (18.04 and 20.04) Note: Ensure installing at least gstreamer1.0-plugins-base and gstreamer1.0-plugins-good . It is recommended to install gstreamer1.0-plugins-bad for playing content from Amazon Music (which uses HLS) and other Music Service Providers. Refer to https://gstreamer.freedesktop.org/documentation/installing/on-linux.html for instructions. Note: GStreamer on Poky Linux for iMX8 does not support Audible or Amazon Music playback. Automotive Grade Linux with 4A framework support (FF or GG) Poky Linux armv7hf and armv8 macOS x86_64 with GStreamer installed by Homebrew OpenMAX AL (Encoded audio playback only) tested with: QNX Multimedia Suite 2.0 on QNX 7.0.0 armv8 QNX Sound Architecture (QSA) (Raw audio only) tested with: QNX 7.0.0 armv8 Note: You'll need a QNX Multimedia Suite license to use OpenMAX AL, and both OpenMAX AL and QSA are required in order to enable full functionality on QNX.","title":"Supported Audio Backends "},{"location":"modules/system-audio/#getting-started","text":"","title":"Getting Started"},{"location":"modules/system-audio/#prerequisites","text":"You'll need GStreamer development packages such as libgstreamer1.0-dev and libgstreamer-plugins-base1.0-dev .","title":"Prerequisites"},{"location":"modules/system-audio/#building-the-alexa-auto-sdk-with-the-system-audio-module","text":"The Alexa Auto SDK Builder automatically includes the System Audio module when you build the C++ sample app. You can include it explicitly by specifying -o aac_modules=aac-module-system-audio,... to the build command.","title":"Building the Alexa Auto SDK with the System Audio Module"},{"location":"modules/system-audio/#running-the-c-sample-app-with-the-audio-configuration","text":"When you run the C++ Sample App, a config-system-audio.json file with default audio settings for Linux platforms is provided under shared/system-audio/config .","title":"Running the C++ Sample App with the Audio Configuration"},{"location":"modules/system-audio/#changing-the-default-audio-settings-for-linux-required-for-poky-32","text":"If you need to modify the configuration defined in the config-system-audio.json file for your Linux platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/linux directory) as necessary. Note: For Poky 32 boards, you must set \"shared\" to \"true\" in the \"default\" node. Save the config-system-audio.json file to the same directory other config files reside. Include a --config path/to/config-system-audio.json line when you run the C++ Sample App.","title":"Changing the Default Audio Settings for Linux (required for Poky 32)"},{"location":"modules/system-audio/#changing-the-default-audio-settings-for-qnx-required","text":"The default audio settings will not work for QNX. To modify the configuration defined in the config-system-audio.json file for your QNX platform, follow these steps: Edit the config-system-audio.json file (located in the aac-sdk/modules/system-audio/configs/neutrino directory) as necessary. See the default QNX configuration for guidance. Save the config-system-audio.json file to the same directory other config files reside. Include a --config /opt/AAC/etc/config-system-audio.json line when you run the C++ Sample App. Note: You may need to set the AAL_CAPATH system environment value to specify which path should OpenMAX AL used for CURLOPT_CAPATH internally. If you don't set the AAL_CAPATH system environment variable, /etc/ssl/certs will be used by default.","title":"Changing the Default Audio Settings for QNX (required)"},{"location":"modules/system-audio/#configuring-system-audio","text":"For complex audio setup, you may need to write your own config file. To use this file, save it as config-system-audio.json and include a --config path/to/config-system-audio.json line when you run the C++ Sample App. Here is the config file template: { \"aace.systemAudio\" : { \"<provider>\" : { \"enabled\" : <boolea n > , \"devices\" : { \"<device-name>\" : { \"module\" : \"<module-name>\" , \"card\" : \"<id>\" , \"rate\" : \"<sample-rate>\" , \"shared\" : <boolea n > } }, \"types\" : { \"<type>\" : \"<device-name>\" } } } } aace.systemAudio.<provider> : Set to AudioInputProvider or AudioOutputProvider . You can write a configuration for each <provider> , depending on the direction (input or output). aace.systemAudio.<provider>.enabled : Set to true or false . Setting this parameter to false disables the registration of the <provider> platform implementation. The default setting is true . aace.systemAudio.<provider>.devices.<device-name> : Set to any \"<device-name>\" or to default . If you set the \"<device-name>\" to \"default\" audio will be routed by default if there is no explicit \"<device-name> \" available for the configured \"<type>\" . You can configure multiple devices, depending on your platform. \"module\" : Specify a \"<module-name>\" to explicitly define which audio backend to use. By default, \"module\" is set to an empty string, which configures the system audio module to use whatever backend is available. \"card\" : Specify the card id for the specific audio backend you defined with the \"<module-name>\" parameter. By default, \"card\" is set to an empty string since by default \"<module-name>\" is not defined. \"rate\" : Specify the sample rate of audio input. By default the \"rate\" is set to 0 . \"shared\" (AudioInputProvider only) : Set to true or false . Set \"shared: to true for Poky 32 boards or in cases where the device should be shared within the Auto SDK Engine; otherwise, the System Audio module will try to open the device for every audio input type. The \"shared\" option is useful when the underlying backend doesn't support the input splitter. By default \"shared\" is set to false . aace.systemAudio.<provider>.types.<type> : Use the \"type\" option to specify which device should be used for various types of audio. If you do not explicitly specify a device, the default type is used. See aace::audio::AudioInputProvider::AudioInputType and aace::audio::AudioOutputProvider::AudioOutputType for the possible \"<type>\" values.","title":"Configuring System Audio"},{"location":"modules/system-audio/#default-qnx-configuration","text":"Here is the default configuration for QNX platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"QSA\" , \"shared\" : true } } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"OpenMAX AL\" }, \"raw\" : { \"module\" : \"QSA\" } }, \"types\" : { \"COMMUNICATION\" : \"raw\" } } } } If you use this configuration: The audio capturing for all types will use QSA , but it will be shared. This means that only a single PCM channel will be opened by the Engine. The audio playback for all types except COMMUNICATION will use OpenMAX AL . COMMUNICATION audio will use QSA instead. Note that the multiple PCM channels will be opened for each types.","title":"Default QNX Configuration "},{"location":"modules/system-audio/#linux-configuration-example","text":"Here is a configuration example for Linux platforms: { \"aace.systemAudio\" : { \"AudioInputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" }, \"loopback\" : { \"module\" : \"GStreamer\" , \"card\" : \"hw:Loopback,1,0\" , \"shared\" : true } }, \"types\" : { \"LOOPBACK\" : \"loopback\" } }, \"AudioOutputProvider\" : { \"devices\" : { \"default\" : { \"module\" : \"GStreamer\" } } } } } The above example shows how you could provide \"Speaker reference\" into the engine.","title":"Linux Configuration Example"},{"location":"modules/system-audio/#specifying-input-and-output-device","text":"The card field specifies the audio input source and audio output sink. For devices using module GStreamer , the card field can be one of the following values: If the card field is an empty string or not specified at all, the input device will be decided by GStreamer autoaudiosrc plugin and the output device will be decided by GStreamer autoaudiosink plugin automatically. If none of the above matches, the string will be treated as an Advanced Linux Sound Architecture (ALSA) device name. You can use aplay -L or arecord -L to list available audio output and input devices.","title":"Specifying Input and Output Device"},{"location":"modules/system-audio/#playlist-url-support","text":"The System Audio module supports playback of playlist URL from media streaming services (such as TuneIn) based on PlaylistParser provided by AVS Device SDK. The current supported formats include M3U and PLS. Note that only the first playable entry will be played in the current implementation. Choosing a variant based on stream information or continuing playback of the second or later entry is not supported right now. After the user asks Alexa to play on TuneIn, if Alexa acknowledges the request but says TuneIn is not available, the parser displays the following error: 2021-03-02 05:04:25.745 [AVS] E PlaylistParser:doDepthFirstSearch:url=http\\://www.podtrac.com/pts/redirect.mp3/chtbl.com/track/5899E/traffic.megaphone.fm/HSW1953246087.mp3:getHeaderFailed To avoid this error, provide a valid cacert.pem to CURLOPT_CAINFO in the Auto SDK configuration. Download the cacert.pem file from here . \"libcurlUtils\": { \"CURLOPT_CAPATH\": \"/path/to/certs\", \"CURLOPT_CAINFO\": \"/path/to/cacert.pem\" }","title":"Playlist URL Support"},{"location":"modules/text-to-speech/","text":"Text To Speech (TTS) Module Table of Contents Overview Configuring the Text To Speech Module Using the Text To Speech AASB Messages Integrating the Text To Speech Module Into Your Application Overview The Text To Speech module enables your Alexa Auto SDK client application to synthesize Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. To synthesize speech, this module uses the Text To Speech provider module (See README ). The Auto SDK does not provide any speech-playing APIs. Your application's TTS module integration is responsible for playing the synthesized speech to deliver a unified Alexa experience to the user. Note: This feature may only be used with voice-guided turn-by-turn navigation. Important! The TTS module requires the Local Voice Control extension. Configuring the Text To Speech Module The Text To Speech module does not require Engine configuration. Using the Text To Speech AASB Messages Prepare Speech To request speech synthesis from a text or SSML input, your application must publish the PrepareSpeech message . The Engine publishes either the PrepareSpeechCompleted message or PrepareSpeechFailed message to indicate success or failure, respectively. Click to expand or collapse sequence diagram: Prepare Speech Note: The prepareSpeechFailed API contains the reason parameter that specifies the error string for failure. Refer to the TTS provider errors for more information on errors defined by the TTS provider. TThe TTS module defines the REQUEST_TIMED_OUT error that occurs when the TTS provider sends no response, causing the speech request to time out. The timeout value is 1000 milliseconds. Get Capabilities To request the capabilities of the TTS provider being used, your application must publish the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message reply with the capabilities of the TTS provider. Click to expand or collapse sequence diagram: Get Capabilities Integrating the Text To Speech Module Into Your Application C++ MessageBroker Integration Use the Engine's MessageBroker to subscribe to and publish \"TextToSpeech\" AASB messages. Click to expand or collapse C++ sample code \u200b #include <AACE/Core/MessageBroker.h> #include <AASB/Message/TextToSpeech/TextToSpeech/GetCapabilitiesMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechCompletedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechFailedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyTextToSpeechHandler { // Subscribe to messages from the Engine void MyTextToSpeechHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechCompletedMessage ( message ); }, PrepareSpeechCompletedMessage :: topic (), PrepareSpeechCompletedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechFailedMessage ( message ); }, PrepareSpeechFailedMessage :: topic (), PrepareSpeechFailedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCapabilitiesReplyMessage ( message ); }, GetCapabilitiesMessageReply :: topic (), GetCapabilitiesMessageReply :: action ()); } // Handle the PrepareSpeechCompleted message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechCompletedMessage ( const std :: string & message ) { PrepareSpeechCompletedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string streamId = msg . payload . streamId ; std :: string metadata = msg . payload . metadata ; prepareSpeechCompleted ( speechId , streamId , metadata ); } // Handle the PrepareSpeechFailed message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechFailedMessage ( const std :: string & message ) { PrepareSpeechFailedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string reason = msg . payload . reason ; prepareSpeechFailed ( speechId , reason ); } // Handle the GetCapabilities reply message from the Engine void MyTextToSpeechHandler::handleGetCapabilitiesReplyMessage ( const std :: string & message ) { GetCapabilitiesMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string capabilities = msg . payload . capabilities ; // ...Handle capabilities of the TTS provider... } // To prepare speech, publish the PrepareSpeech message to the Engine void MyTextToSpeechHandler::prepareSpeech ( const std :: string & speechId , const std :: string & text , const std :: string & provider , const std :: string & options ) { PrepareSpeechMessage msg ; msg . payload . speechId = speechId ; msg . payload . text = text ; msg . payload . provider = provider ; msg . payload . options = options ; m_messageBroker -> publish ( msg . toString ()); } // To get capabilities, publish the GetCapabilities message to the Engine std :: string MyTextToSpeechHandler::getCapabilities ( const std :: string & requestId , const std :: string & provider ) { GetCapabilitiesMessage msg ; msg . header . id = requestId ; msg . payload . provider = provider ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetCapabilitiesReply message // Return the capabilities from reply message payload } void MyTextToSpeechHandler::prepareSpeechCompleted ( const std :: string & speechId , const std :: string & streamId , const std :: string & metadata ) { // Use MessageBroker openStream API to get the MessageStream std :: shared_ptr < MessageStream > preparedAudio = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // Follow the UX guidelines in order to play the audio stream } // Notification of a failed speech synthesis void TextToSpeechHandler::prepareSpeechFailed ( const std :: string & speechId , const std :: string & reason ) { // Use the speechId to correlate the synthesis request to the result // Access the reason for failure } }; Android Integration The Alexa Auto Client Service (AACS) provides the AACS Text-To-Speech Service to integrate the Auto SDK Text To Speech module on Android. See the AACS Text-To-Speech Service documentation for more information.","title":"Text To Speech (TTS) Module"},{"location":"modules/text-to-speech/#text-to-speech-tts-module","text":"","title":"Text To Speech (TTS) Module"},{"location":"modules/text-to-speech/#table-of-contents","text":"Overview Configuring the Text To Speech Module Using the Text To Speech AASB Messages Integrating the Text To Speech Module Into Your Application","title":"Table of Contents"},{"location":"modules/text-to-speech/#overview","text":"The Text To Speech module enables your Alexa Auto SDK client application to synthesize Alexa speech on demand from a text or Speech Synthesis Markup Language (SSML) string. To synthesize speech, this module uses the Text To Speech provider module (See README ). The Auto SDK does not provide any speech-playing APIs. Your application's TTS module integration is responsible for playing the synthesized speech to deliver a unified Alexa experience to the user. Note: This feature may only be used with voice-guided turn-by-turn navigation. Important! The TTS module requires the Local Voice Control extension.","title":"Overview"},{"location":"modules/text-to-speech/#configuring-the-text-to-speech-module","text":"The Text To Speech module does not require Engine configuration.","title":"Configuring the Text To Speech Module"},{"location":"modules/text-to-speech/#using-the-text-to-speech-aasb-messages","text":"","title":"Using the Text To Speech AASB Messages"},{"location":"modules/text-to-speech/#prepare-speech","text":"To request speech synthesis from a text or SSML input, your application must publish the PrepareSpeech message . The Engine publishes either the PrepareSpeechCompleted message or PrepareSpeechFailed message to indicate success or failure, respectively. Click to expand or collapse sequence diagram: Prepare Speech Note: The prepareSpeechFailed API contains the reason parameter that specifies the error string for failure. Refer to the TTS provider errors for more information on errors defined by the TTS provider. TThe TTS module defines the REQUEST_TIMED_OUT error that occurs when the TTS provider sends no response, causing the speech request to time out. The timeout value is 1000 milliseconds.","title":"Prepare Speech"},{"location":"modules/text-to-speech/#get-capabilities","text":"To request the capabilities of the TTS provider being used, your application must publish the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message reply with the capabilities of the TTS provider. Click to expand or collapse sequence diagram: Get Capabilities","title":"Get Capabilities"},{"location":"modules/text-to-speech/#integrating-the-text-to-speech-module-into-your-application","text":"","title":"Integrating the Text To Speech Module Into Your Application"},{"location":"modules/text-to-speech/#c-messagebroker-integration","text":"Use the Engine's MessageBroker to subscribe to and publish \"TextToSpeech\" AASB messages. Click to expand or collapse C++ sample code \u200b #include <AACE/Core/MessageBroker.h> #include <AASB/Message/TextToSpeech/TextToSpeech/GetCapabilitiesMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechCompletedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechFailedMessage.h> #include <AASB/Message/TextToSpeech/TextToSpeech/PrepareSpeechMessage.h> #include <nlohmann/json.hpp> using json = nlohmann :: json ; class MyTextToSpeechHandler { // Subscribe to messages from the Engine void MyTextToSpeechHandler::subscribeToAASBMessages () { m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechCompletedMessage ( message ); }, PrepareSpeechCompletedMessage :: topic (), PrepareSpeechCompletedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handlePrepareSpeechFailedMessage ( message ); }, PrepareSpeechFailedMessage :: topic (), PrepareSpeechFailedMessage :: action ()); m_messageBroker -> subscribe ( [ = ]( const std :: string & message ) { handleGetCapabilitiesReplyMessage ( message ); }, GetCapabilitiesMessageReply :: topic (), GetCapabilitiesMessageReply :: action ()); } // Handle the PrepareSpeechCompleted message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechCompletedMessage ( const std :: string & message ) { PrepareSpeechCompletedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string streamId = msg . payload . streamId ; std :: string metadata = msg . payload . metadata ; prepareSpeechCompleted ( speechId , streamId , metadata ); } // Handle the PrepareSpeechFailed message from the Engine void MyTextToSpeechHandler::handlePrepareSpeechFailedMessage ( const std :: string & message ) { PrepareSpeechFailedMessage msg = json :: parse ( message ); std :: string speechId = msg . payload . speechId ; std :: string reason = msg . payload . reason ; prepareSpeechFailed ( speechId , reason ); } // Handle the GetCapabilities reply message from the Engine void MyTextToSpeechHandler::handleGetCapabilitiesReplyMessage ( const std :: string & message ) { GetCapabilitiesMessageReply msg = json :: parse ( message ); std :: string messageId = msg . header . messageDescription . replyToId ; std :: string capabilities = msg . payload . capabilities ; // ...Handle capabilities of the TTS provider... } // To prepare speech, publish the PrepareSpeech message to the Engine void MyTextToSpeechHandler::prepareSpeech ( const std :: string & speechId , const std :: string & text , const std :: string & provider , const std :: string & options ) { PrepareSpeechMessage msg ; msg . payload . speechId = speechId ; msg . payload . text = text ; msg . payload . provider = provider ; msg . payload . options = options ; m_messageBroker -> publish ( msg . toString ()); } // To get capabilities, publish the GetCapabilities message to the Engine std :: string MyTextToSpeechHandler::getCapabilities ( const std :: string & requestId , const std :: string & provider ) { GetCapabilitiesMessage msg ; msg . header . id = requestId ; msg . payload . provider = provider ; m_messageBroker -> publish ( msg . toString ()); // The Engine will send the GetCapabilitiesReply message // Return the capabilities from reply message payload } void MyTextToSpeechHandler::prepareSpeechCompleted ( const std :: string & speechId , const std :: string & streamId , const std :: string & metadata ) { // Use MessageBroker openStream API to get the MessageStream std :: shared_ptr < MessageStream > preparedAudio = m_messageBroker -> openStream ( msg . payload . streamId , MessageStream :: Mode :: READ ); // Follow the UX guidelines in order to play the audio stream } // Notification of a failed speech synthesis void TextToSpeechHandler::prepareSpeechFailed ( const std :: string & speechId , const std :: string & reason ) { // Use the speechId to correlate the synthesis request to the result // Access the reason for failure } };","title":"C++ MessageBroker Integration"},{"location":"modules/text-to-speech/#android-integration","text":"The Alexa Auto Client Service (AACS) provides the AACS Text-To-Speech Service to integrate the Auto SDK Text To Speech module on Android. See the AACS Text-To-Speech Service documentation for more information.","title":"Android Integration"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/","text":"TextToSpeech Outgoing Messages PrepareSpeechFailed Notifies the platform implementation about a failed speech synthesis. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechFailed\" } }, \"payload\": { \"speechId\": {{String}}, \"reason\": {{String}} } } Payload Property Type Required Description Example speechId String Yes The speech ID. reason String Yes The failure reason. PrepareSpeechCompleted Notifies the platform implementation about a successful speech synthesis. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechCompleted\" } }, \"payload\": { \"speechId\": {{String}}, \"token\": {{String}}, \"source\": {{String}}, \"streamId\": {{String}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}}, \"metadata\": {{String}} } } Payload Property Type Required Description Example speechId String Yes The speech ID. token String Yes A unique token for this audio stream. source String Yes source description. streamId String Yes The URL audio stream being provided. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. metadata String Yes The metadata associated with the speech resource. Incoming Messages PrepareSpeech Prepare Speech from a text/SSML input. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeech\" } }, \"payload\": { \"speechId\": {{String}}, \"text\": {{String}}, \"provider\": {{String}}, \"options\": {{String}} } } Payload Property Type Required Description Example speechId String Yes The speech ID. text String Yes The text/SSML to be used for speech synthesis. provider String Yes The text to speech provider to be used for speech synthesis. options String No The options to be used for speech synthesis. GetCapabilities Get Capabilities of a Text to Speech provider. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\" } }, \"payload\": { \"provider\": {{String}} } } Payload Property Type Required Description Example provider String Yes The provider string. Use text-to-speech-provider here. GetCapabilitiesReply Reply for GetCapabilities message. JSON Structure { \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\", \"replyToId\": {{String}} } }, \"payload\": { \"capabilities\": {{String}} } } Payload Property Type Required Description Example capabilities String Yes The capabilities of the Text to Speech provider.","title":"TextToSpeech"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#texttospeech","text":"","title":"TextToSpeech"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#outgoing-messages","text":"","title":"Outgoing Messages"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#preparespeechfailed","text":"Notifies the platform implementation about a failed speech synthesis.","title":"PrepareSpeechFailed"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#json-structure","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechFailed\" } }, \"payload\": { \"speechId\": {{String}}, \"reason\": {{String}} } }","title":"JSON Structure"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#payload","text":"Property Type Required Description Example speechId String Yes The speech ID. reason String Yes The failure reason.","title":"Payload"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#preparespeechcompleted","text":"Notifies the platform implementation about a successful speech synthesis.","title":"PrepareSpeechCompleted"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#json-structure_1","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeechCompleted\" } }, \"payload\": { \"speechId\": {{String}}, \"token\": {{String}}, \"source\": {{String}}, \"streamId\": {{String}}, \"encoding\": {{AudioStreamEncoding}}, \"properties\": {{dict}}, \"metadata\": {{String}} } }","title":"JSON Structure"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#payload_1","text":"Property Type Required Description Example speechId String Yes The speech ID. token String Yes A unique token for this audio stream. source String Yes source description. streamId String Yes The URL audio stream being provided. encoding AudioStreamEncoding Yes The stream encoding format if known. properties dict Yes List of properties associated with the audio stream. metadata String Yes The metadata associated with the speech resource.","title":"Payload"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#incoming-messages","text":"","title":"Incoming Messages"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#preparespeech","text":"Prepare Speech from a text/SSML input.","title":"PrepareSpeech"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#json-structure_2","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"PrepareSpeech\" } }, \"payload\": { \"speechId\": {{String}}, \"text\": {{String}}, \"provider\": {{String}}, \"options\": {{String}} } }","title":"JSON Structure"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#payload_2","text":"Property Type Required Description Example speechId String Yes The speech ID. text String Yes The text/SSML to be used for speech synthesis. provider String Yes The text to speech provider to be used for speech synthesis. options String No The options to be used for speech synthesis.","title":"Payload"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#getcapabilities","text":"Get Capabilities of a Text to Speech provider.","title":"GetCapabilities"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#json-structure_3","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Publish\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\" } }, \"payload\": { \"provider\": {{String}} } }","title":"JSON Structure"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#payload_3","text":"Property Type Required Description Example provider String Yes The provider string. Use text-to-speech-provider here.","title":"Payload"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#getcapabilitiesreply","text":"Reply for GetCapabilities message.","title":"GetCapabilitiesReply"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#json-structure_4","text":"{ \"header\": { \"version\": \"4.0\", \"messageType\": \"Reply\", \"id\": {{String}}, \"messageDescription\": { \"topic\": \"TextToSpeech\", \"action\": \"GetCapabilities\", \"replyToId\": {{String}} } }, \"payload\": { \"capabilities\": {{String}} } }","title":"JSON Structure"},{"location":"modules/text-to-speech/aasb-docs/TextToSpeech/#payload_4","text":"Property Type Required Description Example capabilities String Yes The capabilities of the Text to Speech provider.","title":"Payload"},{"location":"modules/text-to-speech-provider/","text":"Text To Speech Provider Module Table of Contents Overview Configuring the TTS Provider Module Specifying the TTS Provider in AASB Messages Using TTS Provider Module with Different Input Types TTS Capability Returned SSML Examples Errors Overview The Text to Speech Provider module synthesizes Alexa speech on demand. Currently, the Auto SDK supports only one Text to Speech Provider, which uses Alexa's voice as the default voice for speech synthesis. The TTS Provider module performs the following functions: Generating speech from a text or SSML document to provide the speech to the TTS module. Providing capabilities based on the properties of the TTS provider, such as available locales. The TTS Provider module follows the existing AVS (Alexa Voice Service) protocol to carry out speech synthesis and requires connection to the Local Voice Control (LVC) service. If the device is disconnected from LVC, speech synthesis fails. Note : The module can synthesize speech only in the current locale as set by the application. Configuring the TTS Provider Module The Text To Speech Provider module does not require Engine configuration. Specifying the TTS Provider in AASB Messages In all of the text-to-speech AASB messages that involve the provider parameter, use the string, \"text-to-speech-provider\", to specify the TTS provider. Using TTS Provider Module with Different Input Types How the TTS Provider module synthesizes speech depends on the input type and the requestPayload field in the options parameter of the PrepareSpeech message published to the Engine when request speech synthesis. The requestPayload structure is as follows: { \"requestPayload\" : { \"voiceId\" : {VOICE_IDENTIFIER}, \"locale\" : {LOCALE_STRING} } } Note : You do not need to specify the requestPayload in the options parameter because currently only the default voice (Alexa\u2019s voice) is supported. Therefore, you can leave the options parameter unspecified or supply an empty string for it. The following list explains how the TTS Provider module synthesizes speech depending on the input type and requestPayload : If input is text and requestPayload is empty, the text is synthesized to speech with Alexa's voice and the current locale. If input is text and requestPayload specifies the voice and locale, the text is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is text and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains all the supported tags and requestPayload specifies voice and locale, the SSML document is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is SSML and contains all the supported tags, requestPayload is empty, the SSML document is synthesized to speech with Alexa's voice and current locale. If input is SSML and contains all the supported tags, and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains one or more unsupported tags, speech is synthesized but the unsupported tag is ignored. The text within the tag is synthesized normally. TTS Capability Returned To request the capabilities of the TTS provider being used, your application publishes the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message with the following payload structure: \"text-to-speech-provider\" : { \"voices\" : [ { \"voiceId\": \"Alexa\", \"locales\": [CURRENT_LOCALE] } ] } NOTE : The locale returned is always the current locale because you can load only one locale model at a time, which is the current locale. SSML Examples <speak> ETA <break time=\\\"3s\\\"/> three hours </speak> <speak> Turn right <emphasis level=\\\"strong\\\">in twenty feet</emphasis> </speak> <speak> Turn right on<lang xml:lang=\\\"fr-CA\\\">Moulin Rouge street.</lang> </speak> <speak> <p>Turn left in 500ft.</p> <p>Then turn right.</p> </speak> <speak>Turn left on, <phoneme alphabet=\\\"ipa\\\" ph=\\\"Bo.fort\\\">Beaufort</phoneme></speak> <speak> Turn right onto <phoneme alphabet='nt-sampa' ph='*\\\"stAk|t@n \\\"strit'>Stockton Street</phoneme> </speak> <speak> Your ETA is 5 minutes on <say-as interpret-as=\\\"date\\\" format=\\\"dmy\\\">12-10-2020</say-as>. </speak> <speak> Take a <prosody volume=\\\"-6dB\\\">U turn.</prosody> </speak> <speak> Take the next left onto <sub alias=\\\"John Doe\\\">JD</sub> street </speak> Errors The TTS provider defines its set of error strings or codes. The PrepareSpeechFailed message payload uses the reason parameter to send the error strings to the application. The following list describes the error strings used by the Local TTS provider: LOCALE_NOT_SUPPORTED occurs in any of the following situations: The language model for the current locale is missing. The locale specified in requestPayload is not the current locale. The locale specified is invalid. VOICE_NOT_SUPPORTED occurs when the application specifies in requestPayload an invalid voice or is not Alexa. INTERNAL_ERROR is an internal error that signifies an error when the TTS or TTS Provider module processes a request. PROVIDER_NOT_CONNECTED occurs when the provider is not connected to LVC and a speech synthesis request is made. NOTE : If a speech synthesis request is made during an ongoing Alexa dialog, the speech is synthesized after the current Alexa dialog ends.","title":"Text To Speech Provider Module"},{"location":"modules/text-to-speech-provider/#text-to-speech-provider-module","text":"","title":"Text To Speech Provider Module"},{"location":"modules/text-to-speech-provider/#table-of-contents","text":"Overview Configuring the TTS Provider Module Specifying the TTS Provider in AASB Messages Using TTS Provider Module with Different Input Types TTS Capability Returned SSML Examples Errors","title":"Table of Contents"},{"location":"modules/text-to-speech-provider/#overview","text":"The Text to Speech Provider module synthesizes Alexa speech on demand. Currently, the Auto SDK supports only one Text to Speech Provider, which uses Alexa's voice as the default voice for speech synthesis. The TTS Provider module performs the following functions: Generating speech from a text or SSML document to provide the speech to the TTS module. Providing capabilities based on the properties of the TTS provider, such as available locales. The TTS Provider module follows the existing AVS (Alexa Voice Service) protocol to carry out speech synthesis and requires connection to the Local Voice Control (LVC) service. If the device is disconnected from LVC, speech synthesis fails. Note : The module can synthesize speech only in the current locale as set by the application.","title":"Overview"},{"location":"modules/text-to-speech-provider/#configuring-the-tts-provider-module","text":"The Text To Speech Provider module does not require Engine configuration.","title":"Configuring the TTS Provider Module"},{"location":"modules/text-to-speech-provider/#specifying-the-tts-provider-in-aasb-messages","text":"In all of the text-to-speech AASB messages that involve the provider parameter, use the string, \"text-to-speech-provider\", to specify the TTS provider.","title":"Specifying the TTS Provider in AASB Messages"},{"location":"modules/text-to-speech-provider/#using-tts-provider-module-with-different-input-types","text":"How the TTS Provider module synthesizes speech depends on the input type and the requestPayload field in the options parameter of the PrepareSpeech message published to the Engine when request speech synthesis. The requestPayload structure is as follows: { \"requestPayload\" : { \"voiceId\" : {VOICE_IDENTIFIER}, \"locale\" : {LOCALE_STRING} } } Note : You do not need to specify the requestPayload in the options parameter because currently only the default voice (Alexa\u2019s voice) is supported. Therefore, you can leave the options parameter unspecified or supply an empty string for it. The following list explains how the TTS Provider module synthesizes speech depending on the input type and requestPayload : If input is text and requestPayload is empty, the text is synthesized to speech with Alexa's voice and the current locale. If input is text and requestPayload specifies the voice and locale, the text is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is text and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains all the supported tags and requestPayload specifies voice and locale, the SSML document is synthesized to speech in the specified voice and locale. The locale must be the current locale. If input is SSML and contains all the supported tags, requestPayload is empty, the SSML document is synthesized to speech with Alexa's voice and current locale. If input is SSML and contains all the supported tags, and requestPayload contains one or more unsupported parameters, speech is not synthesized. The speech synthesis fails with the error VOICE_NOT_SUPPORTED or LOCALE_NOT_SUPPORTED , depending on the unsupported parameter. If input is SSML and contains one or more unsupported tags, speech is synthesized but the unsupported tag is ignored. The text within the tag is synthesized normally.","title":"Using TTS Provider Module with Different Input Types"},{"location":"modules/text-to-speech-provider/#tts-capability-returned","text":"To request the capabilities of the TTS provider being used, your application publishes the GetCapabilities message . The Engine publishes the GetCapabilitiesReply message with the following payload structure: \"text-to-speech-provider\" : { \"voices\" : [ { \"voiceId\": \"Alexa\", \"locales\": [CURRENT_LOCALE] } ] } NOTE : The locale returned is always the current locale because you can load only one locale model at a time, which is the current locale.","title":"TTS Capability Returned"},{"location":"modules/text-to-speech-provider/#ssml-examples","text":"<speak> ETA <break time=\\\"3s\\\"/> three hours </speak> <speak> Turn right <emphasis level=\\\"strong\\\">in twenty feet</emphasis> </speak> <speak> Turn right on<lang xml:lang=\\\"fr-CA\\\">Moulin Rouge street.</lang> </speak> <speak> <p>Turn left in 500ft.</p> <p>Then turn right.</p> </speak> <speak>Turn left on, <phoneme alphabet=\\\"ipa\\\" ph=\\\"Bo.fort\\\">Beaufort</phoneme></speak> <speak> Turn right onto <phoneme alphabet='nt-sampa' ph='*\\\"stAk|t@n \\\"strit'>Stockton Street</phoneme> </speak> <speak> Your ETA is 5 minutes on <say-as interpret-as=\\\"date\\\" format=\\\"dmy\\\">12-10-2020</say-as>. </speak> <speak> Take a <prosody volume=\\\"-6dB\\\">U turn.</prosody> </speak> <speak> Take the next left onto <sub alias=\\\"John Doe\\\">JD</sub> street </speak>","title":"SSML Examples"},{"location":"modules/text-to-speech-provider/#errors","text":"The TTS provider defines its set of error strings or codes. The PrepareSpeechFailed message payload uses the reason parameter to send the error strings to the application. The following list describes the error strings used by the Local TTS provider: LOCALE_NOT_SUPPORTED occurs in any of the following situations: The language model for the current locale is missing. The locale specified in requestPayload is not the current locale. The locale specified is invalid. VOICE_NOT_SUPPORTED occurs when the application specifies in requestPayload an invalid voice or is not Alexa. INTERNAL_ERROR is an internal error that signifies an error when the TTS or TTS Provider module processes a request. PROVIDER_NOT_CONNECTED occurs when the provider is not connected to LVC and a speech synthesis request is made. NOTE : If a speech synthesis request is made during an ongoing Alexa dialog, the speech is synthesized after the current Alexa dialog ends.","title":"Errors"},{"location":"samples/cpp/","text":"Alexa Auto SDK C++ Sample App Table of Contents Overview Prerequisites Build and Run the Sample App Configure the Sample App Use the Sample App Troubleshooting Overview The purpose of the C++ Sample App is to provide useful example code to help you integrate your implementation with the Alexa Auto SDK. The C++ Sample App provides an example of creating and configuring an instance of the Engine, and using the MessageBroker API to subscribe to messages from the Engine. It also provides examples of handling audio and stream based interfaces with the MessageStream API, and replying to messages from the Engine. The C++ Sample App also includes detailed logs for interactions with the Alexa Auto SDK, as well as UI elements relevant to the implementation. Prerequisites Amazon developer account To use the C++ Sample App, you need an Amazon Developer account. Register product and security profile After creating an Amazon developer account, you'll need to register a product and create a security profile on the AVS developer portal. When you follow the instructions to fill in the product information : Use your own custom information, taking note of the Product ID , as this information is required to confingure the Sample App. Be sure to select Automotive from the Product category pull-down. When you follow the instructions to set up your security profile , generate a Client ID and take note of it, as this information is required to confingure the Sample App. Optional device capabilities In order to use certain optional Alexa Auto SDK functionality (for example, AmazonLite Wake Word, Alexa Communications, Local Voice Control (LVC), and Device Client Metrics (DCM)) with the Sample App, your product must be placed on the allow list by Amazon. Copy the product's Amazon ID from the Developer Console and follow the directions on the Need Help? page. Note: Most of the commands that follow are meant to be run from this alexa-auto-sdk directory. Build and Run the Sample App Before you build and run the Sample App, it is recommended that you first review and understand how to build Auto SDK . The Sample App can be built by using the Auto SDK Builder Tool, or by using Conan to build the Auto SDK and Sample App packages directly. Each option is described in more detail in this section. Build using Builder Tool The C++ Sample App can be built using the Auto SDK Builder Tool by specifying the --with-sampleapp or --sampleapp option when doing a build. The following examples should be run with alexa-auto-sdk as the working directory. To build Auto SDK and Sample App with all modules included: $ ./builder/build.py --with-sampleapp The build archive is created in the builder/deploy directory, and will include the Sample App binary, along with all of the required libs and configuration files needed to run the application. The name of the archive will depend on your build settings, but in general will match the following pattern: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz You can extract the contents of the build archive to any location on your target device, with the following command: $ tar -xvzf <archive>.tgz After extracting the contents, the directory structure should look something like the following: aac-dev-linux_x86_64-release/ \u251c\u2500 bin/ | \u2514\u2500 SampleApp \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ | \u251c\u2500 sampleapp/ | | \u251c\u2500 certs/ | | \u251c\u2500 config/ | | | \u2514\u2500 config.json | | \u251c\u2500 inputs/ | | \u251c\u2500 menu/ | | | \u2514\u2500 menu.json | | \u2514\u2500 sampledata/ | \u2514\u2500 ... \u2514\u2500 aac-buildinfo.txt Run the Sample App Before running the Sample App, you are required to configure the settings defined in the share/sampleapp/config/config.json file, including setting up your unique client ID and product information. This is described in more detail in the Configure the Sample App section of this document. Once the configuration changes have been made, you can run the Sample App from the root directory of the extracted archive using the following command: $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c share/sampleapp/config/config.json -m share/sampleapp/menu/menu.json Build using Conan The Auto SDK C++ Sample App can be configured using the provided Conan recipe, and then built with CMake. The Conan recipe requires packages that are defined as part of Auto SDK, which must first be installed into the local cache (see Building Auto SDK for instructions about how to install Auto SDK Conan packages). If you are specifying any additional dependencies, such as extra modules for Auto SDK, those packages must also be installed in the Conan cache before configuring the Sample App. If the required dependencies are already installed, the following commands can be used to quickly configure, build and run the Sample App. # export auto sdk conan dependencies $ python conan/setup.py # configure the sample app and install it in a build directory $ conan install samples/cpp -if = build-sampleapp -b missing # build the sample app in the build directory $ conan build samples/cpp -bf = build-sampleapp # run the sample app from the build directory $ cd build-sampleapp $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c ./config/config.json -m ./menu/menu.json Note: These examples assume your working directory is set to the root alexa-auto-sdk directory. Specify build options You can use the following command line options with the Conan install command. The options are defined in the Conan recipe: aac_modules - Specify default Auto SDK modules to build with the Sample App. This is a comma seperated list of modules that must be installed in the Conan local cache before building. If this option is not overriden, the default value will be core, alexa, cbl, system-audio . extra_modules - Specify additional modules to build with the Sample App. This is a comma seperated list of modules that must be installed in the Conan local cache before building. This is a useful option if you want to specify modules to build in addition to the default modules, rather than replacing the default modules entirely. You can specify the options above using -o when running the Conan command. For example, to specify addtional modules that are included when building the Sample App, you can us the following option: $ conan install samples/cpp -if = build-sampleapp -b missing \\ -o extra_modules = \"navigation,phone-control\" Specify environment variables for configuration values For convenience, a config file template has been included for the core Auto SDK modules with well-known tokens (e.g. CLIENT_ID , PRODUCT_ID ) for various configuration values. You can set environment variables for these tokens; when building the Sample App, they will be replaced in the configuration file. For example you can set an environment variable when running conan install like this: $ CLIENT_ID = xxxx \\ PRODUCT_ID = xxxx \\ conan install ... Configure the Sample App You can pass one or more configuration files to the Sample App using the --config <config-file-path> flag. When you build additional modules with the sample app, you may need to pass module-specific configuration. Please refer to the README file within each module to get this configuration information. For convenience, a config file template has been included for the core Auto SDK modules. You must customize this template with values specific to your implementation. You can either edit the configuration file manually or specify environment variables that can be used to override the configuration values when building the Sample App with Conan, see how to specify environment variables for configuration values . To change the config file manually, follow these steps: Edit the config file template and save it. Replace the ${YOUR_CLIENT_ID} , ${YOUR_PRODUCT_ID} , and ${YOUR_DEVICE_SERIAL_NUMBER} placeholders with your values as follows: Replace ${YOUR_CLIENT_ID} with the Client ID, which you can find in your device's Security Profile under the Other devices and platforms tab. Replace ${YOUR_PRODUCT_ID} with the Product ID, which you can find under the Products tab on the AVS Developer Console. (It is different from the Amazon ID.) Replace ${YOUR_DEVICE_SERIAL_NUMBER} with an arbitrary value that must not contain spaces and must be unique. Note: The Client ID and Product ID must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . Replace the ${DATA_PATH} and ${CERTS_PATH} with paths to your database and certificates, respectively. You must ensure that the directories exist and have write permissions. Note: The Auto SDK engine will fail to start if the database directory path does not exist or does not have write permissions. Modify the vehicle information ( aace.vehicle ) to match your vehicle specifics. Use the Sample App Authenticate with AVS using Code-Based Linking (CBL) Every request to AVS requires an Login with Amazon (LWA) access token. Code-Based Linking (CBL) is the recommended method to acquire access tokens and is demonstrated by the C++ Sample App. After the Sample App launches, you will see the Main Menu. Follow these steps to authorize your device with AVS using CBL. Start the CBL authorization Press A , the Sample App displays the below message: ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Start CBL Authorization [ esc ] Go back Press 1 to start the CBL authorization. The Sample App displays messages, including a code and a URL in a format similar to the following: ########################### 123456 ############################################ url: http://www.amazon.com/us/code ############################################ Note: You may have to scroll up to see the code and URL. Open a browser and navigate to the URL displayed in the Sample App. In the browser, enter the code displayed in the Sample App. Click Continue and follow the instructions in the browser to complete the authentication. Cancel the authorization After you start the authorization, the Authorization menu displays option [1] for you to cancel the authorization that is in progress. Press 1 to cancel the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Cancel CBL Authorization [ esc ] Go back Log out of the CBL authorization After the device is registered successfully, the Sample App displays option [1] in the Authorization menu for you to log out of CBL authorization. Press 1 to log out from the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Logout CBL Authorization [ esc ] Go back Multimedia support for QNX The C++ Sample App supports the BlackBerry QNX Multimedia Suite for live audio input and output on QNX platforms. Note: The SHOUTcast/lcecast streaming format is not supported. See the System Audio extension README for details about configuring audio input and output on QNX platforms. AudioFile menu The C++ Sample App provides an AudioFile menu to send pre-recorded utterances. Responses are saved as MP3 audio files within the current directory where the app was run. Refer to the C++ Sample App Menu System documentation for information on how to extend the AudioFile menu with custom audio files. However, this menu is only available if there is no default audio provider specified during the build. By default the Auto SDK Builder will build the C++ Sample App with the System Audio configuration defined in the config-system-audio.json file. Note: The AudioFile menu appears on platforms that do not provide built-in audio support (such as platforms that are under development). On platforms that provide built-in audio support, the AudioFile menu does not appear. Handle unknown locations for navigation use-cases Your platform implementation should handle cases where a GPS location cannot be obtained by returning the UNDEFINED value provided by the Auto SDK. In these cases, the Auto SDK does not report the location in the context, and your platform implementation should return a localization object initialized with UNDEFINED values for latitude and longitude ((latitude,longitude) = ( UNDEFINED , UNDEFINED )) in the context object of every SpeechRecognizer event. Enable SiriusXM as a local media source The Sample App does not configure SiriusXM as a local media source by default. If you need the SiriusXM local media source, you must enable and build it. To do this, add the following line to the list of local media sources in the Application.cpp class then rebuild the Sample App: { aace::alexa::LocalMediaSource::Source::SIRIUS_XM, nullptr } Note: When SiriusXM is present as a local media source, the cloud defaults to local SiriusXM only and blocks any use of the cloud SiriusXM service even if the local implementation/service is unavailable or not enabled. Troubleshooting When interacting with Alexa, if the Dialog State goes from LISTENING immediately to IDLE , you might not be logged in. Try logging into your account via CBL by tapping A from the Main Menu. Note: For security reasons, authentication is not persisted if you quit the Sample App. Upon relaunch, you must re-authenticate via CBL. Restarting the app using the menu system, however, preserves authentication. If the device serial number is not unique, the authentication state bounces between PENDING and CONNECTED states: Auth state changed: REFRESHED ( NO_ERROR ) Connection status changed: PENDING ( ACL_CLIENT_REQUEST ) Connection status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) ... To resolve this, edit the samples/cpp/assets/config.json file and choose a unique serial number.","title":"C++ Sample App"},{"location":"samples/cpp/#alexa-auto-sdk-c-sample-app","text":"","title":"Alexa Auto SDK C++ Sample App"},{"location":"samples/cpp/#table-of-contents","text":"Overview Prerequisites Build and Run the Sample App Configure the Sample App Use the Sample App Troubleshooting","title":"Table of Contents"},{"location":"samples/cpp/#overview","text":"The purpose of the C++ Sample App is to provide useful example code to help you integrate your implementation with the Alexa Auto SDK. The C++ Sample App provides an example of creating and configuring an instance of the Engine, and using the MessageBroker API to subscribe to messages from the Engine. It also provides examples of handling audio and stream based interfaces with the MessageStream API, and replying to messages from the Engine. The C++ Sample App also includes detailed logs for interactions with the Alexa Auto SDK, as well as UI elements relevant to the implementation.","title":"Overview"},{"location":"samples/cpp/#prerequisites","text":"","title":"Prerequisites"},{"location":"samples/cpp/#amazon-developer-account","text":"To use the C++ Sample App, you need an Amazon Developer account.","title":"Amazon developer account"},{"location":"samples/cpp/#register-product-and-security-profile","text":"After creating an Amazon developer account, you'll need to register a product and create a security profile on the AVS developer portal. When you follow the instructions to fill in the product information : Use your own custom information, taking note of the Product ID , as this information is required to confingure the Sample App. Be sure to select Automotive from the Product category pull-down. When you follow the instructions to set up your security profile , generate a Client ID and take note of it, as this information is required to confingure the Sample App.","title":"Register product and security profile"},{"location":"samples/cpp/#optional-device-capabilities","text":"In order to use certain optional Alexa Auto SDK functionality (for example, AmazonLite Wake Word, Alexa Communications, Local Voice Control (LVC), and Device Client Metrics (DCM)) with the Sample App, your product must be placed on the allow list by Amazon. Copy the product's Amazon ID from the Developer Console and follow the directions on the Need Help? page. Note: Most of the commands that follow are meant to be run from this alexa-auto-sdk directory.","title":"Optional device capabilities"},{"location":"samples/cpp/#build-and-run-the-sample-app","text":"Before you build and run the Sample App, it is recommended that you first review and understand how to build Auto SDK . The Sample App can be built by using the Auto SDK Builder Tool, or by using Conan to build the Auto SDK and Sample App packages directly. Each option is described in more detail in this section.","title":"Build and Run the Sample App"},{"location":"samples/cpp/#build-using-builder-tool","text":"The C++ Sample App can be built using the Auto SDK Builder Tool by specifying the --with-sampleapp or --sampleapp option when doing a build. The following examples should be run with alexa-auto-sdk as the working directory. To build Auto SDK and Sample App with all modules included: $ ./builder/build.py --with-sampleapp The build archive is created in the builder/deploy directory, and will include the Sample App binary, along with all of the required libs and configuration files needed to run the application. The name of the archive will depend on your build settings, but in general will match the following pattern: aac-<version>-<os>_<arch>-<build-type>-<datetime>.tgz You can extract the contents of the build archive to any location on your target device, with the following command: $ tar -xvzf <archive>.tgz After extracting the contents, the directory structure should look something like the following: aac-dev-linux_x86_64-release/ \u251c\u2500 bin/ | \u2514\u2500 SampleApp \u251c\u2500 docs/ \u251c\u2500 include/ \u251c\u2500 lib/ | \u251c\u2500 libAACECore.so | \u2514\u2500 ... \u251c\u2500 share/ | \u251c\u2500 sampleapp/ | | \u251c\u2500 certs/ | | \u251c\u2500 config/ | | | \u2514\u2500 config.json | | \u251c\u2500 inputs/ | | \u251c\u2500 menu/ | | | \u2514\u2500 menu.json | | \u2514\u2500 sampledata/ | \u2514\u2500 ... \u2514\u2500 aac-buildinfo.txt","title":"Build using Builder Tool"},{"location":"samples/cpp/#run-the-sample-app","text":"Before running the Sample App, you are required to configure the settings defined in the share/sampleapp/config/config.json file, including setting up your unique client ID and product information. This is described in more detail in the Configure the Sample App section of this document. Once the configuration changes have been made, you can run the Sample App from the root directory of the extracted archive using the following command: $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c share/sampleapp/config/config.json -m share/sampleapp/menu/menu.json","title":"Run the Sample App"},{"location":"samples/cpp/#build-using-conan","text":"The Auto SDK C++ Sample App can be configured using the provided Conan recipe, and then built with CMake. The Conan recipe requires packages that are defined as part of Auto SDK, which must first be installed into the local cache (see Building Auto SDK for instructions about how to install Auto SDK Conan packages). If you are specifying any additional dependencies, such as extra modules for Auto SDK, those packages must also be installed in the Conan cache before configuring the Sample App. If the required dependencies are already installed, the following commands can be used to quickly configure, build and run the Sample App. # export auto sdk conan dependencies $ python conan/setup.py # configure the sample app and install it in a build directory $ conan install samples/cpp -if = build-sampleapp -b missing # build the sample app in the build directory $ conan build samples/cpp -bf = build-sampleapp # run the sample app from the build directory $ cd build-sampleapp $ DYLD_LIBRARY_PATH = lib:+: ${ DYLD_LIBRARY_PATH } \\ LD_LIBRARY_PATH = lib:+: ${ LD_LIBRARY_PATH } \\ ./bin/SampleApp -c ./config/config.json -m ./menu/menu.json Note: These examples assume your working directory is set to the root alexa-auto-sdk directory.","title":"Build using Conan"},{"location":"samples/cpp/#specify-build-options","text":"You can use the following command line options with the Conan install command. The options are defined in the Conan recipe: aac_modules - Specify default Auto SDK modules to build with the Sample App. This is a comma seperated list of modules that must be installed in the Conan local cache before building. If this option is not overriden, the default value will be core, alexa, cbl, system-audio . extra_modules - Specify additional modules to build with the Sample App. This is a comma seperated list of modules that must be installed in the Conan local cache before building. This is a useful option if you want to specify modules to build in addition to the default modules, rather than replacing the default modules entirely. You can specify the options above using -o when running the Conan command. For example, to specify addtional modules that are included when building the Sample App, you can us the following option: $ conan install samples/cpp -if = build-sampleapp -b missing \\ -o extra_modules = \"navigation,phone-control\"","title":"Specify build options"},{"location":"samples/cpp/#specify-environment-variables-for-configuration-values","text":"For convenience, a config file template has been included for the core Auto SDK modules with well-known tokens (e.g. CLIENT_ID , PRODUCT_ID ) for various configuration values. You can set environment variables for these tokens; when building the Sample App, they will be replaced in the configuration file. For example you can set an environment variable when running conan install like this: $ CLIENT_ID = xxxx \\ PRODUCT_ID = xxxx \\ conan install ...","title":"Specify environment variables for configuration values"},{"location":"samples/cpp/#configure-the-sample-app","text":"You can pass one or more configuration files to the Sample App using the --config <config-file-path> flag. When you build additional modules with the sample app, you may need to pass module-specific configuration. Please refer to the README file within each module to get this configuration information. For convenience, a config file template has been included for the core Auto SDK modules. You must customize this template with values specific to your implementation. You can either edit the configuration file manually or specify environment variables that can be used to override the configuration values when building the Sample App with Conan, see how to specify environment variables for configuration values . To change the config file manually, follow these steps: Edit the config file template and save it. Replace the ${YOUR_CLIENT_ID} , ${YOUR_PRODUCT_ID} , and ${YOUR_DEVICE_SERIAL_NUMBER} placeholders with your values as follows: Replace ${YOUR_CLIENT_ID} with the Client ID, which you can find in your device's Security Profile under the Other devices and platforms tab. Replace ${YOUR_PRODUCT_ID} with the Product ID, which you can find under the Products tab on the AVS Developer Console. (It is different from the Amazon ID.) Replace ${YOUR_DEVICE_SERIAL_NUMBER} with an arbitrary value that must not contain spaces and must be unique. Note: The Client ID and Product ID must correspond to a development device profile that you created as an automotive product by selecting the Automotive product category when you filled in the product information . Replace the ${DATA_PATH} and ${CERTS_PATH} with paths to your database and certificates, respectively. You must ensure that the directories exist and have write permissions. Note: The Auto SDK engine will fail to start if the database directory path does not exist or does not have write permissions. Modify the vehicle information ( aace.vehicle ) to match your vehicle specifics.","title":"Configure the Sample App"},{"location":"samples/cpp/#use-the-sample-app","text":"","title":"Use the Sample App"},{"location":"samples/cpp/#authenticate-with-avs-using-code-based-linking-cbl","text":"Every request to AVS requires an Login with Amazon (LWA) access token. Code-Based Linking (CBL) is the recommended method to acquire access tokens and is demonstrated by the C++ Sample App. After the Sample App launches, you will see the Main Menu. Follow these steps to authorize your device with AVS using CBL.","title":"Authenticate with AVS using Code-Based Linking (CBL)"},{"location":"samples/cpp/#start-the-cbl-authorization","text":"Press A , the Sample App displays the below message: ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Start CBL Authorization [ esc ] Go back Press 1 to start the CBL authorization. The Sample App displays messages, including a code and a URL in a format similar to the following: ########################### 123456 ############################################ url: http://www.amazon.com/us/code ############################################ Note: You may have to scroll up to see the code and URL. Open a browser and navigate to the URL displayed in the Sample App. In the browser, enter the code displayed in the Sample App. Click Continue and follow the instructions in the browser to complete the authentication.","title":"Start the CBL authorization"},{"location":"samples/cpp/#cancel-the-authorization","text":"After you start the authorization, the Authorization menu displays option [1] for you to cancel the authorization that is in progress. Press 1 to cancel the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Cancel CBL Authorization [ esc ] Go back","title":"Cancel the authorization"},{"location":"samples/cpp/#log-out-of-the-cbl-authorization","text":"After the device is registered successfully, the Sample App displays option [1] in the Authorization menu for you to log out of CBL authorization. Press 1 to log out from the authorization. ################################################################################ # # # Authorization Menu # # # ################################################################################ [ 1 ] Logout CBL Authorization [ esc ] Go back","title":"Log out of the CBL authorization"},{"location":"samples/cpp/#multimedia-support-for-qnx","text":"The C++ Sample App supports the BlackBerry QNX Multimedia Suite for live audio input and output on QNX platforms. Note: The SHOUTcast/lcecast streaming format is not supported. See the System Audio extension README for details about configuring audio input and output on QNX platforms.","title":"Multimedia support for QNX"},{"location":"samples/cpp/#audiofile-menu","text":"The C++ Sample App provides an AudioFile menu to send pre-recorded utterances. Responses are saved as MP3 audio files within the current directory where the app was run. Refer to the C++ Sample App Menu System documentation for information on how to extend the AudioFile menu with custom audio files. However, this menu is only available if there is no default audio provider specified during the build. By default the Auto SDK Builder will build the C++ Sample App with the System Audio configuration defined in the config-system-audio.json file. Note: The AudioFile menu appears on platforms that do not provide built-in audio support (such as platforms that are under development). On platforms that provide built-in audio support, the AudioFile menu does not appear.","title":"AudioFile menu"},{"location":"samples/cpp/#handle-unknown-locations-for-navigation-use-cases","text":"Your platform implementation should handle cases where a GPS location cannot be obtained by returning the UNDEFINED value provided by the Auto SDK. In these cases, the Auto SDK does not report the location in the context, and your platform implementation should return a localization object initialized with UNDEFINED values for latitude and longitude ((latitude,longitude) = ( UNDEFINED , UNDEFINED )) in the context object of every SpeechRecognizer event.","title":"Handle unknown locations for navigation use-cases"},{"location":"samples/cpp/#enable-siriusxm-as-a-local-media-source","text":"The Sample App does not configure SiriusXM as a local media source by default. If you need the SiriusXM local media source, you must enable and build it. To do this, add the following line to the list of local media sources in the Application.cpp class then rebuild the Sample App: { aace::alexa::LocalMediaSource::Source::SIRIUS_XM, nullptr } Note: When SiriusXM is present as a local media source, the cloud defaults to local SiriusXM only and blocks any use of the cloud SiriusXM service even if the local implementation/service is unavailable or not enabled.","title":"Enable SiriusXM as a local media source"},{"location":"samples/cpp/#troubleshooting","text":"When interacting with Alexa, if the Dialog State goes from LISTENING immediately to IDLE , you might not be logged in. Try logging into your account via CBL by tapping A from the Main Menu. Note: For security reasons, authentication is not persisted if you quit the Sample App. Upon relaunch, you must re-authenticate via CBL. Restarting the app using the menu system, however, preserves authentication. If the device serial number is not unique, the authentication state bounces between PENDING and CONNECTED states: Auth state changed: REFRESHED ( NO_ERROR ) Connection status changed: PENDING ( ACL_CLIENT_REQUEST ) Connection status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) status changed: CONNECTED ( ACL_CLIENT_REQUEST ) Connection status changed: PENDING ( SERVER_SIDE_DISCONNECT ) ... To resolve this, edit the samples/cpp/assets/config.json file and choose a unique serial number.","title":"Troubleshooting"}]}